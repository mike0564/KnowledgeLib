{"./":{"url":"./","title":"前言","keywords":"","body":"前言 对平时遇到的一些问题、知识进行记录总结 同时也方便日后的查询与分享 内容主要来源于互联网，并对解决问题的方案进行验证 如侵联删（Email：roboytim@gmail.com） "},"工具/":{"url":"工具/","title":"工具","keywords":"","body":"工具 "},"工具/Jmeter/":{"url":"工具/Jmeter/","title":"Jmeter","keywords":"","body":"Jmeter Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。 Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。 "},"工具/Jmeter/Jmeter入门.html":{"url":"工具/Jmeter/Jmeter入门.html","title":"Jmeter入门","keywords":"","body":"Jmeter入门 Jmeter简介 Jmeter的基本概念 百度百科： ​ Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。 我们为什么使用Jmeter 开源免费，基于Java编写，可集成到其他系统可拓展各个功能插件 支持接口测试，压力测试等多种功能，支持录制回放，入门简单 相较于自己编写框架或其他开源工具，有较为完善的UI界面，便于接口调试 多平台支持，可在Linux，Windows，Mac上运行 Jmeter安装配置 Windows下Jmeter下载安装 登录 http://jmeter.apache.org/download_jmeter.cgi ，根据自己平台，下载对应文件 历史版本下载地址：https://archive.apache.org/dist/jmeter/binaries/ 安装JDK，配置环境变量（具体步骤不做介绍） JAVA_HOME = JDK安装绝对路径 CLASSPATH = .;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar; PATH = %JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; 将下载Jmeter文件解压，打开/bin/jmeter.bat 其他平台安装Jmeter 与Windows平台一致，除入口文件不同，例如linux平台下为/bin/jmeter.sh Jmeter的目录结构 /bin 目录（常用文件介绍） examples：目录下包含Jmeter使用实例 ApacheJMeter.jar：JMeter源码包 jmeter.bat：windows下启动文件 jmeter.sh：Linux下启动文件 jmeter.log：Jmeter运行日志文件 jmeter.properties：Jmeter配置文件 jmeter-server.bat：windows下启动负载生成器服务文件 jmeter-server：Linux下启动负载生成器文件 /docs目录——Jmeter帮助文档 /extras目录——提供了对Ant的支持文件，可也用于持续集成 /lib目录——存放Jmeter依赖的jar包，同时安装插件也放于此目录 /licenses目录——软件许可文件，不用管 /printable_docs目录——Jmeter用户手册 Jmeter相关插件安装 插件安装 Jmeter的插件安装很简单，只需要下载对应插件解压即可。 下载地址：http://jmeter-plugins.org/downloads/all/ 下载后解压放入：apache-jmeter-2.12\\lib\\ext\\目录下 重启jmeter 使用注意事项：添加第三方插件并使用后保存的jmx文件在未添加该插件的运行环境下会导致无法打开该文件并报错，请保持环境一致性。 注：新版的Jmeter插件统一由插件管理器进行管理（jmeter-plugins-manager） 下载地址：https://jmeter-plugins.org/install/Install/ 下载好之后，将该jar包放入到jmeter的安装路径下的 lib/ext 目录下，重启jmeter即可 Jmeter界面--Options--Plugins Manager 常用插件推荐 支持Base64加解密等多个函数的插件 Custom JMeter Functions 用于服务器性能监视的 PerfMon Metrics Collector 用于建立压力变化模型的 Stepping Thread Group 用于Json解析的 JSON Path Extractor 用于展示响应时间曲线的 Response Times Over Time 用于展示TPS曲线的 Transactions per Second 用例生成与导出 Jmeter的用例格式为jmx文件，实际为xml格式，感兴趣可以学习下自己定制生成想要的jmx文件。 生成原则： 每个功能模块为一个独立的jmx文件。增加可维护性（尽量不要将一个jmx文件放入太多功能，后期维护成本会很高。） 模块的私有变量保存在模块中，多模块共有的（例如服务器ip端口等）可以考虑存在单独的文件中读取 接口测试不要放太多线程，毕竟不是做压力测试，意义也不大 导出方法： 编写测试用例 文件——保存为——确定 Jmeter常用文件类型 Jmx文件 文件的实际类型：xml 文件样本： false false Sample test for demonstrating JMeter Ant build script and Schematic stylesheet 1143889321000 3 false 5 false 1143889321000 continue 1 1 1000 C false 1000000 = 100 Sleep_Time = 0xFF Sleep_Mask = Label = 200 ResponseCode = OK ResponseMessage = OK Status = Request SamplerData = Response C=${C} ResultData org.apache.jmeter.protocol.java.test.JavaTest 3 Assertion.response_data 6 false = 100 Sleep_Time = 0xFF Sleep_Mask = Label = 200 ResponseCode = OK ResponseMessage = OK Status = Request SamplerData = Response C=${C} Tn=${__threadNum} ResultData org.apache.jmeter.protocol.java.test.JavaTest Jtl文件 文件的实际类型：自定义 定义方法： 修改{jmeterhome}/bin/jmeter.profile,可选择格式：csv，xml，db # legitimate values: xml, csv, db. Only xml and csv are currently supported. #jmeter.save.saveservice.output_format=csv Jmeter运行模式及参数 GUI模式 打开已有的jmx文件（文件——打开） 点击启动按钮运行 由于GUI模式本身就是带界面的，也有中文版，就不在此详细介绍了。 命令行模式 依赖： 配置jmeter环境变量（windows下为将${jmeterhome}/bin加入Path变量） 如果未加入环境变量，在执行的时候可以直接给出全路径或在${jmeterhome}/bin下执行 命令： jmeter -n -t -l 参数： -h 帮助 -> 打印出有用的信息并退出 -n 非 GUI 模式 -> 在非 GUI 模式下运行 JMeter -t 测试文件 -> 要运行的 JMeter 测试脚本文件 -l jtl文件 -> 记录结果的文件 -r 远程执行 -> 启动远程服务 -H 代理主机 -> 设置 JMeter 使用的代理主机 -P 代理端口 -> 设置 JMeter 使用的代理主机的端口号 -j 日志文件->设置JMeter日志文件的名称 实例： JMeter -n -t my_test.jmx -l log.jtl -H my.proxy.server -P 8000 执行步骤： JMeter 默认去当前目录寻找脚本文件，并把日志记录在当前目录。比如你在 C:\\tools\\apache-jmeter-2.11\\bin 目录下执行以上命令，JMeter 会去该目录下寻找 test.jmx 脚本并把执行结果放在该目录。如果你的脚本在其他目录，而且想要把执行结果放在另外文件夹，可以使用绝对路径告诉 JMeter。 执行过程查看： D:\\apache-jmeter-3.0\\bin>jmeter -n -t D:\\共享\\bpintocpin.jmx -l D:\\共享\\test.jtl Writing log file to: D:\\apache-jmeter-3.0\\bin\\jmeter.log Creating summariser Created the tree successfully using D:\\共享\\bpintocpin.jmx Starting the test @ Fri Jun 17 15:12:21 CST 2016 (1466147541295) Waiting for possible Shutdown/StopTestNow/Heapdump message on port 4445 summary = 1 in 00:00:01 = 0.8/s Avg: 1178 Min: 1178 Max: 1178 Err: 0 (0.00%) Tidying up ... @ Fri Jun 17 15:12:22 CST 2016 (1466147542649) ... end of run 执行结果查看： GUI界面打开聚合报告 在GUI界面创建一个聚合报告 聚合报告界面点击浏览，选中生成的.jtl文件，打开 执行过程中查看 summary = 1 in 00:00:01 = 0.8/s Avg: 1178 Min: 1178 Max: 1178 Err: 0 (0.00%) jtl件转化成tml式查看 在测试过程中将jtl转成测试报告 jmeter -n -t baidu_requests_results.jmx -r -l baidu_requests_results.jtl -e -o /home/tester/apache-jmeter-3.0/resultReport 使用之前的测试结果，生成测试报告 jmeter -g baidu_requests_results.jtl -e -o /home/tester/apache-jmeter-3.0/resultReport Jeter常用控件： 测试计划（Test Plan） 测试计划包含一个测试的所有内容，包含所有的控件，属性，变量。所以一个jmx文件中只有有一个测试计划。测试计划中可以定义变量，引入jar包，编辑测试模式等。 注意事项：可将一些不常变化的数据存入测试计划的变量，方便在测试计划内调用（例如服务器ip，端口，数据库ip等）。 函数测试模式会记录来每个请求到服务器的取样结果，如果在监听器中定义了数据写入文件，会将这些输入写入到该文件中。同时，该模式会严重影响性能。 工作台 空间的暂存区域，在测试过程中可以把暂时不用的空间放入其中，待测试完成后放回原来的位置。 工作台中的控件不会保存在jmx文件中，所以，如果关闭jmeter，工作台中的控件会丢失。 常用控件： Property Display 创建方式：右键点击工作台，添加——非测试元件——Property Display 功能：查看当前测试计划中的属性以及系统中的属性 线程组（Thread Group）：常规意义上的线程组，即虚拟用户组。虚拟用户组，线程组内线程数量在运行过程中不会发生改变。 注意事项：线程间变量相互独立。一个测试计划内可以包含多个线程组。 可定义内容： 取样器错误后执行的操作：继续执行，启动下一个线程，停止线程，停止测试，立刻停止 线程属性：线程数量，线程启动间隔时间（0为立刻启动所有线程），单线程循环次数，线程执行顺序，是否使用调度器。 调度器配置：持续时间，启动延迟，启动时间，结束时间 setUp Thread Group：测试初始化操作，即线程组开始之前执行的内容。 实际使用：用于初始化测试环境，测试数据准备等。 tearDown Thread Group：测试执行后操作，即线程组执行完成后执行的内容。 实际使用：用于清理测试环境，清空测试数据等。 测试片段（Test Fragment）：与线程组同级别，但是默认不会执行。只有当他被模块控制器引用的时候才会被执行。 逻辑控制器（Logic Controller） 用来控制采样器的执行顺序 控制采样器的逻辑执行顺序，如Loop Controller、If Controller等 对采样器进行分组，方便控制的，如Throughput Controller、Transaction Controller 常用控件： 简单控制器（Simple Controller）： 作用：这是Jmeter里最简单的一个控制器，它可以让我们组织我们的采样器和其它的逻辑控制器（分组功能），提供一个块的结构和控制，并不具有任何的逻辑控制或运行时的功能。 循环控制器（Loop Controller）： 作用：指定其子节点运行的次数，可以使用具体的数值（如下图，设置为5次），也可以使用变量 1、Forever选项：勾选上这一项表示一直循环下去 2、如果同时设置了线程组的循环次数和循环控制器的循环次数，那循环控制器的子节点运行的次数为两个数值相乘的结果 仅一次控制器（Once Only Controller）： 作用：在测试计划执行期间，该控制器下的子结点对每个线程只执行一次，登录场景经常会使用到这个控制器 注意：将Once Only Controller作为Loop Controller的子节点，Once Only Controller在每次循环的第一次迭代时均会被执行 ForEach控制器（ForEach Controller）： 作用：ForEach控制器一般和用户自定义变量一起使用，其在用户自定义变量中读取一系列相关的变量。该控制器下的采样器或控制器都会被执行一次或多次，每次读取不同的变量值。 参数: Input Variable Prefix：输入变量前缀 Output variable name：输出变量名称 Start index for loop(exclusive)：循环开始的索引（这里如果不填写，默认从1开始，如果没有1开始的变量，执行时会报错） End index for loop(inclusive)：循环结束的索引 Add\"_\"before number：输入变量名称中是否使用\"_\"进行间隔。 用户自定义变量： 变量名前缀为ForEach Controller中Input variable prefix定义的name+下划线+数字编号 事务控制器（Transaction Controller）： 作用： 事务控制器会生产一个额外的采样器，用来统计该控制器子结点的所有时间 参数： Generate parent sample：(选中这个参数结果展示如下图红框，否则显示为下图蓝框) Include duration of timer and pre-post processors in generated sample：选中这一项会统计定时器(timer)的时间，否则只统计采样器(sample)的时间 If 控制器（If Controller）： 作用：根据给定表达式的值决定是否执行该节点下的子节点，默认使用javascript的语法进行判断(如下图红框内的文字) 参数： Interpret Condition as Variable Expression?：选中这一项时表示：判断变量值是否等于字符串true（不区分大小写） Evaluate for all children：如果选中这一项，在每个子结点执行前都会计算表达式 Switch控制器（Switch Controller）： 作用：Switch控制器通过给该控制器中的Value赋值，来指定运行哪个采样器。有两种赋值方式： 第一种是数值，Switch控制器下的子节点从0开始计数，通过指定子节点所在的数值来确定执行哪个元素。 第二种是直接指定子元素的名称，比如采样器的Name来进行匹配。当指定的名称不存在时，不执行任何元素。 当Value为空时，默认执行第1个子节点元素。 吞吐量控制器(Throughput Controller): 作用：控制其下的子节点的执行次数与负载比例分配，也有两种方式： Total Executions：设置运行次数 Percent Executions：设置运行比例(1~100之间) 随机控制器(Random Controller): 作用：随机执行其下的所某个子结点 随机顺序控制器(Random Order Controller): 作用：随机执行其下的所有子结点 配置元件（Config Element） 为测试提供数据支持的控件 常用控件 CSV Data Set Config：读取txt，csv格式的测试数据 CSV Data Set Config各个参数的简要说明: FileName:csv文件或txt文件路径，可用相对路径 File Encoding: 文件编码格式设置 Varible Names: 定义文本文件中的参数名,可设置多个参数，参数之间逗号分隔.定义后可在脚本中引用，引用方式${name} Delimiter（use \"\\t\" for tab）:指定参数分隔符号 Allow Quoated data: 是否允许引用数据 Recycle on EOF: 是否循环取值 Stop Thread on EOF: 当Recycle on EOF为false并且Stop Thread on EOF为true,则读完csv文件中的记录后,停止运行 Sharing Mode: 设置是否线程共享 HTTP Cookie管理器： 1.浏览器一样的存储和发送Cookie。如果请求一个站点，然后Response中包含Cookie，Cookie Manager就会自动地保存这些Cookie并在所有后来发送到该站点的请求中使用这些Cookie的值。（在View Results Tree的Request界面可以看到被发送的Cookie Data， 同时每个线程的Cookie Manager是相互独立的） 接受到的Cookie的值能被存储到JMeter 线程变量中（2.3.2版本后的JMeter不自动做这个事情）。要把Cookies保存到线程变量中，要定义属性\"CookieManager.save.cookies=true\"。 线程变量名为COOKIE_ + Cookie名。属性CookieManager.name.prefix= 可以用来修改默认的COOKIE_的值。 2.手动添加Cookie到Cookie Manager，需求注意的是这些Cookie的值被会所有线程共享 定义：属性\"CookieManager.save.cookies=true\" 在jmeter.properties文件中增加CookieManager.save.cookies=true，然后在Debug Sampler中就能看到COOKIE_xxx这样的变量，或者也可以使用正则表达式来提取Cookie的值 使用注意事项： 路径必须填写，否则会导致nocookie 路径和域组成完整的访问地址，谁访问谁就用对应的cookie Cookie不是跨域的 不同的逻辑控制器中要分别放cookie管理器，或放在该cookie逻辑控制器同级，否则会不生效 HTTP信息头管理器：定义信息头，在其覆盖下的所有元件都会使用该信息头。例如定义在测试计划中的信息头，即该测试计划所有请求的信息头。 JDBC Connection Configuration：数据库连接控件，不会进行的具体的数据库操作。需要和JDBC Request配合使用，并且需要安装jdbc驱动，否则无法连接数据库 用户定义的变量：用户自定义的变量，可用于存储接口路径等信息，需要注意变量的作用域，不同线程间变量不共享 定时器（Timer） sampler（采样器）之前执行；如果只想应用于部分sampler，需要将定时器加入子节点；简单理解类似于loadrunner中的思考时间，控制sampler的间隔时间 常用控件 Constant Throughput Timer：设置目标吞吐量，限定QPS的控件 配置选项： Target throughput（in samples per minute）：目标吞吐量。注意这里是每分钟发送的请求数，因此，对应测试需求中所要求的20 QPS ，这里的值应该是1200 。 Calculate Throughput based on ：有5个选项，分别是： This thread only ：控制每个线程的吞吐量，选择这种模式时，总的吞吐量为设置的 target Throughput 乘以矣线程的数量。 All active threads ： 设置的target Throughput 将分配在每个活跃线程上，每个活跃线程在上一次运行结束后等待合理的时间后再次运行。活跃线程指同一时刻同时运行的线程。 All active threads in current thread group ：设置的target Throughput将分配在当前线程组的每一个活跃线程上，当测试计划中只有一个线程组时，该选项和All active threads选项的效果完全相同。 All active threads （shared ）：与All active threads 的选项基本相同，唯一的区别是，每个活跃线程都会在所有活跃线程上一次运行结束后等待合理的时间后再次运行。 All cative threads in current thread group （shared ）：与All active threads in current thread group 基本相同，唯一的区别是，每个活跃线程都会在所有活跃线程的上一次运行结束后等待合理的时间后再次运行。 注意事项： Constant Throughput Timer只有在线程组中的线程产生足够多的request 的情况下才有意义，因此，即使设置了Constant Throughput Timer的值，也可能由于线程组中的线程数量不够，或是定时器设置不合理等原因导致总体的QPS不能达到预期目标。 固定定时器：请求间隔时间 注意事项： 需要注意的是，固定定时器的延时不会计入单个sampler的响应时间，但会计入事务控制器的时间。 对于一个sampler来说，定时器相当于loadrunner中的pacing（理解就是一组请求操作的等待时间）；对于\"事务控制器\"来说，定时器相当于loadrunner中的think time（单次操作的等待时间或间隔时间） 高斯随机定时器：与固定定时器差不多，只不过时间范围可以设置一个指定范围随机。 Synchronizing Timer：LR中的集合点，也就是说，sampler到这里会暂停，达到指定线程数后并发 配置参数： Number of Simulated Users to Group by:线程数量设置 Timeout in milliseconds:响应时间设置，单位毫秒 注意事项： 集合点需要设置在Sampler前，否则不会生效 前置处理器（Per Processors） sampler请求前执行的操作，可以是获取测试数据，修改参数等 常用控件 Bean Shell PreProcessor：Bean Shell编程设置 Simpler Timeout：设置simple的最大响应时间，与直接在Sampler中设置的区别就是，作用域不同 Sampler 请求，设置不同的request 常用控件 HTTP请求：通用的http request（POST、GET） Test Action：请求的执行动作，可放在Sampler后定义，即执行某一个请求后暂停等操作 后置处理器（Post Processors）：请求执行后的处理，与前置处理器相反 正则表达式提取器：当一个Sampler的Reponse中包含我们需要的参数的时候，我们可以通过该控件将参数提取出来 参数含义： 引用名称：将提取的参数转化为变量，该字段定义变量名称 正则表达式：匹配的正则，测试可用搜索引擎搜索在线正则验证测试结果 断言（Assertions） 判断请求响应值的正确性的控件 常用控件 响应断言：判断Reponse是否正确 注意事项： 断言要放在请求内 监听器（Listener） 查看请求执行结果的控件 常用控件 图形结果 参数含义： 样本数目：总共发送到服务器的请求数。 最新样本：代表时间的数字,是服务器响应最后一个请求的时间。 吞吐量：服务器每分钟处理的请求数。 平均值：总运行时间除以发送到服务器的请求数。 中间值：代表时间的数字，有一半的服务器响应时间低于该值而另一半高于该值。 偏离：服务器响应时间变化、离散程度测量值的大小，或者，换句话说，就是数据的分布。 注意事项：图形结果本身会影响Jmeter的性能 查看结果树：可用于调试，查看请求响应的数据，测试的结果，请求的内容。 聚合报告： 参数含义： Label：每个 JMeter 的 element（例如 HTTP Request）都有一个 Name 属性，这里显示的就是 Name 属性的值 Samples：表示你这次测试中一共发出了多少个请求，如果模拟10个用户，每个用户迭代10次，那么这里显示100 Average：平均响应时间——默认情况下是单个 Request 的平均响应时间，当使用了 Transaction Controller 时，也可以以Transaction 为单位显示平均响应时间 Median：中位数，也就是 50％ 用户的响应时间 90% Line：90％ 用户的响应时间 Min：最小响应时间 Max：最大响应时间 Error%：本次测试中出现错误的请求的数量/请求的总数 Throughput：吞吐量——默认情况下表示每秒完成的请求数（Request per Second），当使用了 Transaction Controller 时，也可以表示类似 LoadRunner 的 Transaction per Second 数 KB/Sec：每秒从服务器端接收到的数据量，相当于LoadRunner中的Throughput/Sec Jmeter函数 函数助手：选项——函数助手 ${__time(YMD)}：当前日期函数 ${__time(YMDHMS)}：当前四件函数 ${__MD5(${fkeystr_no_register})}：MD5加密函数 函数调用 选择想要使用的函数 输入想要使用函数的值 点击生成 将所得字符串复制到要使用的位置 Jmeter属性与变量 Jmeter中的属性： 1、JMeter属性统一定义在jmeter.properties文件中，我们可以在该文件中添加自定义的属性 2、JMeter属性在测试脚本的任何地方都是可见的（全局），通常被用来定义一些JMeter使用的默认值，可以用于在线程间传递信息。 3、JMeter属性可以在测试计划中通过函数 _P 进行引用，但是不能作为特定线程的变量值。 4、JMeter属性可以通过_setProperty 函数来定义JMeter属性 5、JMeter属性是大小写敏感的 6、WorkBench中的属性查看组件： WorkBench右键--->Add--->Non Test Elements--->Property Display Jmeter中的变量： 1、JMeter变量对于测试线程而言是局部变量。 2、在不同测试线程中，JMeter变量既可以是完全相同的，也可以是不同的。 3、JMeter变量引用方法：${name} 4、JMeter变量是大小写敏感的 5、如果有某个线程更新了变量，那么仅仅是更新了变量在该线程中复制的值 6、Jmeter中定义变量的地方： a) 测试计划(Test plan)，在右边的面板上添加User Defined Variables b) 线程组，右键选择 配置元件( config element)-->User Defined Variables c) 通过前置或后置处理器生成的变量 d)使用csv参数化的变量 注意：通过 a 和 b 两种方式定义的变量，在JMeter启动时对这个测试计划都是可见的。如果同一个变量在多个 b 中被定义，那么只有最后一个定义会生效。一旦某个线程启动后，那么整个变量集合的初始值就会被复制到该线程中。其他测试元件，例如 c 或者 d 可以被用来重新定义变量，这些重定义仅仅影响当前线程 Jmeter录制回放 BadBoy录制回放 1.打开badboy，点击录制按钮 2.输入网址，在网页中操作 3.导出脚本（File——Export to Jmeter） 4.用Jmeter打开对应脚本 Jmeter使用 Jmeter创建接口测试计划实例 1.模块名称（测试计划）：每个模块独立划分为一个jmx文件（例如登陆模块），最好与接口类一一对应。对应的服务器信息，数据库信息等可存在这里。 2.数据准备：用于测试数据的准备（例如账号信息）。 3.结果查看：用于放置需要查看结果的控件（例如结果树）。 4.线程组：所有的接口测试用例放在线程组下，集中定义线程等信息 5.获取线程对应测试数据：用于获取针对独立线程的测试数据，例如在数据准备里面获得了账号信息，在这里根据账号信息去数据库获取对应的名称，ID等信息。 6.请求名称：用简单控制器为文件夹，内有不同的请求。简单控制器为一个独立的接口，不同请求对应不同的代码路径（例如成功请求，失败请求等）。建议请求名称最好用英文形式，否则后期持续集成或许会出现问题（no zuo no die！）。 7.在每条请求内放置正则匹配（用于应对需要返回值作为下次请求的参数的情况）以及断言。 Jmeter使用注意事项 ○ 变量问题 使用过程中，一定要注意控件的执行顺序以及变量的作用域。 ○ 路径问题 Windows下支持\"/\"\"\\\"并存模式，推荐使用\"/\"，方便跨平台使用。 在linux格式下支持\"/\"格式。 ○ Jmeter自身性能问题 命令行模式：命令相同。 UI模式：操作方式相同，但会存在windows下能打开linux下打不开的情况，暂不知道原因。 "},"工具/Jmeter/Jmeter查看结果数中的响应数据中文乱码.html":{"url":"工具/Jmeter/Jmeter查看结果数中的响应数据中文乱码.html","title":"Jmeter查看结果数中的响应数据中文乱码","keywords":"","body":"Jmeter查看结果数中的响应数据中文乱码 当响应数据或响应页面没有设置编码时，jmeter会按照jmeter.properties文件中，sampleresult.default.encoding设置的格式解析 默认ISO-8859-1，解析中文肯定出错 #The encoding to be used if none is provided (default ISO-8859-1) #sampleresult.default.encoding=ISO-8859-1 例如查看结果树中的中文为乱码，可以通过以下方式进行修改解决： 1.直接修改sampleresult.default.encoding=UTF-8。（记住去掉#，不要还是注释状态哦） 2.动态修改（这种方法方便些） step1：指定请求节点下，新建后置控制器\"BeanShell PostProcessor\" step2：其脚本框中输入：prev.setDataEncoding(\"UTF-8\"); step3：保存 "},"工具/Jmeter/Jmeter接口测试与压力测试.html":{"url":"工具/Jmeter/Jmeter接口测试与压力测试.html","title":"Jmeter接口测试与压力测试","keywords":"","body":"Jmeter接口测试与压力测试 jmeter是apache公司基于java开发的一款开源压力测试工具，体积小，功能全，使用方便，是一个比较轻量级的测试工具，使用起来非常简单。因为jmeter是java开发的，所以运行的时候必须先要安装jdk才可以。jmeter是免安装的，拿到安装包之后直接解压就可以使用，同时它在linux/windows/macos上都可以使用。 jmeter可以做接口测试和压力测试。其中接口测试的简单操作包括做http脚本（发get/post请求、加cookie、加header、加权限认证、上传文件）、做webservice脚本、参数化、断言、关联（正则表达式提取器和处理json-json path extractor）和jmeter操作数据库等等。 接口测试 Jmeter-http接口脚本 一般分五个步骤: （1）添加线程组 （2）添加http请求 （3）在http请求中写入接入url、路径、请求方式和参数 （4）添加查看结果树 （5）调用接口、查看返回值 jmeter 发get请求 jmeter 发post请求 jmeter 添加cookie 需要在线程组里添加配置元件—HTTP Cookie 管理器 jmeter 添加header 需要在线程组里面添加配置元件—HTTP信息头管理器 jmeter 上传文件 jmeter 参数化 入参经常变化的话，则可以设置成一个变量，方便统一修改管理；如果入参要求随机或可多种选择，则通过函数生成器或者读取文件形成一个变量。所以参数化有三种方式：用户定义的变量、函数生成器、读取文件。 （1）用户定义的变量 需要添加配置元件-用户定义的变量。 （2）函数生成器 需要用到函数助手功能，可以调用函数生成一些有规则的数据。常用的几个函数有_uuid、_random、_time。_uuid会生成一个随机唯一的id，比如在避免java请求重发造成未处理数据太多的情况，接口请求可加一个唯一的请求id唯一的响应id进行一一对应；随机数_random，可以在你指定的一个范围里取随机值；取当前时间_time，一些时间类的入参可以使用,如{time(,)} 是生成精确到毫秒的时间戳、{time(/1000,)}是生成精确到秒的时间戳、${__time(yyyy-MM-dd HH:mm:ss,)} 是生成精确到秒的当前时间。 （3）从文件读取 需要在线程组里面添加配置元件-CSV Data Set Config 其中Recycle on EOF:设置True后，允许循环取值 具体的例子如下所示： jmeter 断言 jmeter断言用来检测响应返回的结果和我们预期的是否一致。若针对整个线程组的话，则在线程组下添加断言-响应断言；若只是针对某个请求的话，则在请求下添加断言-响应断言。 jmeter关联 接口请求之间存在参数调用，为了保存这个参数，建立jmeter关联。比如登陆接口和购买商品接口，购买商品接口就需要登陆接口返回的token等登陆信息，jmeter关联就可以保存这个token信息，方便购买商品接口使用。 jmeter关联可以通过二种方式来完成，获取到返回结果中指定的值。它们分别是正则表达式提取器、 json path extractor。 （1）正则表达式提取器 若想获取的返回值未匹配到，可以把正则表达式两边匹配的数据扩大点。 关于正则表达式 ()：括起来的部分就是要提取的。 .：匹配除换行外的任何字符串。 +：代表+号前面的字符必须至少出现一次（一次或多次）。 ?：代表？前面的字符最多可以出现一次，在找到第一个匹配项后停止（0次或1次）。 ：代表号前面的字符可以不出现，也可以出现一次或者多次（0次、1次或者多次） (.*)：贪婪模式，匹配尽可能多的字符 （.*?）或（.+?）：匹配尽可能少的字符，一旦匹配到第一个就不往下走了。 关于模板 若想提取多个值的话，比如是a和b这两个值，则可以写成：$1$$2$。无论要提取多少个值，引用名称就是一个的，比如名称为id，${id_go}:获取整个字符串ab，${id_g1}：获取的是a，${id_g2}：获取的是b。 下面有一个具体的实例，如下图所示： （2）json path extractor jmeter通过安装json path extractor插件来处理json串，提取json串中的字段值。插件的下载地址：https://jmeter-plugins.org/?search=jpgc-json 下载完成，解压后，直接把lib文件夹放到jmeter相应目录下面。特别说明：jmeter 2.xx左右的版本尝试过无法使用该插件，在jmeter 3.xx左右的版本装完插件后能正常使用。 需要在请求下创建后置处理器-jp@gc-JSON Path Extractor。 具体的实例如下所示： jmeter 操作数据库 操作数据库基本有四个步骤： （1）导入mysql的jdbc的jar包 （2）创建数据库的连接配置，线程组里添加配置元件-JDBC Connection Configuration （3）线程组里添加jdbc request，写sql语句 （4）添加察看结果树，点击启动按钮，就能看到执行的SQL。 具体的实例如下截图所示： 特别说明：jmeter还可以操作oracle、postgreSQL、msSQL、mongodb等等数据库，同时不同的数据库，JDBC Connection Configuration填写的Database url格式和JDBC Driver驱动名称也不相同。jmeter数据库驱动列表如下表所示： 数据库 驱动 数据库url mysql com.mysql.jdbc.Driver jdbc:mysql://host:port/{dbname}?allowMultiQueries=true oracle org.postgresql.Driver dbc:postgresql:{dbname} Jmeter-webservice接口脚本 基本分为五个步骤： （1）先需要通过soapui工具获取到webservice接口的请求地址、请求报文和请求soapaction。 （2）jmeter新建一个线程组 （3）线程组下建立SOAP/XML-RPC Request，写入请求url、请求报文、请求soapaction。 （3）启动jmeter，调用接口，通过察看结果树查看返回值。 soapui获取信息的实例如下图所示： soapui提交完后，点击raw,可看到soapation，有些接口若没返回soapation,则jmeter里也就不用填。 jmeter-webservice脚本实例如下图所示： 压力测试 压力测试分两种场景：一种是单场景，压一个接口的；第二种是混合场景，多个有关联的接口。压测时间，一般场景都运行10-15分钟。如果是疲劳测试，可以压一天或一周，根据实际情况来定。 压测任务需求的确认 压测前要明确压测功能和压测指标，一般需要确定的几个问题： 1. 固定接口参数进行压测还是进行接口参数随机化压测？ 2. 要求支持多少并发数？ 3. TPS（每秒钟处理事务数）目标多少？响应时间要达到多少？ 4. 压服务器名称还是压服务器IP，一般都是压测指定的服务器 压测设置 1. 线程数：并发数量，能跑多少量。具体说是一次存在多少用户同时访问 2. Rame-Up Period(in seconds):表示JMeter每隔多少秒发动并发。理解成准备时长：设置虚拟用户数需要多长时间全部启动。如果线程数是20，准备时长为10，那么需要10秒钟启动20个数量，也就是每秒钟启动2个线程。 3. 循环次数：这个设置不会改变并发数，可以延长并发时间。总请求数=线程数*循环次数 4. 调度器：设置压测的启动时间、结束时间、持续时间和启动延迟时间。 压测结果查看 运行完后，聚合报告会显示压测的结果。主要观察Samples、Average、error、Throughput。 1. Samples:表示一共发出的请求数 2. Average：平均响应时间，默认情况下是单个Request的平均响应时间（ms） 3. Error%:测试出现的错误请求数量百分比。若出现错误就要看服务端的日志，配合开发查找定位原因 4. Throughput:简称tps,吞吐量，默认情况下表示每秒处理的请求数，也就是指服务器处理能力，tps越高说明服务器处理能力越好。 压测结果的分析 1. 有错误率同开发确认，确定是否允许错误的发生或者错误率允许在多大的范围内； 2. Throughput吞吐量每秒请求的数大于并发数，则可以慢慢的往上面增加；若在压测的机器性能很好的情况下，出现吞吐量小于并发数，说明并发数不能再增加了，可以慢慢的往下减，找到最佳的并发数； 3. 压测结束，·登陆相应的web服务器查看CPU等性能指标，进行数据的分析; 4. 最大的tps:不断的增加并发数，加到tps达到一定值开始出现下降，那么那个值就是最大的tps。 5. 最大的并发数：最大的并发数和最大的tps是不同的概率，一般不断增加并发数，达到一个值后，服务器出现请求超时，则可认为该值为最大的并发数。 6. 压测过程出现性能瓶颈，若压力机任务管理器查看到的cpu、网络和cpu都正常，未达到90%以上，则可以说明服务器有问题，压力机没有问题。 7. 影响性能考虑点包括：数据库、应用程序、中间件（tomact、Nginx）、网络和操作系统等方面。 jmeter在linux下进行压力测试 1. jmeter 在linux安装 简单说下，就是要先安装jdk,同时再配置环境变量，最后再上传jmeter压缩的安装包，在linux下解压完安装包就可以使用了。 2. jmeter在linux运行 进入jmeter下的bin目录下运行脚本，未配置jmeter环境变量的条件下，运行的命令： ./jmeter -n -t a.jmx -l res.jtl 其中a.jmx是准备好的jmeter脚本,res.jtl是测试结果文件，测试结果文件可以导入到jmeter察看结果树下查看。 "},"工具/Jmeter/Jmeter压力测试简单教程.html":{"url":"工具/Jmeter/Jmeter压力测试简单教程.html","title":"Jmeter压力测试简单教程","keywords":"","body":"Jmeter压力测试简单教程 网上关于Jmeter的资料有很多但是大多千篇一律，要么简单弄个页面测试一下，要么全篇都是介绍很多和Jmeter无关的第三方工具，看起来很专业高深，但是作为测试小白来说，看到这样的东西确实头疼。我只是想好好了解一下Jmeter的使用啊，能不能完整的介绍一下啊？我不需要了解那么多其他的第三方工具啊？能不能截个图说的清楚一点啊？这个步骤里的参数是干嘛的啊？对应的什么啊？你的这一步我怎么出现问题了啊？怎么不说解决方法啊。。。这应该是我前段时间查找Jmeter资料内心最多的问题了，真是哔了狗了（我是一个优雅的程序猿，很少讲粗话啦~嘿嘿）。对于使用某种新的东西，我的习惯往往是先把流程完整的跑一遍，记住，是完整，清晰，好歹别人看了之后对应着自己的需求也能照搬着实现，吐槽了够多了，开始进入正题，我把我遇到的坑都说清楚，包括后来怎么从坑里爬出来的。。。 步骤一 安装Jmeter 我用的版本是3.1版本，为什么是3.1，因为3.2有问题，我也是跑了一段时间后才知道3.2版本太新了还是什么的，有些功能就是不行，在此建议大家，不要轻易使用最新版本，次新版本就可以了。安装好了之后Jmeter的bin目录下有个Jmeter.bat文件，双击就能运行了。 注：最新的版本5.1.1，在请求报文过长时，例如请求中需要以流方式传输图片时，会出现结果树中的请求点击无反应的情况，更换为3.*版本即可 步骤二 使用Jmeter测试未登录页面 运行软件之后，我们当然要找个链接测试一下啦，这里我们以百度为例 我们右击“测试计划”——“添加”——“Threads(Users)——线程组”，这样就建了一个线程组了，这是干嘛，当然是跑线程用的啊。 有了线程组之后，我们再右击线程组，“添加”——“配置元件”——“http请求默认值”，这个默认值是干嘛的？里面可以设置一些常用的默认的设置（这不是废话嘛~）。 在http请求默认值面板里面，我们可以输入要测试的服务器的IP或者域名，这里我们输入“www.baidu.com”，协议是“https”。 你要测试的网址如果是http开头那就填“http”，其他默认不管了，这时候点击左上角保存会弹出一个保存框，这是让你保存你现在所做的测试配置，以后需要再测试的话的直接打开保存的jmx文件就行了。 保存完了之后，我们再右击“线程组”——“添加”——“Sampler”——“http请求”，哎，刚刚不是添加过了吗？刚刚那个不是哦，刚刚那个只是默认值，只是用来设置一些默认配置，真正发起请求的是“http请求”。 在http请求里面我们在“路径”里面输入斜杠“/”就行啦，表示默认路径，IP那一栏就不用输入了，为什么呢？因为在http请求默认值里面已经输过啦，以后可以新建多个http请求，只要修改路径就行了，这样就可以访问同一个网站的不同页面，这就是“http请求默认值”的意义所在，把一些共用的设置写一遍就好了。 接着，我们再右击“线程组”——“添加”——“监听器”——“察看结果数”，在这里可以查看到http请求和结果。每次新建组件和修改配置信息都要点击保存。 好了，页面配置图如下所示： 现在我们点击工具栏的绿色运行按钮，就可以在“察看结果树”中看到结果了 我们新建的“http请求”返回结果200，表明请求成功，从绿色打钩也能看出，上图中的下拉列表框可以选择显示格式，我们选择HTML，切换到“响应数据”就可以看到返回页面，也就是百度首页。 步骤三 设置线程并发数 我们点击“线程组”可以看到线程组的设置页面，默认设置1个线程，1秒启动，循环1次。 线程数表示启动多少个线程，Ramp-Up Period表示花多长时间启动所有线程，循环次数表示每个线程的执行次数。 例如，我设置线程数10，Ramp-Up Period为10，循环次数2，表示软件将在10秒内启动10个线程，也就是1秒启动1个线程，每个线程执行两次请求。 还可以勾选“调度器”，比如填入持续时间100，启动延迟0，将循环次数勾选“永远”，表示线程立即启动，执行100秒后停止。 注意，如果设置了持续时间和启动延迟，那么下面的启动时间和结束时间就不起作用了，也就不用管了，点击运行即可。 步骤四 设置其他监听器 之前我们仅仅设置了“察看结果树”这个监听器，我们右击“线程组”——“添加”——“监听器”，里面有好多监听器可供选择。 比如图形结果，用表格查看结果，聚合报告等等，这些都是反映测试过程的指标数据。 图形结果以图形的形式显示吞吐量、偏移、平均值等信息，表格结果显示每一次请求的时间，返回，发送字节数，连接时间等等，聚合报告里面显示总体请求的吞吐量，错误率等等。下图为表格结果的样式。 可以看出，图中显示了20个Http请求，分别由10个线程执行，每个线程执行两次，正好符合我们对于线程组的设置。 图中每一列的含义分别表示请求序号，开始时间，线程序号，请求名，请求所花的时间，请求状态，请求字节数，发送字节数，等待时长，连接时间。 聚合报告如下图所示，每一列的含义分别表示请求名称，请求总数，请求的平均响应时间（毫秒），50%的请求的响应时间，90%的请求的响应时间，95%的请求的响应时间，99%的请求的响应时间，最小的响应时间，最大的响应时间，错误的请求率（错误请求数/总的请求数），吞吐量（每秒处理的请求数），接收的字节速率，发送的字节速率。 步骤五 登录测试 前面我们测试的页面是不需要登录的，现在我们来测试一下登录操作，由于登录操作涉及到具体的内部网址和参数，我这里就用一般网址和参数代替，但是方法是一样的，例如，我们内网IP是1.1.1.1，登录页面是1.1.1.1/login.do，我们将1.1.1.1填入“http请求默认值”，将/login.do填入“http请求”的路径里面，关于登录需要的参数我要特别说明一下，一般来说就是用户名和密码，但是往往还需要其他参数，我们可以通过抓包工具Fiddler进行抓包，我们在网站中进行一次正常登录，可以在Fiddler中看到登录需要的post参数，例如Fiddler中显示登录操作post参数有username,password,type，那么需要在“http请求”里面填入，下图所示。 点击“添加”按钮就可以添加参数了，保存好后，我们点击运行，就可以在察看结果树中看到登录成功后的页面了，具体的操作和前面一样的。 步骤六 会话保持 我们进入登录后的页面后，我还想访问例如“我的账户”，“我的信息”等模块怎么办，这些网页需要登录成功后才能访问到，这里我们就需要进行会话的保持，我们右击“线程组”——“添加”——“配置元件”——“httpcookie管理器”，要添加的内容我们可以在察看结果树的“请求”选项卡里面看到，里面可以看到登录需要的cookie，例如JSESSIONID，我们将JSESSIONID填入cookie管理器的参数里面，如下 此时，我们在http请求里面输入登录后的页面网址，例如“我的信息”等等，就可以请求成功啦。 步骤七 文件读取网址 我们在“http请求”的路径里面填入的是我们要访问的网页，每次只能填一个，假如我想访问好几个网页，例如首页，通知页，公司介绍页等等，除了新建http请求外，我们还可以将这些网页的地址存储在TXT文件里，例如，我要访问1.1.1.1/index.do，1.1.1.1/information.do，1.1.1.1/company.do，我们可以这样 网址填入后，我们在Jmeter里面的“选项”——“函数助手对话框”——“StringFromFile”，将TXT的完整路径贴到图中位置，点击生成，可以在框里生成TXT文件的读取路径。 我们将$开头的那串路径贴到“http请求”的路径里面，就可以访问到TXT里面的所有网页啦，如图所示。 步骤八 服务器状态实时监听 上面我们介绍了几个Jmeter自带的监听器，不知你是否感觉到有一点点无力，因为里面显示的指标好像都不是你特别需要的，至少对于我来说，我更关心我的请求执行过程中服务器状态的改变，例如CPU，内存，磁盘，网络，TPS，响应时间图等等，因为这才是压力测试的目的所在，服务器状态随着请求增加的变化曲线才是我们更加需要看到的。想看到服务器变化的曲线图，我们需要下载JMeterPlugins-Extras.jar和JMeterPlugins-Standard.jar，将这两个jar包放入Jmeter的安装路径下的lib/ext/下面，重启Jmeter后，右击“线程组”——“添加”——“监听器”，我们可以看到多了好多监听器，大多数以“jp@gc”开头的监听器，我们选择“PerfMon Metrics Collector”，里面将会显示服务器的状态信息，现在还看不到，为什么，因为要测试的服务器需要安装一个包，叫ServerAgent.zip，比如我的服务器是linux，我们将ServerAgent在服务器中解压，运行里面的startAgent.sh就可以啦，启动起来后可以看到如下 默认端口是4444，在这里我要插一句，我当时运行后通过Telnet始终ping不到4444端口导致显示不了，后来改成4445端口启动就可以了。 具体的服务器命令是ServerAgent-2.2.3/startAgent.sh--udp-port 4445 --tcp-port 4445，这样就表示将serverAgent在4445端口启动，你可以将4445换成其他端口，如果默认的4444端口不行的小伙伴可以试试其他端口哦。 好了，我们回到Jmeter软件，按下图填入服务器的地址和端口号，以及需要监控的硬件，如CPU，内存，磁盘，网络等等。 好了，我们点击运行，可以在chart下看到服务器的状态变化曲线啦。 怎么样，是你想要的吧，其实监听器里面还有很多其他的曲线，看英文就知道，比如TPS曲线，响应时间曲线等等，这些你都可以自己添加，我就不赘述啦。 "},"工具/Jmeter/Jmeter使用自定义编写代码.html":{"url":"工具/Jmeter/Jmeter使用自定义编写代码.html","title":"Jmeter使用自定义编写代码","keywords":"","body":"Jmeter使用自定义编写代码 我们在做性能测试时,有时需要自己编写测试脚本,很多测试工具都支持自定义编写测试脚本,比如LoadRunner就有很多自定义脚本的协议,比如\"C Vuser\",\"Java Vuser\"等协议。 同样,Jmeter也支持自定义编写的测试代码,不过与LoadRunner不同的是,Jmeter没有自带编译器,需要借助第三方编译器才能实现。 下面举一个简单的Java自定义测试代码例子,使用Java编译器编写测试代码(Java编译器可以用Eclipse,JBulider等),实现功能为: 判断输入的数字是否等于你指定的数，如果等于，则返回成功，如果小于，则提示该输入数字太小，如果大于，则提示该数字太大，如果不为数字，提示输入数字。 然后在放到Jmeter中模拟10个用户测试,同时运行这段代码,具体实现如下: 一、开始编写前的准备 打开Java编译器，新建一个项目TestNumber，然后新建一个包test。 从Jmeter的安装目录lib/ext中拷贝两个文件ApacheJMeter_core.jar和ApacheJMeter_java.jar到TestNumber项目中，然后引入这两个JAR包。 在test包中新建一个类，类名为TestNum，该类继承AbstractJavaSamplerClient类，AbstractJavaSamplerClient存在于ApacheJMeter_java.jar这个JAR包中，引用即可调用。 TestNum类在继承AbstractJavaSamplerClient类的时候，需要实现四个方法，分别是 setupTest()：初始化方法，用于初始化性能测试时的每个线程； getDefaultParameters()：主要用于设置传入的参数； runTest()：为性能测试时的线程运行体； teardownTest()：测试结束方法，用于结束性能测试中的每个线程。 二、具体的代码实现 package test; import org.apache.jmeter.config.Arguments; import org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient; import org.apache.jmeter.protocol.java.sampler.JavaSamplerContext; import org.apache.jmeter.samplers.SampleResult; public class TestNum extends AbstractJavaSamplerClient{ private SampleResult results; /** * 输入的数字 */ private String inNum; /** * 需要匹配的数字 */ private String resultNum; /** * 初始化方法，初始化性能测试时的每个线程 * 实际运行时每个线程仅执行一次，在测试方法运行前执行，类似于LoadRunner中的init方法 */ public void setupTest(JavaSamplerContext jsc) { results = new SampleResult(); inNum = jsc.getParameter(\"inNum\", \"\"); resultNum = jsc.getParameter(\"resultNum\", \"\"); if (inNum != null && inNum.length() > 0){ results.setSamplerData(inNum); } if (resultNum != null && resultNum.length() > 0){ results.setSamplerData(resultNum); } } /** * 设置传入参数 * 可以设置多个，已设置的参数会显示到Jmeter参数列表中 */ public Arguments getDefaultParameters() { Arguments params = new Arguments(); params.addArgument(\"inNum\",\"\"); params.addArgument(\"resultNum\", \"66\"); return params; } /** * 性能测试时的线程运行体 * 测试执行的循环体，根据线程数和循环次数的不同可执行多次，类似于Loadrunner中的Action方法 */ public SampleResult runTest(JavaSamplerContext arg0) { boolean flag = false; //定义一个事务，表示这是事务的起始点，类似于Loadrunner中的lr.start_transaction results.sampleStart(); for (int i = inNum.length();--i >= 0;){ if (!Character.isDigit(inNum.charAt(i))){ flag = false; }else{ flag = true; } } for (int j = resultNum.length();--j >= 0;){ if (!Character.isDigit(resultNum.charAt(j))){ flag = false; }else{ flag = true; } } //定义一个事务，表示这是事务的结束点，类似于Loadrunner中的lr.end_transaction results.sampleEnd(); if (flag){ Integer num = Integer.parseInt(inNum); Integer rsNum = Integer.parseInt(resultNum); if (num == rsNum){ results.setDataEncoding(\"UTF-8\");//因为响应的数据有中文，所以最好先设置编码 results.setResponseData(\"恭喜你，答对了O(∩_∩)O~\\n答案是【\"+resultNum+\"】\");//响应数据，对应结果树，其他response code等可以自己点出来 results.setSuccessful(true);//告诉系统返回正确还是错误 } else if (num > rsNum){ results.setDataEncoding(\"UTF-8\"); results.setResponseData(\"好像大了点~~~~(>___三、Jmeter运行分析 将上述代码打包成jar包，生成的包名称为TestNumber.jar，将jar包拷贝到Jmeter的安装目录lib/ext下面。 运行Jmeter，添加线程组及java请求，显示如下： 其中，inNum为我们输入的值，因为需要用到多个用户，避免填写的麻烦，我们用随机数函数来随机抽取数字验证，resultNum为匹配的结果。 添加监听器，这里我们添加查看结果树和聚合报告就好。 结果显示如下图： 查看结果树： 我们可以看到，10个请求中，有一个请求回答正确，响应数据对应了我们的代码，表示执行成功。 聚合报告： 可以看到如上信息，请求用户为10个，因为我们的代码基本上没有任何含义，执行速度很快，所以其他值基本为0。 通过上面的例子我们可以发现,使用Jmeter自定义Java测试代码,配合Jmeter自带的函数,就可以实现出LoadRunner中\"Java Vuser\"协议的绝大多数功能,而且是没有用户数限制和完全免费的。 上面的例子非常简单,而且没有任何实际意义,只是一个简单的Jmeter测试代码示例,用于抛砖引玉,希望大家一起交流,共同 进步。 "},"工具/Jmeter/Jmeter参数化.html":{"url":"工具/Jmeter/Jmeter参数化.html","title":"Jmeter参数化","keywords":"","body":"Jmeter参数化 JMeter也有像LR中的参数化，本篇就来介绍下JMeter的参数化如何去实现。 参数化：录制脚本中有登录操作，需要输入用户名和密码，假如系统不允许相同的用户名和密码同时登录，或者想更好的模拟多个用户来登录系统。 这个时候就需要对用户名和密码进行参数化，使每个虚拟用户都使用不同的用户名和密码进行访问。 一、准备脚本，测试数据 录制一个脚本（可以用badboy工具录制），在jmeter中打开，找到有用户名和密码的页面。 如下： 我们需要“参数化”的数据，用记事本写了五个用户名和密码，保存为.dat格式的文件，编码问题在使用CSV Data Set Config参数化时要求的比较严格，记事本另存为修改编码UTF-8。 我将这个文件放在了我的（ C:\\JmeterWorkSpace\\t.dat ）路径下。 注意用户名和密码是一一对应的，中间用户逗号（，）隔开。 二、参数化 这里介绍两种参数化的方式：函数助手，CSV Data Set Config。 1. 借助函数助手的方式 a、点击菜单栏“选项”---->函数助手对话框，看下图: CSV文件列号是从0开始的，第一列0、第二列1、第三列2、依次类推。 b、复制生成的参数化函数，打开登陆请求页面，在右则的参数化中找到我们要参数化的字段，这里对用户名和密码做参数化，第一列是用户名，列号为0；第二列是密码，列号为1；修改函数中对应的参数化字段列号就可以啦。 好了，现在我们的参数化设置完成，在脚本的时候，会调用我们C:\\JmeterWorkSpace盘下面的t.dat文件，第一列是用户，第二列是密码。 2. 借助jmeter中的配置元件（CSV Data Set Config） a、选中线程组，点击右键，添加－配置元件－CSV Data Set Config 说明： Filename --- 参数项文件 File Encoding --- 文件的编码，设置为UTF-8 Vaiable Names --- 文件中各列所表示的参数项；各参数项之间利用逗号分隔；参数项的名称应该与HTTP Request中的参数项一致。 Delimiter --- 如文件中使用的是逗号分隔，则填写逗号；如使用的是TAB，则填写\\t；(如果此文本文件为CSV格式的，默认用英文逗号分隔) Recycle on EOF? --- True=当读取文件到结尾时，再重头读取文件 False=当读取文件到结尾时，停止读取文件 Stop thread on EOF? --- 当Recycle on EOF为False时，当读取文件到结尾时，停止进程，当Recycle on EOF为True时，此项无意义 备注说明：这里我用通俗的语言大概讲一下Recycle on EOF与Stop thread on EOF结果的关联 Recycle on EOF ：到了文件尾处，是否循环读取参数，选项：true和false Stop thread on EOF：到了文件尾处，是否停止线程，选项：true和false 当Recycle on EOF 选择true时，Stop thread on EOF选择true和false无任何意义，通俗的讲，在前面控制了不停的循环读取，后面再来让stop或run没有任何意义 当Recycle on EOF 选择flase时，Stop thread on EOF选择true，线程4个，参数3个，那么只会请求3次 当Recycle on EOF 选择flase时，Stop thread on EOF选择flase，线程4个，参数3个，那么会请求4次，但第4次没有参数可取，不让循环，所以第4次请求错误 b、使用刚才定义好的变量 至此，两种参数化的方法就介绍完了。 需要说明一下：函数助手方法要比CSV控件方法参数化功能要弱，推荐使用CSV控件方法。 再看看与loadrunner参数化不一样的： jmeter参数文件的第一行没有列名称 这里要注意的是参数文件的编码，可以使用记事本另存为就可以修改该编码（编码问题在使用CSV Data Set Config参数化时要求的比较严格） Jmeter的参数化设置没有LoadRunner做的出色，它是依赖于线程设置的（只有CSV Data Set Config参数化方法才有） "},"工具/Jmeter/Jmeter进行https协议的压测.html":{"url":"工具/Jmeter/Jmeter进行https协议的压测.html","title":"Jmeter进行https协议的压测","keywords":"","body":"Jmeter进行https协议的压测 一、HTTPS和HTTP的区别 超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息。HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此HTTP协议不适合传输一些敏感信息，比如信用卡号、密码等。 为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS。为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 HTTPS和HTTP的区别主要为以下四点： https协议需要到ca申请证书，一般免费证书很少，需要交费。 http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络，比http协议安全。 二、 方法 1.安全连接—更多信息—查看证书—详细信息—导出证书 2.生成.cer后缀的文件 3.把导出的证书转换成.store格式的文件 输入密码-添加信任 keytool -import -alias \"test.store\" -file \"test.cer\" -keystore test.store 4.在jmeter中端口号输入443，协议输入https 5.在ssl管理器中添加证书 6.调试脚本，运行场景，开始执行测试。 "},"工具/Jmeter/Jmeter之Non-GUIMode.html":{"url":"工具/Jmeter/Jmeter之Non-GUIMode.html","title":"Jmeter之Non-GUIMode","keywords":"","body":"Jmeter之Non-GUIMode Jmeter是一个纯JAVA的应用，用GUI模式进行压力测试时，对客户端的资源消耗比较高，一般在进行正式的压测时使用Non-GUI模式运行。下面就来说说详细的使用。 设置好JAVA_HOME，这个大家应该都知道的吧。 既然使用Non-GUI模式运行，那么就需要先了解下Non-GUI模式下的命令参数，下面是Non-GUI模式下常用的一些参数： -n This specifies JMeter is to run in non-gui mode #以Non-GUI模式运行 -t [name of JMX file that contains the Test Plan]. #要执行的JMeter脚本 -l [name of JTL file to log sample results to]. #采样器的log文件，一般以.jtl结尾 -j [name of JMeter run log file]. #指定记录JMeter log的文件，默认为bin目录下的jmeter.log。 -r Run the test in the servers specified by the JMeter property \"remote_hosts\" #启动远程server（在jmeter.properties中定义好的remote_hosts） -R [list of remote servers] Run the test in the specified remote servers #启动远程server（如果使用此参数，将会忽略jmeter.properties中定义的remote_hosts） -H proxyHost [proxy server hostname or ip address] #代理服务器地址 -P [proxy server port] #代理服务器端口 -u username Set username for proxy server that JMeter is to use #代理服务器用户名 -a password Set password for proxy server that JMeter is to use #代理服务器密码 -J jmeterproperty = Define additional JMeter properties #JMeter属性，Non_GUI模式时传入参数使用。 -L loglevel = [category=]level e.g. jorphan=INFO or jmeter.util=DEBUG #定义JMeter运行时的日志级别 -X remoteexit Exit the remote servers at end of test (non-GUI) #测试结束后，退出（在Non-GUI模式下） 了解以上参数后，就可以开始我们的Non-GUI模式的测试了。 开始—运行—cmd，进入到命令行模式； cd到JMeter的bin目录下，（如果配置过JMeter的环境变量，在任意目录下都可以执行）； 执行命令： jmeter -n -t .\\scripts\\test.jmx -l .\\jtl\\test001.jtl -j .\\jtl\\test001.log 这里是指定使用1个线程运行10s，执行结果： 以上，是不是很简单呢？ 那么现在有这样一个问题：那如果要使用10个线程，执行10s，怎么操作呢？是不是需要修改脚本，然后再执行呢？如果还有更多场景，是不是每次都要修改脚本呢？ 其实没这么麻烦，参数中有个 -J 参数【Non_GUI模式时传入参数使用】，我们可以使用这个参数来传参，详细步骤如下： 1. 参数化脚本中的Number of Threads(users)【线程数】和Durations(seconds)【持续时间（）秒】。 2. 我们在测试计划中添加如下参数： 参数说明： ${__P(threads,1)} ，threads为执行脚本时传参的名称，1为默认值，如果threads为空的时候，取值1。格式一定是：${__P(参数名,默认值)}，注意中间是两个下划线。 执行脚本的时候传入参数，用 -J 参数名=value 的形式传入。 jmeter -n -t .\\scripts\\test.jmx -J threads=10 -J duration=10 -l .\\jtl\\test001.jtl -j .\\jtl\\test001.log 执行结果： "},"工具/Jmeter/Jmeter参数变量中包含引号导致异常.html":{"url":"工具/Jmeter/Jmeter参数变量中包含引号导致异常.html","title":"Jmeter参数变量中包含引号导致异常","keywords":"","body":"Jmeter参数变量中包含引号导致异常 在使用\"${变量名}\"时，由于变量中包含双引号，导致异常。 解决办法： 使用vars.get(\"变量名\");进行调用 "},"工具/Jmeter/Jmeter和Ant的html报告优化及DashboardReport介绍.html":{"url":"工具/Jmeter/Jmeter和Ant的html报告优化及DashboardReport介绍.html","title":"Jmeter和Ant的html报告优化及DashboardReport介绍","keywords":"","body":"Jmeter和Ant的html报告优化及DashboardReport介绍 通过Ant可以很方便的build执行Jmeter的jmx脚本，并且输出html报告，靠的就是Jmeter的xsl template模板，具体在build.xml是这样对jmeter-results-detail-report_21.xsl进行调用： 90% Line Time 默认调用的jmeter-results-detail-report_21.xsl报告模板是不带有90% Line时间的，以下是生成的报告样例： 我们可以动手进行一些改造，首先我们需要明白2个原理： （1）90% Line的意思是：一组数由小到大进行排列，找到它的第90%个数； （2）Jmeter html报告生成是使用xxx.jtl文件通过xsl模板生成的，因此要在html报告中显示90% line，就需要修改xsl模板文件（jmeter-results-detail-report_21.xsl） 下面开始改造： 1、第一步就是在jmeter-results-detail-report_21.xsl添加xsl template，可以模拟Max Time模板（对比），直接在max模板下新建一个line模板，如下： NaN 这里需要注意的是： （1）与max模板的区别就是sort方面，直接用顺序，而max模板用的是倒序。为什么不能倒序，是由下面第（2）条决定的。 （2）position() = floor(last()*0.9)，其中last()返回当前上下文中的最后一个节点位置数，乘以0.9表示找到第90%个；floor(number) 表示返回不大于number的最大整数。 （3）number(object)使对象转换成数字。 2、有了以上的的90% Line模板，我们可以直接引用了。在Summary中添加90% Line。 Summary .........该处为一堆省略不显示的代码........... 0\">Failure .........该处为一堆省略不显示的代码........... 3、在pagelist中添加90% Line Pages .........该处为一堆省略不显示的代码........... .........该处为一堆省略不显示的代码........... .........该处为一堆省略不显示的代码........... 好了，这样就算修改完了，只要不出现手抖犯的错误，下面我们就能在报告中看到90% Line时间的列了，而且显示的时间跟Jmeter中聚合报告显示的是基本吻合的。 通过以上的过程，我们发现还可继续扩展在html报告中显示95%，99%等时间及其他指标。 QPS扩展 Jmeter的具合报告有Throughput这个值，这个在loadrunner中是表示为吞吐量的，这里可以表示QPS或者TPS（在使用了事务的情况下），个人把这个称为QPS，因为更直观。 和%90Line同样的道理，首先必须知道这个值是怎么计算出来，经过查找资料和官网的比较，发现这个值是通过如下的公式计算出来的： 官网的截图： Throughput = (number of requests) / (total time) total time = 测试结束时间 - 测试开始时间 测试结束时间 = MAX(请求开始时间 + Elapsed Time) 测试开始时间 = MIN(请求开始时间) 知道了公式，那么计算就容易了，以下是关键代码： 说明：allTpCount = count(/testResults/*/@ts) div ($allTotalTime div 1000) 扩展后的结果如下： 吞吐量扩展 在loadrunner中吞吐量就是Throughput，在Jmeter的聚合报告中最后一列的值就是loadrunner中的Throughput，为了便于区分，我把这里的值称为Throughput，也就是吞吐量。 经过查找资料发现吞吐量的计算和QPS的计算公式是一样的，因为也就是如下的公式： Throughput = (请求的总字节数) / (total time) 这里的total time计算和QPS是一样的，而总字节数直接把所有请求的加起来即可，关键代码如下： 因为这里显示的字节，最后的结果我打算以KB的单位显示，因此这里需要除以1024，扩展后的结果如下： TPS扩展 TPS在Jmeter中虽然某些情况和QPS是一致的，但是还是有不一致的地方，因此这里也需要扩展，这样的结果看着更清晰明了。 首先和其他的参数扩展一样，需要知道计算公式，这里的计算公式和QPS也是一样的，只是数据的集合不一样，以下是扩展后的效果。 在扩展的过程中进一步发现Jmeter的聚合结果中最后的”总体“一行在某些情况下计算的数值是不准确的。如果脚本中不包含事务，那么这里的结果是准确的，如果都包含事务并且把Generate parent sample选中后这里的结果也是准确的，在脚本中有事务并且没有选中Generate parent sample，或者有些有事务有些没有时，这时的结果就不准确了，因为查看计算方式发现它把所有的请求都算进去了。 比如，一个jtl文件中即包含HTTP请求也包含事务，因为事务只是对之前请求的一个统计，本身是不发送请求的，所以计算总的吞吐量、QPS，TPS时是不能这么算的。 所以在扩展的过程中分成了两个样式表，一个样式表处理包含事务，或者没有事务的情况，这时的结果以QPS衡量；一个样式表处理全都是事务的情况，这时候的结果以TPS衡量，这样就准确了。 测试：扩展了好几个指标，这些指标的正确性如何呢？需要在多种情况下进行测试，经过测试后各个指标都是正确的。但是还没有在大的数据量级别下测试，本身这个基于Ant通过xls模块生成的报告适合接口测试或是小规模测试，而专门的性能测试还是推荐用Jmeter自带的Dashboard。 Jmeter Dashboard 从Jmeter3.0开始就有了强大的CSV生成Html Dashboard报告的功能（很多人可能不知道），生成报告的方法也很简单： 在jmeter.properties或者user.properties确认如下配置项： jmeter.save.saveservice.data_type=true jmeter.save.saveservice.label=true jmeter.save.saveservice.response_code=true jmeter.save.saveservice.response_data.on_error=true jmeter.save.saveservice.response_message=true jmeter.save.saveservice.successful=true jmeter.save.saveservice.thread_name=true jmeter.save.saveservice.time=true jmeter.save.saveservice.subresults=true jmeter.save.saveservice.assertions=true jmeter.save.saveservice.latency=true jmeter.save.saveservice.connect_time=true jmeter.save.saveservice.bytes=true jmeter.save.saveservice.sent_bytes=true jmeter.save.saveservice.thread_counts=true jmeter.save.saveservice.idle_time=true # Timestamp format - this only affects CSV output files # legitimate values: none, ms, or a format suitable for SimpleDateFormat jmeter.save.saveservice.timestamp_format=ms jmeter.save.saveservice.timestamp_format=yyyy/MM/dd HH:mm:ss.SSS 如果希望在Errors报告中展示更详细数据，需要确保如下配置： jmeter.save.saveservice.assertion_results_failure_message = true 如果使用了事务控制器(Transaction Controller)，确认Generate parent sample为未勾选状态。 以下是生成报告的方式： a. 在压力测试结束时报告 基本命令格式： jmeter -n -t -l -e -o 样例： jmeter -n -t F:\\PerformanceTest\\TestCase\\script\\rfApp接口.jmx -l testLogFile -e -o ./output b. 使用已有的压力测试CSV日志文件生成报告 基本命令格式： jmeter -g -o 样例： jmeter -g -o 当然也可以把相关命令放到bat或sh中做成批处理直接执行（CSV文件带上时间后缀，避免冲突），可以用相对路径来调用jmx脚本，并输出相对路径的CSV文件和html报告文件（需要说明一下html报告的文件夹不能先创建，否则报冲突，测试前可以加个清空文件夹的动作或者加个时间后缀让目录唯一）。 如以下命令（用以上xls报告一样的脚本测试）： @echo off set a=%time:~0,2%%time:~3,2%%time:~6,2% set b=0%time:~1,1%%time:~3,2%%time:~6,2% if %time:~0,2% leq 9 (set c=%b%)else set c=%a% jmeterHome3.1\\bin\\jmeter -n -t rfApp接口.jmx -l DashReport\\log-%Date:~0,4%%Date:~5,2%%Date:~8,2%%c%.csv -e -o DashReport\\htmlReport-%Date:~5,2%%Date:~8,2%%c% pause 产生的文件： 顺便再提供一份Linux版的Shell命令以供参考： #!/bin/bash Cur_Dir=$(cd \"$(dirname \"$0\")\"; pwd) $Cur_Dir/jmeterHome3.2/bin/jmeter -n -t $Cur_Dir/rfAppTest.jmx -l $Cur_Dir/DashReport/log-$(date -d \"today\" +\"%Y%m%d%H%M%S\").csv -e -o $Cur_Dir/DashReport/htmlReport-$(date -d \"today\" +\"%m%d%H%M%S\") 最后上一下生成的报告，看着还是比较高大上的： 最后再提供一下Jmeter生成html报告的命令参数说明： -h 帮助 -> 打印出有用的信息并退出 -n 非 GUI 模式 -> 在非 GUI 模式下运行 JMeter -t 测试文件 -> 要运行的 JMeter 测试脚本文件 -l 日志文件 -> 记录结果的文件 -r 远程执行 -> 启动all远程服务 -R 远程执行 -> 启动指定远程服务 -H 代理主机 -> 设置 JMeter 使用的代理主机 -P 代理端口 -> 设置 JMeter 使用的代理主机的端口号 -e 测试结束后，生成测试报告 -o 指定测试报告的存放位置 "},"工具/Jmeter/JMeter+Ant安装配置使用.html":{"url":"工具/Jmeter/JMeter+Ant安装配置使用.html","title":"JMeter+Ant安装配置使用","keywords":"","body":"JMeter+Ant安装配置使用 一、环境准备： 1、Jdk1.6或以上：http://www.oracle.com/technetwork/java/javase/downloads/index.html 命令行输入：java -version，出现如下提示说明安装成功 2、ANT下载：http://ant.apache.org/bindownload.cgi 设置Ant环境变量 ANT_HOME=E:\\apache-ant-1.9.7; CLASSPATH=E:\\apache-ant-1.9.7; Path=%ANT_HOME%\\bin; 命令行输入：ant -v，出现如下提示说明安装成功 3、将 JMeter的extras目录中ant-jmeter-1.1.1.jar包拷贝至ant安装目录下的lib目录中 4、修改JMeter的bin目录下jmeter.properties文件的配置：jmeter.save.saveservice.output_format=xml 5、任意新建一个脚本存放目录：E:\\apache-jmeter-2.13\\AutoTest，以及报告存放目录report，将Login_test.jmx(已经调试OK的脚本)拷贝此目录 二、构建脚本配置： 在E:\\apache-jmeter-2.13\\AutoTest目录下，新建一个build.xml文件（Ant自动构建文件） 三、配置过程中的问题总结： 1.提示build.xml:2字节的UTF-8 序列的字节 2 无效，如图： 解决方案： 将build.xml默认配置中的字符编码UTF-8改成GB2312即可解决，同时报告标题也可以写中文 2、测试报告中三个指标为NaN。 这个问题也是一个坑，我找了好久才找到原因。 需要从Jmeter的lib包里把xalan-2.7.2.jar和serializer-2.7.2.jar copy到Ant的lib包里。 四、Ant构建运行脚本： 1、cmd进入脚本目录：E:\\apache-jmeter-2.13\\AutoTest。（即build.xml所在的目录） 2、输入：ant 或 ant run(run为build.xml中的task名)，执行结果： 3、测试报告目录：E:\\apache-jmeter-2.13\\AutoTest\\report "},"工具/Loadrunner/":{"url":"工具/Loadrunner/","title":"Loadrunner","keywords":"","body":"Loadrunner 基本介绍 HP Mercury LoadRunner 应用平台： Win2003/WinXP/Win2000/Win9X/ HP-Mercury LoadRunner 是一种预测系统行为和性能的负载测试工具。通过以模拟上千万用户实施并发负载及实时性能监测的方式来确认和查找问题，LoadRunner 能够对整个企业架构进行测试。通过使用LoadRunner ，企业能最大限度地缩短测试时间，优化性能和加速应用系统的发布周期。 目前企业的网络应用环境都必须支持大量用户，网络体系架构中含各类应用环境且由不同供应商提供软件和硬件产品。难以预知的用户负载和愈来愈复杂的应用环境使公司时时担心会发生用户响应速度过慢，系统崩溃等问题。这些都不可避免地导致公司收益的损失。HP-Mercury Interactive 的 LoadRunner 能让企业保护自己的收入来源，无需购置额外硬件而最大限度地利用现有的IT 资源，并确保终端用户在应用系统的各个环节中对其测试应用的质量，可靠性和可扩展性都有良好的评价。 LoadRunner 是一种适用于各种体系架构的自动负载测试工具，它能预测系统行为并优化系统性能。LoadRunner 的测试对象是整个企业的系统，它通过模拟实际用户的操作行为和实行实时性能监测，来帮助您更快的查找和发现问题。此外，LoadRunner 能支持广范的协议和技术，为您的特殊环境提供特殊的解决方案。 软件功能 1.轻松创建虚拟用户 使用LoadRunner 的Virtual User Generator，您能很简便地创立起系统负载。该引擎能够生成虚拟用户，以虚拟用户的方式模拟真实用户的业务操作行为。它先记录下业务流程(如下订单或机票预定)，然后将其转化为测试脚本。利用虚拟用户，您可以在Windows ，UNIX 或Linux 机器上同时产生成千上万个用户访问。所以LoadRunner能极大的减少负载测试所需的硬件和人力资源。另外，LoadRunner 的TurboLoad 专利技术能。 提供很高的适应性。TurboLoad 使您可以产生每天几十万名在线用户和数以百万计的点击数的负载。 用Virtual User Generator 建立测试脚本后，您可以对其进行参数化操作，这一操作能让您利用几套不同的实际发生数据来测试您的应用程序，从而反映出本系统的负载能力。以一个订单输入过程为例，参数化操作可将记录中的固定数据，如订单号和客户名称，由可变值来代替。在这些变量内随意输入可能的订单号和客户名，来匹配多个实际用户的操作行为。 LoadRunner 通过它的Data Wizard 来自动实现其测试数据的参数化。Data Wizard 直接连于数据库服务器，从中您可以获取所需的数据（如定单号和用户名）并直接将其输入到测试脚本。这样避免了人工处理数据的需要，Data Wizard 为您节省了大量的时间。 为了进一步确定您的Virtual user 能够模拟真实用户，您可利用LoadRunner 控制某些行为特性。例如，只需要点击一下鼠标，您就能轻易控制交易的数量，交易频率，用户的思考时间和连接速度等。 2.创建真实的负载 Virtual users 建立起后，您需要设定您的负载方案，业务流程组合和虚拟用户数量。用LoadRunner 的Controller，您能很快组织起多用户的测试方案。Controller 的Rendezvous 功能提供一个互动的环境，在其中您既能建立起持续且循环的负载，又能管理和驱动负载测试方案。 而且，您可以利用它的日程计划服务来定义用户在什么时候访问系统以产生负载。这样，您就能将测试过程自动化。同样您还可以用Controller 来限定您的负载方案，在这个方案中所有的用户同时执行一个动作---如登陆到一个库存应用程序----来模拟峰值负载的情况。另外，您还能监测系统架构中各个组件的性能---- 包括服务器，数据库，网络设备等----来帮助客户决定系统的配置。 LoadRunner 通过它的AutoLoad 技术，为您提供更多的测试灵活性。使用AutoLoad ，您可以根据目前的用户人数事先设定测试目标，优化测试流程。例如，您的目标可以是确定您的应用系统承受的每秒点击数或每秒的交易量。 3.定位性能问题 LoadRunner 内含集成的实时监测器，在负载测试过程的任何时候，您都可以观察到应用系统的运行性能。这些性能监测器为您实时显示交易性能数据（如响应时间）和其它系统组件包括application server, web server，网路设备和数据库等的实时性能。这样，您就可以在测试过程中从客户和服务器的双方面评估这些系统组件的运行性能，从而更快地发现问题。 再者，利用LoadRunner 的ContentCheck TM ，您可以判断负载下的应用程序功能正常与否。ContentCheck 在Virtual users 运行时，检测应用程序的网络数据包内容，从中确定是否有错误内容传送出去。它的实时浏览器帮助您从终端用户角度观察程序性能状况。 4.分析结果以精确定位问题所在 一旦测试完毕后，LoadRunner 收集汇总所有的测试数据，并为您提供高级的分析和报告工具，以便迅速查找到性能问题并追溯原由。使用LoadRunner 的Web 交易细节监测器，您可以了解到将所有的图象、框架和文本下载到每一网页上所需的时间。例如，这个交易细节分析机制能够分析是否因为一个大尺寸的图形文件或是第三方的数据组件造成应用系统运行速度减慢。另外，Web 交易细节监测器分解用于客户端、网络和服务器上端到端的反应时间，便于确认问题，定位查找真正出错的组件。例如，您可以将网络延时进行分解，以判断DNS 解析时间，连接服务器或SSL 认证所花费的时间。通过使用LoadRunner 的分析工具，您能很快地查找到出错的位置和原因并作出相应的调整。 5.重复测试保证系统发布的高性能 负载测试是一个重复过程。每次处理完一个出错情况，您都需要对您的应用程序在相同的方案下，再进行一次负载测试。以此检验您所做的修正是否改善了运行性能。 6.Enterprise Java Beans的测试 LoadRunner 完全支持EJB 的负载测试。这些基于Java 的组件运行在应用服务器上，提供广泛的应用服务。通过测试这些组件，您可以在应用程序开发的早期就确认并解决可能产生的问题。 利用LoadRunner, 您可以很方便地了解系统的性能。它的Controller 允许您重复执行与出错修改前相同的测试方案。它的基于HTML 的报告为您提供一个比较性能结果所需的基准，以此衡量在一段时间内，有多大程度的改进并确保应用成功。由于这些报告是基于HTML 的文本，您可以将其公布于您公司的内部网上，便于随时查阅。 7.最大化投资回报 所有HP-Mercury Interactive 的产品和服务都是集成设计的, 能完全相容地一起运作。由于它们具有相同的核心技术，来自于LoadRunner和ActiveTest TM 的测试脚本，在HP-Mercury Interactive 的负载测试服务项目中，可以被重复用于性能监测。借助HP-Mercury Interactive的监测功能－－Topaz TM 和ActiveWatch TM ，测试脚本可重复使用从而平衡投资收益。更重要的是，您能为测试的前期部署和生产系统的监测提供一个完整的应用性能管理解决方案。 8.支持无线应用协议 随着无线设备数量和种类的增多，您的测试计划需要同时满足传统的基于浏览器的用户和无线互联网设备，如手机和PDA。LoadRunner 支持2 项最广泛使用的协议：WAP和I-mode。此外，通过负载测试系统整体架构，LoadRunner 能让您只需要通过记录一次脚本，就可完全检测上述这些无线互联网系统。 9.支持Media Stream应用 LoadRunner 还能支持Media Stream应用。为了保证终端用户得到良好的操作体验和高质量Media Stream，您需要检测您的Media Stream应用程序。使用LoadRunner ，您可以记录和重放任何流行的多媒体数据流格式来诊断系统的性能问题，查找原由，分析数据的质量。 10.完整的企业应用环境的支持。 LoadRunner 支持广泛的协议，可以测试各种IT 基础架构。 测试组件 1.VuGen Load Generator（虚拟用户生成器）用于捕获最终用户业务流程和创建自动性能测试脚本 （也称为虚拟用户脚本）。 2.Controller （控制器）用于组织、驱动、管理和监控负载测试。 3.Analysis （分析器）有助于您查看、分析和比较性能结果。 "},"工具/Loadrunner/Loadrunner解决HTTP请求中传参的BASE64加密方法.html":{"url":"工具/Loadrunner/Loadrunner解决HTTP请求中传参的BASE64加密方法.html","title":"Loadrunner解决HTTP请求中传参的BASE64加密方法","keywords":"","body":"Loadrunner解决HTTP请求中传参的BASE64加密方法 用于web请求中参数的传参值涉及到了base64加密方法 void GetBase64Encode(const char* in_str,char* out_str)//加密方法 { static unsigned char base64[]=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\"; int curr_out_len = 0; int i = 0; int in_len = strlen(in_str); unsigned char a, b, c; out_str[0] = '\\0'; if (in_len > 0) { while (i = in_len) ? 0 : in_str[i + 1]; c = (i + 2 >= in_len) ? 0 : in_str[i + 2]; if (i + 2 > 2) & 0x3F]); out_str[curr_out_len++] = (base64[((a > 4) & 0xf)]); out_str[curr_out_len++] = (base64[((b > 6) & 0x3)]); out_str[curr_out_len++] = (base64[c & 0x3F]); } else if (i + 1 > 2) & 0x3F]); out_str[curr_out_len++] = (base64[((a > 4) & 0xf)]); out_str[curr_out_len++] = (base64[((b > 6) & 0x3)]); out_str[curr_out_len++] = '='; } else { out_str[curr_out_len++] = (base64[(a >> 2) & 0x3F]); out_str[curr_out_len++] = (base64[((a > 4) & 0xf)]); out_str[curr_out_len++] = '='; out_str[curr_out_len++] = '='; } i += 3; } out_str[curr_out_len] = '\\0'; } } Action() { char * take; char * toke; char res[512]; take=(char *)strtok(lr_eval_string(\"{GUID}\"),\"{\");//格式化“{”字符串 toke=(char *)strtok(take,\"}\");//格式化“}”字符串，并将值存入toke中 lr_error_message(\"GUID: %s\",toke); GetBase64Encode(toke,res);//调用base64函数 lr_output_message(res); return 0; } "},"工具/Loadrunner/Loadrunner安装后启动慢的解决方法.html":{"url":"工具/Loadrunner/Loadrunner安装后启动慢的解决方法.html","title":"Loadrunner安装后启动慢的解决方法","keywords":"","body":"Loadrunner安装后启动慢的解决方法 目录： C:\\Windows\\Microsoft.NET\\Framework\\v2.0.50727\\CONFIG 文件名：machine.config 修改runtime： 增加以下内容： "},"工具/Loadrunner/Loadrunner对字符串进行BASE64编码.html":{"url":"工具/Loadrunner/Loadrunner对字符串进行BASE64编码.html","title":"Loadrunner对字符串进行BASE64编码","keywords":"","body":"Loadrunner对字符串进行BASE64编码 1、在LoadRunner中新建协议为http/html的项目，名称例如“test”。 2、把下面的内容保存到.h格式的文件中(文件名称例如 Base64.h)，并把文件复制到LoadRunner项目（test）的根目录。 /* Base 64 Encode and Decode functions for LoadRunner 用于LoadRunner的 Base 64 编码和解码功能 ================================================== This include file provides functions to Encode and Decode LoadRunner variables. It's based on source codes found on the internet and has been modified to work in LoadRunner. Created by Kim Sandell / Celarius - www.celarius.com 这个include文件提供的方法是为了对LoadRunner变量进行编码和解码。 它根据在网上发现的源码进行修改并运行于LoadRunner中。 */ // Encoding lookup table char base64encode_lut[] = { 'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q', 'R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h', 'i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y', 'z','0','1','2','3','4','5','6','7','8','9','+','/','='}; // Decode lookup table char base64decode_lut[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,62, 0, 0, 0,63,52,53,54,55,56,57,58,59,60,61, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14, 15,16,17,18,19,20,21,22,23,24,25, 0, 0, 0, 0, 0, 0,26,27,28, 29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48, 49,50,51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, }; void base64encode(char *src, char *dest, int len) // Encodes a buffer to base64 { int i=0, slen=strlen(src); for(i=0;i>0x2]; *(dest++)=base64encode_lut[(*src&0x3)>0x4]; *(dest++)=((i+1)>0x6]:'='; *(dest++)=((i+2)>0x4; *(dest++)=(c3!=64)?((c2&0xF)>0x2):'\\0'; *(dest++)=(c4!=64)?((c3&0x3)3、打开test项目，设置成脚本模式，在左侧边栏右键–“向脚本添加文件”，把Base64.h文件添加进来。 4、打开globals.h，添加头文件Base64.h #ifndef _GLOBALS_H #define _GLOBALS_H //-------------------------------------------------------------------- // Include Files #include \"lrun.h\" #include \"web_api.h\" #include \"lrw_custom_body.h\" #include \"base64.h\" //添加头文件Base64.h "},"工具/Loadrunner/Loadrunner使用JDBC执行sql对数据库进行压测.html":{"url":"工具/Loadrunner/Loadrunner使用JDBC执行sql对数据库进行压测.html","title":"Loadrunner使用JDBC执行sql对数据库进行压测","keywords":"","body":"Loadrunner使用JDBC执行sql对数据库进行压测 import lrapi.lr; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class Actions { private Connection conn=null; private Statement stmt=null; private ResultSet rs=null; private String server=\"\";//数据库地址 private String dataBase=\"\";//数据库名 private String username=\"system\";//用户名 private String password=\"123456\";//密码 private String url=\"jdbc:Oracle:thin:@192.168.127.129:1521:powerdes\"; public int init() throws Throwable{ //连接mysql数据库使用下面的方法 //Class.forName(\"com.mysql.jdbc.Driver\").newInstance(); //conn=DriverManager.getConnection(\"jdbc:mysql://\"+server+\"/dkhs?user=\"+username+\"&password=\"+passworkd); //连接DB2数据库使用下面的方法 Class.forName(\"oracle.jdbc.driver.OracleDriver\").newInstance(); conn=DriverManager.getConnection(url,username,password); stmt=conn.createStatement(); return 0; } public int action() throws Throwable{ rs=stmt.executeQuery(\"select * from test\"); while(rs.next()) { lr.error_message(rs.getString(\"ename\")); //打印出查询的结果 } return 0; } public int end() throws Throwable{ stmt.close(); conn.close(); return 0; } } "},"工具/Loadrunner/Loadrunner录制https协议.html":{"url":"工具/Loadrunner/Loadrunner录制https协议.html","title":"Loadrunner录制https协议","keywords":"","body":"Loadrunner录制https协议 一、最简单的方法：浏览器配置 打开浏览器，安装证书，配置完成后直接用http协议录制即可 （配置完成的标识就是打开网页，不显示安全提示） 二、LR配置修改 操作步骤如下： 1、证书的获取 ie选项-内容-证书，找到目标网站的证书选择导出，导出时选择base64的cer格式； 2、证书的准备（若为cer格式可忽略） 常见的证书为：*.pfx格式，该种格式的证书可以通过双击运行安装到IE浏览器上。用户在访问的时候就可以使用到。 但这种证书并不是LoadRunner所使用的类型，因此需要对其进行转换。将其转换为*.pem格式。 (.cer格式的证书不需要转换) 转换方法1如下： a) 安装openssl后 b) 运行C:\\/bin文件夹的openssl二进制文件，它将启动OpenSSL命令提示符 c) 执行以下命令：pkcs12 -in D:\\test1.pfx -out D:\\test01.pem–nodes d) 执行后，将会在指定目录生成test01.pem文件，这个文件将会在下一个步骤，对LoadRunner进行配置的时候使用到。 转换方法2如下： a) 安装openssl后 b) 运行C:\\/out32dll文件夹的openssl二进制文件，它将启动OpenSSL命令提示符(或者 C:\\/bin) c) 执行以下命令：openssl x509 -in mycert.crt -out mycert.pem -outform PEM （用浏览器保存的.crt 文件转为 .pem 文件） c) 执行以下命令：pkcs12 -in D:\\test1.pfx -out D:\\admin149.pem–nodes 3．LR配置 1）启动LoadRunner，打开Recording Option选项。 network中，单击New Enty（如下图） 2）进入Entry配置窗口，进行配置，如下图所示： 红框中的配置为服务器的ip和端口号，按照测试所需要的实际地址进行配置就可以。配置后，将Use specified client-side certificate[Base64/PEM]钩选，为使用客户端证书访问。 单击...选择刚刚转换生成的客户端证书。 如果你为证书有设置密码，在这里也需要输入。 到此为止所有与http区别的配置就完成了。 4.其他设置 1）tools->recording options->port mapping 选择 第二项 winINet level data 2）runtime setting -> Internet protocol->perference 选中 WinInet replay instead of sockets. 5.完成上面4步后可以正常录制脚本。 配置完毕后，录制脚本，正常情况下，录制的脚本前面会出现证书信息，如下所示： web_set_certificate_ex(\"CertFilePath=admin149.pem\", \"CertFormat=PEM\", \"KeyFilePath=admin149.pem\", \"KeyFormat=PEM\", \"Password=123456\", \"CertIndex=1\", LAST); 三、请求开发协助 （仅限测试环境） 1）让开发把协议改成http; 2）使用http录制脚本； 3）让开发改回https; 4）脚本把http改成https; 最简单快捷的方法：脚本最前面加上web_set_sockets_option('SSL_VERSION','TLS'); "},"工具/Loadrunner/LoadrunnerVuser进程线程两种运行方式.html":{"url":"工具/Loadrunner/LoadrunnerVuser进程线程两种运行方式.html","title":"LoadrunnerVuser进程线程两种运行方式","keywords":"","body":"LoadrunnerVuser进程线程两种运行方式 Loadrunner执行场景时出现如下报错： 报错原因：都消息内存，之前用户是按线程跑，一个进程开了多个线程，其中有部分内存是这些线程共享的，出错应该是内存出现冲突了不够用了。现在用户是按进程跑，内存应该是独立的了. 如果跑场景的时候老是报错内存不足，那么可以尝试修改loadrunner-F4的默认设置（线程改成--->进程) 解决方案： 变更这里的设置，其余设置不变。 说明 loadrunner controller将使用驱动程序mmdrv运行Vuser。用户可以在controller的run-time setting中选择Vuser的运行方式,是多进程方式or多线程方式。 如果选择以线程方式来运行虚拟用户： 在场景设置时，“是单行脚本，还是多行脚本”会决定系统启动的进程数的多少： 假设并发用户设置为30，如果是单行30个用户，系统只需启动一个进程； 假设并发用户设置为30，如果是多行，30行，每行一个用户，系统就需要启动30个进程； 如果选择以进程方式来运行虚拟用户： 那么无论脚本在场景组中怎么设置，是单行多用户还是多行少用户方式，系统需要启动的进程数是一定的，就是并发用户的总数； 进程方式和线程方式的优缺点 如果选择按照进程方式运行，每个用户都将启动一个mmdrv进程，多个mmdrv进程会占用大量内存及其他系统资源，这就限制了可以在任一负载生成器上运行的并发用户数的数量，因为负载机的资源（内存及其他系统资源）是有限的。 如果选择按照线程方式运行，在默认情况下，controller为每50个用户仅启动一个mmdrv进程，而每个用户都按线程方式来运行，这些线程用户将共享父进程的内存段，这就节省了大量内存空间，从而可以在一个负载生成器上运行更多的用户。（如果选择线程方式来运行用户，每个进程中会多出几个线程，例如是53个，多出来的进程可能是用于维护进程之间的运行的） 选择线程方式虽然可以减少启动的mmdrv进程数，减少了内存的占用，但是也容易出现一个问题，例如，同一个测试场景，用线程并发就会出现超时失败或报错，而用进程并发就没错。为什么呢？因为线程的资源是从进程资源中分配出来的，因此同一个进程中的多个线程会有共享的内存空间，假设a线程要用资源就必须等待b线程释放，而b线程也在等待其他资源释放才能继续，这样就会出现这个问题。 系统需要启动的mmdrv进程数与哪些因素有关： 与在controller的运行时设置中选择的是进程方式or线程方式来运行虚拟用户有关 进程方式：无论是单行or多行脚本，需要启动的进程数就是并发用户数； 线程方式：假设是单行脚本，每50个用户才启动一个进程；多行脚本，有几行（每行 如果选择了线程方式，需启动的进程数，进一步还与脚本是单行还是多行有关 单行脚本，多用户，假设少于50，只需启动一个进程，100个用户，只需启动2个进程，依此类推； 多行脚本，即使每行一个用户，也需要启动一个进程，多一行就需要多启动一个进程；不是每个用户启动一个进程，有几行（每行 在启动了IP欺骗功能后，所需启动的进程数，还与选择的是按进程还是按线程来分配IP地址有关 按进程分IP：每个ip（负载生成器）就需要多启动一个进程； 按线程分IP：每个ip（负载生成器）不需要多启动一个进程。 一般来说 JAVA VUSER项目用进程模式,WEB用线程.但是如果WEB项目发现有线程冲突(TPS突然降低为0,而压力机、服务器等都无性能瓶颈时)，也需要改成以进程模式运行。 "},"工具/Loadrunner/Loadrunner报错信息整理.html":{"url":"工具/Loadrunner/Loadrunner报错信息整理.html","title":"Loadrunner报错信息整理","keywords":"","body":"Loadrunner报错信息整理 【问题】Error -10776 Failed to find .cfg file 错误分析：在loadrunner打开脚本的情况下，运行磁盘清理工具，导致运行打开的脚本时，提示Mdrv error：Failed to find .cfg file MsgId:MERR-10777 解决方法：从其它文件夹拷贝3个文件到不能正常运行脚本的文件夹下： default.cfg default.usp *.prm（将*的位置改为脚本的名字） 再次运行脚本，可以正常运行 【问题】 Error -13874: missing newline in C:\\Users\\Administrator\\AppData\\Local\\Temp\\brr_YAR.13\\netdir\\C\\TestingResult\\StressTest.2\\Script\\交强险投保\\username.dat 错误分析：The .dat file needs to have an empty line at the bottom of the file. Also, not sure if all your data is on one line,。 解决办法：Put your cursor on it innotepad/whatever you are using to edit your dat files， note that is an empty line at the bottom。 【问题】Fatal Error -26000: Not enough memory (12320 bytes) for \"new buffer in LrwSrvNetTaskItem::AllocSrvNetBuf\". Aborting 错误分析：报错的时候发现任务管理器里mmdrv.exe 内存占用一直增大,最红mmdrv.exe崩溃（LR兼容C，C语言中内存要手动释放）,或报错原因未脚本中设置使用thread线程执行，线程之间共享内存，所以共享内存出现异常也会导致此报错信息，可以换成进程process方式执行场景。 解决办法：注意内存的使用,尽量减少变量声明,new 的变量用完后要及时用free: 注：web_reg_save_param_ex可能存在消耗资源较多的情况，一般不建议使用，更换成web_reg_save_param进行尝试 【问题】回放时lr报错：Error -26488: Could not obtain informationabout submitted file 错误分析：一般情况下上传文件脚本，会报这个错误，原因为找不到文件 解决办法：录制完脚本后，把要上传的文件放到脚本存放的文件夹里面，重新回放就ok 【问题】 Error -26601: Decompression function (wgzMemDecompressBuffer) failed, return code=-5 (Z_BUF_ERROR), inSize=0, inUse=0, 问题原因：这个错误为数据包较大，未下载完整或其他原因导致解压错误。 解决办法： Runtime-setting--->Internet Protocol--->Preferences--->Options--->General->Network buffer size，设置为122880（默认值为12288） Runtime-setting--->Internet Protocol--->Preferences--->Options--->General->Default block size for Dom memory，设置为163840（默认值为16384） 【问题】Error-26608: HTTP Status-Code=504(Gateway Time-out) 解决办法： 1.在Vuser Generator中的Tools--->Recording Options...--->Recording--->HTTP-based script--->HTML Advanced按钮--->在Script type中选择A script containing explicit URLs only(e.g.web_url,web_submit_data)点击“ok”即可 2.runtime-setting, browser emulation, 取消选择download non-HTML resources即可 【问题】Error -26610: HTTP Status-Code=502 (Bad Gateway) for \"https://***s.com/login/login\" 【问题】Error -27727: Step download timeout (120 seconds) has expired when downloading resource(s). 错误分析：对于HTTP协议，默认的超时时间是120秒（可以在Run-time Settings中修改），客户端发送一个请求到端还没有返回结果，则出现超时错误。 解决办法：Set the \"Step Timeout caused by resources is a warning\" Run-Time Setting to Yes/No to have this message as a warning/error, respectively 【问题】 Error -27728: Step download timeout (120 seconds) has expired 错误分析：对于HTTP协议，默认的超时时间是120秒（可以在Run-time Settings中修改），客户端发送一个请求到端还没有返回结果，则出现超时错误。 解决办法：首先在运行环境中对超时进行设置，默认的超时时间可以设置长一些，再设置多次迭代运行，如果还有超时现象，需要在“Runtime Setting”>“Internet Protocol：Preferences”>“Advanced”区域中设置一个“winlnet replay instead of sockets”选项，再回放是否成功 【问题】 Error -27791: Server \"pcisstage.zsins.com\" has shut down the connection prematurely 解决办法：测试中，并发200,300,400人时，LR没报错，在并发500人时，LR报错”Error -27791: Server \"172.16.xx.xxx\" has shut down the connection prematurely“，同时查看WEB服务器日志：出现这样一条信息： ”INFO: Maximum number of threads (200) created for connector with address null and port 8081“ 查看配置文件参数： 采用的是默认配置，这样在高并发情况下肯定撑不住，所以修改参数配置如下： 重新测试，事物全部成功，系统也未报错。 出现”Error -27791: Server \"172.16.xx.xxx\" has shut down the connection prematurely“的原因即有可能是操作系统网络线程连接资源的原因，也可能是应用软件的原因，当出现问题，随时查看系统日志，能帮助我们更快的定位问题。 【问题】Error -27796: Failed to connect to server \"10.2.9.147:80\": 解决办法：runtime-setting, browser emulation, 将默认勾选的simulate a new vuser on each iteration取消勾选 【问题】Error -29724 : Failed to deliver a p2p message from parent to child process, reason - communication error. 可能引起的原因， 1.查看压力机的内存和CPU的使用率，CPU使用率有点高，估计引起的此问题 2.共享内存溢出，也可能出现这个问题 解决方法 ： $installationfolder$\\dat\\channel_configure.dat $installationfolder$\\launch_service\\dat\\channel_configure.dat 在这两个文件中的[general]部分下添加如下配置。 shared_memory_max_size=100 (修改共享内存为100MB，默认是50MB) 重新启动Controller，问题解决。 【问题】Error -30935 \"Error: Failed to send data by channels – post message failed.\" 解决办法1： 在LR的controller负载生成器的菜单栏，单击【Diagnostics】》configuration》Web Page Diagnostics【Max Vuser Sampling 10%】设置为【Eenable】。 解决办法2：直接去掉勾选Enable the following diagnostics即可。 【问题】Error -35061: No match found for the requested parameter \"CorrelationParameter_2\". Check whether the requested boundaries exist in the response data. Also, if the data you want to save exceeds 256 bytes, use web_set_max_html_param_len to increase the parameter size [MsgId: MERR-35061] 解决办法1：可以用web_set_max_html_param_len增加参数长度，我试过到99999999共8位 web_set_max_html_param_len(\"9999999\"); // 以消耗系统资源为代价 解决办法2：还有，你可以在 web_reg_save_param_ex( \"ParamName=CorrelationParameter_3\", \"LB=c\", \"RB=>\\n后面 加上 \"NotFound=warning\", 保存编译下，就不回再提是错误了。 主要是自动关联造成的左右边界定位不精确，需要保存的值大 【问题】Error -60990 : Two Way Communication Error: Function two_way_comm_post_message / two_way_comm_post_message_ex failed. 在做JAVA接口性能测试时，场景在运行中出现：Code - 60990 Error: Two Way Communication Error: Function two_way_comm_post_message /two_way_comm_post_message_ex failed.错误 及Code - 10343 Error: Communication error: Cannot send the message since reached the shared memory buffer max size错误，一般解决的方法如下： 可能的原因一： 共享内存缓存溢出，造成Controller和Load Generator之间通讯出现问题。 解决方法： 修改两个配置文件。 $installation folder$\\dat\\channel_configure.dat $installation folder$\\launch_service\\dat\\channel_configure.dat 在这两个文件中的[general]部分下添加如下配置。 shared_memory_max_size=100 (修改共享内存为100MB，默认是50MB) 重新启动Controller，问题解决。 【问题】LoadRunner超时错误：在录制Web服务器端，如果超过120秒服务器协议脚本回放时超时情况经常出现，产生错误的原因也有很多，解决的方法也不同。 错误现象：Action.c(16): Error -27728: Step download timeout (120 seconds) has expired when downloading non-resource(s)。 错误分析：对于HTTP协议，默认的超时时间是120秒（可以在LoadRunner中修改），客户端发送一个请求到端还没有返回结果，则出现超时错误。 解决办法：首先在运行环境中对超时进行设置，默认的超时时间可以设置长一些，再设置多次迭代运行，如果还有超时现象，需要在“Runtime Setting”>“Internet Protocol：Preferences”>“Advanced”区域中设置一个“winlnet replay instead of sockets”选项，再回放是否成功。 【问题】LoadRunner脚本中出现乱码：在录制Web协议脚本时出现中文乱码，在回放脚本时会使回放停止在乱码位置，脚本无法运行。 错误现象：某个链接或者图片名称为中文乱码，脚本运行无法通过。 错误分析：脚本录制可能采用的是URL-based script方式，如果程序定义的字符集合采用的是国际标准，脚本就会出现乱码现象。 解决办法：重新录制脚本，在录制脚本前，打开录制选项配置对话框进行设置，在“Recording Options”的“Advanced”选项里先将“Surport Charset”选中，然后选中支持“UTF-8”的选项。 【问题】LoadRunner HTTP服务器状态代码：在录制Web协议脚本回放脚本的过程中，会出现HTTP服务器状态代码，例如常见的页面-404错误提示、-500错误提示。 错误现象1：-404 Not Found服务器没有找到与请求URI相符的资源，但还可以继续运行直到结束。 错误分析：此处与请求URI相符的资源在录制脚本时已经被提交过一次，回放时不可再重复提交同样的资源，而需要更改提交资源的内容，每次回放一次脚本都要改变提交的数据，保证模拟实际环境，造成一定的负载压力。 解决办法：在出现错误的位置进行脚本关联，在必要时插入相应的函数。 错误现象2：-500 Internal Server Error服务器内部错误，脚本运行停止。 错误分析：服务器碰到了意外情况，使其无法继续回应请求。 解决办法：出现此错误是致命的，说明问题很严重，需要从问题的出现位置进行检查，此时需要此程序的开发人员配合来解决，而且产生的原因根据实际情况来定，测试人员无法单独解决问题，而且应该尽快解决，以便于后面的测试。 【问题】LoadRunner请求无法找到：在录制Web协议脚本回放脚本的过程中，会出现请求无法找到的现象，而导致脚本运行停止。 错误现象： Action.c(41): Error -27979: Requested form. not found [MsgId: MERR-27979] Action.c(41): web_submit_form. highest severity level was \"ERROR\",0 body bytes, 0 header bytes [MsgId: MMSG-27178]\" 这时在tree view中看不到此组件的相关URL。 错误分析：所选择的录制脚本模式不正确，通常情况下，基于浏览器的Web应用会使用“HTML-based script”模式来录制脚本；而没有基于浏览器的Web应用、Web应用中包含了与服务器进行交互的代码、基于浏览器的应用中使用HTTPSJava Applet、基于浏览器的应用中包含了向服务器进行通信的JavaScript/VBScript安全协议，这时则使用“URL-based script”模式进行录制。 解决办法：打开录制选项配置对话框进行设置，在“Recording Options”的“Internet Protocol”选项里的“Recording”中选择“Recording Level”为“HTML-based script”，单击“HTML Advanced”，选择“Script. Type”为“A script. containing explicit”。然后再选择使用“URL-based script”模式来录制脚本。 【问题】Abnormal termination, caused by mdrv process termination 解决：修改LR中的D:\\Program Files\\Mercury\\LoadRunner\\dat\\protocols 中的http.lrp信息，在[Vugen]下面新加一条MaxThreadPerProcess=要设置的vuser数量 。 【问题】LoadRunner录制脚本时为什么不弹出IE浏览器？ 答：启动浏览器，打开Internet选项对话框，切换到高级标签，去掉“启用第三方浏览器扩展（需要重启动）”的勾选，然后再次运行VuGen即可解决问题； 【问题】LoadRunner录制脚本时提示默认浏览器不支持解决方法? 答：在Recording Options->Browser->修改浏览器设置->改为IE浏览器访问,重新启动LoadRunner录制脚本就ok； 【问题】LR录制Web脚本时，生成的脚本中存在乱码该如何解决？ 答：录制脚本前，打开录制选项配置对话框Record-Options，进入到Advanced标签，先勾选“Support charset”，选择支持UTF-8。重新录制，就不会出现中文乱码问题了。 【问题】HTML-based script与URL-based script的脚本有什么区别？ 答：使用“HTML-based script”的模式录制脚本，VuGen为用户的每个HTML操作生成单独的步骤，这种脚本看上去比较直观；使用“URL-based script”模式录制脚本时，VuGen可以捕获所有作为用户操作结果而发送到服务器的HTTP请求，然后为用户的每个请求分别生成对应方法。通常，基于浏览器的Web应用会使用“HTML-based script”模式来录制脚本；而没有基于浏览器的Web应用、Web应用中包含了与服务器进行交互的Java Applet、基于浏览器的应用中包含了向服务器进行通信的JavaScript/VBScript代码、基于浏览器的应用中使用了HTTPS安全协议，这时使用“URL-based script”模式进行录制。 【问题】为什么脚本中添加了检查方法Web-find，但是脚本回放时却没有执行？ 答：LoadRunner默认关闭了对文本及图像的检查。进入“Run-time Setting”对话框，依次进入“Internet Protocol→Preferences”，勾选Checks下的“Enable Image and text check”选项即可。 备注：推荐web_reg_find函数针对文本及图像的检查。 【问题】运行时的Pacing设置主要影响什么？ 答：Pacing主要用来设置重复迭代脚本的间隔时间。共有三种方法：上次迭代结束后立刻开始、上次迭代结束后等待固定时间、按固定或随机的时间间隔开始执行新的迭代。根据实际需要设置迭代即可。通常，没有时间间隔会产生更大的压力。 【问题】运行时设置Log标签中，如果没有勾选“Enable logging”，则手工消息可以发送吗？ 答：Enable logging选项仅影响自动日志记录和通过lr_log_message发送的消息。即使没有勾选，虚拟用户脚本中如果使用lr_message、lr_output_message、lr_error_message,仍然会记录其发出的消息。 【问题】LoadRunner如何在IE7+Win2003环境下录制脚本? 答： 方法一: 巧借IE6内核录制脚本 在系统安装目录下C:\\WINDOWS\\ie7\\iexplore.exe,然后在Recording Options->Browser,指定Ie6内核;设置完成确认后,即可以用LoadRunner录制脚本; 方法二 查看了下官方提供LoadRunner解决方法 安装LoadRunner 8.1 Feature Pack 4->然后安装:Internet Explorer 7 (IE 7) support for LoadRunner 8.1 Feature Pack 4； 【问题】LoadRunner 8.0版本的VuGen在录制Web Services协议的脚本时一切正常，但回放时报错误“Error：server returned an incorrectly formatted SOAP response”？ 答：原因是LoadRunner 8.0的VuGen在录制Web Service协议的脚本时存在一个缺陷：如果服务器的操作系统是中文的，VuGen会自动将WSDL文件的头改为，因此会有上面的错误提示。 所以需要打上补丁：“LR80WebservicesFPI_setup.exe”和“lrunner_web_sevices_path_1.exe”。 【问题】VuGen支持Netscape的客户证书吗？ 答：不支持。目前的VuGen 8.0版本中仅支持Internet Explorer的客户端证书。录制脚本时可以先从Netscape中导出所需的证书，然后将其导入到Internet Explorer中，并确保以相同的顺序导出和导入这些证书。而且，在每台将要录制或运行需要证书的Web Vuser脚本的计算机上都要重复执行前面的过程。 【问题】LoadRunner场景执行时第1次报错 error:missing newline in d:\\test\\test1.dat，第2次场景执行时不报错？ 答：Loadruner参数设置test1.dat文本时，需要在最后一个参数后回车确认一下。 【问题】LoadRunner场景执行时出现错误：“load generator is currently running the maximum number of vuser of this type” 答：Loadruuner默认场景并发最大用户数=1000，所以需要设置load generator->Details->Vuser limits->Other Vusers更换参数值即可，如10000；当然需要你的序列号是支持，目前最大支持6.2w的序列号。 【问题】VuGen会修改录制浏览器中的代理服务器设置吗？ 答：会修改。在开始录制基于浏览器的Web Vuser脚本时，VuGen首先会启动指定的浏览器。然后，VuGen会指示浏览器访问VuGen代理服务器。为此，VuGen会修改录制浏览器上的代理服务器设置。默认情况下，VuGen会立即将代理服务器设置更改为Localhost:7777。录制之后，VuGen会将原始代理服务器设置还原到该录制浏览器中。因此，在VuGen进行录制的过程中，不可以更改代理服务器设置，否则将无法正常进行。 【问题】在LoadRunner脚本如何输出当前系统时间？ 答：LoadRunner提供了char ctime(const time_t time)函数，调用参数为一个Long型的整数指针，用于存放返回时间的数值表示。 【问题】Loadruner在一些Web虚拟用户脚本录制后立刻回放没有任何问题，但是当设置迭代次数大于1时，如果进行回放则只能成功迭代一次。从第二次迭代开始发生错误？ 答：“Run-time Setting”的“Browse Emulation”的设置中，勾选了“Simulate a new user on each iteration”及其下面的选项“Clear cache on each iteration”这两个选项的含义是每次迭代时模拟一个新的用户及每次迭代时清除缓存。 【问题】LoadRunner中“Run-time Setting”中的线程和进程运行方式的区别？ 答：如果选择“Run Vuser as a process”，则场景运行时会为每一个虚拟用户创建一个进程；选择“Run Vuser as a thread”则将每个虚拟用户作为一个线程来运行，在任务管理器中只看到一个mmdrv.exe，这种方式的运行效率更高，能造成更大的压力，时默认选项。另外，如果启用了IP欺骗功能，则先在Controller中选中Tools菜单下的“Expert Mode”，然后将Tools菜单下的“Options>General”标签页中的IP地址分配方式也设置为与Vuser运行方式一致，同为线程或进程方式。 【问题】在Controller中运行Web相关测试场景时，经常会有很多超时错误提示，如何处理这类问题？ 答：这主要有脚本的默认超时设置引起。当回放Web脚本时，有时候由于服务器响应时间较长，会产生超时的错误。这时需要修改脚本的运行时配置。进入“Run-time Setting”对话框后，依次进入“Internet Protocol→Preference”。然后点击“Options…”按钮，进入高级设置对话框，可以修改各类超时设置的默认值。 【问题】为什么Windows系统中的CPU、内存等资源仍然充足，但是模拟的用户数量却上不去？ 答：在Windows计算机的标准设置下，操作系统的默认限制只能使用几百个Vuser，这个限制与CPU或内存无关，主要是操作系统本身规定了默认的最大线程数所导致。要想突破Windows这个限制，须修改Windows注册表。以Windows XP Professional为例。 (1)打开注册表后，进入注册表项HKEY_LOCAL_MACHINE中的下列关键字：System\\CurrentControlSet\\Control\\Session Manager\\SubSystems。 (2)找到Windows关键字，Windows关键字如下所示： %SystemRoot%\\system32\\csrss.exe bjectDirectory=\\Windows SharedSection=1024,3072,512 Windows=On SubSystemType=Windows ServerDll=basesrv,1 　　ServerDll=winsrv:UserServerDllInitialization,3 ServerDll=winsrv:ConServerDllInitialization,2 　　ProfileControl=Off MaxRequestThreads=16 　　SharedSection=1024,3072,512关键字的格式为xxxx,yyyy,zzz。其中，xxxx定义了系统范围堆的最大值（以KB为单位），yyyy定义每个桌面堆得大小。 (3)将yyyy的设置从3072更改为8192（即8MB），增加SharedSection参数值。 　　通过对注册表的更改，系统将允许运行更多的线程，因而可以在计算机上运行更多的Vuser。这意味着能够模拟的最大并发用户数量将不受Windows操作系统的限制，而只受硬件和内部可伸缩性限制的约束。 【问题】Controller中设置了用户并发数量，但是运行时为何初始化的用户数量少于实际数量？ 答：主要时设置问题。在Tools→options→Run-time setting中可以设置每次最多初始化的虚拟用户。如果需要100个并发用户，则将该值设置为大于100的数值。另外，注意LoadRunner相关协议License的更新，确保使用的License能够允许所需要的并发用户数量。 【问题】如何让场景的用户执行发生错误继续运行，以保证不间断进行压力测试？ 答：用VuGen打开虚拟用户脚本后，进入“Run-time Settings”对话框后，依次进入“General→Miscellaneous”，可以看到Miscellaneous设置中关于“Error Handling”的配置。勾选“Continue on error”即可让虚拟用户发生错误继续运行。 【问题】为什么.NET虚拟用户有时不能在远程主机执行？ 答：主要时LoadRunner的版本问题。根据笔者的经验，如果是Microsoft Visual Studio 2005开发的虚拟用户，同时LoadRunner客户端的版本低于8.1，执行Controller的主机将会发生错误。 因此要想正确的运行Microsoft Visual Studio 2005开发的.NET虚拟用户，客户端最好装8.1以上的版本，Controller的主机则安装8.0和8.1两个版本均可。此外，产生压力的LoadRunner客户端上预先应该安装.NET运行环境，如果Microsoft Visual Studio 2005开发的是.NET虚拟用户，则应该安装Microsoft .NET Framework SDK v2.0。 【问题】测试分析结果中会统计Action时间，而实际上可能并不须要这些数据，如何只显示自己定义的用户事务？ 答：进入脚本的运行时设置，依次进入General→Miscellaneous。默认情况下，自动事务配置“Automatic Transactions”下有两个选项：第一个是把脚本的Action部分定义为一个事务；第二个时把脚本的每一部分定义为一个事务。去掉这两个勾选后，测试结果将会只显示自己定义的用户事务。 【问题】测试结果中，Summary和平均事务响应时间图里的各个事务的最大值、平均值、最小值为什么显示不一样？ 答：主要是受采样时间的影响。Summary里的事务平均响应时间是根据整个场景执行过程得到的数据计算所得，最大值与最小值也是从整个场景中得到的。平均事务响应时间图主要时按照LoadRunner分析出来的采样频率来获取事务响应时间的最大值与最小值，然后计算平均值。可以通过“Set Granularity”来修改平均事务响应时间图的采样频率。如果把“Granularity”设为场景执行时间，则统计结果将会一致。 【问题】统计结果中的总点击量Total Hits时用户的鼠标点击次数吗？ 答：Total Hits不时按照用户的鼠标点击次数来计算的，而是按照各个虚拟客户端向后台发起的总的请求数来进行统计的。例如在向服务器请求的一个页面中，如果该页面包含5个图片，用户只要单击鼠标就可以访问该页面，而单个虚拟用户在LoadRunner访问的点击量为1+5=6次。 【问题】有些Web测试结果分析图（例如每秒返回页面数）在测试结果分析图中无法看到，如何进行配置？ 答：用VuGen打开虚拟用户脚本后，进入“Run-time Settings”对话框后，依次进入“Internet Protocol>Preference”，可以看到一些Web性能图配置。勾选上面得选项后，Controller将会在测试执行过程中生成数据，然后可在Analysis中查看相应的性能结果分析图。 、Step download timeout (120 seconds) 解决办法： 1、修改run time setting中的请求超时时间，增加到600s,其中有三项的参数可以一次都修改了，HTTP-request connect timeout，HTTP-request receieve timeout，Step download timeout，分别建议修改为600、600、5000；run time setting设置完了后记住还需要在control组件的option的run time setting中设置相应的参数； 2、办法一不能解决的情况下，解决办法如下： 设置runt time setting中的internet protocol-preferences中的advaced区域有一个winlnet replay instead of sockets选项，选项后再回放就成功了。切记此法只对windows系统起作用，此法来自zee的资料。 【问题】问题描述Connection reset by peer 这个问题不多遇见，一般是由于下载的速度慢，导致超时，所以，需要调整一下超时时间 解决办法：Run-time setting窗口中的‘Internet Protocol’－‘Preferences’设置set advanced options（设置高级选项），重新设置一下“HTTP-request connect timeout（sec），可以稍微设大一些”； 【问题】问题描述connection refused 这个的错误的原因比较复杂，也可能很简单也可能需要查看好几个地方，解决起来不同的操作系统方式也不同； 1、首先检查是不是连接weblogic服务过大部分被拒绝，需要监控weblogic的连接等待情况，此时需要增加acceptBacklog，每次增加25%来提高看是否解决，同时还需要增加连接池和调整执行线程数，（连接池数*Statement Cache Size）的值应该小于等于oracle数据库连接数最大值； 2、如果方法一操作后没有变化，此时需要去查看服务器操作系统中是否对连接数做了限制，AIX下可以直接vi文件limits修改其中的连接限制数，还有tcp连接等待时间间隔大小，wiodows类似，只不过wendows修改注册表，具体修改方法查手册，注册表中有TcpDelayTime项； 【问题】问题描述open many files 答：问题一般都在压力较大的时候出现，由于服务器或者应用中间件本身对于打开的文件数有最大值限制造成，解决办法： 1、修改操作系统的文件数限制，aix下面修改limits下的nofiles限制条件，增大或者设置为没有限制，尽量对涉及到的服务器都作修改； 2、方法一解决不了情况下再去查看应用服务器weblogic的commonEnv.sh文件，修改其中的nofiles文件max-nofiles数增大，应该就可以通过了，具体就是查找到nofiles方法，修改其中else条件的执行体，把文件打开数调大；修改前记住备份此文件，防止修改出错； 【问题】问题描述has shut down the connection prematurely 一般是在访问应用服务器时出现，大用户量和小用户量均会出现； 1> 应用访问死掉。 小用户时：程序上的问题。程序上存在数据库的问题 2> 应用服务没有死应用服务参数设置问题 　　 例如：在许多客户端连接Weblogic应用服务器被拒绝，而在服务器端没有错误显示，则有可能是Weblogic中的server元素的AcceptBacklog属性值设得过低。 如果连接时收到connection refused消息，说明应提高该值，每次增加25％ Java连接池的大小设置，或JVM的设置等 3> 数据库的连接 在应用服务的性能参数可能太小了 数据库启动的最大连接数（跟硬件的内存有关） 以上信息有一定的参考价值，实际情况可以参考此类调试。 如果是以上所说的小用户时：程序上的问题。程序上存在数据库的问题，那就必须采用更加专业的工具来抓取出现问题的程序，主要是程序中执行效率很低的sql语句，weblogic可以采用introscope定位，期间可以注意观察一下jvm的垃圾回收情况看是否正常，我在实践中并发500用户和600用户时曾出现过jvm锯齿型的变化，上升下降都很快，这应该是不太正常的。 【问题】问题描述Failed to connect to server 这个问题一般是客户端链接到服务失败，原因有两个客户端连接限制（也就是压力负载机器），一个网络延迟严重。 解决办法： 1、修改负载机器的tcpdelaytime注册表键值，改小； 2、检查网络延迟情况，看问题出在什么环节； 建议为了减少这种情况，办法一最好测试前就完成了，保证干净的网络环境，每个负载机器的压力测试用户数不易过大，尽量平均每台负载器的用户数，这样以上问题出现的概率就很小了。 【问题】问题描述：Overlapped transmission of request to ... WSA_IO_PENDING 解决方法： 1、方法一，在脚本前加入web_set_sockets_option(\"OVERLAPPED_SEND\", \"0\")，禁用TTFB细分，问题即可解决，但是TTFB细分图将不能再使用，附图。 2、方法二，可以通过增加连接池和应用系统的内存，每次增加25%。 【问题】问题描述：Deleted the current transaction ... since response time is not accurate 这个问题不多遇见，一般出现在压力机器上发生ping值为负数（AMD双核CPU），可以重新启动pc机或者打补丁。 【问题】问题描述：HTTP Status-Code=500 (Internal Server Error) for 1、应用服务当掉，重新启动应用服务。 2、当应用系统处于的可用内存处于阀值以下时，出现HTTP Status-Code=500的概率非常高，此时只要增加应用系统的内存，问题即可解决。 【问题】问题描述：Failed to transmit data to network: [10057] Socket is not connected 这个错误是由网络原因造成的，PC1 和PC2上面都装了相同的loadrunner 9.0，且以相同数量的虚拟用户数运行相同的业务（机器上的其他条件都相同），PC1上面有少部分用户报错，PC2上的用户全部执行通过。 【问题】问题描述：Error -27257: Pending web_reg_save_param/reg_find/create_html_param[_ex] request(s) detected and reset at the end of iteration number 1 解决方法：web_reg_save_param位置放错了，应该放到请求页面前面。 【问题】问题描述：通过Controler调用远程代理时报错，Error: CCI security error:You are running under secure mode and the function system is not allowed in this mode. 解决方法：在代理开启的时候，去掉勾选防火墙选项。 【问题】Error -27796: Failed to connect to server \"10.102.8.201:80\": [10048] Address already in use Try changing the registry value HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\tcpip\\Parameters\\TcpTimedWaitDelay to 30and HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\tcpip\\Parameters\\MaxUserPort to 65534 and rebooting the machine See the readme.doc file for more information 解决办法：因为负载生成器的性能太好，发数据包特别快，服务器也响应特别快，从而导致负载生成器的机器的端口在没有timeout之前就全部占满了。在全部占满后，就会出现上面的错误。执行netstat –na命令，可以看到打开了很多端口。所以就调整TCP的time out。即在最后一个端口还没有用到时，前面已经有端口在释放了。 1.打开LoadRunner负载机所在机器的注册表，将HKEY_LOCAL_MACHINESystemCurrentControlSetServicestcpipParameters项中的TcpTimedWaitDelay值设置为5s或者其它（按需要调整）也可以把MaxUserPort值调大（如果这个值不是最大值的话），同时增加脚本的think time，再重启机器。 2.取消勾选controller的run-setting-times-browser-browser emulation “simulate a new user on each iteration”项。 Action.c(6): Error -27792: Failed to transmit data to network: [10054] Connection reset by peer 解决办法：脚本和场景迭代延迟时间设置要相同 【问题】Files transfer error: C:\\Documents and Settings\\Administrator.SCMCC\\Local Settings\\Temp\\brr_YAR.313\\netdir\\e\\测试组\\生产环境\\UUC接口\\uuc_shell\\综合场景2\\results\\res\\10.101.11.82_2073.eve Write failure on machine 10.101.11.82. Check the available disk space. All Vusers on this machine will stop running Error: Failed to write data to the .eve file. Check that the remote host has enough disk space: system error - 磁盘空间不足 Error: Failed returning to the last proper record in the .eve file: \"C:\\Documents and Settings\\Administrator.SCMCC\\Local Settings\\Temp\\brr_YAR.313\\netdir\\e\\测试组\\生产环境\\UUC接口\\uuc_shell\\综合场景2\\results\\res\\10.101.11.82_2073.eve\". 解决办法：压力机磁盘空间不足造成的。 【问题】Action.c(38): Error -27492: \"HttpSendRequest\" failed, Windows error code=12002 and retry limit (0) exceeded for URL 解决办法：在runtime setting中的preferences- ->options-->http-request connect timeout(sec)的值设为999。 【问题】Action.c(6): Error -26612: HTTP Status-Code=500 (Internal Server Error) for http://192.168.0.8:10001/logonConsole.do;jsessionid={JSESSIONID2} 解决办法：造成HTTP－500错误如下几个可能： 1、运行的用户数过多，对服务器造成的压力过大，服务器无法响应，则报HTTP500错误。减小用户数或者场景持续时间，问题得到解决。 2、该做关联的地方没有去做关联，则报HTTP500错误。进行手工或者自动关联，问题得到解决。 3、录制时请求的页面、图片等，在回放的时候服务器找不到，则报HTTP500错误，若该页面无关紧要，则可以在脚本中注释掉，问题将会得到解决。例如：有验证码的情况下，尽管测试时已经屏蔽了，但是录制的时候提交了请求，但回放的时候不存在响应。 4、参数化时的取值有问题，则报HTTP500错误。可将参数化列表中的数值，拿到实际应用系统中进行测试，可排除问题。 5、更换了应用服务器（中间件的更换，如tomcat、websphere、jboss等），还是利用原先录制的脚本去运行，则很可能报HTTP500错误。因为各种应用服务器处理的机制不一样，所录制的脚本也不一样，解决办法只有重新录制脚本。 6、Windows xp2 与ISS组件不兼容，则有可能导致HTTP500错误。对ISS组件进行调整后问题解决。 7、系统开发程序写的有问题，则报HTTP500错误。例如有些指针问题没有处理好的，有空指针情况的存在。修改程序后问题解决。 日志发现报了很多0ra-01000错误,这是oracle达到最大游标参数值,google了下,最大原因可能是JDBC连接没关闭。最后查找weblogic连接池出了问题,很多连接没关闭。查找后台 【问题】Action.c(15): 错误-27496: 内部错误(呼叫客户服务): _eStat (7) != LRW_ITEM_STAT_ENUM_UNHANDLED for HandledTask at 048E180C Action.c(56): Error -27995: Requested link (\"Text=计划管理\") not found [MsgId: MERR-27995] 解决方法：在IE中的工具—>Internet选项—>高级—>HTML设置中选择第二个脚本类型。 【问题】错误 -27279： 内部错误（呼叫客户服务）：Report initialization failed , error code = -2147467259 [MsgId : MERR-27279 ] 解决办法：建议重装一下LR。这种问题有可能和你安装有关.dll文件出错不是说写的程序就能修改的。 【问题】Error -10489 : Exception was raised when calling per-thread-terminate function 在用Loadrunner实施性能测试时，采用Goal模式加压，存在如果持续长时加压时ＬoadRunner的Controller会报 Error -10489 : Exception was raised when calling per-thread-terminate function错误； 产生原因： Unlike the earlier Windows versions, Windows 2000 and Windows XP have the default environment set to C:\\Document and Settings\\\\Local Settings\\Temp instead of C:\\Windows\\temp. This long path with a space can cause several problems for LoadRunner. To resolve the issue, change to a directory without empty spaces。 解决方法：在C盘（或是其它盘均可以）新建TEMP文件夹（为了后续设置临时文件准备），右键＂我的电脑＂->高级->环境变量->编辑修改TEMP变量目录，指身上面新建的目录，如我的指向C:\\TEMP->保存即可。 【问题】Error -27727: Step download timeout (120 seconds)has expired when downloading resource(s). Set the “Resource Page Timeout is a Warning” Run-Time Setting to Yes/No to have this message as a warning/error, respectively 解决方法：Run-Time Setting → Internet Protocol →Preferences→Option →Step download timeout(sec)改为32000 A、应用服务参数设置太大导致服务器的瓶颈 B、页面中图片太多 C、在程序处理表的时候检查字段太大或多 【问题】Action.c(16): Error -27728: Step download timeout (120 seconds) has expired when downloading non-resource(s)。 错误分析：对于HTTP协议，默认的超时时间是120秒（可以在LoadRunner中修改），客户端发送一个请求到服务器端，如果超过120秒服务器端还没有返回结果，则出现超时错误。 解决办法：首先在运行环境中对超时进行设置，默认的超时时间可以设置长一些，再设置多次迭代运行，如果还有超时现象，需要在\"Runtime Setting\">\"Internet Protocol：Preferences\">\"Advanced\"区域中设置一个\"winlnet replay instead of sockets\"选项，再回放是否成功。 【问题】Action.c(38): Error -27492: \"HttpSendRequest\" failed, Windows error code=12002 and retry limit (0) exceeded for URL 解决办法：在runtime setting中的preferences- ->options-->http-request connect timeout(sec)的值设为999。 【问题】Action.c(81):Continuing after Error -27498: Timed out while processing URL=http://172.18.20.70:7001/workflow/bjtel/leasedline/ querystat/ subOrderQuery.do 错误分析：这种错误常常是因为并发压力过大，服务器端太繁忙，无法及时响应客户端的请求而造成的，所以这个错误是正常现象，是压力过大造成的。如果压力很小就出现这个问题，可能是脚本某个地方有错误，要仔细查看脚本，提示的错误信息会定位某个具体问题发生的位置。 解决办法：例如上面的错误现象问题定位在某个URL上，需要再次运行一下场景，同时在其他机器上访问此URL。如果不能访问或时间过长，可能是服务器或者此应用不能支撑如此之大的负载。分析一下服务器，最好对其性能进行优化。如果再次运行场景后还有超时现象，就要在各种图形中分析一下原因，例如可以查看是否服务器、DNS、网络等方面存在问题。最后，增加一下运行时的超时设置，在\"Run-Time Settings\">\"Internet Protocol:Preferences\"中，单击\"options\"，增加\"HTTP-request connect timeout\" 或者\"HTTP-request receive\"的值。 【问题】用strtok函数分割字符串 需要在loadrunner里面获得“15”（下面红色高亮的部分），并做成关联参数。 //Body response 内容： //OK[8,7,5,15,6,5,0,4,0,3,0,3,2,0,0,0,1 用web_reg_save_param取出“8,7,5,15,6,5,0,4,0,3,0,3,2,0,0,0,1”这一段，然后用strtok函数切割出一个个数字，第四个数字就是要找的值 例如： extern char * strtok(char * string, const char * delimiters ); // Explicit declaration char separators[] = \",\"; char * token; lr_save_string(\"1,2,3,4,5,6\",\"str\"); token = (char *)strtok(lr_eval_string(\"{str}\"), separators); // Get the first token if (!token) { lr_output_message (\"No tokens found in string!\"); return( -1 ); } while (token != NULL ) { // While valid tokens are returned lr_output_message (\"%s\", token ); token = (char *)strtok(NULL, separators); // Get the next token } 【问题】测试RTMP协议应该在LoadRunner选择什么协议来录制？ 解决办法：用flex协议，有这几个函数可用： flex_rtmp_connect Connects a client to an RTMP server and sets connection options. flex_rtmp_disconnect Disconnects a client from an RTMP server. flex_rtmp_send Sends messages to an RTMP server. flex_rtmp_receive Receives responses from an RTMP server Flex can record and replay scripts involving RTMP (Real Time Messaging Protocol). In order to enable RTMP simulation, you must configure the recording options for the Flex protocol. To enable RTMP: 1 Open the Recording Options dialog box by selecting Tools > Recording Options or clicking the Options button in the Start Recording dialog box. 2 In the Network > Port Mapping node click Options. 3 Set the Send-Receive buffer size threshold to 1500. 【问题】如何在LoadRunner中运行QTP脚本？ 1、运行准备： 1）勾选QTP的Tools--Options--Run的\"Alow other Mercury products to run tests and components\" 2）录制需要在lr中运行的QTP脚本，并且在QTP脚本中设置事务，Services.StartTransaction \"start\"与Services.EndTransaction \"start\" 2、运行QTP脚本 在LR中运行时选择QTP脚本，为QTP脚本存放目录下文件扩展名为.usr的文件。 注：LR中运行QTP脚本时，只能有一个Vuser,否则将报错：The load generator is currently running the maximum number of Vusers of this type 【问题】在LR中如何忽略Socket接收数据的验证 在LR中对Socket进行性能测试时，LR会自己判断lrs_receive回来的数据的长度，而如果长度不符的话会有时间延迟的情况(这是性能测试完全不能接受的事情)，如果做到这一点呢，经过反复尝试，发现一种简单的方法(用*代替具体的长度)： 类似于将： recv buf1 12 \"Hello, Denny\" 改为： recv buf1 * \"Hello, Denny\" 一切OK。 【问题】LoadRunner9.5的Controller中不能添加Apache的监控 在C:\\Program Files\\HP\\LoadRunner\\dat\\online_graphs中找到online_resource_graphs.rmd文件，修改[Apache]部分中的EnableInUI为1 【问题】VB Vuser开发ADO脚本，提示“user-defined type not defined” 想在VB Vuser写入模拟数据操作的过程，然后在VB Vuser里定义了这个全局变量 Private m_Conn As ADODB.Connection '连接对象 Private m_Reco As ADODB.Recordset '结果集 但是在VB Vuser中不识别这个对象，报出user-defined type not defined 需要在Run-Time 设置中的VBA部分把ADO的库选上 如果用VB Script虚拟用户来开发就不要，直接用CreateObject来创建ADO对象即可 【问题】loadrunner9.5录制脚本时出现c:\\PROGRA~1\\MICROS~1\\office12\\Grooveutil.DLL时出错内存位置访问无效 解决办法：Office2007的问题，IE加载项禁用Groove GFSBrowser Helper 组件 【问题】LR自带的例子端口号怎么修改？ LR自带的例子端口号是1080,我怎么样把这个端口设置我自己想用的端口号8088,在什么地方设置 在LR安装目录下，找到Xitami.config文件，找到portbase，可以修改它（默认是1000）；默认的端口号是portbase+80；要把端口号改成8088，就把portionbase改为8008，保存之后就是了（8088=8008+80）。 【问题】用Web_reg_find查找中文字符串时查找不到？ 解决办法：脚本文件里有个default.cfg ，里面有个参数是 UTF8InputOutput ，将其值改为0 【问题】替代IP Wizard的脚本 LoadRunner自带的“IP Wizard”用起来非常麻烦，要不停的点，重要的是最后还必须重启系统生效。 于是乎写个脚本替代之： 假设客户端IP为 192.168.10.31 假设服务端IP为 192.168.10.10 需要模拟的IP为 110.119.120.122 那么，客户端提供添加虚拟IP的BAT脚本： netsh interface ip add address 本地连接 110.119.120.122 255.255.0.0 对应的删除设置为： netsh interface ip del address 本地连接 110.119.120.122 对应服务器添加虚拟路由的Shell脚本： route add -host 110.119.120.122 gw 192.168.10.31 删除路由的脚本： route del -host 110.119.120.122 gw 192.168.10.31 这样就非常方便了，不用重启任何机器，执行脚本就生效，再执行脚本就取消。 【问题】如何从命令行调用LoadRunner脚本？ Here is the command line that you need to execute to run a VuGen script from the command prompt: \\bin\\mmdrv.exe -usr Note: In order to get all the other options that go with the command, run mmdrv.exe from the command prompt without any options. 【问题】请问\"int64这个类型,在LR中怎么表示\"。我将一段C的代码放在LR中,LR不认int64这个类型,怎么解决? 解决办法：把那段C代码做成DLL，然后在LR中调用。 【问题】loadrunner运行场景时，用户卡在run状态，且退出时卡在gradual exiting状态 原因分析：当你设置了集合点的脚本运行场景时，出现部分用户一直卡在run状态，当你没有设置集合点的脚本运行场景时，在用户退出是部分用户一直卡在gradual exiting状态，且出现错误step download timeout (120 seconds) has expired，以上这两种情况都是一个原因导致的，就是这些卡在run状态或者gradual exiting状态的用户线程已经卡死，一直无法完成本次迭代。 解决办法： 降低一个mmdrv进程的启动数量（mmdrv为loadrunner启动虚拟用户线程的进程，一个mmdrv进程默认启动50个线程） 配置详情： 进入loadrunner安装目录下\\HP\\LoadRunner\\dat\\protocols\\目录，根据你脚本的协议找到对应的*.lrp文件 如：web(http/html)协议选择http.lrp文件、Mobile协议选择Mobile.lrp文件 使用文本方式打开对应的*.lrp文件 找到文件中[Vugen]这一行，在这一行下方加入MaxThreadPerProcess=20，20表示每个进程启动20个线程，根据实际情况调整，也可是试试30。 "},"工具/Loadrunner/Loadrunner经典面试题.html":{"url":"工具/Loadrunner/Loadrunner经典面试题.html","title":"Loadrunner经典面试题","keywords":"","body":"Loadrunner经典面试题 在LoadRunner中为什么要设置思考时间和pacing 答： 录制时记录的是客户端和服务端的交互，如果要精确模拟用户的行为，那么客户操作客户端时花费了很多时间要怎么模拟呢?录入填写提交的内容，从列表中下拉搜索选择特定的值等，这时LOADRUNNER不会记录用户的客户端操作，而是记录了用户这段时间，成为思考时间(Think-time)，因为用户的这些客户端操作不会影响服务端，只是让服务器端在这段时间内没有请求而已。所以加入思考时间就能模拟出熟练的或者生疏的用户操作，接近实际对于服务端的压力。Vuser思考时间模拟实际用户在不同操作之间等待的时间。例如，当用户收到来自服务器的数据时，可能要等待几秒钟查看数据，然后再做出响应。这种延迟就称为“思考时间”。VuGen使用lr_think_time函数将思考时间值录制到 Vuser 脚本中。以下录制的函数指明用户等待了8秒钟才执行下一个操作： lr_think_time(8); 当您运行了Vuser脚本并且Vuser遇到了上述lr_think_time语句时，默认情况下，Vuser将等待8秒钟后再执行下一个操作。可以使用思考时间运行时设置来影响运行脚本时Vuser使用录制思考时间的方式。 如何理解TPS? 答：TPS主要还是体现服务器对当前录制的事务的处理速度快慢。TPS高并不代表性能好。 TPS 是Transactions Per Second的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息来估计得分。客户机使用加权协函数平均方法来计算客户机的得分，软件就是利用客户机的这些信息使用加权协函 数平均方法来计算服务器端的整体TPS得分。 如何使用loadrunner批量添加树型结构数据 /*此段代码为:添加”树状”节点数据，代码源于*****项目，此码仅添加数据到第三层。*/ /*前置条件:用户已登录并具有操作权限*/ /*思路:新增一级节点–>获取一级ID–>添加二级节点–>展开一级节点–>获取二级ID–>添加三级数据*/ /*说明：添加一级节点–>逐个读取一级节点ID–>读到一个一级节点就给它添加二级节点–> 二级节点添加完一次就读一次ID–>读一次二级节点直接添加三级节点*/ /*修改”树状”节点数据的代码类似，Submit修改时，要多建一个参数TreeCode*/ int i,j,k,p; //循环变量 int No1,No2,No3; //分别保存一、二、三级节点的个数 int M1,M2,M3; //分别定义一、二级节点的数量，三级节点不保存数据，故未限制大小 char *MyID1[90],*MyID2[90],m[40]; //MyID1用于储存所有一级节点数据，m为临时数组变量 /* MyID的长度也大于M的长度；m的长度要大于ID的长度+1 */ M1=30;M2=20;M3=10; /*RootID名称需要按模块修改，Control里需要重新参数化*/ lr_save_string (“FindRootIDinWebResource”,”RootID”);//根节点的ID,修改此处即可使用 lr_output_message (“当前根节点的ID号为:%s”,lr_eval_string (“{RootID}”)); for (i=1;iM1) { No1=M1;}//让No1M2) { No2=M2;}//让No2 loadrunner对应用程序性能分析的总结 一个应用程序是由很多个组件组成的，整个应用程序的性能好不好需要从整体入手去分析。 打开analysis页面，将左下角的display only graphs containing data 置为不选，然后选中web page breakdown ，点击“open graph”添加需要分析的功能项。 web page breakdown中显示的是每个页面的下载时间。点选左下角web page breakdown 展开,可以看到每个页中包括的css 样式表，js 脚本，jsp 页面等所有的属性。 在select page to breakdown 中选择页面。选中后，在选择栏下方看到属于它的组件。哪一行的事物占据的时间较长，那么它的消耗时间点就在这里，分析问题也就要从这里入手。 对相应的组件所标注的颜色分析如下： 1、dns resolution 显示使用最近的dns服务器，将dns解析为ip地址所需要的时间，“dns查找”度量是指示dns解析问题或dns服务器问题的一个很好的指示器。 2、connection 显示与包含指定的URL的web服务器建立初始连接所需要的时间。连接度量是一个很好的网络问题指示器。另外，他还能判断服务器是否对请求作出响应。 3、first buffer 显示从初始HTTP请求（通常为get） 到成功收到来自web服务器的第一次缓冲时为止所经过的时间。第一次缓冲度量可以判断是否存在web服务器延迟或者网络滞后。 注意点：由于缓冲区最大为8k，因此第一次缓冲时间可能也就是完成元素下载所需要的时间。 4、ssl handshaking 显示建立ssl连接（包括客户端请求，服务器请求，客户端公用密钥传输，服务器证书传输及其它部分可选阶段）所用的时间。自此点之后，客户端及服务器之间所有的通信都将被加密。 注意点：ssl握手度量仅适用用https通信。 5、receive 显示从服务器收到最后一个字节，并完成下载之前所经过的时间。 接收度量可以查看网络质量，查看用来计算接收速率的时间/大小比率。 6、ftp authentication 显示验证客户端所用的时间。如果使用ftp，则服务器在开始处理客户端命令之前，必须验证该客户端。、 此功能只是用与使用ftp通信。 7、client 显示因浏览器思考时间或其它与客户端有关的延迟而使客户机上的请求发生延迟时，所经过的平均时间。 8、error 显示从发出HTTP请求到返回错误消息（仅限于HTTP错误）期间所经过的平均时间。 分析以上指标，结合系统资源监控指标，会比较准确快速的定位问题。从而对系统的性能及随后的调优提供针对性的意见。 使用LoadRunner进行性能测试的一般步骤是什么？ 确定需要进行测试的业务或交易，通过手工操作和Vuser Generator的录制功能来记录并生成虚拟用户脚本。 手工修改虚拟用户脚本，确定脚本能够成功回放。 在Controller中对场景进行配置后，启动测试。在测试过程中，Controller控制Load Generator对被测系统的加压方式和行为。 Controller同时负责搜集被测系统各个环节的性能数据。各个Loaded Generator会记录最终用户响应时间和脚本执行的日志。 压力运行结束后，Loaded Generaror将数据传输到Controller中，有Controller对测试结果进行汇总。 借助数据分析工具Analysis对性能测试数据进行分析，确定瓶颈和调优方法。 对系统进行针对性的调优，重复进行压力测试，确定性能是否有所提高。 loadrunner中的设置线程和进程的区别 loadrunner中，在进行运行设置中有一项选择，是按进程运行Vuser或按线程运行Vuser?下面进行分别来讲： 1.按进程运行Vuser：Controller将使用驱动程序mdrv运行Vuser。如果按进程方式运行每个Vuser，则对于每个Vuser实例，都将启动一个mdrv进程。如果设置了10个Vuser，则在任务管理器中出现10个mdrv进程。多个mdrv进程肯定会占用大量内存及其他系统资源，这就限制了可以在任一负载生成器上运行的Vuser的数量。 2.按线程运行Vuser:及设置了10个Vuser，其只会调用一个驱动程序mdrv.而每个Vuser都按线程运行，这些线程Vuser将共享父进程的内存段。这就节省了大量内存控件，从而可以在一个负载生成器上运行更多的Vuser。 任何选择都是有两面性的。选择线程方式运行Vuser会带来一些安全问题。因为线程的资源是从进程资源中分配出来的，因此同一个进程中的多个线程会有共享的内存空间，这样可能会引起多个线程的同步问题，调度不好，就会出问题，不如A线程要用的资源就必须等待B线程释放，而B也在等待其他资源释放才能继续。这就会出现这样的问题：同一个测试场景，用线程并发就会超时失败或报错，而用进程并发就没错。 虽然会有区别，但两种方式的运行都会给服务端造成的压力是一样的。 如何用loadrunner录制sql server测试一个sql语句或存储过程的执行 本次通过loadRunner录制SQL Server介绍一下如何测试一个sql语句或存储过程的执行性能。 主要分如下几个步骤完成： 第一步、测试准备 第二步、配置ODBC数据源 第三步、录制SQL语句在Sql Server查询分析器中的运行过程 第四步、优化录制脚本，设置事务 第五步、改变查询数量级查看SQL语句的性能 第六步、在controller中运行脚本 下面开始具体的介绍： 测试准备阶段我们首先要确认测试数据库服务器：我们可以在本地安装SQL SERVER数据库服务端及客户端，也可以确定一台装好的SQL SERVER服务器。 接下来，准备测试数据：对数据库测试时我们要考虑的不是SQL语句是否能够正确执行，而是在某数量级的情况下SQL语句的执行效率及数据库服务的运行情况，所以我们分别准备不同数量级的测试数据，即根据实际的业务情况预估数据库中的记录数，在本次讲解中我们不考虑业务逻辑也不考虑数据表之间的关系，我们只建立一张表，并向此表中加入不同数量级的数据，如分别加入1000条、10000条、50000条、100000条数据查看某SQL语句的执行效率。 在查询分析器中运行如下脚本： --创建测试数据库 create database loadrunner_test; use loadrunner_test --创建测试数据表 create table test_table (username varchar(50),sex int,age int,address varchar(100),post int) --通过一段程序插入不同数量级的记录，具体的语法在这里就不多说了 declare @i int set @i=0 while @i 0 begin rollback; select @@error end else begin commit; set @i = @i+1 end end 好了，执行完上述语句后，建立的数据表中已经有1000条记录了，下面进行第二步的操作，配置ODBC数据源，为了能让loadrunner能够通过ODBC协议连接到我们建立的SQL SERVER数据路，我们需要在本机上建立ODBC数据源，建立方法如下： 控制面板—性能和维护—管理工具—数据源（ODBC）--添加，在列表中选择SQL SERVER点击完成，根据向导输入数据源名称，链接的服务器，下一步，输入链接数据库的用户名和密码，更改链接的数据库，完成ODBC的配置，如果配置正确的话，在最后一步点击“测试数据源”，会弹出测试成功的提示。 配置好ODBC数据源后就要录制SQL语句在查询分析器中的执行过程了： 1、 打开loadrunner，选择ODBC协议 2、 在start recording中的application type 选择win32 application；program to record中录入SQL SERVER查询分析器的路径“..\\安装目录\\isqlw.exe” 3、 开始录制，首先通过查询分析器登录SQL SERVER，在打开的查询分析器窗口中输入要测试的SQL语句，如“select * from test_table;” 4、 在查询分析器中执行该语句，执行完成后，结束录制 好了，现在就可以看到loadrunner生成的脚本了，通过这些语句，我们可以看出，登录数据库的过程、执行SQL语句的过程。 接下来，我们来优化脚本，我们分别为数据库登录部分和执行SQL语句的部分加一个事物，在增加一个double的变量获取事务执行时间，简单内容如下： Action() { double trans_time; //定义一个double型变量用来保存事务执行时间 lr_start_transaction(\"sqserver_login\"); //设置登录事务的开始 lrd_init(&InitInfo, DBTypeVersion); //初始化链接（下面的都是loadrunner生成的脚本了，大家可以通过帮助查到每个函数的意思） lrd_open_context(&Ctx1, LRD_DBTYPE_ODBC, 0, 0, 0); lrd_db_option(Ctx1, OT_ODBC_OV_ODBC3, 0, 0); lrd_alloc_connection(&Con1, LRD_DBTYPE_ODBC, Ctx1, 0 /*Unused*/, 0); ……………… trans_time=lr_get_transaction_duration( \"sqserver_login\" ); //获得登录数据库的时间 lr_output_message(\"sqserver_login事务耗时 %f 秒\", trans_time); //输出该时间 lr_end_transaction(\"sqserver_login\", LR_AUTO); //结束登录事务 lr_start_transaction(\"start_select\");//开始查询事务 lrd_cancel(0, Csr2, 0 /*Unused*/, 0); lrd_stmt(Csr2, \"select * from test_table;\\r\\n\", -1, 1, 0 /*None*/, 0);//此句为执行的SQL lrd_bind_cols(Csr2, BCInfo_D42, 0); lrd_fetch(Csr2, -10, 1, 0, PrintRow24, 0); …………….. trans_time=lr_get_transaction_duration( \"start_select\" ); //获得该SQL的执行时间 lr_output_message(\"start_select事务耗时 %f 秒\", trans_time); //输出该时间 lr_end_transaction(\"start_select\", LR_AUTO); //结束查询事务 优化后，在执行上述脚本后，就可以得到登录到数据库的时间及运行select * from test_table这条语句的时间了，当然我们也可以根据实际情况对该条语句进行参数化，可以测试多条语句的执行时间，也可以将该语句改为调用存储过程的语句来测试存储过程的运行时间。 接下来把该脚本在controller中运行，设置虚拟用户数，设置集合点，这些操作我就不说了，但是值得注意的是，没有Mercury 授权的SQL SERVER用户license，在运行该脚本时回报错，提示“You do not have a license for this Vuser type. 最起码在VUGen中运行该脚本我们可以得到任意一个SQL语句及存储过程的执行时间，如果我们测试的B/S结构的程序 如何完全卸载LoadRunner? 1.首先保证所有LoadRunner的相关进程（包括Controller、VuGen、Analysis和Agent Process）全部关闭。 2.备份好LoadRunner安装目录下测试脚本，一般存放在LoadRunner安装目录下的“scrīpts”子目录里。 3.在控制面板的“删除与添加程序”中运行LoadRunner的卸载程序。如果弹出提示信息关于共享文件的，都选择全部删除。 4.卸载向导完成后，重新启动电脑。完成整个LoadRunner卸载过程。 5.删除整个LoadRunner目录。（包括Agent Process） 6.在操作中查找下列文件，并且删除它们（如果有） 1） wlrun. 2） vugen.7.运行注册表程序（开始－ 运行－ regedit）8.删除下列键值： 如果只安装了MI公司的LoadRunner这一个产品，请删除： HKEY_LOCAL_MACHINESOFTWAREMercury Interactive. HKEY_CURRENT_USERSOFTWAREMercury Interactive. 否则请删除： HKEY_LOCAL_MACHINESOFTWAREMercury InteractiveLoadRunner. HKEY_CURRENT_USERSOFTWAREMercury InteractiveLoadRunner. 9.最后清空回收站 完成了以上操作就可以正常的重新安装LoadRunner。安装LoadRunner时最好关闭所有的杀毒程序。 loadrunner如何遍历一个页面中的url并进行访问？ 代码如下： Action() { char temp[64]; int num = 0 ; int i = 0 ; char *str ; // char *temp ; //获取函数，是一个数组 web_reg_save_param( “UrlList”, “LB/ALNUMIC= LoadRunner分析实例面试题 1.Error: Failed to connect to server “172.17.7.230″: [10060] Connection Error: timed out Error: Server “172.17.7.230″ has shut down the connection prematurely 分析： A、应用服务死掉。 (小用户时：程序上的问题。程序上处理数据库的问题，实际测试中多半是服务器链接的配置问题) B、应用服务没有死 (应用服务参数设置问题) 对应的Apache和tomcat的最大链接数需要修改，如果连接时收到connection refused消息，说明应提高相应的服务器最大连接的设置，增加幅度要根据实际情况和服务器硬件的情况来定，建议每次增加25%! C、数据库的连接 (数据库启动的最大连接数(跟硬件的内存有关)) D、我们的应用程序spring控制的最大链接数太低 性能调优的基本原则是什么？ 如果某个部分不是瓶颈，就不要试图优化。 优化是为系统提供足够的资源并且充分的利用资源，而不是无节制的扩充资源。 优化有时候也意味着合理的分配或划分任务。 优化可能会过头，注意协调整个系统的性能。 LoadRunner如何插入Text/Image 检查点 ？ 在进行压力测试时，为了检查Web 服务器返回的网页是否正确，这些检查点验证网页上是否存在指定的Text 或者Image，还可以测试在比较大的压力测试环境中，被测的网站功能是否保持正确。 操作步骤: 1、可以将视图切换到TreeView 视图 2、在树形菜单中选择需要插入检查点的一项，然后点鼠标右键，选择将检查点插到该操作执行前(Insert Before)还是执行后(Insert After)。 3、在弹出对话框中选择web Checks 下面的Image Check 或是 Text Check 4、对需要检查点设置相关的属性 LoadRunner如何从现有数据库中导入数据 通过 LoadRunner，可以从数据库中导入数据以用于参数化。您可以用下列两种方法中的一种导入数据： 1.新建查询 2.指定 SQL 语句 VuGen 提供一个指导您完成从数据库中导入数据的过程的向导。在该向导中，您可以指定如何导入数据（通过 MS Query 新建查询或者指定 SQL 语句）。 导入数据之后，它被另存为一个扩展名为.dat 的文件，并且存储为常规参数文件。 LoadRunner如何模拟用户思考时间？ 用户在执行两个连续操作期间等待的时间称为“思考时间”。 Vuser 使用lr_think_time 函数模拟用户思考时间。录制 Vuser 脚本时，VuGen 将录制实际的思考时间并将相应的 lr_think_time 语句插入到 Vuser 脚本。 可以编辑已录制的 lr_think_time 语句，也可在 脚本中手动添加更多lr_think_time 语句。 以秒为单位指定所需的思考时间 LoadRunner脚本中如何插入集合点(Rendezvous) 插入集合点(Rendezvous) 集合点：如果脚本中设置集合点，可以达到绝对的并发，但是集合点并不是并发用户的代名词，设置结合点和不设置结合点，需要看你站在什么角度上来看待并发，是整个服务器，还是提供服务的一个事务； 1.插入集合点是为了衡量在加重负载的情况下服务器的性能情况。 2.在测试计划中，可能会要求系统能够承受1000 人甚至更多同时提交数据，在LR 中可以通过在提交数据操作前面加入集合点，当虚拟用户运行到提交数据的集合点时，LR 就会检查同时有多少用户运行到集合点，从而达到测试计划中的需求。 3.Rendezvous，也可在录制时按插入集合点按钮?具体的操作方法如下：在需要插入集合点的前面，点击菜单Insert 注意：集合点经常和事务结合起来使用。集合点只能插入到Action 部分，vuser_init和vuser_end 中不能插入集合点。 LoadRunner如何插入事务(Transaction) ？ 事务为衡量服务器的性能，需要定义事务。 LoadRunner 运行到该事务的开始点时，LR就会开始计时，直到运行到该事务的结束点，这个事务的运行时间在结果中会有反映。 插入事务操作可以在录制过程中进行，也可以在录制结束后进行。LR 运行在脚本中插入不限数量的事务。 在菜单中单击Insert Transaction后，输入事务名称，也可在录制过程中进行，在需要定义事务的操作后面插入事务的“结束点”。默认情况下，事务的名称列出最近的一个事务名称。一般情况下，事务名称不用修改。事务的状态默认情况下是LR_AUTO。一般情况下，我们也不需要修改状态的 LoadRunner如何创建脚本？ 启动VuGen:选择需要新建的协议脚本，可以创建单协议，或是多协议脚本 点击Start Record按钮，输入程序地址，开始进行录制 使用VuGen进行录制：创建的每个 Vuser 脚本都至少包含三部分：vuser_init、一个或多个 Actions 及vuser_end。录制期间，可以选择脚本中 VuGen 要插入已录制函数的部分。运行多次迭代的Vuser 脚本时，只有脚本的Actions部分重复，而vuser_init和vuser_end部分将不重复 HTML-Based scrīpt 和URL-Based scrīpt 录制的区别？ 1.基于浏览器的应用程序推荐使用HTML-Based scrīpt。 2.不是基于浏览器的应用程序推荐使用URL-Based scrīpt。 3.如果基于浏览器的应用程序中包含了Java scrīpt并且该脚本 向服务器产生了请求，比如DataGrid的分页按钮等，也要使用URL-Based scrīpt方式录制。 4.基于浏览器的应用程序中使用了HTTPS安全协议，使用URL-Based scrīpt方式录制。 5.录制过程中不要使用浏览器的“后退”功能，LoadRunner对其支持不太好。 LoadRunner如何设置Recording Options 选项？（以单协议http/html为例） 1.菜单tools->Recording Options进入录制的设置窗体 2.Recording标签页:选用哪种录制方式 3.Browser标签页：浏览器的选择 4.Recording Proxy 标签页：浏览器上的代理设置 5.Advanced 标签页：可以设置录制时的think time，支持的字符集标准等 6.Correlation标签页：手工设置关联，通过关联可在测试执行过程中保存动态值。使用这些设置可以配置 VuGen 在录制过程中执行的自动关联的程度。 LoadRunner如何选择协议？ 很多人使用loadrunner录制脚本时都得不到理想的结果，出现这种情况大多是由于录制脚本时选择了不当的协议。那我们在录制脚本前如何选择合适的通信协议呢？用单协议还是双协议？ LoadRunner属于应用在客户端的测试工具，在客户端模拟大量并发用户去访问服务器，从而达到给服务器施加压力的目的。所以说LoadRunner模拟的就是客户端，其脚本代表的是客户端用户所进行的业务操作，即只要脚本能表示用户的业务操作就可以。 1.LR支持多种协议，请大家一定要注意，这个地方协议指的是你的Client端通过什么协议访问的Server，Client一般是面向最终使用者的，Server是第一层Server端，因为现在的体系架构中经常Server层也分多个层次，什么应用层，什么数据层等等，LR只管Client如何访问第一层Server. 2.特别要注意某些应用，例如一个Web系统，这个系统是通过ActiveX控件来访问后台的，IE只是一个容器，而ActiveX控件访问后台是通过COM/DCOM协议的，这种情况就不能使用Web协议，否则你什么也录制不到，所以，LR工程师一定要了解应用程序的架构和使用的技术。 如HTTPS，一般来讲一定要选择多协议，但在选择具体协议的时候一定只选Web协议，这时候才能作那个端口映射。 通常协议选择 1.对于常见的B/S系统，选择Web(Http/Html) 2.测一个C/S系统，根据C/S结构所用到的后台数据库来选择不同的协议，如果后台数据库是sybase，则采用sybaseCTlib协议，如果是SQL server,则使用MS SQL server的协议，至于oracle 数据库系统，当然就使用Oracle 2-tier协议。 3.对于没有数据库的C/S（ftp,smtp）这些可以选择Windwos Sockets协议。 4.至于其他的ERP，EJB（需要ejbdetector.jar），选择相应的协议即可. 一般可以使用Java vuser协议录制由java编写的C/S模式的软件, ,当其他协议都没有用时,只能使用winsocket协议 Loadrunner支持哪些常用协议？ 1.Web(HTTP/HTML) 2.Sockets 3..net 协议 4.web services 5.常用数据库协议（ODBC，ORACLE，SQLSERVER 等） 6.邮件(SMTP、pop3) 7.其它协议 性能测试的类型都有哪些？ 负载测试(Load Test) 通过逐步增加系统负载，测试系统性能的变化，并最终确定在满足性能指标的情况下，系统所能承受的最大负载量的测试。 压力测试(Stress Test) 通过逐步增加系统负载，测试系统性能的变化，并最终确定在什么负载条件下系统性能处于失效状态，并以此来获得系统能够提供的最大服务级别的测试。 压力测试是一种特定类型的负载测试。 疲劳强度测试 通常是采用系统稳定运行情况下能够支持的最大并发用户数或者日常运行用户数，持续执行一段时间业务，通过综合分析交易执行指标和资源监控指标来确定系统处理最大工作量强度性能的过程。 疲劳强度测试可以反映出系统的性能问题，例如内存泄漏等。 大容量测试(Volume Test) 对特定存储、传输、统计、查询业务的测试。 并发用户数是什么？跟在线用户数什么关系？ 并发主要是针对服务器而言，是否并发的关键是看用户操作是否对服务器产生了影响。因此，并发用户数量的正确理解为：在同一时刻与服务器进行了交互的在线用户数量，这种交互既可以是单向的传输数据，也可以是双向的传送数据。 1.并发用户数是指系统运行期间同一时刻进行业务操作的用户数量。 2.该数量取决于用户操作习惯、业务操作间隔和单笔交易的响应时间。 3.使用频率较低的应用系统并发用户数一般为在线用户数的5%左右。 4.使用频率较高的应用系统并发用户数一般为主线用户数的10%左右 Loadrunner常用的分析点都有哪些？ Vusers： 提供了生产负载的虚拟用户运行状态的相关信息，可以帮助我们了解负载生成的结果。 Rendezvous（负载过程中集合点下的虚拟用户）： 当设置集合点后会生成相关数据，反映了随着时间的推移各个时间点上并发用户的数目，方便我们了解并发用户的变化情况。 Errors（错误统计）： 通过错误信息可以了解错误产生的时间和错误类型，方便定位产生错误的原因。 Errors per Second（每秒错误）： 了解在每个时间点上错误产生的数目，数值越小越好。通过统计数据可以了解错误随负载的变化情况，定为何时系统在负载下开始不稳定甚至出错。 Average Transaction Response Time（平均事务响应时间）： 反映随着时间的变化事务响应时间的变化情况，时间越小说明处理的速度越快。如果和用户负载生成图合并，就可以发现用户负载增加对系统事务响应时间的影响规律。 Transactions per Second（每秒事务）： TPS吞吐量，反映了系统在同一时间内能处理事务的最大能力，这个数据越高，说明系统处理能力越强。 Transactions Summary（事务概要说明） 统计事物的Pass数和Fail数，了解负载的事务完成情况。通过的事务数越多，说明系统的处理能力越强；失败的事务数越小说明系统越可靠。 Transaction performance Summary(事务性能概要)： 事务的平均时间、最大时间、最小时间柱状图，方便分析事务响应时间的情况。柱状图的落差越小说明响应时间的波动小，如果落差很大，说明系统不够稳定。 Transaction Response Time Under Load（用户负载下事务响应时间）： 负载用户增长的过程中响应时间的变化情况，该图的线条越平稳，说明系统越稳定。 Transactions Response time(事务响应时间百分比)： 不同百分比下的事务响应时间范围，可以了解有多少比例的事物发生在某个时间内，也可以发现响应时间的分布规律，数据越平稳说明响应时间变化越小。 Transaction Response Time（各时间段上的事务数）： 每个时间段上的事务个数，响应时间较小的分类下的是无数越多越好。 Hits per Second（每秒点击）： 当前负载重对系统所产生的点击量记录，每一次点击相当于对服务器发出了一次请求，数据越大越好。 Throughput（吞吐量）： 系统负载下所使用的带宽，该数据越小说明系统的带宽依赖就越小，通过这个数据可以确定是不是网络出现了瓶颈。 HTTP Responses per Second（每秒HTTP响应）： 每秒服务器返回各种状态的数目，一般和每秒点击量相同。点击量是客户端发出的请求数，而HTTP响应数是服务器返回的响应数。如果服务器的响应数小于点击量，那么说明服务器无法应答超出负载的连接请求。 Connections per Second（每秒连接）： 统计终端的连接和新建的连接数，方便了解每秒对服务器产生连接的数量。同时连接数越多，说明服务器的连接池越大，当连接数随着负载上升而停止时，说明系统的连接池已满，通常这时候服务器会返回504错误。需要修改服务器的最大连接来解决该问题。 LoadRunner不执行检查方法怎么解决？ 在录制Web协议脚本中添加了检查方法Web_find，但是在脚本回放的过程中并没有执行。 错误现象：在脚本中插入函数Web_find，在脚本中设置文本以及图像的检查点，但是在回放过程中并没有对设置的检查点进行检查，即Web_find失效。 错误分析：由于检查功能会消耗一定的资源，因此LoadRunner默认关闭了对文本以及图像的检查，所以在设置检查点后，需要开启检查功能。 解决办法：打开运行环境设置对话框进行设置，在“Run-time Settings”的“Internet Protocol”选项里的“Perference”中勾选“Check”下的“Enable Image and text check”选项。 LoadRunner请求无法找到如何解决？ 在录制Web协议脚本回放脚本的过程中，会出现请求无法找到的现象，而导致脚本运行停止。 错误现象：Action.c(41): Error -27979: Requested form. not found [MsgId: MERR-27979] Action.c(41): web_submit_form. highest severity level was “ERROR”,0 body bytes, 0 header bytes [MsgId: MMSG-27178]” 这时在tree view中看不到此组件的相关URL。 错误分析：所选择的录制脚本模式不正确，通常情况下，基于浏览器的Web应用会使用“HTML-based script”模式来录制脚本；而没有基于浏览器的Web应用、Web应用中包含了与服务器进行交互的Java Applet、基于浏览器的应用中包含了向服务器进行通信的JavaScript/VBScript代码、基于浏览器的应用中使用HTTPS安全协议，这时则使用“URL-based script”模式进行录制。 解决办法：打开录制选项配置对话框进行设置，在“Recording Options”的“Internet Protocol”选项里的“Recording”中选择“Recording Level”为“HTML-based script”，单击“HTML Advanced”，选择“Script. Type”为“A script. containing explicit”。然后再选择使用“URL-based script”模式来录制脚本。 LoadRunner HTTP服务器状态代码都有哪些？如何解决？ 在录制Web协议脚本回放脚本的过程中，会出现HTTP服务器状态代码，例如常见的页面-404错误提示、-500错误提示。 错误现象1：-404 Not Found服务器没有找到与请求URI相符的资源，但还可以继续运行直到结束。 错误分析：此处与请求URI相符的资源在录制脚本时已经被提交过一次，回放时不可再重复提交同样的资源，而需要更改提交资源的内容，每次回放一次脚本都要改变提交的数据，保证模拟实际环境，造成一定的负载压力。 解决办法：在出现错误的位置进行脚本关联，在必要时插入相应的函数。 错误现象2：-500 Internal Server Error服务器内部错误，脚本运行停止。 错误分析：服务器碰到了意外情况，使其无法继续回应请求。 解决办法：出现此错误是致命的，说明问题很严重，需要从问题的出现位置进行检查，此时需要此程序的开发人员配合来解决，而且产生的原因根据实际情况来定，测试人员无法单独解决问题，而且应该尽快解决，以便于后面的测试。 这两天测试并发修改采购收货时，录制回放正确，运行脚本，集合点3个并发时，却老是出错 如下： Action.c(30): Error -26612: HTTP Status-Code=500 (Internal Server Error) forhttp://192.168.100.88:88/Purchase/stockin_action.asp?Oper=Edt 解决过程：按Help提示在浏览器输入原地址，发现提示“请重新登陆系统”。 被此误导，偶以为是Session ID、或Cookie失效，于是尝试找关联，花了N多时间。可是脚本里确实不存在需要关联的地方呀，系统默认关联了。 与程序员沟通，证实此过程不会涉及到Session ID 或Cookie。那为什么？ 因为集合点下一站就是修改的提交操作，于是查找web_submit_data–>定位查找Log文档 注意点：怎么找log文件 –>Controller–>Results–>Results Settings 查找本次log文件保存目录–>到该目录下查找log文件夹–>打开 惊喜的发现其中竟然有所有Vuser 的运行log。–>打开Error 查找报错的Vuser–>打开相应的log文件 查找error，然后偶发现了一段让偶热泪盈眶的话： Action.c(30): Microsoft OLE DB Provider for ODBC Drivers 错误 ’800040 Action.c(30): 05′\\n Action.c(30): \\n Action.c(30): [Microsoft][ODBC SQL Server Driver][SQL Server]事务（进程 ID 53） Action.c(30): 与另一个进程已被死锁在 lock 资源上，且该事务已被选作死锁牺牲品。请重新运行该事务。 Action.c(30): \\n Action.c(30): \\n Action.c(30): /Purchase/stockin_action.asp，行 Action.c(30): 205 Action.c(30): Error -26612: HTTP Status-Code=500 (Internal Server Error) for “http://192.168.100.88:88/Purchase/stockin_action.asp?Oper=Edt” [MsgId: MERR-26612] Action.c(30): t=37758ms: Closing connection to 192.168.100.88 after receiving status code 500 [MsgId: MMSG-26000] Action.c(30): t=37758ms: Closed connection to 192.168.100.88:88 after completing 43 requests [MsgId: MMSG-26000] Action.c(30): t=37760ms: Request done “http://192.168.100.88:88/Purchase/stockin_action.asp?Oper=Edt” [MsgId: MMSG-26000] Action.c(30): web_submit_data(“stockin_action.asp”) highest severity level was “ERROR”, 1050 body bytes, 196 header bytes [MsgId: MMSG-26388] Ending action Action. [MsgId: MMSG-15918] Ending iteration 1. [MsgId: MMSG-15965] Ending Vuser… [MsgId: MMSG-15966] Starting action vuser_end. [MsgId: MMSG-15919] 解决了。。。。。。。 很寒。由此可以看出，查看日志文件是件多么重要的事情啊！！！！！ 其实并发死锁本来就是本次的重点，之前是写事务，但没有做整个页面的锁定，只是写在SQL里。程序员说这样容易出现页面错误， 又改成页面锁定，具体怎么锁偶没看懂asp外行。之前事务冲突，偶让他写个标志，定义个数值字段增一，偶就可以直观看出来了。 这次改成页面就删掉这些标志了，于是出错就无处可寻。 这次最大的收获就是知道怎么查找Controller的log文件。以后看到Error就不会被牵着鼻子走了~~~~ LoadRunner脚本中出现乱码如何解决？ 在录制Web协议脚本时出现中文乱码，在回放脚本时会使回放停止在乱码位置，脚本无法运行。 错误现象：某个链接或者图片名称为中文乱码，脚本运行无法通过。 错误分析：脚本录制可能采用的是URL-based script方式，如果程序定义的字符集合采用的是国际标准，脚本就会出现乱码现象。 解决办法：重新录制脚本，在录制脚本前，打开录制选项配置对话框进行设置，在“Recording Options”的“Advanced”选项里先将“Surport Charset”选中，然后选中支持“UTF-8”的选项。 LoadRunner超时错误如何解决？ 在录制Web协议脚本回放时超时情况经常出现，产生错误的原因也有很多，解决的方法也不同。 错误现象1：Action.c(16): Error -27728: Step download timeout (120 seconds) has expired when downloading non-resource(s)。 错误分析：对于HTTP协议，默认的超时时间是120秒（可以在LoadRunner中修改），客户端发送一个请求到服务器端，如果超过120秒服务器端还没有返回结果，则出现超时错误。 解决办法：首先在运行环境中对超时进行设置，默认的超时时间可以设置长一些，再设置多次迭代运行，如果还有超时现象，需要在“Runtime Setting”>“Internet Protocol：Preferences”>“Advanced”区域中设置一个“winlnet replay instead of sockets”选项，再回放是否成功。 错误现象2：Action.c(81):Continuing after Error -27498: Timed out while processing URL=http://172.18.20.70:7001/workflow/bjtel/leasedline/ querystat/ subOrderQuery.do 错误分析：这种错误常常是因为并发压力过大，服务器端太繁忙，无法及时响应客户端的请求而造成的，所以这个错误是正常现象，是压力过大造成的。 如果压力很小就出现这个问题，可能是脚本某个地方有错误，要仔细查看脚本，提示的错误信息会定位某个具体问题发生的位置。 解决办法：例如上面的错误现象问题定位在某个URL上，需要再次运行一下场景，同时在其他机器上访问此URL。如果不能访问或时间过长，可能是服务器或者此应用不能支撑如此之大的负载。分析一下服务器，最好对其性能进行优化。 如果再次运行场景后还有超时现象，就要在各种图形中分析一下原因，例如可以查看是否服务器、DNS、网络等方面存在问题。 最后，增加一下运行时的超时设置，在“Run-Time Settings”>“Internet Protocol:Preferences”中，单击“options”，增加“HTTP-request connect timeout”或者“HTTP-request receive”的值。 Error -27257: Pending web_reg_save_param/reg_find/create_html_param如何解决？ 问题描述Error -27257: Pending web_reg_save_param/reg_find/create_html_param[_ex] request(s) detected and reset at the end of iteration number 1 解决方法：web_reg_save_param位置放错了，应该放到请求页面前面。 Failed to transmit data to network: [10057]Socket is not connected什么错误？ 这个错误是由网络原因造成的，PC1和PC2上面都装了相同的loadrunner 9.0，且以相同数量的虚拟用户数运行相同的业务（机器上的其他条件都相同），PC1上面有少部分用户报错，PC2上的用户全部执行通过。 Overlapped transmission of request to … WSA_IO_PENDING错误如何解决？ 这个问题，解决方法： 1、方法一，在脚本前加入web_set_sockets_option(“OVERLAPPED_SEND”, “0″)，禁用TTFB细分，问题即可解决，但是TTFB细分图将不能再使用，附图。 2、方法二，可以通过增加连接池和应用系统的内存，每次增加25%。 Failed to connect to server错误是什么原因？ 这个问题一般是客户端链接到服务失败，原因有两个客户端连接限制（也就是压力负载机器），一个网络延迟严重，解决办法： 1、修改负载机器注册表中的TcpTimedWaitDelay减小延时和MaxUserPort增加端口数。注：这将增加机器的负荷。 2、检查网络延迟情况，看问题出在什么环节。 建议为了减少这种情况，办法一最好测试前就完成了，保证干净的网络环境，每个负载机器的压力测试用户数不易过大，尽量平均每台负载器的用户数，这样以上问题出现的概率就很小了。 has shut down the connection prematurely什么错误？ 一般是在访问应用服务器时出现，大用户量和小用户量均会出现。 来自网上的解释： 1>应用访问死掉 小用户时：程序上的问题。程序上存在数据库的问题 2>应用服务没有死 应用服务参数设置问题 例如： 在许多客户端连接Weblogic应用服务器被拒绝，而在服务器端没有错误显示，则有可能是Weblogic中的server元素的AcceptBacklog属性值设得过低。如果连接时收到connection refused消息，说明应提高该值，每次增加25％Java连接池的大小设置，或JVM的设置等 3>数据库的连接 在应用服务的性能参数可能太小了 数据库启动的最大连接数（跟硬件的内存有关） 以上信息有一定的参考价值，实际情况可以参考此类调试。 如果是以上所说的小用户时：程序上的问题。程序上存在数据库的问题，那就必须采用更加专业的工具来抓取出现问题的程序，主要是程序中执行效率很低的sql语句，weblogic可以采用introscope定位，期间可以注意观察一下jvm的垃圾回收情况看是否正常，我在实践中并发500用户和600用户时曾出现过jvm锯齿型的变化，上升下降都很快，这应该是不太正常的。 实际测试中，可以用telent站点看看是否可以连接进去，可以通过修改连接池中的连接数和适当增加应用内存值，问题可以解决。 LoadRunner出现open many files错误是什么原因？ 问题一般都在压力较大的时候出现，由于服务器或者应用中间件本身对于打开的文件数有最大值限制造成，解决办法： 1、修改操作系统的文件数限制，aix下面修改limits下的nofiles限制条件，增大或者设置为没有限制，尽量对涉及到的服务器都作修改。 2、方法一解决不了情况下再去查看应用服务器weblogic的commonEnv.sh文件，修改其中的nofiles文件max-nofiles数增大，应该就可以通过了，具体就是查找到nofiles方法，修改其中else条件的执行体，把文件打开数调大。修改前记住备份此文件，防止修改出错。 3、linux上可以通过ulimit –HSn 4096来修改文件打开数限制，也可以通过ulimit -a来查看。 4、linux上可以通过lsof -p pid | wc -l来查看进程打开的句柄数。 connection refused是什么原因？ 这个的错误的原因比较复杂，也可能很简单也可能需要查看好几个地方，解决起来不同的操作系统方式也不同。 1、首先检查是不是连接weblogic服务过大部分被拒绝，需要监控weblogic的连接等待情况，此时需要增加acceptBacklog，每次增加25%来提高看是否解决，同时还需要增加连接池和调整执行线程数，（连接池数*Statement Cache Size）的值应该小于等于oracle数据库连接数最大值。 2、如果方法一操作后没有变化，此时需要去查看服务器操作系统中是否对连接数做了限制，AIX下可以直接vi文件limits修改其中的连接限制数、端口数，还有tcp连接等待时间间隔大小，wiodows类似，只不过windows修改注册表，具体修改注册表中有TcpTimedWaitDelay和MaxUserPort项，键值在[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters]。因为负载生成器的性能太好，发数据包特别快，服务器也响应特别快，从而导致负载生成器的机器的端口在没有timeout之前就全部占满了。在全部占满后，就会出现上面的错误。执行netstat –na命令，可以看到打开了很多端口。所以就调整TCP的time out。即在最后一个端口还没有用到时，前面已经有端口在释放了。 a,这里的TcpTimedWaitDelay默认值应该中是30s，所以这里，把这个值调小为5s（按需要调整）。 b,也可以把MaxUserPort调大（如果这个值不是最大值的话）。 Loadrunner出现 Connection reset by peer.是什么原因？ 这个问题不多遇见，一般是由于下载的速度慢，导致超时，所以，需要调整一下超时时间。 解决办法：Run-time setting窗口中的‘Internet Protocol’－‘Preferences’设置set advanced options（设置高级选项），重新设置一下“HTTP-request connect timeout（sec），可以稍微设大一些”。 Step download timeout (120 seconds)是什么问题？ 这是一个经常会遇到的问题，解决得办法走以下步骤： 1、修改run time setting中的请求超时时间，增加到600s,其中有三项的参数可以一次都修改了，HTTP-request connect timeout，HTTP-request receieve timeout，Step download timeout，分别建议修改为600、600、5000。run time setting设置完了后记住还需要在control组件的option的run time setting中设置相应的参数。 2、办法一不能解决的情况下，解决办法如下： 设置runt time setting中的internet protocol-preferences中的advaced区域有一个winlnet replay instead of sockets选项，选项后再回放就成功了。切记此法只对windows系统起作用 Loadrunner相关问题 1,action和init、end除了迭代的区别还有其他吗？ 在init、end 中不能使用集合点、事务等。 2,HTTP的超时有哪三种？ HTTP-request connect timeout、HTTP-request receive timeout、step download timeout 3,在什么地方设置HTTP页面filter? 在runtime_settings中download filter里面进行设置。 4,pot mapping的原理是什么？ 就是代理服务器 5,如何设置可以让一个虚拟IP对应到一个Vuser? 利用线程和进程做中介，逻辑上的对应。 选中Expert Mode，设置Options中的General 6,什么是contentcheck?如何来用？ ContentCheck的设置是为了让VuGen 检测何种页面为错误页面。如果被测的Web 应用没有使用自定义的错误页面，那么这里不用作更改；如果被测的Web 应用使用了自定义的错误页面，那么这里需要定义，以便让VuGen 在运行过程中检测，服务器返回的页面是否包含预定义的字符串，进而判断该页面是否为错误页面。如果是，VuGen就停止运行，指示运行失败。 使用方法：点击在runtime settings中点击“contentcheck”，然后新建立一个符合要求的应用程序和规则，设定需要查找的文本和前缀后缀即可使用。 7,network中的speed simulation是模拟的什么带宽？ 模拟用户访问速度的带宽。 8,进程和线程有什么区别？ 进程和线程的区别网上很多，不作过多讨论，重点说一下其在LR中选择的区别。最显著的区别是：线程有自己的全局数据。线程存在于进程中,因此一个进程的全局变量由所有的线程共享。由于线程共享同样的系统区域,操作系统分配给一个进程的资源对该进程的所有线程都是可用的,正如全局数据可供所有线程使用一样。在Controller中将使用驱动程序（如mdrv.exe、r3vuser.exe）运行vuser。如果按进程运行每个vuser，则对于每个vuser实例，都将反复启动同一驱动程序并将其加载到内存中。将同一驱动程序加载到内存中会占用大量的RAM（随机存储器）及其他系统资源。这就限制了可以在任一负载生成器上运行的vuser数量。如果按线程运行每个vuser，Controller为每50个vuser（默认情况下）仅启动驱动程序（如mdrv.exe）的一个实例。该驱动程序将启动几个vuser，每个vuser都按线程运行。这些线程vuser将共享父驱动进程的内存段。这就消除了多次重新加载驱动程序/进程的需要，节省了大量内存空间，从而可以在一个负载生成器上运行更多的Vuser。 9,生成WEB性能图有什么意义？大概描述即可。 可以很直观的看到，在负载下系统的运行情况以及各种资源的使用情况，可以对系统的性能瓶颈定位、性能调优等起到想要的辅助作用。 10,如何刷新controller里的脚本？ 在controller中，点击detailis－Refresh-script即可。 11,WAN emulation是模拟什么的？ 答：是模拟广域网环境的。模拟大量网络基础架构的行为。可以设置突出 WAN 效果的参数（如延迟、丢包、动态路由效果和链接故障），并监控模拟设置对网络性能的影响。 12,如何把脚本和结果放到load generator的机器上？ 在controller中，点击Results-Results settings,在里面进行相应的设置即可。 13,如何设置才能让集合点只对一半的用户生效？ 对集合点策略进行相应的设置即可。即在controller中，点击Scenario－Rendezvous-policy进行相应的设置即可，由于题目中“一半的用户”没有说明白具体指什么样的用户，现在不好确定具体对里面的哪个选项进行设置。 14,在设置windows资源图监控的时候，用到的是什么端口和协议？在这一过程中，会有大概哪些问题？（大概描述） 这个比较容易看吧，连上去，netstat -nao就可以看了 microsoft-ds ：445 ；要有权限、开启服务。 LR中的API分为几类？ Ａ：通用的ＡＰＩ：，就是跟具体的协议无关，在任何协议的脚本里都能用的； Ｂ：针对协议的：像lrs前缀是winsock的；lrd的是针对database; Ｃ：自定义的：这个范围就比较广了； 比如至少有Java Vuser API 、lrapi、XML API。还可以添加WindowsAPI和自定义函数库。 树视图和脚本视图各有什么优点？ Tree View的好处是使用户更方便地修改脚本，Tree View支持拖拽，用户可以把任意一个节点拖拽到他想要的地方，从而达到修改脚本的目的。用户可以右键单击节点，进行修改/删除当前函数参数属性，增加函数等操作，通过Tree View能够增加LoadRunner提供的部分常用通用函数和协议相关函数。 Script View适合一些高级用户，在Script View中能够看到一行行的API函数，通过Script View向脚本中增加一些其他API函数，对会编程的高手来说很方便 LR的协议包分为多少类？ 协议包不是指vuser类型。打开ＬＲ后，在选择vuser类型时，我们一般选择的上面一个下拉框都是all protocol。那个就是我说的协议包。 应用程序部署解决方案：Citrix ICA。 客户端/服务器：DB2 CLI、DNS、Informix、MS SQL Server、ODBC、Oracle（2层）、Sybase Ctlib、Sybase Dblib和Windows Sockets协议。 自定义：C模板、Visual Basic模板、Java模板、JavaScript和VBScript类型的脚本。 分布式组件：适用于COM/DCOM、Corba-Java和Rmi-Java协议。 电子商务：FTP、LDAP、Palm、PeopleSoft 8 mulit-lingual、SOAP、Web（HTTP/HTML）和双Web/WinSocket协议。 Enterprise Java Bean：EJB测试和Rmi-Java协议。 ERP/CRM：Baan、Oracle NCA、PeopleSoft-Tuxedo、SAP-Web、SAPGUI、 Siebel-DB2 CLI、Siebel-MSSQL、Siebel-Web和Siebel-Oracle协议。 传统：终端仿真（RTE）。 邮件服务：Internet邮件访问协议（IMAP）、MS Exchange（MAPI）、POP3和SMTP。 中间件：Jacada和Tuxedo（6、7）协议。 流数据：Media Player（MMS）和Real协议。 无线：i-Mode、VoiceXML和WAP协议。 需要关联的数据怎么确定？ （１）通过LR自动关联来确定。 （２）通过手动关联，查找服务器返回的动态数据，利用关联函数来确定。 （３）对录制好的脚本，通过“scan action for correlations或CTRL+F8”来进行扫描查找需要关联的数据 （４）如果知道需要做关联数据的左右边界等信息，可以自己添加相应的关联的规则来录制脚本，从而确定需要关联的数据。 场景设置有哪几种方法？ 性能测试用例设计首先要分析出用户现实中的典型场景，然后参照典型场景进行设计。下面详细介绍一下常见的三类用户场景： 一天内不同时间段的使用场景。在同一天内，大多数系统的使用情况都会随着时间发生变化。例如对于新浪、网易等门户网站，在周一到周五早上刚一上班时，可能邮件系统用户比较多，而上班前或者中午休息时间则浏览新闻的用户较多；而对于一般的OA系统则早上阅读公告的较多，其他时间可能很多人没有使用系统或者仅有少量的秘书或领导在起草和审批公文。这类场景分析的任务是找出对系统产生压力较大的场景进行测试。 系统运行不同时期的场景。系统运行不同时期的场景是大数据量性能测试用例设计的依据。随着时间的推移，系统历史数据将会不断增加，这将对系统响应速度产生很大的影响。大数据量性能测试通常会模拟一个月、一季度、半年、一年、……的数据量进行测试，其中数据量的上限是系统历史记录转移前可能产生的最大数据量，模拟的时间点是系统预计转移数据的某一时间。 不同业务模式下的场景。同一系统可能会处于不同的业务模式，例如很多电子商务系统在早上8点到10点以浏览模式为主，10点到下午3点以定购模式为主，而在下午3点以后可能以混合模式为主。因此需要分析哪些模式是典型的即压力较大的模式，进而对这些模式单独进行测试，这样做可以有效的对系统瓶颈进行隔离定位。与“一天内不同时间段的场景测试”不同，“不同业务模式下的场景测试”更专注于某一种模式的测试，而“一天内不同时间段的场景测试”则多数是不同模式的混合场景，更接近用户的实际使用情况 什么是吞吐量？ 网络定义：吞吐量是指在没有帧丢失的情况下，设备能够接受的最大速率。 软件工程定义：吞吐量是指在单位时间内中央处理器（CPU）从存储设备读取->处理->存储信息的量。 影响吞吐量因素： 1、存储设备的存取速度，即从存储器读出数据或数据写入存储器所需时间； 2、CPU性能： 1）时钟频率； 2）每条指令所花的时钟周期数（即CPI）； 3）指令条数； 3、系统结构，如并行处理结构可增大吞吐量。 解释以下函数及他们的不同之处： Lr_debug_message Lr_output_message Lr_error_message Lrd_stmt Lrd_fetch 1. 【lr_debug_message函数组】 int lr_debug_message (unsigned int message_level, const char *format, … ); 中文解释：lr_debug_message函数在指定的消息级别处于活动状态时发送一条调试信息。 如果指定的消息级别未出于活动状态，则不发送消息。 您可以从用户界面或者使用lr_set_debug_message， 将处于活动状态的消息级别设置为MSG_CLASS_BRIEF_LOG 或MSG_CLASSS_EXTENDED_LOG。 要确定当前级别，请使用lr_get_debug_message。 unsigned int lr_get_debug_message ( ); 中文解释：lr_get_debug_message函数返回当前的日志运行时设置。该设置确定发送到输出端的信息。日志设置是使用运行时设置对 话框或通过使用lr_set_debug_message函数指定的。 int lr_set_debug_message (unsigned int message_level, unsigned int on_off); 中文解释：lr_set_debug_message函数设置脚本执行的调试消息级别message_lvl。 通过设置消息级别，可以确定发送哪些信息。 启动设置的方法是将LR_SWITCH_ON作为on_off传递，禁用设置的方法是传递LR_SWITCH_OFF。 2.【lr_output_message】 int lr_output_message (const char *format, exp1, exp2,…expn.); 中文解释：lr_output_message函数将带有脚本部分的行号的消息发送到输出窗口和日志文件。 3. 【lr_message】 int lr_message (const char *format, exp1, exp2,…expn.); 中文解释：lr_message函数将信息发送到日志文件和输入窗口。在VuGen中运行时，输入文件为output.txt。 4. 【lr_log_message】 int lr_log_message (const char *format, exp1, exp2,…expn.); 中文解释：lr_log_message函数将消息发送到Vuser或代理日志文件（取决于应用程序），而不是发送到输出窗口。通过向日志文件 发送错误消息或其他信息性消息，可以将该函数用于调试。 5. 【lr_error_message】 int lr_error_message (const char *format, exp1, exp2,…expn. ); 中文解释：lr_error_message函数将错误消息发送到输出窗口和Vuser日志文件。要发送不是特定错误消息的特殊通知，请使用lr_output_message。 6. 【lrd_stmt 】： 将SQL语句与光标关联 7. 【lrd_fetch】： 提取结果集中得下一条记录 如何识别性能瓶颈？ 性能瓶颈，可以侦测到使用显示器。这些显示器可能是应用服务器的监测，监控Web服务器，数据库服务器的监控和网络监控。他们帮助找到了动乱地区的情况，原因增加响应时间。该测量通常性能的响应时间，吞吐量，访问/秒，网络延迟图表等 响应时间和吞吐量之间的关系是什么？ 吞吐量图显示的是虚拟用户每秒钟从服务器接收到的字节数。当和响应时间比较时，可以发现随着吞吐量的降低，响应时间也降低，同样的，吞吐量的峰值和最大响应时间差不多在同时出现。 以线程方式运行的虚拟用户有哪些优点？ VuGen提供了用多线程的便利。这使得在每个生成器上可以跑更多的虚拟用户。如果是以进程的方式跑虚拟用户，为每个用户加载相同的驱动程序到内存中，因此占用了大量的内存。这就限制了在单个生成器上能跑的虚拟用户数。如果按进程运行，给定的所有虚拟用户数（比如100）只是加载一个驱动程序实例到内存里。每个进程共用父驱动程序的内存，因此在每个生成器上可以跑更多的虚拟用户。 LR中如何编写自定义函数？ 在创建用户自定义函数前我们需要和创建DLL（external libary）。把库放在VuGen bin 目录下。一旦加了库，把自定义函数分配做一个参数。该函数应该具有一下格式：__declspec (dllexport) char (char, char*)。 如何调试LoadRunner脚本？ VuGen 包含两个选项来帮助调试 Vuser 脚本：“分步运行”命令和断点。这些选项不适用于VBscript 和 VB 应用程序类型的 Vuser。 要查看“调试”工具栏，请执行下列操作： 右键单击工具栏区域，然后选择“调试”。“调试”工具栏将显示在工具栏区域中。 “分步运行”命令 “分步运行”命令在运行脚本时一次运行一行。通过该命令，可以依次查看脚本每一行的执行情况。 要分步运行脚本，请执行下列操作： 1 依次选择“Vuser” > “分步运行”，或者单击“调试”工具栏上的“步骤”按钮。VuGen 将执行脚本的第一行。 2 继续单击“步骤”按钮来执行该脚本，直到脚本运行完成为止。 断点 通过断点可以使脚本在特定位置暂停执行。它可用于在执行期间的预定点处检查 该脚本对应用程序的影响。要管理书签，请参阅第 186 页上的“断点管理器”。 要设置断点，请执行下列操作： 1 将光标置于脚本中要停止执行的行上。 2 依次选择“插入” > “切换断点”，或者单击“调试”工具栏上的“断点”按钮。也可以按键盘上的 F9 键。将在脚本的左边距显示“断点”符号 ( )。 3 要禁用断点，请将光标置于包含断点符号的行上，然后单击“调试”工具栏上的“启用 / 禁用断点”按钮。“断点”符号中将会显示一个白点 ( )。禁用一个断点后，执行将在下一个断点处暂停。再次单击该按钮可以启用断点。要删除断点，请将光标置于包含断点符号的行上，然后单击“断点”按钮或者按F9 键。 要运行包含断点的脚本，请执行下列操作： 1 照常运行脚本。 到达断点时， VuGen 将暂停脚本的执行。可以检查脚本运行到断点时的效果，并进行必要的更改，然后从断点处重新启动脚本。 2 要继续执行，请依次选择“Vuser” > “运行”。重新启动后，脚本将继续执行，直到遇到下一个断点或脚本完成。 断点管理器 可以使用断点管理器来查看和管理断点。通过断点管理器您可以操纵脚本中的所有断点。 要打开断点管理器，请选择“编辑” > “断点”。 要跳至脚本中的断点处，请执行下列操作： 1 从列表中选择一个断点。 2 单击“在脚本中突出显示”。则将在脚本中突出显示该行。 注意，每次只能突出显示一个断点。 管理断点 可以通过断点管理器添加、删除、禁用断点或者为断点设置条件 要添加断点，请执行下列操作： 1 单击“添加”。将打开“添加断点”对话框。 2 选择“操作”，并指定要添加断点的行号。 3 单击“确定”。该断点将被添加到断点列表中。 要删除断点，请执行下列操作： 1 要删除单个断点，请选择该断点并单击“删除”。 2 要立即删除所有断点，请单击“全部删除”。 要启用 / 禁用断点，请执行下列操作： 1 要启用断点，请在“操作”列内选中操作的复选框。 2 要禁用断点，请在“操作”列内清除操作的复选框。 通过断点管理器您可以将断点设置为在某些条件下暂停执行。 要为断点设置条件，请执行下列操作： 1 要在特定的迭代次数后暂停运行脚本，请选择“当迭代次数为下值时暂停”并输入所需的数字。 2 要在参数 X 具有特定值时暂停脚本，请选择“当参数 X 值为下值时暂停”并输入所需的值。有关参数的详细信息，请参阅第 8 章“使用 VuGen 参数”。 书签 当使用脚本视图时， VuGen 使您可以在脚本中各个不同的置放置书签。您可以在书签之间导航来分析和调试代码。 要创建书签，请执行下列操作： 1 将光标置于所需的位置，然后按 Ctrl + F2 组合键。VuGen 会在脚本的左边距放置一个图标。 2 要删除书签，请单击要删除的标签，然后按 Ctrl + F2 组合键。VuGen 将删除左边距处的图标。 3 要在书签之间移动，请执行下列操作： 要移动到下一个书签，请按 F2 键。 要导航到上一个书签，请按 Shift + F2 组合键 您还可以通过“编辑” > “书签”菜单项来创建书签和在书签之间进行导航。 注意： 只能在当前操作中的书签之间导航。要导航到另一操作中的书签，请在左窗格中选择该操作然后按 F2 键。 “转至”命令 要不使用书签在脚本中进行导航，可以使用“转至”命令。请依次选择“编辑”> “转至行”并指定脚本的行号。在树视图中也支持此种导航。 如果要检查特定步骤或函数的“回放日志”消息，请在 VuGen 中选择该步骤，然后依次选择“编辑” > “转至回放日志中的步骤”。VuGen 将把光标放置在“输出”窗口的“回放日志”选项卡中的相应步骤处。 你在VUGen中何时选择关闭日志？何时选择标准和扩展日志？ Run-time，log， 当调试脚本时，可以只输出错误日志，当在场景找你管加载脚本时，日志自动变为不可用。 Standard Log Option：选择标准日志时，就会在脚本执行过程中，生成函数的标准日志并且输出信息，供调试用。大型负载测试场景不用启用这个选项。 扩展日志包括警告和其他信息。大型负载测试不要启用该选项。用扩展日志选项，可以指定哪些附加信息需要加到扩展日志中 请解释一下如何录制web脚本？ 解释： 1.基于浏览器的应用程序推荐使用HTML-based Script, 脚本中采用HTML页面的形式来表示，这种方式的Script脚本容易维护，容易理解，使用该选项中的advance中的第一个选项，如果单纯的HTML方式，是不允许使用关联的。 2．不是基于浏览器的应用程序推荐使用URL-based Script，脚本中的表示采用基于URL 的方式，不是很好阅读。 解释： 1 . 是否记录录制过程中的ThinkTime，如果记录，还可以设置最大值，一般我不记录这个值。 2．通知Vugen去重新设置每个action之间的Http context，缺省是需要的。 3．完整记录录制过程的log， 4．保存一个本地的snapshot，可以加速显示 5．把html的title放到web_reg_find函数里面 6 . 支持的字符集标准 7．Http header的录制，我们采用缺省即可，不需要用web_add_header去录制非标准的header信息。 对录制的content的内容进行filter，不作为resource处理的。 解释：这个就是我前面提到的关联，系统已经预先设置好了一些常见的关联rules，我们录制脚本之前，可以把系统的可以把系统的都关掉，定义自己的，只是有的时候，它不能自动关联，就干脆手工关联。 什么是场景？场景的重要性有哪些?如何设置场景? 用例场景应该说是写测试用例，甚至是分析测试要素、设计测试策略另外一个重要的依据了。首先，软件研发最终是要再用户那里使用的，用例场景都将在用户的使用过程中被一一实现。其次，需求的文档会变，设计会变，但用户的用例场景是基本上不会变的（除非是政策或者战略上的变更）。这样使测试工作的任务更加明确了，也更加容易定义修改的优先级以及在修改建议上和开发人员达成一致。毕竟满足用户的用例场景是首要的。与微软等技术主导的软件企业相比，我向国内的软件更多的是市场主导，用户需求主导的软件企业和设计思想甚至开发模式。用例场景会比需求文档和分析报告更容易理解，同时也是对于理解用户的需求，产品设计更有帮助。在测试中能够帮助我们发现不仅仅是功能上的问题。 测试有两个目的：确认功能是否实现正确；确认软件是否实现了正确的功能。 什么是集合点？设置集合点有什么意义?Loadrunner中设置集合点的函数是哪个? 插入集合点是为了衡量在加重负载的情况下服务器的性能情况。在测试计划中，可能会要求系统能够承受1000 人同时提交数据，在LoadRunner 中可以通过在提交数据操作前面加入集合点，这样当虚拟用户运行到提交数据的集合点时，LoadRunner 就会检查同时有多少用户运行到集合点，如果不到1000 人，LoadRunner 就会命令已经到集合点的用户在此等待，当在集合点等待的用户达到1000 人时，LoadRunner 命令1000 人同时去提交数据，从而达到测试计划中的需求。 说明：在脚本中设置了“集合点”后，当运行场景时可以对集合点进行设置，可以设置当百分之多少用户到达时，系统开始执行以下操作，详细的可以参考中文的用户手册 添加方法： 1、其中录制脚本script view中添加：lr_rendezvous(“XXX”); 2、在录制脚本的tree view里添加：rendezvous-XXX; LoadRunner由哪些部件组成？ 使用LoadRunner 完成测试一般分为四个步骤： 1）Virtual User Generator 创建脚本 创建脚本，选择协议 录制脚本 编辑脚本 检查修改脚本是否有误 2）中央控制器（Controller）来调度虚拟用户 创建Scenario，选择脚本 设置机器虚拟用户数 设置Schedule 如果模拟多机测试，设置Ip Spoofer 3）运行脚本 分析scenario 4）分析测试结果 "},"工具/Loadrunner/Loadrunner对IBMMQ进行性能测试.html":{"url":"工具/Loadrunner/Loadrunner对IBMMQ进行性能测试.html","title":"Loadrunner对IBMMQ进行性能测试","keywords":"","body":"Loadrunner对IBMMQ进行性能测试 一、概述 使用Loadrunner对IBM MQ进行性能测试，需要用到java vuser以及java编码知识。此次先介绍什么是IBM MQ，然后java vuser的使用与配置细节，最后介绍IBM MQ的测试脚本。 二、IBM MQ介绍 IBM MQ（IBM Message Queue）是IBM的一款商业消息中间产品，适用于分布式计算环境或异构系统之中。消息队列技术是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上，队列存储消息直到它们被应用程序读走。 通过消息队列应用程序可独立地执行，它们不需要知道彼此的位或在继续执行前不需要等待接收程序接收此消息。 对列管理器 队列管理器是MQ系统中最上层的一个概念，由它为我们提供基于队列的消息服务。 对列 队列是消息的安全存放地，队列存储消息直到它被应用程序处理。 通道 通道是MQ系统中队列管理器之间传递消息的管道，它是建立在物理的网络连接之上的一个逻辑概念，也是MQ产品的精华。 在 MQ中，主要有三大类通道类型，即消息通道，MQI通道和Cluster通道。 消息通道是用于在MQ的服务器和服务器之间传输消息的，需要强调指出的是， 该通道是单向的，它又有发送(sender), 接收(receive), 请求者(requestor), 服务者(server)等不同类型，供用户在不同情况下使用。 MQI通道是MQ Client和MQ Server之间通讯和传输消息用的，与消息通道不同，它的传输是双向的。 群集(Cluster)通道是位于同一个MQ 群集内部的队列管理器之间通讯使用的。 消息 在MQ中，我们把应用程序交由MQ传输的数据定义为消息，我们可以定义消息的内容并对消息进行广义的理解，比如：用户的各种类型的数据文件，某个应用向其 它应用发出的处理请求等都可以作为消息。消息有两部分组成：消息描述符(Message Discription或Message Header)，描述消息的特征，如：消息的优先级、生命周期、消息Id等；消 息体(Message Body)，即用户数据部分。在MQ中，消息分为两种类型，非永久性(non-persistent)消息和永久性(persistent)消息，非永久 性消息是存储在内存中的，它是为了提高性能而设计的，当系统掉电或MQ队列管理器重新启动时，将不可恢复。当用户对消息的可靠性要求不高，而侧重系统的性 能表现时，可以采用该种类型的消息，如：当发布股票信息时，由于股票信息是不断更新的，我们可能每若干秒就会发布一次，新的消息会不断覆盖旧的消息。永久 性消息是存储在硬盘上，并且纪录数据日志的，它具有高可靠性，在网络和系统发生故障等情况下都能确保消息不丢、不重。 此外，在MQ中，还有逻辑消息和物理消息的概念。利用逻辑消息和物理消息，我们可以将大消息进行分段处理，也可以将若干个本身完整的消息在应用逻辑上归为一组进行处理。 三、Loadrunner java vuser的使用与配置 准备 loadrunner 11 jdk 1.6（32位） 所需jar包名(安装MQ windows后，在安装目录中可以找到) com.ibm.mq.jar connector.jar com.ibm.mq.jmqi.jar com.ibm.mq.headers.jar com.ibm.mq.commonservices.jar 创建 打开loadrunner选择新建Java Vuser，如下图所示： 配置 开启Run-time Setting，导入之前准备好的jar，如下图所示： 配置Java VM，先选中红框所示单选框，然后输入本机所安装JDK位置，如下图所示： 四、测试脚本 以下为MQ发送测试脚本，利用此脚本只用根据相应测试需求，调整注释部分： /* * LoadRunner Java script. (Build: _build_number_) * * Script Description: simple test harness to PUT messages on a MQ queue * */ import lrapi.lr; import com.ibm.mq.*; import java.util.HashMap; import java.util.Random; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class Actions { // 队列管理器 String queueMgrName = \"QMCCPS01\"; // 队列名 String putQueueName = \"CNAPS_BPH\"; // 通道名 String channel = \"SYSTEM.DEF.SVRCONN\"; // 消息 String msgBody = \"\"; // ip 地址 String hostname = \"10.40.2.16\"; // 端口号 int port = 1601; // 字符集 int CCSID = 819; MQQueueManager queueMgr = null; MQQueue getQueue = null; MQQueue putQueue = null; MQPutMessageOptions pmo = new MQPutMessageOptions(); MQGetMessageOptions gmo = new MQGetMessageOptions(); MQMessage requestMsg = new MQMessage(); MQMessage responseMsg = new MQMessage(); public int init() throws Throwable{ // Open a connection to the queue manager and the put/get queues try { // As values set in the MQEnvironment class take effect when the // MQQueueManager constructor is called, you must set the values // in the MQEnvironment class before you construct an MQQueueManager // object. MQEnvironment.hostname=hostname; MQEnvironment.port=port; MQEnvironment.CCSID =CCSID; MQEnvironment.properties.put(\"transport\", \"MQSeries\"); // MQEnvironment.channel = \"SYSTEM.DEF.SVRCONN\"; MQEnvironment.channel = channel; queueMgr = new MQQueueManager(queueMgrName); // Access the put/get queues. Note the open options used. putQueue = queueMgr.accessQueue(putQueueName, 49); // getQueue= queueMgr.accessQueue(getQueueName, // MQC.MQOO_INPUT_AS_Q_DEF | MQC.MQOO_OUTPUT); } catch (Exception e) { e.printStackTrace(); } return 0; } public int action() throws Throwable{ // This is an XML message that will be put on the queue. Could do some // fancy // things with XML classes here if necessary. // The message string can contain {parameters} if lr.eval_string() is // used. // Clear the message objects on each iteration. requestMsg.clearMessage(); responseMsg.clearMessage(); //读取报文内容，并利用replace函数参数化报文编号 String req = read(\"G:\\\\大额贷记来账.xml\"); String data_msg = \"\"; String msgBody = req.replace(\"2010101000000000\", \"20200117\" + data_msg + \"\"); // Create a message object and put it on the request queue try { pmo.options = MQC.MQPMO_NEW_MSG_ID; // The queue manager replaces // the contents of the MsgId // field in MQMD with a new // message identifier. // should be put on this queue requestMsg.report = MQC.MQRO_PASS_MSG_ID; // If a report or reply is // generated as a result // of this message, the // MsgId of this message // is copied to the // MsgId of the report // or reply message. requestMsg.format = MQC.MQFMT_STRING; // Set message format. The // application message data // can be either an SBCS // string (single-byte // character set), or a DBCS // string (double-byte // character set). // requestMsg.messageType=MQC.MQMT_REQUEST; // The message is one // that requires a reply. lr.start_transaction(\"大额贷记来账\"); requestMsg.writeString(msgBody); // message payload MQMessage inMsg = new MQMessage(); inMsg.write(msgBody.getBytes(\"UTF-8\")); putQueue.put(inMsg,pmo); lr.end_transaction(\"大额贷记来账\",lr.PASS ); } catch (Exception e) { e.printStackTrace(); } /*** * // Get the response message object from the response queue try { * responseMsg.correlationId = requestMsg.messageId; // The Id to be * matched against when getting a message from a queue * gmo.matchOptions=MQC.MQMO_MATCH_CORREL_ID; // The message to be * retrieved must have a correlation identifier that matches the value * of the CorrelId field in the MsgDesc parameter of the MQGET call. * gmo.options=MQC.MQGMO_WAIT; // The application waits until a suitable * message arrives. gmo.waitInterval=60000; // timeout in ms * getQueue.get(responseMsg, gmo); * * // Check the message content byte[] responseMsgData = * responseMsg.readStringOfByteLength * (responseMsg.getTotalMessageLength()).getBytes(); String msg = new * String(responseMsgData); lr.output_message(msg); // for debugging. * Disable this for a load test. // TODO: add your own message checking * here using string functions. // I have found that extracting XML * fields and comparing them (rather than // comparing the whole message * body or substrings) is more resistant to change. // If no match is * found, then lr.error_message() and lr.exit(). } catch(Exception e) { * e.printStackTrace(); lr.error_message(\"Error receiving message.\"); * lr.exit(lr.EXIT_VUSER, lr.FAIL); } * * lr.end_transaction(\"test_message\", lr.AUTO); */ return 0; }// end of action public int end() throws Throwable{ // Close all the connections try { putQueue.close(); // getQueue.close(); queueMgr.close(); } catch (Exception e) { e.printStackTrace(); } return 0; }// end of end public static String read(String fileName){ String req = \"\"; FileInputStream in = null; try { in = new FileInputStream(fileName); int len = in.available(); byte[] b = new byte[len]; in.read(b); req = new String(b); in.close(); } catch (IOException e) { e.printStackTrace(); } return req; } } "},"工具/Loadrunner/Loadrunner使用初探.html":{"url":"工具/Loadrunner/Loadrunner使用初探.html","title":"Loadrunner使用初探","keywords":"","body":"Loadrunner使用初探 性能测试是利用产品、人员和流程来降低应用程序、升级程序或补丁程序部署风险的一种手段。性能测试的主要思想是通过模拟产生真实业务的压力对被测系统进行加压，验证被测系统在不同压力情况下的表现，找出其潜在的瓶颈。 性能测试原理如下图所示： 性能测试相关术语：响应时间、并发用户数、事务响应时间、吞吐量、TPS（每秒事务响应数）、性能计数器等。 性能测试方法：负载测试、压力测试、配置测试、并发测试、可靠性测试等。 应用领域：能力验证、规划能力、性能调优、缺陷发现。 性能测试工具架构一般包括：虚拟用户脚本产生器（Virtual User Generator）、压力产生器（player）、用户代理（Agent）、压力调度和监控系统（Controller）、压力结果分析工具（Analysis）。 LoadRunner简介 LoadRunner是一种预测系统行为和性能的负载测试工具，通过模拟实际用户的操作行为进行实时性能监测，来帮助测试人员更快的查找和发现问题。LoadRunner适用于各种体系架构，能支持广泛的协议和技术，为测试提供特殊的解决方案。企业通过LoadRunner能最大限度地缩短测试时间，优化性能并加速应用系统的发布周期。 LoadRunner提供了3大主要功能模块，既可以作为独立的工具完成各自的功能，又可以作为LoadRunner的一部分彼此衔接，与其他模块共同完成软件性能的整体测试，这3大模块分别是： Virtual User Generator —— 用于录制性能测试脚本 LoadRunner Controller—— 用于创建、运行和监控场景 LoadRunner Analysis —— 用于分析性能测试结果 LoadRunner 常用术语: 场景（Scenario）：即测试场景，在LoadRunner的Controller部件中，可以设计与执行用例的场景，设置场景的步骤主要包括：在Controller中选择虚拟用户脚本、设置虚拟用户数量、配置虚拟用户运行时的行为、选择负载发生器（Load Generator）、设置执行时间等。 负载发生器（Load Generator）：用来产生压力的机器，受Controller控制，可以使用户脚本在不同的主机上执行。在性能测试工作中，通常由一个Controller控制多个Load Generator以对被测试系统进行加压。 虚拟用户（Virtual User/Vuser）：对应于现实中的真实用户，使用LoadRunner模拟的用户称为虚拟用户。性能测试模拟多个用户操作可以理解为这些虚拟用户在跑脚本，以模拟多个真正用户的行为。 虚拟用户脚本（Vuser script）：通过Vuser Generator录制或开发的脚本，这些脚本用来模拟用户的行为。 事务（Transaction）：测试人员可以将一个或多个操作步骤定义为一个事务，可以通俗的理解事务为“人为定义的一系列请求（请求可以是一个或者多个）”。在程序上，事务表现为被开始标记和结束标记圈定的一段代码区块。Loadrunner根据事务的开头和结尾标记，计算事务响应时间、成功/失败的事务数。 思考时间（Think Time）：即请求间的停顿时间。实际中，用户在进行一个操作后往往会停顿然后再进行下一个操作，为了更真实的模拟这种用户行为而引进该概念。在虚拟用户脚本中用函数lr_think_time()来模拟用户处理过程，执行该函数时用户线程会按照相应的time值进行等待。 集合点(Rendezvous)：设集合点是为了更好模拟并发操作。设了集合点后，运行过程中用户可以在集合点等待到一定条件后再一起发后续的请求。集合点在虚拟用户脚本中对应函数lr_rendezvous() 。 事务响应时间：事务响应时间是一个统计量，是评价系统性能的重要参数。定义好事务后，在场景执行过程和测试结果分析中即可以看到对应事务的响应时间。通过对关键或核心事务的执行情况进行分析，以定位是否存在性能问题。 LoadRunner测试流程 规划测试：确定测试要求，如并发用户数量、典型业务场景流程；测试计划；设计用例；…… 创建Vuser脚本：使用Virtual User Generator录制、编辑和完善测试脚本。 定义场景：使用LoadRunner Controller 设置测试场景。 运行场景：使用LoadRunner Controller 驱动、管理并监控场景的运行。 分析结果：使用LoadRunner Analysis 生成报告和图表并评估性能。 规划测试: 好的测试规划，能够指导整个测试过程，以更好的收集到测试目标要求的性能数据。规划可以包括测试的计划、用例的设计、场景的设计、性能计数器设置的设计等。 以下列出几点规划事项： 测试用例：测试用例一般根据需要测试的功能进行设计，如监控宝登陆，创建任务等 场景设计：一般情况会设计两种加压方式进行测试：瞬时加压（多人同时进行某项业务操作）与逐渐加压（多人先后进行某项业务操作，操作时间间隔根据计划设定）。 性能计数器方面：可以收集CPU时间、内存、硬盘、网络、数据库参数等。 创建Vuser脚本—准备: Loadrunner脚本开发步骤分为：录制基本脚本->增强/编辑脚本->配置运行时设置->试运行脚本 1. 启动LoadRunner：选择开始->程序->HPLoadRunner LoadRunner，打开HP LoadRunner11，如下图所示。 2. 打开VuGen：在LoadRunner Launcher窗格中，单击Create/Edit Scripts，链接启动Virtual user Generator起始页。 3. 创建一个空白Web脚本：选择File New菜单，或点击 按钮，打开New Virtual User对话框，显示可供选择脚本的协议。 对于常用的应用软件，我们可以根据被测应用是B/S结构还是C/S结构来选择协议。如果是B/S结构，就要选择Web（HTTP/HTML）协议。如果是C/S结构，则可以根据后端数据库的类型来选择，如MS SQL Server协议用于测试后台数据库为SQL Server的应用；对于没有数据库的WINDOWS应用，可以选择Windows Sockets协议。 根据选择协议的不同，Virtual User Generator 会使用不同的方式和界面引导用户完成脚本的录制。 4. 录制前的设置：选择Web（HTTP/HTML），点击Create按钮，打开Start Recording对话框。 选择的协议不同，打开的窗口就会不同，实例是针对Web录制的对话框。 VuGen的脚本分为三个部分：Vuser_init，Action，Vuser_end。其中Vuser_init和Vuser_end都只能存在一个，而Action可分成无数多个部分，可以通过点击旁边的【new】按钮来创建Action。在迭代执行测试脚本时，Vuser_init和Vuser_end中的内容只会执行一次，迭代的是Action部分。 在Start Recording对话框，点击Options按钮，进入录制选项设置。一般要设置以下选项： 1.基于浏览器的应用程序推荐使用HTML-based script。 2.不是基于浏览器的应用程序推荐使用URL-based script。 3.基于浏览器的应用程序中包含了JavaScript，并且该脚本向服务器发送了请求，比如DataGrid的分页按钮等，推荐使用URL-based script。 4.基于浏览器的应用程序中使用了HTTPS安全协议，建议使用URL-based script。 Advanced Support charset中设置编码格式：UTF-8； 提示：录制Web脚本时，生成的脚本中存在乱码该如何解决？ 1.新建脚本--->选择协议(Http)-->选项-->高级-->选择“支持字符集”并点选“UTF-8”。 2.在回放脚本之前：Vuser-->运行时设置-->浏览器-->浏览器仿真-->更改-->使用浏览器-->语言下来选择 “中文(中国)”5、录制：在Start Recording对话框，点击OK按钮，开始录制。系统自动弹出IE，加载营销系统的登录界面。在录制的过程中，屏幕上有一个悬浮的录制工具栏，是脚本录制过程中测试人员和VuGen交互的主要平台。 通过操作被测系统，操作的每一个步骤都被记录，在录制的过程中，可以在相应的步骤插入action、事务、检查点、集合点等信息。录制完成后单击按钮，Loadrunner开始生成脚本，生成的脚本如图所示。 脚本有两种查看方式： 1.Script View 可以查看全部录制的脚本代码（下图） 2.Tree View可以查看每个URL获取来的页面（下图） 创建Vuser脚本—增强/编辑脚本 参数化：参数化的作用是在进行场景执行的时候，每个不同的虚拟用户可以按照参数的读取策略读取到参数值，以模拟不同用户在提交或者读取不同的数据。 每个用户在界面上读取和提交的信息都不太相同，因此一般都需要参数化，其它与输入信息对应的比如用户id之类的信息也需要参数化；另外，录制环境绝大多数情况下与执行环境不一致，因此一般需要对IP、端口或者域名做参数化。 打开脚本后，首先要确定哪些常量需要参数化。 可以看出，在web_submit_data函数中，两条语句包含了两个常量：用户名和密码。 \"Name=usernam\", \"Value=Test123433333@sina.com\", ENDITEM, \"Name=password\", \"Value=123456\", ENDITEM, 当我们想模拟多个不同的用户来运行登录脚本的时候，需要对Value= Test123433333@sina.com和Value=123456进行参数化，以e号参数化为例，参数化过程如下： 1）选中Test123433333@sina.com 右击鼠标 在右键菜单上选择replace with a parameter。 2）在弹出窗口填写参数名称，或选择一个已经存在的参数名。 常用的参数类型： Data/Time：使用当前日期/时间替换所选常量。 Group Name：使用Vuser组的名称替换所选常量。 Load Generator Name：使用Vuser脚本的负载发生器名替换所选常量。 Iteration Number：使用当前的迭代编号替换所选常量。 Random Number：使用一个随机生成的整数替换所选常量，可以通过参数属性设定参数的范围。 Unique Number：使用一个唯一编号替换所选常量，可以通过参数属性设定参数的第一个值和递增的规则。 Vuser ID：使用运行脚本的虚拟用户ID来代替选择的常量。 File：采用外部的数据来代替，可以使用单独的文件，也可以使用现成的数据库中获取数据。 User Defined Function：从用户开发的dll文件中获取数据。 3）单击窗口的properties按钮，设置parameter的properties。参数名称：Username；选择参数类型File，来写入已准备好的数据。 文件File：参数化结束后，脚本保存的根目录下会自动生成一个 以参数名称命名的 参数文件；也可以直接选择一个已准备好的参数文件。 选择参数列Select Column： By number：以列号为参数列。 By name：以列名为参数列。 文件格式： Column：参数之间的分隔符：逗号、空格、Tab。 First data：从第几行读取数据。 选择参数分配方法Select next row： Sequential：顺序的分配Vuser参数值。当正在运行的Vuser访问数据表格时，它将会提取下一个可用的数据行。 Random：当脚本开始运行时，“随机”的为每个Vuser分配一个数据表格中的随机值。 Unique：为Vuser的参数分配一个“唯一”的顺序值。注意，参数数量一定要大于等于“Vuser量*迭代数量”。 选择参数更新方法Update value on： Each iteration：脚本每次迭代都顺序的使用数据表格中的下一个新值。 Each occurrence：在迭代中只要遇到该参数就重新取值。 Once：在所有的迭代中都使用同一个值。 当超出范围时When out of values：（选择数据为unique时才可用到） Abort Vuser：中止。 Continue in a cyclic manner：继续循环取值。 Continue with last value：取最后一个值。 设置完成后，被参数化的值会被参数名代替 关联：关联的含义是在脚本回放过程中，客户端发出请求，通过关联函数所定义的左右边界值（也就是关联规则），在服务器所响应的内容中查找，得到相应的值，以变量的形式替换录制时的静态值，从而向服务器发出正确的请求，最典型的是用于sessionID，常用的关联技术有三种：录制中关联、录制后关联、手动关联。 录制中关联：设置录制前的recording options correlation，可以勾选LR已有的关联规则，也可以新建规则；录制过程中，关联自动在脚本体现。 录制后关联：关联的使用可以在脚本录制完成后，回放一次脚本，然后在脚本的菜单的vuser scan script for correlations进行设置。 通过回放脚本和扫描关联，系统尝试找到录制与执行时服务器响应的差异部分，找到需要关联的数据，并建立关联。 手动关联：录制前关联与录制后关联都属于自动关联的范畴，如果出现自动关联不能解决的问题，就需要使用手动关联的方法，手动关联的一般步骤如下： 1）录制两份脚本，保证业务流程和使用的数据相同。 2）使用WinTiff工具比较两份脚本，对两份脚本中不同的地方进行判断，找到需要关联的数据。 3）找到左边界和右边界字符串，写出关联函数。 4）在脚本中‘需要关联的数据’前面插入关联函数。 5）用关联函数中定义的参数取代脚本中‘需要关联的数据’。 其他：前面讲解了插入事务、插入集合点、参数化、建立关联的方法，一般的脚本都需要做以上几项的修改工作。此外，还可以通过插入注释、插入检查点来完善脚本。另外脚本出现问题了，也可以通过打印信息来调试脚本。 插入注释：在脚本中插入注释，可以清晰找到需要修改的位置，增强脚本的可读性。 插入检查点：在脚本中设置检查点函数，将返回值的结果反映在Controller的状态面板上和Analysis统计结果中，由此可以判断数据传递的正确性。 创建Vuser脚本—配置运行时设置 在VuGen中，选择 Vuser Run-time Settings，可以设定脚本回放过程的一些参数。如Iteration Count (迭代次数)、Think Time (思考时间)、Error Handling(错误处理)、Multithreading(运行方式)等。 1、Iteration Count (迭代次数) 选择General：Run Logic 说明：设定每个Action的迭代次数。 2.Think Time (思考时间) 选择General：Think Time 说明：设定脚本回放时对思考时间的处理方式。 Ignore think time 脚本回放时，将不执行lr_think_time()函数，这样会给服务器产生更大的压力。 Replay think time 脚本回放时，执行lr_think_time()函数，具体执行方式有一下3种： 1)按照录制时获取的think time值回放。 2)按照录制时获取值的整数倍数回放脚本。 3)制定一个最大和最小的比例，按照两者之间的随机值回放脚本。 Limit think time to 选项，用于限制think time的最大值，脚本回放过程中，如果发现有超过这个值的，用这个最大值替代。 3、Error Handling(错误处理) 选择General：Miscellaneous 说明：设定遇到错误时的处理方式 Continue on error：遇到错误时继续运行。 Fail open transactions on lr_error_message：执行到事务中调用的lr_error_message()函数时将事务的结果置为Failed。 Generate snapshot on error：对错误进行快照 4.Multithreading(运行方式) 选择 General：Miscellaneous 说明：设定脚本是以多线程方式运行还是以多进程方式运行。 Run Vuser as a process：以多进程方式运行。 Run Vuser as a thread：以多线程方式运行。 这个根据实际情况而定，通常B/S通常用线程，C／S用进程。 创建Vuser脚本—试运行脚本 1.脚本录制完毕后，按F5键，或点击菜单中的按钮，可以试运行脚本。回放过程中VuGen在下方同步打印日志。 2.如果需要查看不同的日志形式，可以在脚本页面菜单的vuser runtime-settings log选择不同的项，回放脚本时将打印不同级别的日志。 3.运行结束后，系统会给出相应的运行结果，可以通过View Test Results查看回放结果 在VuGen中试运行脚本的作用，主要是查看录制的脚本能否正常通过，如果有问题，系统会给出提示信息，并定位到出错的行上，便于用户查找到错误，修改完善测试脚本。定义场景 脚本准备完成后，可以根据场景用例设置场景。Controller控制器提供了手动和面向目标两种测试场景。 手动设计场景（Manual Scenario）最大的优点是能够更灵活地按照需求来设计场景模型，使场景能更好地接近用户的真实使用。一般情况下使用手动场景设计方法来设计场景。 面向目标场景（Goal Oriented Scenario）则是测试性能是否能达到预期的目标，在能力规划和能力验证的测试过程中经常使用。 Controller控制器可以从程序中打开，然后选择保存好的脚本；也可以从VuGen中直接连接到该脚本的控制场景。 实例从VuGen中启动Controller的步骤如下： 1、单击VuGen菜单栏的tools create controller scenario。 2、在弹出窗口选择虚拟用户数、运行结果保存目录（按照事先约定选择目录，结果文件的命名最好包含用户数/加压方式/场景名）、负载产生的负载机所在地。 3、在Create Scenario窗口中点击OK，链接启动LoadRunner Controller。 定义场景—设置Schedule 在Controller的Scenario Schedule中，可以设置场景的各项计划，如虚拟用户的加载方式、释放策略等。 1.设置场景的基本信息 Schedule Name：设置场景名称。 Schedule by：选择按场景计划或按用户组计划。 Run Mode： real-world schedule 是真实场景模式，可以通过增加Action来增加多个用户。 basic schedule 是我们以前用的‘经典模式’，只能设置一次负载的上升和下降。2.设置场景的各类参数：双击Global Schedule中的对应行，可以设置schedule的各类参数。 Initialize：初始化是指运行脚本中的Vuser_init操作，为测试准备Vuser和Load Generator。 Start Vusers：设置场景Vuser加载方式。 Duration：设置场景持续运行的情况。 Stop Vusers：设置场景执行完成后虚拟用户释放的策略。 Start Time：设置场景启动时间。 场景设计完成后，单击Controller界面下方的Run选项卡，可以进入场景的执行界面。这个界面用于控制场景的执行，包括启动停止执行场景，观察执行时是否出错及出错信息、执行时用户情况、相关性能数据。 单击Start Scenario按钮，场景开始运行。一些即时的数据（比如用户数，等待数，成功事务数，失败事务数等）以及性能数据的折线图，会在Run的过程中显示。 执行完成后，执行结果以事先的命名默认保存在建立场景时设置的保存目录。如果涉及到调优，需要多次执行同一个场景，建议每次运行前先调整菜单的Results Results Settings，场景结果保存的名字建议包含重要调优参数值。调优参数比较多样，可以在具体的项目用附件约定。 测试期间，可以使用LoadRunner的联机监控器观察Web服务器在负载下的运行情况。特别是可以看到，负载的增加如何影响服务器对用户操作的响应时间（事务响应时间），以及如何引起错误的产生。 分析结果 LR的Analysis模块是分析系统的性能指标的一个主要工具，它能够直接打开场景的执行结果文件，将场景数据信息生成相关的图表进行显示。Analysis集成了强大的数据统计分析功能，允许测试员对图表进行比较和合并等多种操作，分析后的图表能够自动生成需要的测试报告文档。 通常测试报告需要给出“虚拟用户—用户响应时间”的折线图，这个折线图可以通过合并报表的形式生成，过程如下：选中Average Transaction Response Time报表，单击菜单栏的View Merge Graphs 然后选择与Running Vuser图合并，生成的折线图即为“虚拟用户—用户响应时间”。 LoadRunner作为商业性能测试工具拥有强大的功能，License的价格也很高。还有一个Apache开发的开源免费性能测试工具Jmeter,互联网公司使用比较多。这些工具只适合应用后端的压力测试，使用时都是需要先安装才能使用，如果想模拟大并发，前期还需要准备大量的工作压力机，测试所占用的资源成本比较高，压测周期很长，越来越不适合移动应用产品敏捷开发、快速交付的需求。 "},"工具/Loadrunner/Loadrunner中浏览器仿真器的缓存设置.html":{"url":"工具/Loadrunner/Loadrunner中浏览器仿真器的缓存设置.html","title":"Loadrunner中浏览器仿真器的缓存设置","keywords":"","body":"Loadrunner中浏览器仿真器的缓存设置 路径：runtimesetting- > Browser- > Browser Emulation Simulate browser cache Cache URLs requiring content(HTMLs) 这个选项是指Vugen仅缓存网页的一些必要信息，这些信息可以是一些必须的验证信息、分析数据或者关联数据，当你勾选了这项后，这些信息自动被缓存（默认是启用）。 提示：为了减少虚拟用户的内存占用量，可以禁用该选项，除非它是一个明确规定的测试要求。 Cache URLs Requiring Content – Advanced 选项 在高级设置里可以设置指定类型的信息存储到cache中 注意：这里的高级设置时同时针对所有的用户组，而不能对单独用户组进行设置。 修改指定类型信息步骤： 勾选Specify URLs requiring content in addition to HTML page。 点“+”号，添加指定类型信息，如text/plain, text/xml, image/jpeg, and image/gif。 点“-”号，从缓存中去除指定类型信息。 Check for newer versions of stored pages every visit to the page 这个选项是指浏览器会将存储在cache中的网页信息和最新浏览的页面进行比较 ，当你勾选此项时，vugen会增加'If-modified-since'到HTTP包头，在场景执行过程中这个选项可以显示最新的网页信息，但是也增加了更多的网络流量，通常配置这个选项是用来匹配浏览器设置来达到模拟浏览器的目的。 通常，默认不勾选。 Download non-HTML resources 这个选项是指虚拟用户在回放期间访问网站时加载图片的过程，这里图片是指随着页面录制的图片和那些没有随页面录制下来的图片。当一个真实的用户访问网站，他们总是等待图片的加载。因此如果你想测试整个系统的时候（用户体验时间），可以勾选这项（默认勾选）；如果为了提高性能且不是模拟真实用户行为的话，可以不勾选这项。 提示：禁用此选项后，可能会遇到图片验证失败，因为在访问网站的时候有些图片是会发生变化的，如广告条。 【run-time-setting里面的Browser Emulation下的 download non html resources的勾去掉, 这样不会下载非html的资源了~~！简化脚本，请求少了，或许可以适当提高响应速度。 Simulate a new uer on each iteration Clear cache on each iteration 每次迭代过程后都清除浏览器中缓存来达到模拟一个真实用户第一次访问网页。取消勾选后，允许虚拟用户使用缓存来存储用户信息，来模拟一个已经访问过网页的用户。 亦可使用如下函数达到清除缓存的作用： web_cleanup_cookies web_remove_cookie "},"工具/Loadrunner/Loadrunner对报表导出下载进行性能测试.html":{"url":"工具/Loadrunner/Loadrunner对报表导出下载进行性能测试.html","title":"Loadrunner对报表导出下载进行性能测试","keywords":"","body":"Loadrunner对报表导出下载进行性能测试 几乎所有报表都提供导出下载功能，测试时为了模拟下载的场景，需要编写相关脚本。在HTTP中，没有任何一个方法或是动作能够标识“下载”这个动作，对HTTP来说，无论是下载文件或者请求页面，都只是发出一个GET请求，Loadrunner记录了客户端发出的对文件的请求，并能够收到文件内容。因此，完全可以通过关联的方法，从Loadrunner发出的请求的响应中获取到文件的内容，然后通过Loadrunner的操作方法，自行生成文件。 简单来说，只要实现对服务器返回所有内容保存到本地，就实现了“下载”的模拟，因此思路为： 1.针对所有返回内容保存到本地 这里采用关联函数可以实现web_reg_save_param web_reg_save_param(\"fcontent\", \"LB=\", \"RB=\", \"SEARCH=BODY\", LAST); 注意：由于参数SEARCH默认是针对消息头域和消息体，而我们保存目标仅在返回的body中，所以设置为body； 2.设置接受返回响应的参数大小 由于关联函数保存参数的参数值默认大小为1024字节，下载文件往往不止这个大小，所以在使用关联函数之前需要使用函数：web_set_max_html_param_len重新设置参数size web_set_max_html_param_len(\"9000000\"); 3.把参数写入到本地文件 使用fwrite( const void buffer, size_t size, size_t count, FILE file_pointer ); const void *buffer：要把关联函数找到的参数作为常量写入，因此使用lr_eval_string函数把参数转换为常量 size_t size：指定缓冲区的大小，也就是服务器响应的大小，使用web_get_int_property函数取得，所以需要在导出请求后面加入：flen = web_get_int_property(HTTP_INFO_DOWNLOAD_SIZE); size_t count：指定数目，为1 FILE *file_pointer：指定写入的文件路径： 创建文件路径，使用到long fopen( const char filename, const char access_mode ); const char *filename参数为写入文件的路径和文件名，例如 d:\\下载\\order_20181127110251.xls const char *access_mode存储模式参数为：wb，w为写，b也就是二进制模式： filedes = fopen(\"D:\\\\下载\\\\order_20181127110251\", \"wb\") 完成该步骤以后： fwrite(lr_eval_string(\"{fcontent}\"), flen, 1, filedes); 4.关闭文件fclose(filedes); 代码如下： Action() { int flen; //文件大小 long filedes; //响应数据内容大小 char filename[1024]; //文件名 web_set_max_html_param_len(\"90000000\"); //设置最大长度 web_reg_save_param(\"fcontent\",\"LB=\",\"RB=\",\"Search=Body\",LAST); //将响应信息存放到fcontent变量 lr_start_transaction(\"导出\"); web_url(\"exportOrderExcel.shtml\", \"URL=http://10.201.60.110/receive-web/omsweb/fileController/exportOrderExcel.shtml&language=zh_cn\", \"TargetFrame=\", \"Resource=1\", \"RecContentType=application/x-msdownload\", \"Referer=http://10.201.60.110/receive-web/security/public/index.html\", \"Snapshot=t38.inf\", LAST); lr_end_transaction(\"导出\", LR_AUTO); flen = web_get_int_property(HTTP_INFO_DOWNLOAD_SIZE); //获取响应中的文件长度 strcpy(filename,\"D:\\\\下载\\\\order_\"); //生成随机的文件名称，便于并发 strcat(filename,lr_eval_string(\"{Num}\")); strcat(filename,\".xlsx\"); if(flen > 0){ //以写方式打开文件 if((filedes = fopen(filename, \"wb\")) == NULL){ lr_output_message(\"Open File Failed!\"); return -1; } //写入文件内容 fwrite(lr_eval_string(\"{fcontent}\"), flen, 1, filedes); //关闭文件 fclose(filedes); } return 0; } 为了并发时生成的文件名不重复，因此增加一个参数表取当前时间戳作为文件名后缀，设置为每次迭代时更新，例如： 此时，执行脚本后，发现在本地电脑D:\\下载目录下生成下载文件，如图： 这个脚本如果在controller中直接进行性能测试的话，跟实际还是会有点差距的，由于实际业务场景里面各个用户都是选择不一样的报表进行导出，因此再对导出请求中的两个报表名进行关联，ord属性配置为参数，让vuser每次选择不一样的报表进行导出，例如： web_reg_save_param_ex( \"ParamName=CorrelationParameter_2\", \"LB=\\\">\", \"RB=\", \"Ordinal={报表行数}\", SEARCH_FILTERS, \"Scope=Body\", \"RequestUrl=*/CsgPlanDrawReportQuery.jsp*\", LAST); 最后，就实现了报表模块中，针对各个不同报表执行导出操作并下载到本地的性能测试目的。 "},"工具/Loadrunner/Loadrunner在Linux下安装负载机Generator.html":{"url":"工具/Loadrunner/Loadrunner在Linux下安装负载机Generator.html","title":"Loadrunner在Linux下安装负载机Generator","keywords":"","body":"Loadrunner在Linux下安装负载机Generator 本文主要介绍怎么在Linux下安装LoadRunner负载机loadrunner-11-load-generator.iso 挂载load-generator镜像 第一种方式：采用citrix或VMware虚拟化，客户端操作装入iso盘 – 创建挂载区 mkdir /mnt/cdrom – 挂载镜像 mount /dev/cdrom /mnt/cdrom 第二种方式：采用linux物理机或者云服务器挂载iso文件 – 创建挂载区 mkdir /mnt/cdrom – 挂载iso文件，先将iso文件拷贝至任意目录中 mount -o loop /home/xxx.iso /mnt/cdrom 安装load-generator 进入目录 cd /mnt/cdrom/Linux 安装 ./installer.sh 卸载load-generator 卸载则使用以下命令： rpm -e LoadGenerator 启动load-generator 在启动之前确保系统支持csh命令 cat /etc/shells 如果不支持，则需要安装csh yum install csh -y 进入HP_LoadGenerator目录，切换csh命令行 cd /opt/HP/HP_LoadGenerator csh 设置环境变量 source env.csh 进入bin目录并启动 m_daemon_setup -install 使用Loadrunner连接负载机 打开Loadrunner Controller，进入Load Generators，添加负载机 设置负载机信息 连接负载机 开启端口54345或关闭防火墙 iptables -A INPUT -p tcp --dport 端口号 -j ACCEPT 使用Controller连接，在“UNIX Environment Tab”下选择“Don't use RSH”即可连接Linux负载机。 注意事项 启动前需要关闭防火墙，否则无法启动 安装过程中若出现错误提示，则根据错误提示安装所需的依赖包即可，使用yum命令安装 每次系统重启，需要重新进行设置环境变量及启动步骤，可以将两个步骤加入系统自启动服务中 load_generator的Docker镜像 一、说明 HP官方提供了load_generator的docker镜像，镜像是12.5版本，兼容11.0版本的controller。 官方镜像地址 二、安装部署 步骤1：安装docker ubuntu 16.04安装docker curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun sudo systemctl enable docker sudo systemctl start docker CentOS7一键部署脚本 #!/bin/sh # @author ling # 定义显示颜色 RED='\\e[1;91m' GREEN='\\e[1;92m' WITE='\\e[1;97m' NC='\\e[0m' # centos7环境中安装docker function install_docker_in_contos7() { echo \"Install docker in centos7!\" echo \"Remove old docker!\" yum remove docker docker-common docker-selinux docker-engine && echo -e $GREEN\"Remove old docker success!\"$NC echo \"Install docker dependent packages!\" yum install -y yum-utils device-mapper-persistent-data lvm2 && echo -e $GREEN\"Install docker dependent packages success!\"$NC echo \"Add yum repo!\" yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo && echo -e $GREEN\"Add yum repo success!\"$NC echo \"Install docker-ce!\" yum makecache fast && yum install -y docker-ce && echo -e $GREEN\"Install docker-ce success!\"$NC echo \"Chkconfig docker on!\" systemctl enable docker && systemctl start docker && echo -e $GREEN\"Chkconfig docker on success!\"$NC echo \"{\\\"registry-mirrors\\\": [\\\"http://hub-mirror.c.163.com\\\"]}\" >> /etc/docker/daemon.json systemctl daemon-reload && systemctl restart docker && echo -e $GREEN\"Install docker in centos7 success!\"$NC echo \"Stop firewalld!\" systemctl stop firewalld && systemctl disable firewalld && echo -e $GREEN\"Stop firewalld success!\"$NC echo \"Install iptables services!\" yum -y install iptables-services && systemctl enable iptables && systemctl start iptables && echo -e $GREEN\"Install iptables services success!\"$NC echo \"Reload docker!\" systemctl restart docker && echo -e $GREEN\"Reload docker success!\"$NC } install_docker_in_contos7 步骤2：下载最新版本的load_generator镜像，命令如下： docker pull hpsoftware/load_generator 步骤3：load_generator镜像实例化成docker容器，命令如下： docker run -d -i -p 54345:54345 --net=host hpsoftware/load_generator 步骤4：查看容器日志，命令如下： docker logs -f 如果显示如下信息，说明启动成功。 步骤5： 在controller里添加一个load_generator，name填写linux机器的ip。 步骤6：点击【Details】-【Unix Enviroment】勾上【Don’t use RSH】否则会连接不上。 步骤7：点击【Connect】按钮，查看【Status】，若为Ready则表示连接成功。 问题1： [loadrunner@localhost bin]$ ./m_daemon_setup start ./m_daemon_setup: ./m_agent_daemon: /lib/ld-linux.so.2: bad ELF interpreter: No such file or directory 【解决】： yum install glibc.i686 问题2： [loadrunner@localhost bin]$ ./m_daemon_setup start m_agent_daemon: error while loading shared libraries: libstdc++.so.5: cannot open shared object file: No such file or directory 【解决思路】： yum install libstdc++.i686* find / -name libstdc++.so* 找到发现有libstdc++.so.5，在/usr/lib64/libstdc++.so.5中； 修改上面的LD_LIBRARY_PATH，添加:/usr/lib64 问题3： [loadrunner@centos1 bin]$ ./m_daemon_setup start m_agent_daemon: error while loading shared libraries: libstdc++.so.5: wrong ELF class: ELFCLASS64 【解决思路】： 查看发现是由于版本不对，64位的libstdc++.so.5不适用，应该安装32位的，所以把上一步的操作还原，然后执行yum whatprovides libstdc++.so.5，查看到该动态库是compat-libstdc++-33-3.2.3-72.el7.i686提供，因此执行yum install compat-libstdc++-33-3.2.3-72.el7.i686安装。 问题4： [loadrunner@centos1 bin]$ ./m_daemon_setup start m_agent_daemon ( is down ), 【解决思路】： 没有提示信息，只有直接查看日志了： vim /tmp/m_agent_daemonTihVLp.log DriverLogger: Log started at 21/04/2016 06:33:04 . 21/04/2016 06:33:04 Error: Communication error: Failed to get the server host IP by calling the gethostbyname function. (sys error message - Resource temporarily unavailable) [MsgId: MERR-10344] 21/04/2016 06:33:04 Error: Two Way Communication Error: Function two_way_comm_create_acceptor failed. [MsgId: MERR-60999] 21/04/2016 06:33:04 Error: Failed to create \"launchservice\" server. [MsgId: MERR-29974] 21/04/2016 06:33:04 Warning: Extension liblauncher.so reports error -1 on call to function ExtPerThreadInitialize [MsgId: MWAR-10485] 21/04/2016 06:33:04 Error: Vuser failed to initialize extension liblauncher.so. [MsgId: MERR-10700] DriverLogger: Log ended at 21/04/2016 06:33:04 . 执行env，查看到HOSTNAME=centos1， vim /etc/hosts，添加 192.168.108.10 centos1, 注意其中的192.168.108.10是本机IP "},"工具/Loadrunner/LR测试脚本开发WebService.html":{"url":"工具/Loadrunner/LR测试脚本开发WebService.html","title":"LR测试脚本开发WebService","keywords":"","body":"[TOC] LR测试脚本开发WebService 常用的调试工具 WebService：SoapUI Http：Postman、Jmeter、Postwoman、Fiddler、Charles TCP：WireShark Socket：SocketTool（可以使用LR直接进行录制） WebService协议 什么是WebService 简书： 百度百科： CSDN： XML百度百科： WebService到底是什么 　　一言以蔽之：WebService是一种跨编程语言和跨操作系统平台的远程调用技术。 　　所谓跨编程语言和跨操作平台，就是说服务端程序采用java编写，客户端程序则可以采用其他编程语言编写，反之亦然！跨操作系统平台则是指服务端程序和客户端程序可以在不同的操作系统上运行。 　　所谓远程调用，就是一台计算机a上 的一个程序可以调用到另外一台计算机b上的一个对象的方法，譬如，银联提供给商场的pos刷卡系统，商场的POS机转账调用的转账方法的代码其实是跑在银 行服务器上。再比如，amazon，天气预报系统，淘宝网，校内网，百度等把自己的系统服务以webservice服务的形式暴露出来，让第三方网站和程 序可以调用这些服务功能，这样扩展了自己系统的市场占有率，往大的概念上吹，就是所谓的SOA应用。 　　其实可以从多个角度来理解 WebService，从表面上看，WebService就是一个应用程序向外界暴露出一个能通过Web进行调用的API，也就是说能用编程的方法通过 Web来调用这个应用程序。我们把调用这个WebService的应用程序叫做客户端，而把提供这个WebService的应用程序叫做服务端。从深层次 看，WebService是建立可互操作的分布式应用程序的新平台，是一个平台，是一套标准。它定义了应用程序如何在Web上实现互操作性，你可以用任何 你喜欢的语言，在任何你喜欢的平台上写Web service ，只要我们可以通过Web service标准对这些服务进行查询和访问。 　　WebService平台需要一套协议来实现分布式应用程序的创建。任何平台都有它的数据表示方法和类型系统。要实现互操作性，WebService平台 必须提供一套标准的类型系统，用于沟通不同平台、编程语言和组件模型中的不同类型系统。Web service平台必须提供一种标准来描述 Web service，让客户可以得到足够的信息来调用这个Web service。最后，我们还必须有一种方法来对这个Web service进行远 程调用,这种方法实际是一种远程过程调用协议(RPC)。为了达到互操作性，这种RPC协议还必须与平台和编程语言无关。 WebService平台技术 XML+XSD,SOAP和WSDL就是构成WebService平台的三大技术。 XML+XSD 　　WebService采用HTTP协议传输数据，采用XML格式封装数据（即XML中说明调用远程服务对象的哪个方法，传递的参数是什么，以及服务对象的 返回结果是什么）。XML是WebService平台中表示数据的格式。除了易于建立和易于分析外，XML主要的优点在于它既是平台无关的，又是厂商无关 的。无关性是比技术优越性更重要的：软件厂商是不会选择一个由竞争对手所发明的技术的。 　　XML解决了数据表示的问题，但它没有定义一套标准的数据类型，更没有说怎么去扩展这套数据类型。例如，整形数到底代表什么？16位，32位，64位？这 些细节对实现互操作性很重要。XML Schema(XSD)就是专门解决这个问题的一套标准。它定义了一套标准的数据类型，并给出了一种语言来扩展这套数据类型。WebService平台就 是用XSD来作为其数据类型系统的。当你用某种语言(如VB.NET或C#)来构造一个Web service时，为了符合WebService标准，所 有你使用的数据类型都必须被转换为XSD类型。你用的工具可能已经自动帮你完成了这个转换，但你很可能会根据你的需要修改一下转换过程。 SOAP WebService通过HTTP协议发送请求和接收结果时，发送的请求内容和结果内容都采用XML格式封装，并增加了一些特定的HTTP消息头，以说明 HTTP消息的内容格式，这些特定的HTTP消息头和XML内容格式就是SOAP协议。SOAP提供了标准的RPC方法来调用Web Service。 SOAP协议 = HTTP协议 + XML数据格式 SOAP协议定义了SOAP消息的格式，SOAP协议是基于HTTP协议的，SOAP也是基于XML和XSD的，XML是SOAP的数据编码方式。打个比 喻：HTTP就是普通公路，XML就是中间的绿色隔离带和两边的防护栏，SOAP就是普通公路经过加隔离带和防护栏改造过的高速公路。 WSDL 　　好比我们去商店买东西，首先要知道商店里有什么东西可买，然后再来购买，商家的做法就是张贴广告海报。 WebService也一样，WebService客户端要调用一个WebService服务，首先要有知道这个服务的地址在哪，以及这个服务里有什么方 法可以调用，所以，WebService务器端首先要通过一个WSDL文件来说明自己家里有啥服务可以对外调用，服务是什么（服务中有哪些方法，方法接受 的参数是什么，返回值是什么），服务的网络地址用哪个url地址表示，服务通过什么方式来调用。 　　WSDL(Web Services Description Language)就是这样一个基于XML的语言，用于描述Web Service及其函数、参数和返回值。它是WebService客户端和服务器端都 能理解的标准格式。因为是基于XML的，所以WSDL既是机器可阅读的，又是人可阅读的，这将是一个很大的好处。一些最新的开发工具既能根据你的 Web service生成WSDL文档，又能导入WSDL文档，生成调用相应WebService的代理类代码。 　　WSDL 文件保存在Web服务器上，通过一个url地址就可以访问到它。客户端要调用一个WebService服务之前，要知道该服务的WSDL文件的地址。 WebService服务提供商可以通过两种方式来暴露它的WSDL文件地址：1.注册到UDDI服务器，以便被人查找；2.直接告诉给客户端调用者。 HTTP协议 HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。 序号 方法 描述 1 GET 请求指定的页面信息，并返回实体主体。 2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 5 DELETE 请求服务器删除指定的页面。 6 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。 7 OPTIONS 允许客户端查看服务器的性能。 8 TRACE 回显服务器收到的请求，主要用于测试或诊断。 9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 。 GET与POST的区别 GET和POST本质上就是TCP链接，并无差别 GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。 GET产生一个TCP数据包，POST产生两个TCP数据包。 注意 GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 Request Headers GET / HTTP/1.1 Host: www.baidu.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Sec-Fetch-Site: none Sec-Fetch-Mode: navigate Sec-Fetch-User: ?1 Sec-Fetch-Dest: document Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9 Cookie: BIDUPSID=***; PSTM=1605274186; BAIDUID=***:FG=1; BD_UPN=12314353; BDORZ=***; COOKIE_SESSION=***; H_PS_645EC=***; BA_HECTOR=***; BD_HOME=1; H_PS_PSSID=***; BAIDUID_BFESS=***:FG=1 Response Headers HTTP/1.1 200 OK Bdpagetype: 1 Bdqid: 0xe499e36e0007aa38 Cache-Control: private Connection: keep-alive Content-Encoding: gzip Content-Type: text/html;charset=utf-8 Date: Mon, 16 Nov 2020 10:00:53 GMT Expires: Mon, 16 Nov 2020 10:00:48 GMT Server: BWS/1.1 Set-Cookie: BDSVRTM=0; path=/ Set-Cookie: BD_HOME=1; path=/ Set-Cookie: H_PS_PSSID=***; path=/; domain=.baidu.com Strict-Transport-Security: max-age=172800 Traceid: *** X-Ua-Compatible: IE=Edge,chrome=1 Transfer-Encoding: chunked 测试脚本开发 使用web_service_call进行脚本开发 前提： WSDL地址：http://www.webxml.com.cn/WebServices/IpAddressSearchWebService.asmx?wsdl 功能：通过IP地址查询所在地 在LR中新建WebService协议脚本。 在Manage Services中，使用URL方式，导入WSDL。（如果有对应文件，使用File方式也可以）。 添加对应的请求。 根据实际情况，修改优化验证测试脚本。 添加事务 添加检查点、事务成功判断 ```C Action() { web_service_call( \"StepName=getCountryCityByIp_101\", \"SOAPMethod=IpAddressSearchWebService|IpAddressSearchWebServiceSoap|getCountryCityByIp\", \"ResponseParam=response\", \"Service=IpAddressSearchWebService\", \"ExpectedResponse=SoapResult\", \"Snapshot=t1605496282.inf\", BEGIN_ARGUMENTS, \"theIpAddress=172.168.5.9\", END_ARGUMENTS, BEGIN_RESULT, \"getCountryCityByIpResult=Result\", END_RESULT, LAST); lr_output_message(\"%s\",lr_eval_string(\"{Result}\")); return 0; } ### 使用soap_request进行脚本开发 >前提： >URL请求地址:http://www.webxml.com.cn/WebServices/TranslatorWebService.asmx > >WDSL地址：http://www.webxml.com.cn/WebServices/TranslatorWebService.asmx?WDSL > >WebService页面查看具体请求：http://www.webxml.com.cn/WebServices/TranslatorWebService.asmx?op=getEnCnTwoWayTranslator > 1. 在LR中新建WebService协议的脚本。 2. 将具体的请求拷贝下来，另存为xml文件。 3. 在LR脚本中，选择Import SOAP。 4. 选择刚才保存的xml文件后，点击load。 5. 填入对应的信息。 6. 根据实际情况修改、优化、验证测试脚本。 - 添加事务 - 添加检查点、事务判断 - 添加报文头信息 - 字符编码转码 ```C Action() { web_add_header(\"Host\",\"www.webxml.com.cn\"); web_add_header(\"Content-Type\",\"text/xml; charset=utf-8\"); web_add_header(\"SOAPAction\",\"\\\"http://WebXml.com.cn/getEnCnTwoWayTranslator\\\"\"); soap_request(\"StepName=SOAP Request\", \"URL=http://www.webxml.com.cn/WebServices/TranslatorWebService.asmx\", \"SOAPEnvelope=\" \"\" \"\" \"\" \"hello\" \"\" \"\", \"ResponseParam=soap-response\", \"Snapshot=t1605508031.inf\", LAST); lr_convert_string_encoding(lr_eval_string(\"{soap-response}\"),\"UTF-8\",NULL,\"soap-response\"); lr_output_message(\"soap：%s\",lr_eval_string(\"{soap-response}\")); return 0; } 使用web_custom_request进行脚本开发 可以先行使用postman来协助进行脚本开发，验证请求地址、请求方法、请求报文头、请求报文体信息。 在LR中新建HTTP协议的脚本 使用web_reg_save_param函数进行关联，保存响应中的信息 使用web_add_header函数进行请求报文头信息的添加 使用web_custom_request函数来进行http请求的发送 使用lr_convert_string_encoding函数进行对应的转码 Action() { web_reg_save_param(\"ReturnMsg\",\"LB=\",\"RB=\",LAST); web_add_header(\"User-Agent\",\"Apache-HttpClient/4.1.1 (java 1.5)\"); web_add_header(\"Content-Type\",\"text/xml;charset=UTF-8\"); web_add_header(\"Accept-Encoding\",\"gzip,deflate\"); web_add_header(\"SOAPAction\",\"urn:queryIndex\"); web_add_header(\"Host\",\"9.1.6.59:9080\"); web_custom_request(\"web_custom_request\", \"URL=http://9.1.6.59:9080/queryweb/services/ESBOfflineQueryService.ESBOfflineQueryServiceHttpSoap11Endpoint/\", \"Method=POST\", \"TargetFrame=\", \"Resource=0\", \"Referer=\", \"EncType=text/xml;charset=UTF-8\", \"Body=\" \"\" \"3007030010\" \"02\" \"12\" \"20170809\" \"11:43:40\" \"202007300001\" \"12\" \"17\" \"01\" \"13\" \"567\" \"100100\" \"1234\" \"123\" \"US\" \"Y\" \"456\" \"123\" \"45678\" \"123456\" \"3456\" \"3456\" \"4537\" \"12345\" \"12090\" \"3345\" \"2343545\" \"32345\" \"234545\" \"234315\" \"23456\" \"456\" \"3345\" \"2345\" \"123789\" \"213455\" \"\" \"\" \"1\" \"50\" \"{\\\"QRYID\\\":\\\"trd_dtl_idn_dqd\\\",\\\"HBTAB\\\":\\\"trd_dtl_idn_dqd\\\",\\\"HBCF\\\":\\\"c\\\",\\\"CONDT\\\":{\\\"\\\":{\\\"actno\\\":{\\\"EQ\\\":\\\"2707050101109031262864\\\"},\\\"mch_dt\\\":{\\\"LE\\\":\\\"2072-06-20\\\"},\\\"dtl_amttm\\\":{\\\"GE\\\":\\\"105\\\",\\\"LE\\\":\\\"217\\\"},\\\"sys_apltn\\\":{\\\"EQ\\\":\\\"CORE\\\"}}},\\\"RESP\\\":[\\\"trd_dt\\\",\\\"trd_tm\\\",\\\"trd_mchcd\\\",\\\"dbcrd_flg\\\",\\\"trd_amt\\\",\\\"the_trd_aft_bal\\\",\\\"trd_tlr_nbr\\\",\\\"abstc_abbr\\\"],\\\"LIMIT\\\":\\\"100\\\",\\\"OFFSET\\\":\\\"0\\\",\\\"ORDER\\\":{\\\"trd_tm\\\":\\\"ASC\\\"},\\\"ROUND\\\":{\\\"trd_amt\\\":2,\\\"the_trd_aft_bal\\\":2}}\" \"\" \"\", LAST); lr_convert_string_encoding(lr_eval_string(\"{ReturnMsg}\"),\"UTF-8\",NULL,\"ReturnMsg\"); lr_output_message(\"%s\",lr_eval_string(\"{ReturnMsg}\")); return 0; } 脚本调试方法 在脚本开发的过程中可能会遇到各种问题，较为常见的一种就是，开发使用Postman或者自己使用soapui工具发送请求，能够正常收到响应，但是自己写的脚本，却无法正常使用，返回500，或者其他报错，此时就需要用到wireshark工具，进行TCP数据包抓包对比分析，看看请求成功的数据包与请求失败的数据包的具体差异，然后做出对应的调整，再进行验证。一般都可以解决此类问题。 该方法同样适用socket脚本调试，使用sockettool工具能够正常收到响应，但是测试脚本却收不到正确的响应。 问题 1.下列哪种工具能够简单直接的验证WebService接口以及报文 A.SocketTool B.Jmeter C.SoapUI D.Postman 2.哪个工具可以用来对比TCP数据包的差异 A.Fiddler B.Charles C.Burpsuite D.Wireshark 3.HTTP请求包含哪些 A.请求行 B.请求头 C.空行 D.请求体 E.以上所有选项 4.HTTP请求行中不包含的内容 A.请求方式 B.请求路径 C.协议版本号 D.请求码 5.响应码为500表示下列哪种状态 A.处理成功 B.重定向 C.客户端错误 D.服务端错误 "},"工具/Appium/":{"url":"工具/Appium/","title":"Appium","keywords":"","body":"Appium Appium是一个开源、跨平台的测试框架，可以用来测试原生及混合的移动端应用。Appium支持IOS、Android及FirefoxOS平台。Appium使用WebDriver的json wire协议，来驱动Apple系统的UIAutomation库、Android系统的UIAutomator框架。Appium对IOS系统的支持得益于Dan Cuellar’s对于IOS自动化的研究。Appium也集成了Selendroid，来支持老android版本。 Appium支持Selenium WebDriver支持的所有语言，如java、Object-C、JavaScript、Php、Python、Ruby、C#、Clojure，或者Perl语言，更可以使用Selenium WebDriver的Api。Appium支持任何一种测试框架。如果只使用Apple的UIAutomation，我们只能用javascript来编写测试用例，而且只能用Instruction来运行测试用例。同样，如果只使用Google的UIAutomation，我们就只能用java来编写测试用例。Appium实现了真正的跨平台自动化测试。 "},"工具/Appium/Appium之获取appPackage和appActivity.html":{"url":"工具/Appium/Appium之获取appPackage和appActivity.html","title":"Appium之获取appPackage和appActivity","keywords":"","body":"Appium之获取appPackage和appActivity appPackage和appActivity是desired capabilities中非常重要的两个参数，在使用appium进行自动化测试时我们常常会用到这两个参数，那么如何获取这两个参数呢？ 一、使用adb shell 首先要通过USB将手机与电脑连接，注意将手机的调试模式打开，打开Android SDK的platform-tools的文件夹，在上方地址栏输入cmd，进入cmd后首先输入adb shell ，出现$后输入 dumpsys activity | grep mFocusedActivity（如图） 其中红框的即为appPackage，蓝框的即为appActivity adb dumpsys activity activities | grep mFocusedActivity # 8.0以下 adb shell dumpsys activity activities | grep mResumedActivity # 8.0 二、使用aact 首先要通过USB将手机与电脑连接，注意将手机的调试模式打开，打开Android SDK的build-tools的文件夹，在上方地址栏输入cmd，进入cmd后输入aact dump badging +存放apk的地址（如图） package:name 就是appPackage launchable-activity: name 就是appActivity 三、通过查看log文件获取 1.打开APP。 2.执行> adb logcat>D:/log.txt 3.胡乱的对APP做一些操作。 4.Ctrl+c 结束adb命令。 5.打开log.txt文件，搜索：Displayed appPackage: com.android.messaging appActivity：.ui.conversationlist.ConversationListActivity 四、通过apk程序包获取 1.通过解压工具，解压apk程序包。 2.通过notepad++ 打开AndroidManifest.xml 文件，在里面搜索：manifest对应的就是appPackage。 3.搜索：activity对应的就是appActivity。（activity关键字很多，你要注意辨别。） "},"工具/Appium/AppiumAPI.html":{"url":"工具/Appium/AppiumAPI.html","title":"AppiumAPI","keywords":"","body":"AppiumAPI 1、创建新的会话 创建一个新的会话 DesiredCapabilities desiredCapabilities =new DesiredCapabilities(); desiredCapabilities.setCapability(MobileCapabilityType.PLATFORM_VERSION,\"10.3\"); desiredCapabilities.setCapability(MobileCapabilityType.DEVICE_NAME,\"iPhone Simulator\"); desiredCapabilities.setCapability(MobileCapabilityType.AUTOMATION_NAME,\"XCUITest\"); desiredCapabilities.setCapability(MobileCapabilityType.APP,\"/path/to/ios/app.zip\"); URL url = newURL(\"http://127.0.0.1:4723/wd/hub\"); IOSDriver driver = new IOSDriver(url,desiredCapabilities); String sessionId =driver.getSessionId().toString(); 2、结束会话 结束正在运行的会话 driver.quit(); 3、获取会话功能 检索指定会话的功能 Map caps = driver.getSessionDetails(); 4、回退 如果可能，在浏览器历史记录中向后浏览（仅限Web上下文） driver.back(); 5、截图 截取当前的视口/窗口/页面 File scrFile =((TakesScreenshot)driver).getScreenshotAs(OutputType.FILE); 6、超时 设置超时 配置特定类型的操作在被中止之前可以执行的时间量 driver.manage().timeouts().pageLoadTimeout(30,TimeUnit.SECONDS); 设置隐式等待超时 设置搜索元素时驱动程序应该等待的时间量 driver.manage().timeouts().implicitlyWait(30,TimeUnit.SECONDS); 设置脚本超时 设置的时间量，以毫秒为单位，通过执行异步脚本执行异步允许运行它们都将立即中止之前（仅限于Web上下文） driver.manage().timeouts().setScriptTimeout(30,TimeUnit.SECONDS); 7、方向 获取方向 获取当前的设备/浏览器方向 ScreenOrientation orientation =driver.getOrientation(); 设置方向 设置当前的设备/浏览器方向 driver.rotate(ScreenOrientation.LANDSCAPE); 8、地理位置 获取地理位置 获取当前的地理位置 Location location = driver.location(); //必须是一个驱动程序，实现了LocationContext 设置地理位置 设置当前的地理位置 driver.setLocation(new Location(49, 123,10)); //必须是一个驱动程序，实现了LocationContext 9、日志 获取可用的日志类型 获取给定日志类型的日志。日志缓冲区在每次请求后都会重置 Set logTypes =driver.manage().logs().getAvailableLogTypes(); 获取日志 获取给定日志类型的日志。日志缓冲区在每次请求后都会重置 LogEntries logEntries =driver.manage().logs().get(\"driver\"); 10、设置 更新设备设置 更新设备上的当前设置 driver.setSetting(Setting.WAIT_FOR_IDLE_TIMEOUT,Duration.ofSeconds(5)); 检索设备设置 检索设备上的当前设置 Map settings =driver.getSettings(); 11、活动 开始活动 通过提供软件包名称和活动名称来开始Android活动 driver.startActivity(newActivity(\"com.example\", \"ActivityName\")); 获取当前活动 获取当前Android活动的名称 String activity = driver.currentActivity(); 获取当前包 获取当前Android包的名称 String package =driver.getCurrentPackage(); 12、应用 安装应用程序 将给定的应用程序安装到设备上 driver.installApp(\"/Users/johndoe/path/to/app.apk\"); 应用程序已安装 检查设备上是否安装了指定的应用程序 driver.isAppInstalled(\"com.example.AppName\"); 启动应用程序 在设备上启动应用程序 driver.launchApp(); 背景应用程序 将当前正在运行的应用程序发送到后台 driver.runAppInBackground(Duration.ofSeconds(10)); 关闭应用程序 关闭设备上的应用 driver.closeApp(); 重置应用程序 重置此会话的当前正在运行的应用程序 driver.resetApp(); 删除应用程序 从设备中删除应用程序 driver.removeApp(\"com.example.AppName\"); 获取应用程序字符串 获取应用程序字符 Map appStrings =driver.getAppStringMap(\"en\", \"/path/to/file\"); 结束测试覆盖率 获取测试覆盖率数据 driver.endTestCoverage(\"Intent\",\"/path\"); 13、文件 推送文件 将文件放置在设备的特定位置 driver.pushFile(\"/path/to/device/foo.bar\",new File(\"/Users/johndoe/files/foo.bar\")); 拉文件 从设备的文件系统中检索文件 byte[] fileBase64 =driver.pullFile(\"/path/to/device/foo.bar\"); 拉文件夹 从设备的文件系统中检索文件夹 byte[] folder =driver.pullFolder(\"/path/to/device/foo.bar\"); 14、互动 摇 在设备上执行摇动操作 driver.shake(); 锁 锁定设备 driver.lockDevice(); 开锁 解锁设备 driver.lockDevice(); driver.unlockDevice(); 设备是否被锁定 检查设备是否被锁定 boolean isLocked = driver.isLocked(); 旋转 旋转三维设备 driver.rotate(new DeviceRotation(10, 10,10)); 15、按键 按键代码 按下设备上的特定按键 driver.pressKeyCode(AndroidKeyCode.SPACE,AndroidKeyMetastate.META_SHIFT_ON); 长按键代码 按住设备上的特定键码 driver.longPressKeyCode(AndroidKeyCode.HOME); 隐藏键盘 隐藏软键盘 driver.hideKeyboard(); 显示键盘 是否显示软键盘 boolean isKeyboardShown =driver.isKeyboardShown(); 16、网络 切换飞行模式 在设备上切换飞行模式 //Java不支持 切换数据 切换数据服务的状态 //Java不支持 切换WiFi 切换wifi服务的状态 //Java不支持 切换位置服务 切换位置服务的状态 driver.toggleLocationServices(); 发简讯 模拟短信（仅适用于仿真器） //Java不支持 GSM呼叫 拨打GSM电话（仅限Emulator） //Java不支持 GSM信号 设置GSM信号强度（仅限仿真器） //Java不支持 GSM语音 设置GSM语音状态（仅适用于仿真器） //Java不支持 17、性能数据 获取性能数据 返回支持读取的系统状态信息，如CPU，内存，网络流量和电池 List>performanceData = driver.getPerformanceData(\"my.app.package\",\"cpuinfo\", 5); 获取性能数据类型 返回支持读取的系统状态的信息类型，如CPU，内存，网络流量和电池 List performanceTypes =driver.getSupportedPerformanceDataTypes(); 18、模拟器 执行Touch ID 模拟触摸ID事件（仅适用于iOS模拟器） driver.performTouchID(false); //模拟失败的触摸 driver.performTouchID(true); //模拟通过的触摸 切换触摸ID注册 切换正在注册的模拟器以接受touchId（仅适用于iOS模拟器） driver.toggleTouchIDEnrollment(true); 19、系统 打开通知 打开Android通知（仅适用于仿真器） driver.openNotifications(); 获取系统栏 检索状态和导航栏的可见性和边界信息 Map systemBars =driver.getSystemBars(); 获取系统时间 在设备上获取时间 String time = driver.getDeviceTime(); 20、查找元素 查找元素 搜索页面上的元素 MobileElement elementOne = (MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); MobileElement elementTwo = (MobileElement)driver.findElementByClassName(\"SomeClassName\"); 21、操作 点击 点击中心点的元素 MobileElement el = driver.findElementByAccessibilityId(\"SomeId\"); el.click(); 发送键 将一系列击键发送到一个元素 MobileElement element = (MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); element.sendKeys(\"Hello world!\"); 清除元素 清除元素的值 MobileElement element = (MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); element.clear(); 22、属性 获取元素文本 返回元素的可见文本 MobileElement element = (MobileElement)driver.findElementByClassName(\"SomeClassName\"); let elText = element.getText(); 获取标签名称 获取元素的标签名称 List element =(MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); String tagName = element.getTagName(); 获取元素属性 获取元素属性的值 List element =(MobileElement) driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); String tagName =element.getAttribute(\"content-desc\"); 元素被选中 确定是否选择了表单或表单类元素（复选框，选择等） MobileElement element = (MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); boolean isSelected = element.isSelected(); 元素已启用 确定元素当前是否启用 MobileElement element = (MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); boolean isEnabled = element.isEnabled(); 获取元素位置 确定元素在页面或屏幕上的位置 List element =(MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); Point location = element.getLocation(); 获取元素大小 以像素为单位确定元素的大小 List element =(MobileElement) driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); Dimension elementSize = element.getSize(); 获取元素矩形 获取元素的尺寸和坐标 List element =(MobileElement)driver.findElementByAccessibilityId(\"SomeAccessibilityID\"); Rectangle rect = element.getRect(); 获取元素CSS值 查询Web元素的计算CSS属性的值 List element =(MobileElement) driver.findElementById(\"SomeId\"); String cssProperty =element.getCssValue(\"style\"); 在视图中获取元素位置 一旦将元素滚动到视图中，确定元素在屏幕上的位置 （主要是内部命令并且不被所有客户端支持） //Java不支持 23、其他 提交表单 提交一个FORM元素 MobileElement element = (MobileElement)driver.findElementByClassName(\"SomeClassName\"); element.submit(); 获取活动元素 获取当前会话的活动元素 WebElement currentElement =driver.switchTo().activeElement(); 元素是否相等 测试两个元素ID是否指向相同的元素 //重写equals方法的java对象 MobileElement elementOne = (MobileElement)driver.findElementByClassName(\"SomeClassName\"); MobileElement elementTwo = (MobileElement)driver.findElementByClassName(\"SomeOtherClassName\"); boolean isEqual =elementOne.equals(elementTwo); 24、上下文 获取当前上下文 获取Appium正在运行的当前上下文 String context = driver.getContext(); 获取所有上下文 获取所有可用的自动化上下文 Set contextNames =driver.getContextHandles(); 设置当前上下文 设置自动化的上下文 Set contextNames =driver.getContextHandles(); for (String contextName : contextNames) { System.out.println(contextNames); //打印出NATIVE_APP/WEBVIEW_1 } driver.context(contextNames.toArray()[1]); //设置上下文为WEBVIEW_1 。。。。。。 driver.context(\"NATIVE_APP\"); //设置上下文为NATIVE_APP 25、鼠标 将鼠标移至 将鼠标移动特定元素的偏移量 Actions action = new Actions(driver); action.moveTo(element, 10, 10); action.perform() 点击 在当前鼠标坐标点击任意鼠标按钮 Actions action = new Actions(driver); action.moveTo(element); action.click(); action.perform(); 双击 双击当前鼠标坐标（由moveto设置） Actions action = new Actions(driver); action.moveTo(element); action.doubleClick(); action.perform(); 按钮关闭 在当前的鼠标坐标上单击并按住鼠标左键 Actions action = new Actions(driver); action.moveTo(element); action.clickAndHold(); action.perform(); 释放按钮 释放先前保持的鼠标按钮 Actions action = new Actions(driver); action.moveTo(element); action.clickAndHold(); action.moveTo(element, 10, 10); action.release(); action.perform(); 26、触摸 单击 单击轻触设备 TouchActions action = newTouchActions(driver); action.singleTap(element); action.perform(); 双击 使用手指动作事件双击触摸屏 TouchActions action = newTouchActions(driver); action.doubleTap(element); action.perform(); 移动 手指在屏幕上移动 TouchActions action = newTouchActions(driver); action.down(10, 10); action.move(50, 50); action.perform(); 触摸下来 手指在屏幕上 TouchActions action = newTouchActions(driver); action.down(10, 10); action.move(50, 50); action.perform(); 润色（作小的修改） 手指在屏幕上 TouchActions action = newTouchActions(driver); action.down(10, 10); action.up(20, 20); action.perform(); 长按 使用手指运动事件长按触摸屏 TouchActions action = newTouchActions(driver); action.longPress(element); action.perform(); 滚动 使用基于手指的动作事件在触摸屏上滚动 TouchActions action = newTouchActions(driver); action.scroll(element, 10, 100); action.perform(); 拂去 使用手指运动事件轻击触摸屏 TouchActions action = newTouchActions(driver); action.flick(element, 1, 10, 10); action.perform(); 多点触摸执行 执行多点触摸动作序列 TouchAction actionOne = new TouchAction(); actionOne.press(10, 10); actionOne.moveTo(10, 100); actionOne.release(); TouchAction actionTwo = new TouchAction(); actionTwo.press(20, 20); actionTwo.moveTo(20, 200); actionTwo.release(); MultiTouchAction action = newMultiTouchAction(); action.add(actionOne); action.add(actionTwo); action.perform(); 触摸执行 执行一个触摸动作序列 TouchAction action = new TouchAction(driver); action.press(10, 10); action.moveTo(10, 100); action.release(); action.perform(); 27、窗口 切换到窗口 将焦点更改为另一个窗口（仅限Web上下文） driver.switchTo().window(\"handle\"); 关闭窗口 关闭当前窗口（仅限Web上下文） driver.close(); 获取窗口句柄 检索当前窗口句柄（仅限Web上下文） String windowHandle =driver.getWindowHandle(); 获取所有窗口句柄 检索可用于会话的所有窗口句柄的列表（仅限Web上下文） Set windowHandles =driver.getWindowHandles(); 获取标题 获取当前页面标题（仅限Web上下文） String title = driver.getTitle(); 获取窗口大小 获取指定窗口的大小（仅限Web上下文） Dimension windowSize =driver.manage().window().getSize(); 设置窗口大小 更改指定窗口的大小（仅限Web上下文） driver.manage().window().setSize(newDimension(10, 10)); 获取窗口位置 获取指定窗口的位置（仅限Web上下文） Point windowPosition =driver.manage().window().getPosition(); 设置窗口位置 更改指定窗口的位置（仅限Web上下文） driver.manage().window().setPosition(newDimension(10, 10)); 最大化窗口 最大化指定的窗口（仅限Web上下文） driver.manage().window().maximize(); 28、导航 导航到URL 导航到新的URL（仅限Web上下文） driver.get(\"http://appium.io/\"); 获取URL 检索当前页面的URL（仅限Web上下文） String url = driver.getCurrentUrl(); 前进 如果可能，在浏览器历史记录中向前浏览（仅限Web上下文） driver.forward(); 刷新 刷新当前页面（仅限Web上下文） driver.refresh(); 29、Cookie 获取所有Cookie 检索当前页面可见的所有cookie（仅限Web上下文） Set allcookies =driver.manage().getCookies(); 设置Cookie 设置一个cookie（仅限Web上下文） driver.manage().addCookie(newCookie(\"foo\", \"bar\")); 删除Cookie 删除具有给定名称的cookie（仅限Web上下文） driver.manage().deleteCookieNamed(\"cookie_name\"); 删除所有Cookie 删除当前页面可见的所有cookie（仅限Web上下文） driver.manage().deleteAllCookies(); 30、Frame 切换到帧 将焦点更改为页面上的其他框架（仅限Web上下文） driver.switchTo().frame(3); 切换到父框架 将焦点更改为父上下文（仅限Web上下文） driver.switchTo().parentFrame(); 31、JavaScript 执行脚本 将JavaScript片段注入页面以在当前选定框架的上下文中执行（仅限Web上下文） ((JavascriptExecutor)driver).executeScript(\"window.setTimeout(arguments[arguments.length - 1],500);\"); 执行异步脚本 将JavaScript片段注入页面以在当前选定框架的上下文中执行（仅限Web上下文） ((JavascriptExecutor)driver).executeAsyncScript(\"window.setTimeout(arguments[arguments.length -1], 500);\"); "},"工具/Git/":{"url":"工具/Git/","title":"Git","keywords":"","body":"Git Git(读音为/gɪt/)是一个开源的分布式版本控制系统，可以有效. 高速地处理从很小到非常大的项目版本管理。 [1] Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 Git的功能特性： 从一般开发者的角度来看，git有以下功能： 从服务器上克隆完整的Git仓库（包括代码和版本信息）到单机上。 在自己的机器上根据不同的开发目的，创建分支，修改代码。 在单机上自己创建的分支上提交代码。 在单机上合并分支。 把服务器上最新版的代码fetch下来，然后跟自己的主分支合并。 生成补丁（patch），把补丁发送给主开发者。 看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。 一般开发者之间解决冲突的方法，开发者之间可以使用pull 命令解决冲突，解决完冲突之后再向主开发者提交补丁。 从主开发者的角度（假设主开发者不用开发代码）看，git有以下功能： 查看邮件或者通过其它方式查看一般开发者的提交状态。 打上补丁，解决冲突（可以自己解决，也可以要求开发者之间解决以后再重新提交，如果是开源项目，还要决定哪些补丁有用，哪些不用）。 向公共服务器提交结果，然后通知所有开发人员。 "},"工具/Git/GitBook的基本使用方法.html":{"url":"工具/Git/GitBook的基本使用方法.html","title":"GitBook的基本使用方法","keywords":"","body":"GitBook的基本使用方法 标题 这是最为常用的格式，在平时常用的的文本编辑器中大多是这样实现的：输入文本、选中文本、设置标题格式。 而在 Markdown 中，你只需要在文本前面加上 # 即可，同理、你还可以增加二级标题、三级标题、四级标题、五级标题和六级标题，总共六级，只需要增加 # 即可，标题字号相应降低。例如： # 一级标题 一级标题 ## 二级标题 二级标题 ### 三级标题 三级标题 #### 四级标题 四级标题 ##### 五级标题 五级标题 ###### 六级标题 六级标题 注：# 和「一级标题」之间建议保留一个字符的空格，这是最标准的 Markdown 写法。 列表 列表格式也很常用，在 Markdown 中，你只需要在文字前面加上 - 就可以了，例如： - 列表1 - 列表2 - 列表3 效果如下： 列表1 列表2 列表3 如果你希望有序列表，也可以在文字前面加上 1. 2. 3. 就可以了，例如： 文本1 文本2 文本3 注：-、1.和文本之间要保留一个字符的空格。 代码 插入的文本以代码格式显示 `code` 效果如下： code 代码块 命令： ```这是代码块``` 效果如下： Markdown具有书写代码块(code block)的功能，而且可以为不同的语言进行相应的代码高亮。 代码块用一对```括起来，在第一个```后面紧跟语言的名称即可。 如果你是个程序猿，需要在文章里优雅的引用代码框，在 Markdown 下实现也非常简单，只需要用两个` 把中间的代码包裹起来，如 `code`。 插入代码的方式有两种 1. 在每行代码前加入4个空格或者添加一个制表符（TAB键） 2. 在代码两侧添加三个反引号‘```’。 \\```代码块\\ \\``` 一整段代码 \\``` 两种方法都有需要注意的地方，很多入门文档未能提及。 其缩进是相对于当前格式状态下的。 在列表项状态下，需要输入两次TAB键(制表符)才能以代码格式插入。 例如： a. 代码： •列表项 •列表项 [TAB][TAB]printf(\"hello world!\"); b. 效果： - 列表项 - 列表项 printf(\"hello world!\"); 反引号最好在代码的前后行添加，而不是直接加在代码两边。 a. 代码 ``` 可以高亮度显示的代码内容 ``` b. 效果 可以高亮度显示的代码内容 链接和图片 在 Markdown 中，插入链接不需要其他按钮，你只需要使用 显示文本 这样的语法即可，例如： [简书](http://jianshu.io) 简书 在 Markdown 中，插入图片不需要其他按钮，你只需要使用 ![](图片链接地址) 这样的语法即可，例如： ![](http://ww4.sinaimg.cn/bmiddle/aa397b7fjw1dzplsgpdw5j.jpg) 注：插入图片的语法和链接的语法很像，只是前面多了一个 ！。 引用 在我们写作的时候经常需要引用他人的文字，这个时候引用这个格式就很有必要了，在 Markdown 中，你只需要在你希望引用的文字前面加上 > 就好了，例如： > 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 注：> 和文本之间要保留一个字符的空格。 粗体和斜体 Markdown 的粗体和斜体也非常简单，用两个 包含一段文本就是粗体的语法，用一个 包含一段文本就是斜体的语法。例如： *一盏灯， 一片昏黄；*一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 最终显示的就是下文，其中「一盏灯」是斜体，「一简书」是粗体： 一盏灯， 一片昏黄；一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 表格 相关代码： | Tables | Are | Cool | | ------------- |--------------| ------| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | 显示效果： Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 显示链接中带括号的图片 代码如下: ![]1 [1]: http://latex.codecogs.com/gif.latex?\\prod%20\\(n_{i}\\)+1 "},"工具/Git/Git插入图片.html":{"url":"工具/Git/Git插入图片.html","title":"Git插入图片","keywords":"","body":"Git插入图片 使用绝对路径添加图片 将图片文件拷贝到本地仓库目录下，执行 git add * git commit git push -u origin master 查看上传的图片url 在要引用的md文件中插入代码 ![image](url) 使用相对路径插入图片 在本地仓库md文件的同目录下创建images文件夹，将图片放至上述文件夹中，步骤同上。 在md文件中引用时使用相对路径。 ![](./image/*.png) 相同路径用./表示，上级目录用../表示 注意：存放图片的文件夹或者图片名中含有空格或其他特殊字符，会导致图片无法加载，以下两种方案解决： 1.文件夹以及图片命名中不要用到空格和特殊字符 2.将相对路径进行URL编码，URL编码链接http://tool.oschina.net/encode?type=4 如果想改变图片的尺寸，可以通过代码标签 . 如果想改变图片居中 . "},"工具/Git/Git常用命令.html":{"url":"工具/Git/Git常用命令.html","title":"Git常用命令","keywords":"","body":"Git常用命令 初始化 git init 添加文件 git add path/file 提交 git commit -m \"frist commit\" 添加远程仓库映射 git remote add origin git@github.com:mike0564/zycfc_jmeter.git 提交到仓库 git push -u origin master 强制提交到仓库 git push -u origin master -f 安装配置Git 安装git brew install git yum install git sudo apt-get install git 也可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：./config，make，sudo make install这几个命令安装就好了。 配置 git config --global user.name 'XXX' git config --global user.email 'XXX' 创建本地库 mkidir learngit //自定义文件夹 cd learngit touch test.md //创建test.md文件 pwd //显示当前目录 常用CRT git init //初始化代码仓库 git add learngit.txt //把所有要提交的文件修改放到暂存区 git commit -m 'add a file' //把暂存区的所有内容提交到当前分支 git status //查看工作区状态 git diff //查看文件修改内容 git log //查看提交历史 git log --pretty=oneline //单行显示 git reset --hard HEAD^ //回退到上一个版本，其中（HEAD^^(上上版本),HEAD~100(往上100个版本)） commit id //(版本号) 可回到指定版本 git reflog //查看历史命令 其中说明: 工作区（Working Directory） 版本库（Repository） #.git stage(index) 暂存区 master Git自动创建的分支 HEAD 指针 git diff HEAD -- //查看工作区和版本库里最新版本的区别 git checkout -- //用版本库的版本替换工作区的版本，无论是工作区的修改还是删除，都可以'一键还原' git reset HEAD //把暂存区的修改撤销掉，重新放回工作区。 git rm //删除文件，若文件已提交到版本库，不用担心误删，但是只能恢复文件到最新版本 创建SSH Key 建立本地Git仓库和GitHub仓库之间的传输的秘钥 ssh-keygen -t rsa -C 'your email' //创建SSH Key git remote add origin git@github.com:username/repostery.git //关联本地仓库，远程库的名字为origin git push -u origin master //第一次把当前分支master推送到远程，-u参数不但推送，而且将本地的分支和远程的分支关联起来 git push origin master //把当前分支master推送到远程 git clone git@github.com:username/repostery.git //从远程库克隆一个到本地库 分支 git checkout -b dev //创建并切换分支 \\#相当于git branch dev 和git checkout dev git branch //查看当前分支，当前分支前有个*号 git branch //创建分支 git checkout //切换分支 git merge //合并某个分支到当前分支 git branch -d //删除分支 git log --graph //查看分支合并图 git merge --no-ff -m 'message' dev //禁用Fast forward合并dev分支 git stash //隐藏当前工作现场，等恢复后继续工作 git stash list //查看stash记录 git stash apply //仅恢复现场，不删除stash内容 git stash drop //删除stash内容 git stash pop //恢复现场的同时删除stash内容 git branch -D //强行删除某个未合并的分支 //开发新feature最好新建一个分支 git remote //查看远程仓库 git remote -v //查看远程库详细信息 git pull //抓取远程提交 git checkout -b branch-name origin/branch-name //在本地创建和远程分支对应的分支 git branch --set-upstream branch-name origin/branch-name //建立本地分支和远程分支的关联 其他---标签 git tag v1.0 //给当前分支最新的commit打标签 git tag -a v0.1 -m 'version 0.1 released' 3628164 //-a指定标签名，-m指定说明文字 git tag -s -m 'blabla' //可以用PGP签名标签 git tag //查看所有标签 git show v1.0 //查看标签信息 git tag -d v0.1 //删除标签 git push origin //推送某个标签到远程 git push origin --tags //推送所有尚未推送的本地标签 "},"工具/Git/Git常见报错与解决方案.html":{"url":"工具/Git/Git常见报错与解决方案.html","title":"Git常见报错与解决方案","keywords":"","body":"Git常见报错与解决方案 git添加远程库git remote add origin git@github.com:roboytim/zycfc_jmeter.git报错：“fatal: remote origin already exists.” 解决步骤： 先删除$ git remote rm origin 再次执行添加就可以了。 git push -u origin master报错“[rejected] master -> master (non-fast-forward)” 解决步骤： git pull origin master --allow-unrelated-histories //把远程仓库和本地同步，消除差异 重新add和commit相应文件 git add filename git commit -m \"first commit\" git push origin master 此时就能够上传成功了 Git删除文件方法 方法一： 步骤： 在本地库中删除对应文件 使用git status查看文件 git rm filename,从版本库中删除文件 git commit -m \"remove filename\"，提交确认删除 方法二： 步骤： git init cd “你的本地仓库地址” git pull origin master (#将远程仓库里面的项目拉下来) dir (#查看有哪些文件夹) git rm -r --cached “你要删除的文件名” git commit -m '备注更改信息' git push -u origin master （#更新状态） "},"工具/Git/Gitbook插入表格.html":{"url":"工具/Git/Gitbook插入表格.html","title":"Gitbook插入表格","keywords":"","body":"Gitbook插入表格 Markdown表格设计 Markdown本身不提供单元格合并语法，好在Markdown是兼容HTML的，通过HTML的方式实现单元格合并。 在线生成表格 行合并 示例1： #的个数为：行数 合并多行成一列： #的个数为：列数 使用rowspan=\"n\" 跨 n 行合并 文件标识： 内容 第一行： 该写什么呢？ 第二行： 随便写吧！ 第三行： OK了！ 合并多行成一列： 使用rowspan=\"n\" 跨 n 行合并 文件标识： 内容 第一行： 该写什么呢？ 第二行： 随便写吧！ 第三行： OK了！ ## 列合并 示例2： ``` 第一列 第二列 第三列 合并第1，2列 第2行，第3列 合并第1，2列 第3行，第3列 ``` 第一列 第二列 第三列 合并第1，2列 第2行，第3列 合并第1，2列 第3行，第3列 使用跨行或者跨列时，使用th标签 跨行： rowspan的的参数就是要跨的行数 跨列： colspan的参数就是要跨的列数 颜色库 #FFFFFF #FFFFF0 #FFFFE0 #FFFF00 #FFFAFA #FFFAF0 #FFFACD #FFF8DC #FFF68F #FFF5EE #FFF0F5 #FFEFDB #FFEFD5 #FFEC8B #FFEBCD #FFE7BA #FFE4E1 #FFE4C4 #FFE4B5 #FFE1FF #FFDEAD #FFDAB9 #FFD700 #FFD39B #FFC1C1 #FFC125 #FFC0CB #FFBBFF #FFB90F #FFB6C1 #FFB5C5 #FFAEB9 #FFA54F #FFA500 #FFA07A #FF8C69 #FF8C00 #FF83FA #FF82AB #FF8247 #FF7F50 #FF7F24 #FF7F00 #FF7256 #FF6EB4 #FF6A6A #FF69B4 #FF6347 #FF4500 #FF4040 #FF3E96 #FF34B3 #FF3030 #FF1493 #FF00FF #FF0000 #FDF5E6 #FCFCFC #FAFAFA #FAFAD2 #FAF0E6 #FAEBD7 #FA8072 #F8F8FF #F7F7F7 #F5FFFA #F5F5F5 #F5F5DC #F5DEB3 #F4F4F4 #F4A460 #F2F2F2 #F0FFFF #F0FFF0 #F0F8FF #F0F0F0 #F0E68C #F08080 #EEEEE0 #EEEED1 #EEEE00 #EEE9E9 #EEE9BF #EEE8CD #EEE8AA #EEE685 #EEE5DE #EEE0E5 #EEDFCC #EEDC82 #EED8AE #EED5D2 #EED5B7 #EED2EE #EECFA1 #EECBAD #EEC900 #EEC591 #EEB4B4 #EEB422 #EEAEEE #EEAD0E #EEA9B8 #EEA2AD #EE9A49 #EE9A00 #EE9572 #EE82EE #EE8262 #EE7AE9 #EE799F #EE7942 #EE7621 #EE7600 #EE6AA7 #EE6A50 #EE6363 #EE5C42 #EE4000 #EE3B3B #EE3A8C #EE30A7 #EE2C2C #EE1289 #EE00EE #EE0000 #EDEDED #EBEBEB #EAEAEA #E9967A #E8E8E8 #E6E6FA #E5E5E5 #E3E3E3 #E0FFFF #E0EEEE #E0EEE0 #E0E0E0 #E066FF #DEDEDE #DEB887 #DDA0DD #DCDCDC #DC143C #DBDBDB #DB7093 #DAA520 #DA70D6 #D9D9D9 #D8BFD8 #D6D6D6 #D4D4D4 #D3D3D3 #D2B48C #D2691E #D1EEEE #D1D1D1 #D15FEE #D02090 #CFCFCF #CDCDC1 #CDCDB4 #CDCD00 #CDC9C9 #CDC9A5 #CDC8B1 #CDC673 #CDC5BF #CDC1C5 #CDC0B0 #CDBE70 #CDBA96 #CDB7B5 #CDB79E #CDB5CD #CDB38B #CDAF95 #CDAD00 #CDAA7D #CD9B9B #CD9B1D #CD96CD #CD950C #CD919E #CD8C95 #CD853F #CD8500 #CD8162 #CD7054 #CD69C9 #CD6889 #CD6839 #CD661D #CD6600 #CD6090 #CD5C5C #CD5B45 #CD5555 #CD4F39 #CD3700 #CD3333 #CD3278 #CD2990 #CD2626 #CD1076 #CD00CD #CD0000 #CCCCCC #CAFF70 #CAE1FF #C9C9C9 #C7C7C7 #C71585 #C6E2FF #C67171 #C5C1AA #C4C4C4 #C2C2C2 #C1FFC1 #C1CDCD #C1CDC1 #C1C1C1 #C0FF3E #BFEFFF #BFBFBF #BF3EFF #BEBEBE #BDBDBD #BDB76B #BCEE68 #BCD2EE #BC8F8F #BBFFFF #BABABA #BA55D3 #B9D3EE #B8B8B8 #B8860B #B7B7B7 #B5B5B5 #B4EEB4 #B4CDCD #B452CD #B3EE3A #B3B3B3 #B2DFEE #B23AEE #B22222 #B0E2FF #B0E0E6 #B0C4DE #B0B0B0 #B03060 #AEEEEE #ADFF2F #ADD8E6 #ADADAD #ABABAB #AB82FF #AAAAAA #A9A9A9 #A8A8A8 #A6A6A6 #A52A2A #A4D3EE #A3A3A3 #A2CD5A #A2B5CD #A1A1A1 #A0522D #A020F0 #9FB6CD #9F79EE #9E9E9E #9C9C9C #9BCD9B #9B30FF #9AFF9A #9ACD32 #9AC0CD #9A32CD #999999 #9932CC #98FB98 #98F5FF #97FFFF #96CDCD #969696 #949494 #9400D3 #9370DB #919191 #912CEE #90EE90 #8FBC8F #8F8F8F #8EE5EE #8E8E8E #8E8E38 #8E388E #8DEEEE #8DB6CD #8C8C8C #8B8B83 #8B8B7A #8B8B00 #8B8989 #8B8970 #8B8878 #8B8682 #8B864E #8B8386 #8B8378 #8B814C #8B7E66 #8B7D7B #8B7D6B #8B7B8B #8B795E #8B7765 #8B7500 #8B7355 #8B6969 #8B6914 #8B668B #8B6508 #8B636C #8B5F65 #8B5A2B #8B5A00 #8B5742 #8B4C39 #8B4789 #8B475D #8B4726 #8B4513 #8B4500 #8B3E2F #8B3A62 #8B3A3A #8B3626 #8B2500 #8B2323 #8B2252 #8B1C62 #8B1A1A #8B0A50 #8B008B #8B0000 #8A8A8A #8A2BE2 #8968CD #87CEFF #87CEFA #87CEEB #878787 #858585 #848484 #8470FF #838B8B #838B83 #836FFF #828282 #7FFFD4 #7FFF00 #7F7F7F #7EC0EE #7D9EC0 #7D7D7D #7D26CD #7CFC00 #7CCD7C #7B68EE #7AC5CD #7A8B8B #7A7A7A #7A67EE #7A378B #79CDCD #787878 #778899 #76EEC6 #76EE00 #757575 #737373 #71C671 #7171C6 #708090 #707070 #6E8B3D #6E7B8B #6E6E6E #6CA6CD #6C7B8B #6B8E23 #6B6B6B #6A5ACD #698B69 #698B22 #696969 #6959CD #68838B #68228B #66CDAA #66CD00 #668B8B #666666 #6495ED #63B8FF #636363 #616161 #607B8B #5F9EA0 #5E5E5E #5D478B #5CACEE #5C5C5C #5B5B5B #595959 #575757 #556B2F #555555 #551A8B #54FF9F #548B54 #545454 #53868B #528B8B #525252 #515151 #4F94CD #4F4F4F #4EEE94 #4D4D4D #4B0082 #4A708B #4A4A4A #48D1CC #4876FF #483D8B #474747 #473C8B #4682B4 #458B74 #458B00 #454545 #43CD80 #436EEE #424242 #4169E1 #40E0D0 #404040 #3D3D3D #3CB371 #3B3B3B #3A5FCD #388E8E #383838 #36648B #363636 #333333 #32CD32 #303030 #2F4F4F #2E8B57 #2E2E2E #2B2B2B #292929 #282828 #27408B #262626 #242424 #228B22 #218868 #212121 #20B2AA #1F1F1F #1E90FF #1E1E1E #1C86EE #1C1C1C #1A1A1A #191970 #1874CD #171717 #141414 #121212 #104E8B #0F0F0F #0D0D0D #0A0A0A #080808 #050505 #030303 #00FFFF #00FF7F #00FF00 #00FA9A #00F5FF #00EEEE #00EE76 #00EE00 #00E5EE #00CED1 #00CDCD #00CD66 #00CD00 #00C5CD #00BFFF #00B2EE #009ACD #008B8B #008B45 #008B00 #00868B #00688B #006400 #0000FF #0000EE #0000CD #0000AA #00008B #000080 #000000 "},"工具/Prometheus/":{"url":"工具/Prometheus/","title":"Prometheus","keywords":"","body":"Prometheus Prometheus（普罗米修斯）是一套开源的监控&报警&时间序列数据库的组合.由SoundCloud公司开发。 Prometheus基本原理是通过HTTP协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供HTTP接口就可以接入监控系统，不需要任何SDK或者其他的集成过程。这样做非常适合虚拟化环境比如VM或者Docker 。 Prometheus应该是为数不多的适合Docker、Mesos、Kubernetes环境的监控系统之一。近几年随着k8s的流行，prometheus成为了一个越来越流行的监控工具。 Prometheus可以做什么 在业务层用作埋点系统 Prometheus支持各个主流开发语言（Go，java，python，ruby官方提供客户端，其他语言有第三方开源客户端）。我们可以通过客户端方面的对核心业务进行埋点。如下单流程、添加购物车流程。在应用层用作应用监控系统 一些主流应用可以通过官方或第三方的导出器，来对这些应用做核心指标的收集。如redis,mysql。在系统层用作系统监控 除了常用软件， prometheus也有相关系统层和网络层exporter,用以监控服务器或网络。集成其他的监控 prometheus还可以通过各种exporte，集成其他的监控系统，收集监控数据，如AWS CloudWatch,JMX，Pingdom等等。 不要用Prometheus做什么 prometheus也提供了Grok exporter等工具可以用来读取日志，但是prometheus是监控系统，不是日志系统。应用的日志还是应该走ELK等工具栈。 grafana 一般配合grafana做前端展示 Prometheus的特点： 1、多维数据模型（时序列数据由metric名和一组key/value组成） 2、在多维度上灵活的查询语言(PromQl) 3、不依赖分布式存储，单主节点工作. 4、通过基于HTTP的pull方式采集时序数据 5、可以通过中间网关进行时序列数据推送(pushing) 6、目标服务器可以通过发现服务或者静态配置实现 7、多种可视化和仪表盘支持 prometheus 相关组件，Prometheus生态系统由多个组件组成，其中许多是可选的： 1、Prometheus 主服务,用来抓取和存储时序数据 2、client library 用来构造应用或 exporter 代码 (go,java,python,ruby) 3、push 网关可用来支持短连接任务 4、可视化的dashboard (两种选择,promdash 和 grafana.目前主流选择是 grafana.) 4、一些特殊需求的数据出口(用于HAProxy, StatsD, Graphite等服务) 5、实验性的报警管理端(alartmanager,单独进行报警汇总,分发,屏蔽等 ) promethues 的各个组件基本都是用 golang 编写,对编译和部署十分友好.并且没有特殊依赖.基本都是独立工作。 "},"工具/Prometheus/Prometheus服务端部署.html":{"url":"工具/Prometheus/Prometheus服务端部署.html","title":"Prometheus服务端部署","keywords":"","body":"Prometheus服务端部署 一、安装Prometheus 官网：https://prometheus.io/ 根据自己的系统版本，下载对应的安装包或组件包。（Prometheus支持docker镜像） 由于使用Windows压力机作为服务器，因此本次选择prometheus-2.22.0.windows-amd64.tar.gz进行下载。 下载后，解压文件。 双击prometheus.exe运行 在本地打开浏览器，输入http://localhost:9090，出现如图界面，则安装Prometheus成功。 Prometheus自带的图形并不够强大，于是我们可以使用Grafana作为Prometheus的Dashboard。 二、安装Grafana 由于压缩包超过限制，无法上传，可自行下载，解压后，执行bin/grafana-server.exe 通过本地浏览器访问地址：http://localhost:3000，出现下图，则表示Grafana安装成功。 默认登录用户名密码均为admin，首次登录后需要修改密码。 "},"工具/Prometheus/Prometheus监控JVM.html":{"url":"工具/Prometheus/Prometheus监控JVM.html","title":"Prometheus监控JVM","keywords":"","body":"Prometheus监控JVM "},"工具/Prometheus/Prometheus监控MySQL数据库.html":{"url":"工具/Prometheus/Prometheus监控MySQL数据库.html","title":"Prometheus监控MySQL数据库","keywords":"","body":"Prometheus监控MySQL数据库 1.下载安装mysqld_exporter mysqld_exporter-0.12.1.linux-amd64.tar.gz mysqld_exporter-0.12.1.windows-amd64.tar.gz 根据服务器不同的操作系统，选择对应的版本。 本次以linux服务器为例。 tar -xvf mysqld_exporter-0.12.1.linux-amd64.tar.gz cd mysqld_exporter-0.12.1.linux-amd64.tar.gz chmod +x mysqld_exporter 2.在数据库中添加对应的用户以及权限 因为mysqld_export需要通过连接数据库去获取监控数据，因此先给它创建一个用户，并赋予对应的权限。 GRANT REPLICATION CLIENT, PROCESS ON . TO 'exporter'@'localhost' identified by 'exporter'; GRANT SELECT ON performance_schema.* TO 'exporter'@'localhost'; flush privileges; 3.在同目录下，创建mysqld_export启动使用的配置文件 vim .my.cnf 内容如下： [client] user=exporter password=exporter 4.执行mysqld_export ./mysqld_export -config.my_cfg=\".my.cnf\" 5.验证能否正常获取到监控数据 浏览器访问服务器ip:9104/metrics，能够正常看到数据即为正常。 6.Prometheus配置中添加数据库节点 修改prometheus.yml加入MySql节点： \\- job_name: 'mysql' static_configs: \\- targets: ['9.1.17.43:9104'] 保存文件后，重启Prometheus。 7.查看Prometheus能否获取到节点 打开Prometheus页面，默认服务器ip:9090 8.在Grafana添加对应的mysql监控模板 mysql-overview_rev5.json 选择刚才下载的json文件。 9.查看监控结果 其他： 1.配置alertmanager报警,添加prometheus配置： alerting: alertmanagers: \\- scheme: http static_configs: \\- targets: \\- \"10.100.110.171:9093\" rule_files: \\- /opt/prometheus/rules/mysql*.rules 2.制定mysql报警规则 groups: \\- name: MySQLStatsAlert rules: \\- alert: MySQL is down expr: mysql_up == 0 for: 1m labels: severity: critical annotations: summary: \"Instance {{ $labels.instance }} MySQL is down\" description: \"MySQL database is down. This requires immediate action!\" \\- alert: open files high expr: mysql_global_status_innodb_num_open_files > (mysql_global_variables_open_files_limit) * 0.75 for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} open files high\" description: \"Open files is high. Please consider increasing open_files_limit.\" \\- alert: Read buffer size is bigger than max. allowed packet size expr: mysql_global_variables_read_buffer_size > mysql_global_variables_slave_max_allowed_packet for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} Read buffer size is bigger than max. allowed packet size\" description: \"Read buffer size (read_buffer_size) is bigger than max. allowed packet size (max_allowed_packet).This can break your replication.\" \\- alert: Sort buffer possibly missconfigured expr: mysql_global_variables_innodb_sort_buffer_size 4*1024*1024 for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} Sort buffer possibly missconfigured\" description: \"Sort buffer size is either too big or too small. A good value for sort_buffer_size is between 256k and 4M.\" \\- alert: Thread stack size is too small expr: mysql_global_variables_thread_stack mysql_global_variables_max_connections * 0.8 for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} Used more than 80% of max connections limited\" description: \"Used more than 80% of max connections limited\" \\- alert: InnoDB Force Recovery is enabled expr: mysql_global_variables_innodb_force_recovery != 0 for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} InnoDB Force Recovery is enabled\" description: \"InnoDB Force Recovery is enabled. This mode should be used for data recovery purposes only. It prohibits writing to the data.\" \\- alert: InnoDB Log File size is too small expr: mysql_global_variables_innodb_log_file_size mysql_global_variables_table_definition_cache for: 1m labels: severity: page annotations: summary: \"Instance {{ $labels.instance }} Table definition cache too small\" description: \"Your Table Definition Cache is possibly too small. If it is much too small this can have significant performance impacts!\" \\- alert: Table open cache too small expr: mysql_global_status_open_tables >mysql_global_variables_table_open_cache * 99/100 for: 1m labels: severity: page annotations: summary: \"Instance {{ $labels.instance }} Table open cache too small\" description: \"Your Table Open Cache is possibly too small (old name Table Cache). If it is much too small this can have significant performance impacts!\" \\- alert: Thread stack size is possibly too small expr: mysql_global_variables_thread_stack 0 for: 1m labels: severity: page annotations: summary: \"Instance {{ $labels.instance }} Binlog Statement Cache size too small\" description: \"Binlog Statement Cache size is possibly to small. A value of 1 Mbyte or higher is typically OK.\" \\- alert: Binlog Transaction Cache size too small expr: mysql_global_variables_binlog_cache_size 30 for: 1m labels: severity: warning annotations: summary: \"Instance {{ $labels.instance }} Slave lagging behind Master\" description: \"Slave is lagging behind Master. Please check if Slave threads are running and if there are some performance issues!\" \\- alert: Slave is NOT read only(Please ignore this warning indicator.) expr: mysql_global_variables_read_only != 0 for: 1m labels: severity: page annotations: summary: \"Instance {{ $labels.instance }} Slave is NOT read only\" description: \"Slave is NOT set to read only. You can accidentally manipulate data on the slave and get inconsistencies...\" 3.将mysqld_export添加为系统服务 添加系统服务：vi /usr/lib/systemd/system/mysql_exporter.service [Unit] Description=[https://prometheus.io](https://prometheus.io/) [Service] Restart=on-failureExecStart=/usr/local/mysql_exporter/mysqld_exporter --[config.my](http://config.my/)-cnf=.my.cnf [Install] WantedBy=multi-user.target 添加后可以使用 systemctl restart mysql_exporter.service 重启服务 systemctl stop mysql_exporter.service 停止服务 systemctl start mysql_exporter.service 启动服务 "},"工具/Prometheus/Prometheus监控Oracle数据库.html":{"url":"工具/Prometheus/Prometheus监控Oracle数据库.html","title":"Prometheus监控Oracle数据库","keywords":"","body":"Prometheus监控Oracle数据库 "},"工具/Prometheus/Prometheus监控Linux主机.html":{"url":"工具/Prometheus/Prometheus监控Linux主机.html","title":"Prometheus监控Linux主机","keywords":"","body":"Prometheus监控Linux主机 首先在Linux系统上安装一个探测器node explorer, 下载地址https://prometheus.io/docs/guides/node-exporter/ 下载压缩包，并解压： tar -zxvf node_exporter-1.0.1.linux-amd64.tar.gz 这个探测器会定期将linux系统的各项硬件指标和内核参数通过9100端口和url metrics暴露给外部。 #后台执行node_exporter ./node_exporter & 添加服务为系统服务： # vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=node_exporter After=network.target [Service] Type=simple User=prometheus ExecStart=/usr/local/prometheus/node_exporter/node_exporter Restart=on-failure [Install] WantedBy=multi-user.target 启动 #添加为开机自启 # systemctl enable node_exporter.service #启动服务 # systemctl start node_exporter.service 浏览器里输入ip:9100/metrics，可以看到node explorer收集到的各项参数信息，则表示运行成功。 在Prometheus安装目录的prometheus.yml文件里定义一个job，指向Linux系统上运行的node explorer: - job_name: 'node' file_sd_configs: - files: ['./node/node.yml'] refresh_interval: 5s 在同级目录下新建一个node文件夹，创建node.yml文件。 内容为： - targets: - 9.1.17.43:9100 或者直接添加如下内容： # vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'linux' static_configs: - targets: ['10.10.10.1:9100'] 重启Prometheus，打开下面的url： http://PrometheusServerIP:9090/ 输入node_cpu_seconds_total{mode=\"system\"}，查询该服务器上所有CPU工作在系统态消耗的时间： 还可以指定时间窗口，只查询过去1分钟之内的CPU运行数据： rate(node_cpu_seconds_total{mode=\"system\"}[1m]) 添加对应的模板，显示监控信息。 Linux监控模板node-exporter_rev5.json 如果联网的话，直接输入dashboards的id，也可以添加。 添加dashboards 点击Create - Import，输入dashboards的id（推荐1860） "},"工具/Prometheus/Prometheus监控Windows主机.html":{"url":"工具/Prometheus/Prometheus监控Windows主机.html","title":"Prometheus监控Windows主机","keywords":"","body":"Prometheus监控Windows主机 "},"工具/Prometheus/Prometheus监控容器.html":{"url":"工具/Prometheus/Prometheus监控容器.html","title":"Prometheus监控容器","keywords":"","body":"Prometheus监控容器 "},"操作系统/":{"url":"操作系统/","title":"操作系统","keywords":"","body":"操作系统 "},"操作系统/IOS/":{"url":"操作系统/IOS/","title":"IOS","keywords":"","body":"IOS iOS是由苹果公司开发的移动操作系统。苹果公司最早于2007年1月9日的Macworld大会上公布这个系统，最初是设计给iPhone使用的，后来陆续套用到iPod touch、iPad以及Apple TV等产品上。iOS与苹果的macOS操作系统一样，属于类Unix的商业操作系统。原本这个系统名为iPhone OS，因为iPad，iPhone，iPod touch都使用iPhone OS，所以2010年WWDC大会上宣布改名为iOS(iOS为美国Cisco 公司网络设备操作系统注册商标，苹果改名已获得Cisco公司授权）。 "},"操作系统/IOS/IOS模拟器命令xcrun_simctl系列.html":{"url":"操作系统/IOS/IOS模拟器命令xcrun_simctl系列.html","title":"IOS模拟器命令xcrun_simctl系列","keywords":"","body":"IOS模拟器命令xcrun_simctl系列 simctl是iOS模拟器命令行管理工具 simctl于安卓的adb命令非常相似。虽然苹果官方文档没有对它进行任何说明。但是我们可以通过Applications/Xcode.app/Contents/Developer/usr/bin/simctl路径找到它。由于是XCode内置的命令，所以在使用的时候要在该命令前面加上xcrun。我们可以通过以下命令来查看该命令所有的功能选项。 xcrun simctl help 如下图： simctl子命令以及其功能说明 子命令 功能 create 创建新的模拟器 clone 克隆一个已有的模拟器 upgrade 给模拟器升级系统 delete 删除一个模拟器或删除全部不可用模拟器 pair 将手表模拟器和iPhone模拟器进行配对 pair_active 激活手表模拟器和iPhone模拟器的配对 erase 清楚模拟器的所有数据和设置 boot 启动一个模拟器 shutdowm 关闭一个模拟器 rename 重命名模拟器 getenv 获取模拟器环境变量对应的值 openurl 打开一个链接（不局限于网页链接） addphoto 给模拟器添加照片 addvideo 给模拟器相册中添加视频 addmedia 给模拟器相册中添加照片、LIVE照片或者视频 install 安装一个应用 uninstall 卸载一个应用 get_app_container 获取应用的沙盒路径 terminate 关闭一个应用 spawn 开启一个新进程 list 列出所有可用的模拟器、模拟器类型、系统版本、设备配对情况 icloud_sync 触发设备上的iCloud同步 pbinfo 打印模拟器粘贴板的信息 pbsync 将设备粘贴板的信息同步给其他设备 pbcopy 将标准输入复制到设备粘贴板上 pbpaste 将设备的剪切板打印到标准输出中 notify_post 发送一个Darwin通知 notify_get_state 获取Darwin通知的状态值 notify_set_state 设置Darwin通知的状态值 register 注册一个服务 unregister 注销一个服务 keyboard 设置键盘的主语言 monitor 当通知到达的时候打印出来 appinfo 获取一个已安装的app的信息 listapps 获取全部已安装的app help 显示如何使用 io 设置设备IO操作 diagnose 收集诊断信息和日志 logverbose 启用或禁用设备的详细日志记录 bootstatus 检查设备的运行状态 darwinup 调用darwinup来安装一个root运行环境 这些都是些简单的命令，多运用几次就能学会了。不熟的时候可以借助 help命令来辅助 注意： 如果模拟器应用没有打开，直接调用上面的命令来启动一个模拟器是无效的，所以我们要先打开模拟器应用，然后再启动一个模拟器。 所以补充下打开模拟器命令： 启动默认模拟器 open \"/Applications/Xcode.app/Contents/Developer/Applications/Simulator.app/\" 启动指定的模拟器 xcrun instruments -w 'iPhone 6 Plus' 列出安装的可用的模拟器： xcrun instruments -s 【如：iPhone 5s (9.0) [00AB3BB6-C5DC-45C7-804F-6B88F57C2AFF] (Simulator)】 查看已安装的模拟器：ios-sim showdevicetypes 【如：iPhone-6s, 11.1 iPhone-6s, 10.0 iPhone-6s, 9.0 iPhone-6s, 11.2 iPhone-6s, 10.1 iPhone-6s, 9.2】 查看已安装的模拟器：xcrun simctl list 【如： -- iOS 11.3 -- iPhone 5s (9ABF3B1A-4A86-4BAC-BBB2-5D63CC30F0DE) (Shutdown)】 如查看启动的模拟器： xcrun simctl list | grep Booted 开启上面列表中指定的模拟器： xcrun instruments -w \"iPhone 8(11.2)\" 开启指定的模拟器： xcrun simctl boot udid 关掉模拟器: xcrun simctl shutdown udid 关掉所有打开的模拟器： xcrun simctl shutdown all 重置模拟器(清除模拟器的数据和设置)xcrun simctl erase udid 安装指定app: xcrun simctl install booted 多设备时：xcrun simctl install 安装指定app: ios-sim launch /Users/nali/Desktop/ting.app --devicetypeid iPhone-X, 11.2 运行指定的app: xcrun simctl launch booted 多设备时：xcrun simctl launch 关闭已经打开的应用： xcrun simctl terminate booted 多设备时：xcrun simctl terminate 卸载指定应用： xcrun simctl uninstall booted 多设备时：xcrun simctl uninstall 截图：xcrun simctl io booted screenshot screenshot.png 会发现在当前目录下会多了一张照片 多设备时： xcrun simctl io screenshot screenshot.png 录屏：xcrun simctl io booted recordVideo example.mp4 多设备时：xcrun simctl io recordVideo example.mp4 日志： tail -f \\ 日志文件的路径： /Users/\\$UserName/Library/Logs/CoreSimulator/$simulator_hash/system.log "},"操作系统/Android/":{"url":"操作系统/Android/","title":"Android","keywords":"","body":"Android Android（读音：英：['ændrɔɪd]，美：[ˈænˌdrɔɪd]），常见的非官方中文名称为安卓，是一个基于Linux内核的开放源代码移动操作系统，由Google成立的Open Handset Alliance（OHA，开放手持设备联盟）持续领导与开发，主要设计用于触摸屏移动设备如智能手机和平板电脑与其他便携式设备。 2005年8月由Google收购注资。2007年11月，Google与84家硬件制造商、软件开发商及电信营运商组建开放手机联盟共同研发改良Android系统。随后Google以Apache开源许可证的授权方式，发布了Android的源代码。第一部Android智能手机发布于2008年10月。Android逐渐扩展到平板电脑及其他领域上，如电视、数码相机、游戏机、智能手表等。 Android一词的本义指“机器人”，同时也是Google于2007年11月5日宣布的基于Linux平台的开源手机操作系统的名称，该平台由操作系统、中间件、用户界面和应用软件组成。 Android的Logo是由Ascender公司设计的，诞生于2010年，其设计灵感源于男女厕所门上的图形符号，于是布洛克绘制了一个简单的机器人，它的躯干就像锡罐的形状，头上还有两根天线，Android小机器人便诞生了。其中的文字使用了Ascender公司专门制作的称之为“Droid ” 的字体。Android是一个全身绿色的机器人，绿色也是Android的标志。颜色采用了PMS 376C和RGB中十六进制的#A4C639来绘制，这是Android操作系统的品牌象徵。有时候，它们还会使用纯文字的Logo。 Android在正式发行之前，最开始拥有两个内部测试版本，并且以著名的机器人名称来对其进行命名，它们分别是：阿童木（AndroidBeta），发条机器人（Android 1.0）。后来由于涉及到版权问题，谷歌将其命名规则变更为用甜点作为它们系统版本的代号的命名方法。甜点命名法开始于Android 1.5发布的时候。作为每个版本代表的甜点的尺寸越变越大，然后按照26个字母数序：纸杯蛋糕（Android 1.5），甜甜圈（Android 1.6），松饼（Android 2.0/2.1），冻酸奶（Android 2.2），姜饼（Android 2.3），蜂巢（Android 3.0），冰激凌三明治（Android 4.0），果冻豆（Jelly Bean，Android4.1和Android 4.2），奇巧（KitKat，Android 4.4），棒棒糖（Lollipop，Android 5.0），棉花糖（Marshmallow，Android 6.0），牛轧糖（Nougat，Android 7.0），奥利奥（Oreo，Android 8.0），派（Pie,Android 9.0）。 从Android 10开始，Android不会再按照基于美味零食或甜点的字母顺序命名，而是转换为版本号，就像Windows和iOS系统一样。 "},"操作系统/Android/Android性能问题分析神器Systrace.html":{"url":"操作系统/Android/Android性能问题分析神器Systrace.html","title":"Android性能问题分析神器Systrace","keywords":"","body":"Android性能问题分析神器Systrace 一、简介 Systrace是分析Android设备的性能的主要工具，Google IO 2017上更是对其各种强推. 是分析卡顿掉帧问题核心工具，只要能提供卡顿现场，systrace就能很好定位问题. 二、原理 在介绍使用之前，先简单说明一下Systrace的原理：它的思想很朴素，在系统的一些关键链路（比如System Service，虚拟机，Binder驱动）插入一些信息（我这里称之为Label），通过Label的开始和结束来确定某个核心过程的执行时间，然后把这些Label信息收集起来得到系统关键路径的运行时间信息，进而得到整个系统的运行性能信息。Android Framework里面一些重要的模块都插入了Label信息（Java层的通过android.os.Trace类完成，native层通过ATrace宏完成），用户App中可以添加自定义的Label，这样就组成了一个完成的性能分析系统。另外说明的是：Systrace对系统版本有一个要求，就是需要Android 4.1以上。系统版本越高，Android Framework中添加的系统可用Label就越多，能够支持和分析的系统模块也就越多；因此，在可能的情况下，尽可能使用高版本的Android系统来进行分析。 作用 用于收集可帮助您检查原生系统进程的详细系统级数据，包括跟踪系统的I/O操作、内核工作队列、CPU负载以及Android各个子系统的运行状况等，例如CPU调度、磁盘活动、应用线程等，并解决掉帧引起的界面卡顿。 本质 它是 atrace 的主机端封装容器，是用于控制用户空间跟踪和设置 ftrace 的设备端可执行文件，也是 Linux 内核中的主要跟踪机制。 systrace 使用 atrace 来启用跟踪，然后读取 ftrace 缓冲区并将其全部封装到一个独立的 HTML 查看器中。 组成 内核部分：Systrace利用了Linux Kernel中的ftrace功能。所以，如果要使用systrace的话，必须开启kernel中和ftrace相关的模块 数据采集部分：Android定义了一个Trace类。应用程序可利用该类把统计信息输出给ftrace。同时，Android还有一个atrace程序，它可以从ftrace中读取统计信息然后交给数据分析工具来处理。 数据分析工具：Android提供一个systrace.py（python脚本文件，位于Android SDK目录/sdk/platform-tools/systrace中，其内部将调用atrace程序）用来配置数据采集的方式（如采集数据的标签、输出文件名等）和收集ftrace统计数据并生成一个结果网页文件供用户查看。 官网 https://source.android.google.cn/devices/tech/debug/systrace https://developer.android.google.cn/studio/command-line/systrace extra:什么是atrace?什么是ftrace? ftrace 是一种调试工具，用于了解 Linux 内核中的情况；而 atrace (frameworks/native/cmds/atrace) 使用 ftrace 来捕获内核事件； 官网简单的介绍地址：https://source.android.google.cn/devices/tech/debug/ftrace 三、抓取方法 systrace.py AndroidStudio Systrace工具 自定义trace 1.systrace.py 使用python命令以及systrace.py工具 systrace.py工具位置在 sdk/platform-tools/systrace； python systrace.py [options] [categories] 示例：调用systrace来记录10秒钟内的设备进程，包括图形进程，并生成mynewtrace.html报告 具体命令如下 python systrace.py --time=10 -o mynewtrace.html gfx options参数表 options description -o 输出的目标文件 -t N, –time=N 执行时间，默认5s -b N, –buf-size=N buffer大小（单位kB),用于限制trace总大小，默认无上限 -k ，–ktrace= 追踪kernel函数，用逗号分隔 -a ,–app= 追踪应用包名，用逗号分隔 –from-file= 从文件中创建互动的systrace -e ,–serial= 指定设备 -l, –list-categories 列举可用的tags -h , --help 显示帮助信息 -l,--list-categories 列出可用于连接设备的跟踪categories类别 -o file |将HTML跟踪报告写入指定的文件。 如果您不指定此选项，systrace会将您的报告保存到systrace.py所在的同一目录中，并将其命名为trace.|html。| |-t N ,--time=N |跟踪设备活动N秒。如果不指定此选项，systrace将提示您通过按命令行中的Enter键结束跟踪。| |-b N ,--buf-size=N |使用N千字节的跟踪缓冲区大小。通过此选项，可以限制跟踪期间收集的数据的总大小。| |-k functions,--ktrace=functions |跟踪中指定的特定内核函数的活动，以逗号分隔的列表| |-a app-name,--app=app-name |跟踪指定应用，为逗号分隔列表。| |--from-file=file-path |从文件（例如包含原始跟踪数据的TXT文件）创建交互式HTML报告，而不是运行实时跟踪。| |-e device-serial,--serial=device-serial |跟踪指定的设备序列号标识的特定连接设备| catagories参数表 category description gfx Graphics input Input view View System webview WebView wm Window Manager am Activity Manager sm Sync Manager audio Audio video Video camera Camera hal Hardware Modules app Application res Resource Loading dalvik Dalvik VM rs RenderScript bionic Bionic C Library power Power Management sched CPU Scheduling irq IRQ Events freq CPU Frequency idle CPU Idle disk Disk I/O mmc eMMC commands load CPU Load sync Synchronization workq Kernel Workqueues memreclaim Kernel Memory Reclaim regulators Voltage and Current Regulators 2.AndroidStudio Systrace工具 打开AndroidStudio，连接好设备，打开DDMS ， 点击 Tools——>Android——>Android device monitor 点击systrace按钮，弹出信息配置框，确认后，会记录Trace duration 5秒钟内的设备进程，并生成一个名为trace.html报告 此处信息对应上面的命令参数表，请自行参照 注意：Enable Application Trace from :若是需要自定义trace信息，必须选择对应的应用进程，否则不会被捕获到 3.自定义trace 用户可以自己添加自定义的trace块，来捕获指定trace的信息 Android 4.3 (API level 18) 以及更高版本可以使用 Android Trace.beginSection(); Trace.endSection(); 代码示例 public class MyAdapter extends RecyclerView.Adapter { ... @Override public MyViewHolder onCreateViewHolder(ViewGroup parent, int viewType) { Trace.beginSection(\"MyAdapter.onCreateViewHolder\"); MyViewHolder myViewHolder; try { myViewHolder = MyViewHolder.newInstance(parent); } finally { // In 'try...catch' statements, always call endSection() // in a 'finally' block to ensure it is invoked even when an exception // is thrown. Trace.endSection(); } return myViewHolder; } @Override public void onBindViewHolder(MyViewHolder holder, int position) { Trace.beginSection(\"MyAdapter.onBindViewHolder\"); try { try { Trace.beginSection(\"MyAdapter.queryDatabase\"); RowItem rowItem = queryDatabase(position); mDataset.add(rowItem); } finally { Trace.endSection(); } holder.bind(mDataset.get(position)); } finally { Trace.endSection(); } } ... } native #include ATrace_beginSection(); ATrace_endSection(); 创建一个便利的对象/宏结构来跟踪代码块 #define ATRACE_NAME(name) ScopedTrace ___tracer(name) // ATRACE_CALL is an ATRACE_NAME that uses the current function name. #define ATRACE_CALL() ATRACE_NAME(__FUNCTION__) class ScopedTrace { public:inline ScopedTrace(const char *name) { ATrace_beginSection(name); } inline ~ScopedTrace() { ATrace_endSection(); } }; void myExpensiveFunction() { ATRACE_CALL(); ... // trace-worthy work here } 四、快捷键 查看Systrace生成的trace.html，浏览器打开界面如下： 分析trace.html图形信息之前，先了解下快捷键 点击浏览器界面上右上角“？”，可以查看到各个快捷键提示 快捷键 作用 w 放大，[+shift]速度更快 s 缩小，[+shift]速度更快 a 左移，[+shift]速度更快 d 右移，[+shift]速度更快 f 放大当前选定区域 m 标记当前选定区域 v 高亮VSync g 切换是否显示60hz的网格线 0 恢复trace到初始态，这里是数字0而非字母o h 切换是否显示详情 / 搜索关键字 enter 显示搜索结果，可通过← →定位搜索结果 ` 显示/隐藏脚本控制台 ? 显示帮助功能 五、分析trace.html 颜色块每块颜色占据的长度即为该系统或者自定义trace等执行所占据的时间长度 Alerts含有三角状的圆圈图标，对应出现警告的位置，点击可以在右边栏Alerts查看具体警告内容； 警告会告诉你可能丢帧或者卡顿等的原因 Frame含有F字母的圆圈图标，对应每一帧开始的位置，不同颜色有不同意义； 绿色表示正常，当颜色为橙色或者红色时，意味着这一帧超过16.6ms（即发现丢帧）； Kernel（上图为四核CPU）显示每个CPU各自执行的系统方法或自定义trace块，以及占据的时间长度 SurfaceFlingersurfaceFilnger，进程id为118，显示系统方法以及占据的时间长度 com.android.janktown应用进程，进程id为13409，显示应用进程内各个线程等信息每个线程有颜色表示各自不同的状态 • 灰色：正在休眠。 • 蓝色：可运行（它可以运行，但是调度程序尚未选择让它运行）。 • 绿色：正在运行（调度程序认为它正在运行）。 • 红色：不可中断休眠（通常在内核中处于休眠锁定状态）。可以指示 I/O 负载，在调试性能问题时非常有用。 • 橙色：由于 I/O 负载而不可中断休眠。 分析卡顿或掉帧 Systrace可以直观的看到掉帧引起的界面卡顿如下图 点击F，使用快捷键f放大该帧，可以选择m高亮该选区，查看该帧的所有系统trace块执行时间 查看下面面板的Frame里的信息 ListView recycling takiing too mush time per frame.Ensure your Adapter#getView() binds data efficiently 主要问题是在ListView回收和重新绑定中花费了太多时间。 Alerts选项卡可以查看每个警报以及设备触发每个警报的次数 如果你在UI线程上看到了太多的工作，你需要找出哪些方法消耗了太多的CPU时间。 一种方法是添加跟踪标记即自定义trace信息到您认为会导致这些瓶颈的方法； 另一种由于不确定哪些方法可能导致UI线程出现瓶颈，可以使用Android Studio的内置CPU分析器，或生成跟踪日志并使用Traceview来进行查看。 "},"操作系统/Windows/":{"url":"操作系统/Windows/","title":"Windows","keywords":"","body":"Windows 简介 Microsoft公司从1983年开始研制Windows系统，最初的研制目标是在MS - DOS的基础上提供一个多任务的图形用户界面。第一个版本的Windows 1.0于1985年问世，它是一个具有图形用户界面的系统软件。1987年推出了Windows 2.0版，最明显的变化是采用了相互叠盖的多窗口界面形式。但这一切都没有引起人们的关注。直到1990年推出Windows 3.0成为一个重要的里程碑，它以压倒性的商业成功确定了Windows系统在PC领域的垄断地位。现今流行的Windows窗口界面的基本形式也是从Windows3.0开始基本确定的。1992年主要针对Windows 3.0的缺点推出了Windows 3.1，为程序开发提供了功能强大的窗口控制能力，使Windows和在其环境下运行的应用程序具有了风格统一、操纵灵活、使用简便的用户界面。Windows3.1在内存管理上也取得了突破性进展。它使应用程序可以超过常规内存空间限制，不仅支持16MB内存寻址，而且在80386及以上的硬件配置上通过虚拟存储方式可以支持几倍于实际物理存储器大小的地址空间。Windows 3.1还提供了一定程度的网络支持、多媒体管理、超文本形式的联机帮助设施等，对应用程序的开发有很大影响。 众所周知，Windows在个人计算机领域是普及度很高的操作系统。当计算机的体积不断变小，发展成掌上电脑的形态时，Windows系统自然电延伸到这类便携式产品的领域。然而，掌上电脑在续航能力、显示屏幕、输入界面等方面与普通的PC还是有很大差别的，考虑功耗和用户使用习惯等方面的因素，Windows系统针对手持没备的特点进行了多次调整和优化，先后形成了Windows CE，Windows Mobile，Windows Phone等移动版本的系统。 早期的Windows移动版本系统并未充分考虑智能手机的特点，更多的是从掌上电脑的角度在设计系统。例如，开始菜单虽然在PC上早已为人们所习惯和熟知，但将开始菜单放到手机屏幕上使用时，层层展开的菜单在狭小的屏幕上会让用户很难找到自己所需要的程序。因此，当微软充分认识到移动互联网的发展潜力后，Windows针对智能手机系统的各种设计才逐渐朝着扁平化的风格演变，其中一个特色就是动态磁贴的概念。 目前，虽然Windows Phone系统凭借Windows系统在桌面计算领域的优势，以及其办公软件Office多年培养起来的庞大用户群体和操作习惯，一直试图在移动计算领域扩大份额。然而，决定一个系统生命力的是应用程序的数量和质量，在这一点上，Windows Phone系统似乎起步太晚了，如何将开发者和用户从已经较为成熟的安卓和iOS系统吸引到这个平台上来是WP面临的最大挑战。 特点 1、Windows操作系统的人机操作性优异。 操作系统是人使用计算机硬件沟通的平台，没有良好的人机操作性，就难以吸引广大用户使用。手机领域，诺基亚手机能够占据手机市场半壁江山，手机操作系统互动性良好是其成功的重要因素之一，而其迅速的衰败也是因为操作系统的落伍。Windows操作系统能够作为个人计算机的主流操作系统，其优异的人机操作性是重要因素。Windows操作系统界面友好，窗口制作优美，操作动作易学，多代系统之间有良好的传承，计算机资源管理效率较高，效果较好。 2、Windows操作系统支持的应用软件较多。 Windows操作系统作为优秀的操作系统，由开发操作系统的微软公司控制接口和设计，公开标准，因此，有大量商业公司在该操作系统上开发商业软件。Windows操作系统的大量应用软件为客户提供了方便。这些应用软件门类全，功能完善，用户体验性好。譬如，Windows操作系统有大量的多媒体应用软件，搜集管理多媒体资源，客户只需要使用这些基于系统开发出来商业软件就可以享受多媒体带来的快乐。 3、Windows操作系统对硬件支持良好。 硬件的良好适应性是Windows操作系统的有一个重要特点。Windows操作系统支持多种硬件平台对于硬件生产厂商宽泛、自由的开发环境，激励了这些硬件公司选择与Windows操作系统相匹配，也激励了Windows操作系统不断完善和改进，同时，硬件技术的提升，也为操作系统功能拓展提供了支撑。另外，该操作系统支持多种硬件的热插拔，方便了用户的使用，也受到了广大用户的欢迎。 Windows系列 一、Windows 1.0 Windows 1.0是微软公司第一次对个人电脑操作平台进行用户图形界面的尝试。Windows 1.0基于MS-DOS操作系统。Microsoft Windows 1.0是Windows系列的第一个产品，于1985年开始发行。 当时很多人认为Windows 1.0只是一个低劣的产品。当时最好的GUI电脑平台是GEM。另外一个选择是Desqview/X。 Windows 1.0中鼠标作用得到特别的重视，用户可以通过点击鼠标完成大部分的操作。Windows 1.0 自带了一些简单的应用程序，包括日历、记事本、计算器等等。总之，刚诞生的Windows 1.0，总会让人感到它像是一个PDA，甚至可能功能还赶不上PDA，不过这在Windows 1.0诞生时已经相当吸引人了。Windows 1.0的另外一个显著特点就是允许用户同时执行多个程序，并在各个程序之间进行切换，这对于DOS来说是不可想象的。 Windows 1.0 可以显示256种颜色，窗口可以任意缩放，当窗口最小化的时候桌面上会有专门的空间放置这些窗口（其实就是现在的任务栏）。 在Windows 1.0中已经出现了控制面板（Control Panel），对驱动程序、虚拟内存有了明确的定义，不过功能非常有限。 二、Windows 2.0 1987年12月9日，Windows 2.0发布，最初售价为100美元；是一个基于MS-DOS操作系统、看起来像Mac OS的微软Windows图形用户界面的Windows版本。但这个版本依然没有获得用户认同。之后又推出了windows 386和windows 286版本，有所改进，并为之后的Windows 3.0的成功作好了技术铺垫。并且具有比Windows 1.0更多的功能。 在Windows2.0中，用户不但可以缩放窗口，而且可以在桌面上同时显示多个窗口（也就是现在的层叠模式），而在Windows 1.0中屏幕上不能同时显示多个窗口，打开一个窗口时其他窗口必须最小化。Windows 2.0的另外一个重大突破是在1987年的年底，微软为Windows2.0增加了386扩展模式支持，Windows第一次跳出了640K基地址内存的束缚，更多的内存可以充分发挥Windows的优势。 三、Windows 3.0 1990年5月22日， Microsoft迎来了第一个具有时代意义的作品— Windows3.0，虽然很多人更愿意将 Windows3.1作为Microsoft跨时代的作品，但毕竟 Windows3.0是 Windows3.x系列的起点，假如没有 Windows3.0的成功，也不会有更多人对后续产品的关注。 Windows3.0的主要特点有: 具备了模拟32位操作系统的功能，图片显示效果大有长进，对当时最先进的386处理器有良好的支持;提供了对虚拟设备驱动(VxDs)的支持，极大改善了系统的可扩展性;用户界面和运行环境得到了很大的改进，系统开始支持16位色，DOS的文件管理程序被基于图标的程序管理器以及基于列表的文件管理器所取代；简化了程序的启动，打印管理器也诞生了，控制面板成为系统设置的核心;模仿了苹果公司 Macintosh的设计，使用一些新的图标；开发了 Software Development Kit(SDK)来帮助硬件厂商开发驱动程序，使操作系统能与硬件完美结合。 1992年4月，一个更为成熟的版本 Windows3.1诞生了。Windows3.1添加了多媒体功能、CD播放器以及对桌面排版很重要的 True Type字体。次年发布的 Windows for Workgroups3.11又引人了对网络的支持―包括以太网和当时如日中天的Novell netware，并利用对等网络的概念构建 Windows工作组网络。 1994年 Windows3.2发布，这也是 Windows系统第一次有了中文版。由于消除了语言障碍，降低了学习门槛，因此在国内得到了较为广泛的应用。 四、Windows 95 1995年8月24日，微软公司推出了Windows 95，它是第一个不要求先安装DOS的32位操作系统。Windows 95的大部分内核代码都重新改写，虽然仍有部分16位代码（如USER.EXE和GDI.EXE）存在于Windows 95之中，但大多数代码是32位的。Windows 95的大多数1/0操作、存储管理和进程管理是保护模式的。但所有的Windows 95系统都先以实模式方式引导，以便有机会装载旧的设备和网络驱动程序。其文件系统还承担着一定数量的实模式管理任务，以便将重要的系统事件通知1日的应用程序。Windows 95具有全新的图形川户界面，提高了用户的可学性、可用性和高效率。Windows 95支持多达255个字符的文件名和扩展名，而在DOS提示符下又可转换成8.3规则的别名以保持兼容性。 Windows 95自身的32位Windows应用程序接口(Win32)能使应用程序得到更快的响应，能更快地处理CPU密集的任务。Windows 95不需要利用DOS或进入实模式来访问磁盈，使得运行频繁的I/O程序仍具有很高的效率。Windows 95采用优先级多任务使运行的几个应用程序更平滑，系统反应更迅速。其线程允许一个应用程序在自身范围内进行多任务处理，使得响应更加迅速。Windows 95将32位的OLE集成为系统的一部分，性能有了极大的提高。Windows 95还集成了网络的连接和管理，其连接特性也从LAN扩展到了拨号访问。它还支持TCP/IP结构和PnP技术。 1996年10月，Windows 95的OSR2版(OEM Service Release 2，该版本又被称为Windows97)推出，它里面支持许多新功能，如FAT32和改进的拨号网络等，它还包含有IntemetExplorer 3.0。 五、Windows 98 1998年6月25日发布的Windows 98是Windows 95的改进版。Windows 98中集成了Intemet Explorer 4.0。Windows 98具有Web集成和活动桌面，增加了频道等网络功能，Windows 98采用FAT32文件系统，并提供FAT32转换工具，Windows 98支持ACPI电源管理、USB总线，IEEE1394总线和AGP总线。它同时支持DVD功能，DirectX是Windows 98中增强多媒体功能的实用程序。 六、Windows 98 SE Windows 98 SE（第二版）发行于1999年5月5日。它包括一系列改进，如Internet Explorer 5、Windows Netmeeting 3、Internet Connection Sharing、对DVD-ROM和对USB的支持。另外98SE的核心部分比Windows 98多支援了影音流媒体接收能力，以及5.1声道支持。 七、Windows Me 2000年9月14日微软公司发布Windows ME( Windows Millennium Edition，简称WindowsME)，Windows ME是在Windows 9X的基础上开发的，主要针对的是家庭和个人用户，Windows ME重点改进了对多媒体和硬件设备的支持，但同时也加入了不少在Windows 2000上拥有的新概念。主要增加的功能包括系统恢复、UPnP即插即用、自动更新等。由于WindowsME的稳定性和可靠性较差，相当多的1日Dos程序无法在Windows ME上运行。相比其他版本的Windows系统，Windows ME只延续了短短一年，就被Windows XP取代了。 八、Windows NT Windows NT是基于OS/2 NT的基础编制的。OS/2是由微软和IBM联合研制，分为微软的Microsoft OS/2 NT与IBM的IBM OS/2。由于种种原因，协作后来不欢而散，IBM继续向市场提供先前的OS/2版本，而微软则把自己的OS/2 NT的名称改为Windows NT，即第一代的Windows NT 3.1（1993年8月31日发布）。Windows NT是纯32位操作系统，采用先进的NT核心技术，NT即新技术（New Technology）。1996年4月发布的Windows NT 4.0是NT系列的一个里程碑，该系统面向工作站、网络服务器和大型计算机，它与通信服务紧密集成，提供文件和打印服务，能运行客户机/服务器应用程序，内置了Internet/Intranet功能。 Windows NT具有以下特点： (1) 32位操作系统，多重引导功能，可与其他操作系统共存。 (2)实现了“抢先式”多任务和多线程操作。 (3)采用SMP（对称多处理）技术，支持多CPU系统。 (4)支持CISC（如Intel系统）和RISC（如Power PC、R4400等）多种硬件平台。 (5)可与各种网络操作系统实现互操作，如真INIX、Novel Netware、Macintosh等系统；对客户操作系统提供广泛支持，如MS-DOS、Windows、Windows NT Workstation、urNX、OS/2、Macintosh等系统：支持多种协议，如TCP /IP、NetBEUI、DLC、AppleTalk、NWLINK等。 (6)安全性达到美国国防部的C2标准。 九、Windows 2000 Microsofi Windows 2000是沿袭微软公司Windows NT系列的32位视窗操作系统，是Windows操作系统发展的一个新里程碑。Windows 2000起初称为Windows NT 5.0。它的英文版于1999年12月19日上市，中文版于次年2月上市。Windows 2000是一个先占式多任务、可中断的、面向商业环境的图形化操作系统，为单一处理器或对称多处理器的32位Intelx86电脑而设计。它的客户机版本（Professional版本）在2001年l0月被Windows XP所取代；而服务器版本则在2003年4月被Windows Server 2003所取代。 十、WindowsXP Windows XP是Microsoft公司于2001年10月发布的一款操作系统。它不再采用微软公司一贯的以年份命名的方式（如先前的Windows 95、Windows 98和Windows 2000），而是以一个全新的名字WindowsXP来命名这款全新的操作系统。按照微软公司的解释，XP是experience的缩写，旨在在全新技术和功能的引导下，让使用者拥有更加丰富而广泛的全新计算机使用体验，感受科技带来的乐趣。 [8] Windows XP是个人计算机的一个重要里程碑，它集成了数码媒体、远程网络等最新的技术规范，还具有很强的兼容性，外观清新美观，能够带给用户良好的视觉享受。Windows XP产品功能几乎包含了所有计算机领域的需求。同时，根据不同用户的需求，Windows XP又包括了多个版本。其中最为常见的是针对个人用户的家庭版Windows XP Home Edition和针对商业用户的专业版Windows XP Professional。家庭版的消费者是家庭用户，专业版则在家庭版的基础上添加了新的面向商业而设计的网络认证、双处理器等特性。 十一、Windows 7 2009年10月，微软公司推出了Windows 7，核心版本号为Windows NT 6.1。Windows7可供家庭及商业工作环境、笔记本电脑、平板电脑、多媒体中心等使用。Windows 7先后推出了简易版、家庭普通版、家庭高级版、专业版、企业版等多个版本。Windows 7的启动时间大幅缩减，增加了简洁的搜索和信息使用方式，改进了安全和功能合法性，使用Aero效果更显华丽和美观。 十二、Windows 8 2012年10月26日，微软正式推出Windows 8。Windows 8是由微软公司开发的具有革命性变化的操作系统。该系统旨在让人们的日常电脑操作更加简单和快捷，为人们提供高效易行的工作环境。Windows 8支持个人电脑（X86构架）及平板电脑(X86构架或ARM构架)。Windows 8大幅改变以往的操作逻辑，提供更佳的屏幕触控支持。新系统画面与操作方式变化极大，采用全新的Metro风格用户界面，各种应用程序、快捷方式等能以动态方块的样式呈现在屏幕上，用户可自行将常用的浏览器、社交网络、游戏、操作界面融入。 十三、Windows 10 2015年7月29日，美国微软公司正式发布计算机和平板电脑操作系统Windows 10。 2014年10月1日，微软在旧金山召开新品发布会，对外展示了新一代Windows操作系统，将它命名为“Windows 10”，新系统的名称跳过了数字“9”。2015年1月21日，微软在华盛顿发布新一代Windows系统，并表示向运行Windows7、Windows 8.1以及Windows Phone 8.1的所有设备提供，用户可以在Windows 10发布后的第一年享受免费升级服务。 2月13日，微软正式开启Windows 10手机预览版更新推送计划。 3月18日，微软中国官网正式推出了Windows 10中文介绍页面。 4月22日，微软推出了Windows Hello和微软Passport用户认证系统，微软又公布了名为“Device Guard”(设备卫士)的安全功能。 4月29日，微软宣布Windows 10将采用同一个应用商店，即可展示给Windows 10覆盖的所有设备用，同时支持Android和iOS程序。 7月29日，微软发布Windows 10正式版。 Windows服务器版 1. Windows server NT4.0 Windows server NT是 Microsoft公司1993年推出的32位网络操作系统，是向分布式图形应用程序的完整的交叉平台系统，可运行于nteX86、 Digital、 Alpha、SiliGraphics MIPS及 Power pc等主要计算机系统。 Windows server nt4.0网络操作系统与其他网络操作系统相比，有以下的特点： (1)基于32位结构的操作系统，处理速度较快。 (2)采用了流行的图形用户界面GUI。 (3)提供较全面的网络管理工具。 (4)通用性好，可以安装在不同的计算机上。这是因为 Windows server NT4.0除核是用汇编语言编写的以外，其他部分都是用C语言编写的，而C语言的通用性很好。同时 Windows server nt4.0用一系列的小模块来构筑某些底层部件，将依赖硬件的封装于一个动态链接库中，这样就可以做到与应用程序隔离，应用程序则通过一个接口与 Windows server NT4.0相连。 (5)支持FAT和NTFS两种文件系统，保证了 Windows server NT4.0与以前的操统的兼容性。 (6)具有较高的安全性，能够控制用户对网络的访问。 (7)集成了多种传输协议，因此它可以与其他网络操作系统共同组网。 2. Windows server 2000 Windows server2000是 Windows server NT4.0的后续版本，它继了 Windows server NT和 Windows server95/98的优点，并且增加了许多新的功能，这使得它的实用性、靠性、安全性和网络功能等方面都得到了加强，适应了信息技术发展和应用的需要。 3. Windows server 2008 Windows server2008是微软最新开发的一个服务器操作系统。 Windows server 2008是一套相当于 Windows Vista的服务器系统，两者有很多相同功能，使用 Windows server2008，管理员对服务器和网络基础结构的控制能力更强Windows server2008通过加强操作系统和保护网络环境提高了安全性。通过加快系统的部署与维护，使服务器和应用程序的合并与虚拟化更加简单， Windows server2008任何组织的服务器和网络基础结构奠定了最好的基础。 4. Windows server 2012 Windows Server 2012是微软于2012年9月4日发布的服务器系统。它是Windows 8的服务器版本，并且是Windows Server 2008 R2的继任者。它可向企业和服务提供商提供可伸缩、动态、支持多租户以及通过云计算得到优化的基础结构。Windows Server 2012包含了大量的更新以及新功能，通过虚拟化技术、Hyper-V、云计算、构建私有云等新特性，让 Windows Server 2012 变成一个无比强大且灵活的平台。 5. Windows server 2016 Windows Server 2016是微软于2016年10月13日正式发布的最新服务器操作系统。它在整体的设计风格与功能上更加靠近了Windows 10。 "},"操作系统/Windows/Windows系统下TCP参数优化.html":{"url":"操作系统/Windows/Windows系统下TCP参数优化.html","title":"Windows系统下TCP参数优化","keywords":"","body":"Windows系统下TCP参数优化 通常会采用修改注册表的方式改进Windows的系统参数。 下面将为大家介绍Windows系统下的TCP参数优化方式，适用于Windows 2003、Windows XP、Windows 7以及Server版。 对于具体的系统环境与性能需求，优化方式会有所差异，效果也不尽相同，仅是个人的建议。所有的优化操作都通过修改注册表实现，需要使用regedit命令进入注册表并创建或修改参数，修改完成后需要重启系统，以使之生效。 以下使用的参数值均为10进制。 1. TCPWindowSize TCPWindowSize的值表示TCP的窗口大小。 TCP Receive Window（TCP数据接收缓冲）定义了发送端在没有获得接收端的确认信息的状态下可以发送的最大字节数。此数值越大，返回的确认信息就越少，相应的在发送端和接收端之间的通信就越好。此数值较小时可以降低发送端在等待接收端返回确认信息时发生超时的可能性，但这将增加网络流量，降低有效吞吐率。TCP在发送端和接收端之间动态调整一个最大段长度MSS（Maximum Segment Size）的整数倍。MSS在连接开始建立时确定，由于TCP Receive Window被调整为MSS的整数倍，在数据传输中完全长度的TCP数据段的比例增加，故而提高了网络吞吐率。 缺省情况下，TCP将试图根据MSS来优化窗口大小，起始值为16KB，最大值为64KB。TCPWindowSize的最大值通常为65535字节（64KB），以太网最大段长度为1460字节，低于64KB的1460的最大整数倍为62420字节，因而可以在注册表中将TCPWindowSize设置为62420，作为高带宽网络中适用的性能优化值。 具体操作如下： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为TCPWindowSize的REG_DWORD值，该值的范围是从0到65535，将该值设置为62420。 2. TCP1323Opts 为了更高效地利用高带宽网络，可以使用比上述TCP窗口大得多的TCP窗口大小，此特性是Windows 2000和Windows Server 2003中的新特性，称为TCP Window Scaling，它将以前的65535字节（64KB）的限制提高到了1073741824字节（1GB）。在带宽与延迟的乘积值很高的连接上（例如卫星连接），可能需要将窗口的大小增加到64KB以上。使用TCP Window Scaling，系统可以允许确认信息间更大数据量的传输，增加了网络吞吐量及性能。发送端和接收端往返通信所需的时间被称为回环时间（RTT）。TCP Window Scaling仅在TCP连接的双方都开启时才真正有效。 TCP有一个时间戳选项，通过更加频繁地计算来提高RTT值的估测值，此选项特别有助于估测更长距离的广域网上连接的RTT值，并更加精确地调整TCP重发超时时间。时间戳在TCP报头提供了两个区域，一个记录开始重发的时间，另一个记录接收到的时间。时间戳对于TCP Window Scaling，即确认信息收到前的大数据包传送特别有用，激活时间戳仅仅在每个数据包的头部增加12字节，对网络流量的影响微乎其微。 数据完整性与数据吞吐率最大化哪个更为重要是个需要评估的问题。在某些环境中，例如视频流传输，需要更大的TCP窗口，这是最重要的，而数据完整性排在第二位。在这种环境中，TCP Window Scaling可以不打开时间戳。当发送端和接收端均激活TCP Window Scaling和时间戳时，此特性才有效。不过，若在发包时加入了时间戳，经过NAT之后，如果前面相同的端口被使用过，且时间戳大于这个连接发出的SYN中的时间戳，就会导致服务器忽略该SYN，表现为用户无法正常完成TCP的3次握手。初始时生成小的TCP窗口，之后窗口大小将按照内部算法增大。 具体操作如下： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为TCP1323Opts的REG_DWORD值，该值的具体含义为：0（缺省值）表示禁用TCP Window Scaling和时间戳；1表示只启用TCP Window Scaling；2表示只启用时间戳；3表示同时启用TCP Window Scaling和时间戳。TCP1323Opts设置为激活TCP Window Scaling后，可以将上文中的注册表项TCPWindowSize的值增大，最大能达到1GB，为了达到最佳性能，这里的值最好设置成MSS的倍数，推荐值为256960字节。 3. TCP 控制块表 对于每个TCP连接，控制变量保存在一个称为TCP控制块（TCB）的内存块中。 TCB表的大小由注册表项MaxHashTableSize控制。在活动连接很多的系统中，设定一个较大的表可以降低系统定位TCB表的时间。在TCB表上分区可以降低对表的访问的争夺。增加分区的数量，TCP的性能会得到优化，特别是在多处理器的系统上。注册表项NumTcbTablePartitions控制分区的数量，默认是处理器个数的平方。TCB通常预置在内存中，以防止TCP反复连接和断开时，TCB反复重新定位浪费时间，这种缓冲的方式促进了内存管理，但同时也限制了同一时刻允许的TCP连接数量。 注册表项MaxFreeTcbs决定了处于空闲等待状态的TCB重新可用之前的连接数量，在NT架构中常设置成高于默认值，以确保有足够的预置的TCB。从Windows 2000开始添加了一个新特性，降低超出预置TCB运行的可能性。如果处于等待状态的连接多于MaxFreeTWTcbs中的设置，所有等待时间超过60秒的连接将被强制关闭，以后再次启用。 此特性合并到Windows 2000 Server和Windows Server 2003后，MaxFreeTcbs将不再用于优化性能。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为MaxHashTableSize的REG_DWORD值，该值的范围是从1到65536，并且必须为2的N次方，缺省值为512，建议设为8192。然后在Parameters子键下创建或修改名为NumTcbTablePartitions的REG_DWORD值，该值的范围是从1到65536，并且必须为2的N次方，缺省值为处理器个数的平方，建议设为处理器核心数的4倍。 4. TcpTimedWaitDelay TcpTimedWaitDelay的值表示系统释放已关闭的TCP连接并复用其资源之前，必须等待的时间。 这段时间间隔就是以前的Blog中提到的TIME_WAIT状态（2MSL，数据包最长生命周期的两倍状态）。如果系统显示大量连接处于TIME_WAIT状态，则会导致并发量与吞吐量的严重下降，通过减小该项的值，系统可以更快地释放已关闭的连接，从而为新连接提供更多的资源，特别是对于高并发短连接的Server具有积极的意义。 该项的缺省值是240，即等待4分钟后释放资源；系统支持的最小值为30，即等待时间为30秒。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为TcpTimedWaitDelay的REG_DWORD值，该值的范围是从0到300，建议将该值设置为30。 5. MaxUserPort MaxUserPort的值表示当应用程序向系统请求可用的端口时，TCP/IP可分配的最大端口号。 如果系统显示建立连接时出现异常，那么有可能是由于匿名（临时）端口数不够导致的，特别是当系统打开大量端口来与Web service、数据库或其他远程资源建立连接时。 该项的缺省值是十进制的5000，这也是系统允许的最小值。Windows默认为匿名（临时）端口保留的端口号范围是从1024到5000。为了获得更高的并发量，建议将该值至少设为32768以上，甚至设为理论最大值65534，特别是对于模拟高并发测试环境的Client具有积极的意义。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为MaxUserPort的REG_DWORD值，该值的范围是从5000到65534，缺省值为5000，建议将该值设置为65534。 6. 动态储备 动态储备的值使系统能自动调整其配置，以接受大量突发的连接请求。 如果同时接收到大量连接请求，超出了系统的处理能力，那么动态储备就会自动增大系统支持的暂挂连接的数量（即Client已请求而Server尚未处理的等待连接数，TCP连接的总数包括已连接数与等待连接数），从而可减少连接失败的数量。系统的处理能力和支持的暂挂连接的数量不足时，Client的连接请求将直接被拒绝。 缺省情况下，Windows 不启用动态储备，可以通过以下操作进行开启和设置： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\AFD\\Parameters注册表子键，在Parameters子键下创建或修改下列名称的REG_DWORD值。 • EnableDynamicBacklog，值为1，表示开启动态储备。 • MinimumDynamicBacklog，值为128，表示支持的最小暂挂连接的数量为128。 • MaximumDynamicBacklog，值为2048，表示支持的最大暂挂连接的数量为2048。对于高并发短连接的Server，建议最大值设为1024及以上。 • DynamicBacklogGrowthDelta，值为128，表示支持的暂挂连接的数量的增量为128，即数量不足时自增长128，直到达到设定的最大值，如2048。 7. KeepAliveTime KeepAliveTime的值控制系统尝试验证空闲连接是否仍然完好的频率。 如果该连接在一段时间内没有活动，那么系统会发送保持连接的信号，如果网络正常并且接收方是活动的，它就会响应。如果需要对丢失接收方的情况敏感，也就是说需要更快地发现是否丢失了接收方，请考虑减小该值。而如果长期不活动的空闲连接的出现次数较多，但丢失接收方的情况出现较少，那么可能需要增大该值以减少开销。 缺省情况下，如果空闲连接在7200000毫秒（2小时）内没有活动，系统就会发送保持连接的消息。 通常建议把该值设为1800000毫秒，从而丢失的连接会在30分钟内被检测到。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为KeepAliveTime的REG_DWORD值，为该值设置适当的毫秒数。 8. KeepAliveInterval KeepAliveInterval的值表示未收到另一方对“保持连接”信号的响应时，系统重复发送“保持连接”信号的频率。 在无任何响应的情况下，连续发送“保持连接”信号的次数超过TcpMaxDataRetransmissions（下文将介绍）的值时，将放弃该连接。如果网络环境较差，允许较长的响应时间，则考虑增大该值以减少开销；如果需要尽快验证是否已丢失接收方，则考虑减小该值或TcpMaxDataRetransmissions值。 缺省情况下，在未收到响应而重新发送“保持连接”的信号之前，系统会等待1000毫秒（1秒），可以根据具体需求修改。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为KeepAliveInterval的REG_DWORD值，为该值设置适当的毫秒数。 9. TcpMaxDataRetransmissions TcpMaxDataRetransmissions的值表示TCP数据重发，系统在现有连接上对无应答的数据段进行重发的次数。 如果网络环境很差，可能需要提高该值以保持有效的通信，确保接收方收到数据；如果网络环境很好，或者通常是由于丢失接收方而导致数据的丢失，那么可以减小该值以减少验证接收方是否丢失所花费的时间和开销。 缺省情况下，系统会重新发送未返回应答的数据段5次，可以根据具体需求修改。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为TcpMaxDataRetransmissions的REG_DWORD值，该值的范围是从0到4294967295，缺省值为5，根据实际情况进行设置。 10. TcpMaxConnectRetransmisstions TcpMaxConnectRetransmisstions的值表示TCP连接重发，TCP退出前重发非确认连接请求（SYN）的次数。 对于每次尝试，重发超时是成功重发的两倍。在Windows Server 2003中默认超时次数是2，默认超时时间为3秒（在注册表项TCPInitialRTT中）。速度较慢的WAN连接中超时时间可相应增加，不同环境中可能会有不同的最优化设置，需要在实际环境中测试确定。超时时间不要设置太大否则将不会发生网络连接超时时间。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters注册表子键，在Parameters子键下创建或修改名为TcpMaxConnectRetransmisstions的REG_DWORD值，该值的范围是从0到255，缺省值为2，根据实际情况进行设置。然后在Parameters子键下创建或修改名为TCPInitialRTT的REG_DWORD值，同样根据实际情况进行设置。 11. TcpAckFrequency TcpAckFrequency的值表示系统发送应答消息的频率。 如果值为2，那么系统将在接收到2个分段之后发送应答，或是在接收到1个分段但在200毫秒内没有接收到任何其他分段的情况下发送应答；如果值为3，那么系统将在接收到3个分段之后发送应答，或是在接收到1个或2个分段但在200毫秒内没有接收到任何其他分段的情况下发送应答，以此类推。如果要通过消除应答延迟来缩短响应时间，那么建议将该值设为1。在此情况下，系统会立即发送对每个分段的应答；如果连接主要用于传输大量数据，而200毫秒的延迟并不重要，那么可以减小该值以降低应答的开销。 缺省情况下，系统将该值设为2，即每隔一个分段应答一次。该值的有效范围是0到255，其中0表示使用缺省值2，可以根据具体需求修改。 具体操作： 浏览至HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TCPIP\\Parameters\\Interfaces\\xx（xx由网络适配器决定）注册表子键，在xx子键下创建或修改名为TcpAckFrequency的REG_DWORD值，该值的范围是从1到13，缺省值为2，根据希望每发送几个分段返回一个应答而设置该值，建议百兆网络设为5，千兆网络设为13。 "},"操作系统/Windows/Windows通过ssh连接远程服务器.html":{"url":"操作系统/Windows/Windows通过ssh连接远程服务器.html","title":"Windows通过ssh连接远程服务器","keywords":"","body":"Windows通过ssh连接远程服务器 Windows CMD 命令行下输入ssh，报错'SSH' 不是内部或外部命令，也不是可运行的程序。 方法一：下载安装GIT GIT下载 cd ~/.ssh：进入c盘下的.ssh文件，如果文件不存在，则执行“mkdir ~/.ssh”新建文件 配置全局的name和email，这里是的你github或者bitbucket的name和email： git config --global user.name \"用户名\"： git config --global user.email \"邮箱\" 生成key： ssh-keygen -t rsa -C\"邮箱\" 连接远程服务器： ssh 用户名@远程服务器的ip地址 方法二：下载安装OpenSSH OpenSSH下载 安装步骤： 1、进入链接下载最新 OpenSSH-Win64.zip（64位系统），解压至C:\\Program Files\\OpenSSH 2、打开cmd，cd进入C:\\Program Files\\OpenSSH（安装目录），执行命令： powershell.exe -ExecutionPolicy Bypass -File install-sshd.ps1 3、设置服务自动启动并启动服务： sc config sshd start= auto net start sshd 到此服务已经安装完毕，默认端口一样是22，默认用户名密码为Window账户名和密码，当然防火墙还是要设置对应端口允许通讯 修改设置： 通常linux下会修改ssh_config文件来修改ssh配置，但在安装目录并没有发现这个文件，查阅官方wiki后发现，原来是在C:\\ProgramData\\ssh目录下（此目录为隐藏目录） 端口号：Port 22 密钥访问：PubkeyAuthentication yes 密码访问：PasswordAuthentication no 空密码：PermitEmptyPasswords no 然后进入C:\\Users\\账户名.ssh目录，创建authorized_keys公钥文件（也可在ssh_config修改路径）（仅限7.7之前版本，7.9版本请看最后更新） 设置完成后重启sshd服务，接下来就可以使用Xshell等工具使用密钥连接了~ 下载安装完成后，如果ssh命令仍然无法正常识别，请在Path中添加对应环境变量。 "},"操作系统/Windows/Windows中bat脚本延时执行.html":{"url":"操作系统/Windows/Windows中bat脚本延时执行.html","title":"Windows中bat脚本延时执行","keywords":"","body":"Windows中bat脚本延时执行 在批处理中，经常需要用到“延时（等待）”，那么如何让批处理延时呢？ [方法1] 在windows vista及以上系统中，系统提供了一个“timeout”命令。优点：方便，一行命令搞定。缺点：不能在旧系统中（例如xp）使用，且延时精度较低（1秒）。 TIMEOUT [/T] timeout [/NOBREAK] 描述: 这个工具接受超时参数，等候一段指定的时间(秒)或等按任意键。它还接受一个参数，忽视按键。 参数列表: /T timeout 指定等候的秒数。有效范围从 -1 到 99999 秒。不能使用表达式例如 60*5之类的。 /NOBREAK 忽略按键并等待指定的时间。 /? 显示此帮助消息。 注意: 超时值 -1 表示无限期地等待按键。 ::等待10秒，并且可以按任意键跳过等待 TIMEOUT /T 10 ::等待300秒，并且只能按下CTRL+C来跳过 TIMEOUT /T 300 /NOBREAK ::持续等待，直到按下任意按键.功能类似于pause TIMEOUT /T -1 ::持续等待，直到按下CTRL+C按键 TIMEOUT /T -1 /NOBREAK [方法2] 使用vbs的sleep方法来实现延时（等待）。优点：能在旧系统中（例如xp）使用，且延时精度较高（1毫秒）缺点：代码行数较多，3行。 echo CreateObject(\"Scripting.FileSystemObject\").DeleteFile(WScript.ScriptFullName) >%Temp%\\Wait.vbs echo wscript.sleep ▲ >>%Temp%\\Wait.vbs start /wait %Temp%\\Wait.vbs 注意：其中的“▲”为等待的毫秒数，1秒=1000毫秒，等待10000毫秒，即10秒。 当然，也可以使用并行符号“&”，把命令并成一行 echo createobject(\"scripting.filesystemobject\").deletefile(wscript.scriptfullname) >%temp%\\VBScriptWait.vbs& echo wscript.sleep ▲ >>%temp%\\VBScriptWait.vbs& start /wait %temp%\\VBScriptWait.vbs "},"操作系统/Linux/":{"url":"操作系统/Linux/","title":"Linux","keywords":"","body":"Linux 简介 Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。伴随着互联网的发展，Linux得到了来自全世界软件爱好者、组织、公司的支持。它除了在服务器操作系统方面保持着强劲的发展势头以外，在个人电脑、嵌入式系统上都有着长足的进步。使用者不仅可以直观地获取该操作系统的实现机制，而且可以根据自身的需要来修改完善这个操作系统，使其最大化地适应用户的需要。 Linux不仅系统性能稳定，而且是开源软件。其核心防火墙组件性能高效、配置简单，保证了系统的安全。在很多企业网络中，为了追求速度和安全，Linux操作系统不仅仅是被网络运维人员当作服务器使用，Linux既可以当作服务器，又可以当作网络防火墙是Linux的 一大亮点。 Linux与其他操作系统相比 ，具有开放源码、没有版权、技术社区用户多等特点 ，开放源码使得用户可以自由裁剪，灵活性高，功能强大，成本低。尤其系统中内嵌网络协议栈 ，经过适当的配置就可实现路由器的功能。这些特点使得Linux成为开发路由交换设备的理想开发平台。 Linux简史 Linux操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：Unix操作系统、MINIX操作系统、GNU计划、POSIX标准和Internet网络。 20世纪80年代，计算机硬件的性能不断提高，PC的市场不断扩大，当时可供计算机选用的操作系统主要有Unix、DOS和MacOS这几种。Unix价格昂贵，不能运行于PC；DOS显得简陋，且源代码被软件厂商严格保密； MacOS是一种专门用于苹果计算机的操作系统。此时，计算机科学领域迫切需要一个更加完善、强大、廉价和完全开放的操作系统。由于供教学使用的典型操作系统很少，因此当时在荷兰当教授的美国人AndrewS.Tanenbaum编写了一个操作系统，名为MINIX，为了向学生讲述操作系统内部工作原理。MINIX虽然很好，但只是一个用于教学目的的简单操作系统，而不是一个强有力的实用操作系统，然而最大的好处就是公开源代码。全世界学计算机的学生都通过钻研MINIX源代码来了解电脑里运行的MINIX操作系统，芬兰赫尔辛基大学大学二年级的学生Linus Torvalds就是其中一个，在吸收了MINIX精华的基础上，Linus于1991年写出了属于自己的Linux操作系统，版本为Linux0.01，是Linux时代开始的标志。他利用Unix的核心，去除繁杂的核心程序，改写成适用于一般计算机的x86系统，并放在网络上供大家下载，1994年推出完整的核心Version1.0，至此，Linux逐渐成为功能完善、稳定的操作系统，并被广泛使用。 主要特性 基本思想 Linux的基本思想有两点：第一，一切都是文件；第二，每个软件都有确定的用途。其中第一条详细来讲就是系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件。至于说Linux是基于Unix的，很大程度上也是因为这两者的基本思想十分相近。 完全免费 Linux是一款免费的操作系统，用户可以通过网络或其他途径免费获得，并可以任意修改其源代码。这是其他的操作系统所做不到的。正是由于这一点，来自全世界的无数程序员参与了Linux的修改、编写工作，程序员可以根据自己的兴趣和灵感对其进行改变，这让Linux吸收了无数程序员的精华，不断壮大。 完全兼容POSIX1.0标准 这使得可以在Linux下通过相应的模拟器运行常见的DOS、Windows的程序。这为用户从Windows转到Linux奠定了基础。许多用户在考虑使用Linux时，就想到以前在Windows下常见的程序是否能正常运行，这一点就消除了他们的疑虑。 多用户、多任务 Linux支持多用户，各个用户对于自己的文件设备有自己特殊的权利，保证了各用户之间互不影响。多任务则是现在电脑最主要的一个特点，Linux可以使多个程序同时并独立地运行。 良好的界面 Linux同时具有字符界面和图形界面。在字符界面用户可以通过键盘输入相应的指令来进行操作。它同时也提供了类似Windows图形界面的X-Window系统，用户可以使用鼠标对其进行操作。在X-Window环境中就和在Windows中相似，可以说是一个Linux版的Windows。 支持多种平台 Linux可以运行在多种硬件平台上，如具有x86、680x0、SPARC、Alpha等处理器的平台。此外Linux还是一种嵌入式操作系统，可以运行在掌上电脑、机顶盒或游戏机上。2001年1月份发布的Linux 2.4版内核已经能够完全支持Intel64位芯片架构。同时Linux也支持多处理器技术。多个处理器同时工作，使系统性能大大提高。 优点 1)Linux由众多微内核组成，其源代码完全开源； 2)Linux继承了Unix的特性，具有非常强大的网络功能，其支持所有的因特网协议，包括TCP/IPv4、 TCP/IPv6和链路层拓扑程序等，且可以利用Unix的网络特性开发出新的协议栈； 3)Linux系统工具链完整，简单操作就可以配置出合适的开发环境，可以简化开发过程，减少开发中仿真工具的障碍，使系统具有较强的移植性； "},"操作系统/Linux/Linux使用SSH首次登陆无需确认.html":{"url":"操作系统/Linux/Linux使用SSH首次登陆无需确认.html","title":"Linux使用SSH首次登陆无需确认","keywords":"","body":"Linux使用SSH首次登陆无需确认 第一次登录另外一台linux主机的时候，会弹出下面的信息，问是否yes确认登陆和no [root@ghs ~]# ssh -i 2 192.168.1.201 The authenticity of host '192.168.1.201 (192.168.1.201)' can't be established. ECDSA key fingerprint is 3f:80:ce:88:9c:b9:72:f1:26:71:d0:8e:a4:91:e0:01. Are you sure you want to continue connecting (yes/no) 如果，我们输入yes，就能正常登录。但如果是分发文件的时候，几十台服务器，我们就得不停的输yes，这样很费时间和人力，我们也可以写expect脚本代替执行输入yes，其实还有更简单的方法，输入下面这条命令就可以省去很多事情，也不用专门去写脚本。 [root@ghs ~]# echo \"StrictHostKeyChecking no\" >~/.ssh/config 此时，ssh登录远程任意机器都不会问你yes or no. "},"操作系统/Linux/SSH常用命令.html":{"url":"操作系统/Linux/SSH常用命令.html","title":"SSH常用命令","keywords":"","body":"SSH常用命令 OpenSSH是SSH连接工具的免费版本。telnet，rlogin和ftp用户可能还没意识到他们在互联网上传输的密码是未加密的，但SSH是加密的，OpenSSH加密所有通信（包括密码），有效消除了窃听，连接劫持和其它攻击。此外，OpenSSH提供了安全隧道功能和多种身份验证方法，支持SSH协议的所有版本。 SSH是一个非常伟大的工具，如果你要在互联网上远程连接到服务器，那么SSH无疑是最佳的候选。下面是通过网络投票选出的25个最佳SSH命令，你必须牢记于心。 （注：有些内容较长的命令，在本文中会显示为截断的状态。如果你需要阅读完整的命令，可以把整行复制到您的记事本当中阅读。） 1、复制SSH密钥到目标主机，开启无密码SSH登录 ssh-copy-id user@host 如果还没有密钥，请使用ssh-keygen命令生成。 2、从某主机的80端口开启到本地主机2001端口的隧道 ssh -N -L2001:localhost:80 somemachine 现在你可以直接在浏览器中输入http://localhost:2001访问这个网站。 3、将你的麦克风输出到远程计算机的扬声器 dd if=/dev/dsp | ssh -c arcfour -C username@host dd of=/dev/dsp 这样来自你麦克风端口的声音将在SSH目标计算机的扬声器端口输出，但遗憾的是，声音质量很差，你会听到很多嘶嘶声。 4、比较远程和本地文件 ssh user@host cat /path/to/remotefile | diff /path/to/localfile – 在比较本地文件和远程文件是否有差异时这个命令很管用。 5、通过SSH挂载目录/文件系统 sshfs name@server:/path/to/folder /path/to/mount/point 从http://fuse.sourceforge.net/sshfs.html下载sshfs，它允许你跨网络安全挂载一个目录。 6、通过中间主机建立SSH连接 ssh -t reachable_host ssh unreachable_host Unreachable_host表示从本地网络无法直接访问的主机，但可以从reachable_host所在网络访问，这个命令通过到reachable_host的“隐藏”连接，创建起到unreachable_host的连接。 7、将你的SSH公钥复制到远程主机，开启无密码登录 – 简单的方法 ssh-copy-id username@hostname 8、直接连接到只能通过主机B连接的主机A ssh -t hostA ssh hostB 当然，你要能访问主机A才行。 9、创建到目标主机的持久化连接 ssh -MNf @ 在后台创建到目标主机的持久化连接，将这个命令和你~/.ssh/config中的配置结合使用： Host host ControlPath ~/.ssh/master-%r@%h:%p ControlMaster no 所有到目标主机的SSH连接都将使用持久化SSH套接字，如果你使用SSH定期同步文件（使用rsync/sftp/cvs/svn），这个命令将非常有用，因为每次打开一个SSH连接时不会创建新的套接字。 10、通过SSH连接屏幕 ssh -t remote_host screen –r 直接连接到远程屏幕会话（节省了无用的父bash进程）。 11、端口检测（敲门） knock 3000 4000 5000 && ssh -p user@host && knock 5000 4000 3000 在一个端口上敲一下打开某个服务的端口（如SSH），再敲一下关闭该端口，需要先安装knockd，下面是一个配置文件示例。 [options] logfile = /var/log/knockd.log [openSSH] sequence = 3000,4000,5000 seq_timeout = 5 command = /sbin/iptables -A INPUT -i eth0 -s %IP% -p tcp –dport 22 -j ACCEPT tcpflags = syn [closeSSH] sequence = 5000,4000,3000 seq_timeout = 5 command = /sbin/iptables -D INPUT -i eth0 -s %IP% -p tcp –dport 22 -j ACCEPT tcpflags = syn 12、删除文本文件中的一行内容，有用的修复 ssh-keygen -R 在这种情况下，最好使用专业的工具。 13、通过SSH运行复杂的远程shell命令 ssh host -l user $(更具移植性的版本： ssh host -l user “`cat cmd.txt`” 14、通过SSH将MySQL数据库复制到新服务器 mysqldump –add-drop-table –extended-insert –force –log-error=error.log -uUSER -pPASS OLD_DB_NAME | ssh -C user@newhost “mysql -uUSER -pPASS NEW_DB_NAME” 通过压缩的SSH隧道Dump一个MySQL数据库，将其作为输入传递给mysql命令，我认为这是迁移数据库到新服务器最快最好的方法。 15、删除文本文件中的一行，修复“SSH主机密钥更改”的警告 sed -i 8d ~/.ssh/known_hosts 16、从一台没有SSH-COPY-ID命令的主机将你的SSH公钥复制到服务器 cat ~/.ssh/id_rsa.pub | ssh user@machine “mkdir ~/.ssh; cat >> ~/.ssh/authorized_keys” 如果你使用Mac OS X或其它没有ssh-copy-id命令的*nix变种，这个命令可以将你的公钥复制到远程主机，因此你照样可以实现无密码SSH登录。 17、实时SSH网络吞吐量测试 yes | pv | ssh $host “cat > /dev/null” 通过SSH连接到主机，显示实时的传输速度，将所有传输数据指向/dev/null，需要先安装pv。 如果是Debian： apt-get install pv 如果是Fedora： yum install pv （可能需要启用额外的软件仓库）。 18、如果建立一个可以重新连接的远程GNU screen ssh -t user@some.domain.com /usr/bin/screen –xRR 人们总是喜欢在一个文本终端中打开许多shell，如果会话突然中断，或你按下了“Ctrl-a d”，远程主机上的shell不会受到丝毫影响，你可以重新连接，其它有用的screen命令有“Ctrl-a c”（打开新的shell）和“Ctrl-a a”（在shell之间来回切换），请访问http://aperiodic.net/screen/quick_reference阅读更多关于screen命令的快速参考。 19、继续SCP大文件 rsync –partial –progress –rsh=ssh $file_source $user@$host:$destination_file 它可以恢复失败的rsync命令，当你通过VPN传输大文件，如备份的数据库时这个命令非常有用，需要在两边的主机上安装rsync。 rsync –partial –progress –rsh=ssh $file_source $user@$host:$destination_file local -> remote 或 rsync –partial –progress –rsh=ssh $user@$host:$remote_file $destination_file remote -> local 20、通过SSH W/ WIRESHARK分析流量 ssh root@server.com ‘tshark -f “port !22″ -w -' | wireshark -k -i – 使用tshark捕捉远程主机上的网络通信，通过SSH连接发送原始pcap数据，并在wireshark中显示，按下Ctrl+C将停止捕捉，但也会关闭wireshark窗口，可以传递一个“-c #”参数给tshark，让它只捕捉“#”指定的数据包类型，或通过命名管道重定向数据，而不是直接通过SSH传输给wireshark，我建议你过滤数据包，以节约带宽，tshark可以使用tcpdump替代： ssh root@example.com tcpdump -w – ‘port !22′ | wireshark -k -i – 21、保持SSH会话永久打开 autossh -M50000 -t server.example.com ‘screen -raAd mysession’ 打开一个SSH会话后，让其保持永久打开，对于使用笔记本电脑的用户，如果需要在Wi-Fi热点之间切换，可以保证切换后不会丢失连接。 22、更稳定，更快，更强的SSH客户端 ssh -4 -C -c blowfish-cbc 强制使用IPv4，压缩数据流，使用Blowfish加密。 23、使用cstream控制带宽 tar -cj /backup | cstream -t 777k | ssh host ‘tar -xj -C /backup’ 使用bzip压缩文件夹，然后以777k bit/s速率向远程主机传输。Cstream还有更多的功能，请访问http://www.cons.org/cracauer/cstream.html#usage了解详情，例如： echo w00t, i’m 733+ | cstream -b1 -t2 24、一步将SSH公钥传输到另一台机器 ssh-keygen; ssh-copy-id user@host; ssh user@host 这个命令组合允许你无密码SSH登录，注意，如果在本地机器的~/.ssh目录下已经有一个SSH密钥对，ssh-keygen命令生成的新密钥可能会覆盖它们，ssh-copy-id将密钥复制到远程主机，并追加到远程账号的~/.ssh/authorized_keys文件中，使用SSH连接时，如果你没有使用密钥口令，调用ssh user@host后不久就会显示远程shell。 25、将标准输入（stdin）复制到你的X11缓冲区 ssh user@host cat /path/to/some/file | xclip 你是否使用scp将文件复制到工作用电脑上，以便复制其内容到电子邮件中？xclip可以帮到你，它可以将标准输入复制到X11缓冲区，你需要做的就是点击鼠标中键粘贴缓冲区中的内容。 "},"操作系统/Linux/Linux中最常用的一套Sed技巧.html":{"url":"操作系统/Linux/Linux中最常用的一套Sed技巧.html","title":"Linux中最常用的一套Sed技巧","keywords":"","body":"Linux中最常用的一套Sed技巧 sed命令应用广泛，使用简单，是快速文本处理的利器。它其实没多少技巧，背诵、使用是最合适的学习渠道，属于硬技能。但它又很复杂，因为高级功能太多。本篇不去关注sed的高级功能，仅对常用的一些操作，进行说明。 随着使用，你会发现它和vim的一些理念是相通的，正则表达式的语法也基本上一样，并没有多少学习成本。从个人视野和工作效率上来看，sed命令都是程序员必须掌握的一个重要工具。 一个简单的入门 如图，一个简单的sed命令包含三个主要部分：参数、范围、操作。要操作的文件，可以直接挂在命令行的最后。除了命令行，sed也可以通过-f参数指定一个sed脚本，这个属于高级用法，不做过多描述。 有些示例命令我会重复多次，聪明如你一定能发现其中规律，有时连解释都用不着。 参数 -n 这个参数是--quiet或者--silent的意思。表明忽略执行过程的输出，只输出我们的结果即可。 我们常用的还有另外一个参数 ：-i。 使用此参数后，所有改动将在原文件上执行。你的输出将覆盖原文件。非常危险，一定要注意。 范围 1,4 表示找到文件中1,2,3,4行的内容。 这个范围的指定很有灵性，请看以下示例（请自行替换图中的范围部分）。 5 选择第5行。 2,5 选择2到5行，共4行。 1~2 选择奇数行。 2~2 选择偶数行。 2,+3 和2,5的效果是一样的，共4行。 2,$ 从第二行到文件结尾。 范围的选择还可以使用正则匹配。请看下面示例。 /sys/,+3 选择出现sys字样的行，以及后面的三行。 /\\^sys/,/mem/ 选择以sys开头的行，和出现mem字样行之间的数据。 为了直观，下面的命令一一对应上面的介绍，范围和操作之间是可以有空格的。 sed -n '5p' file sed -n '2,5 p' file sed -n '1~2 p' file sed -n '2~2 p' file sed -n '2,+3p' file sed -n '2,$ p' file sed -n '/sys/,+3 p' file sed -n '/^sys/,/mem/p' file 操作 最常用的操作就是p，意思就是打印。比如，以下两个命令就是等同的： cat file sed -n 'p' file 除了打印，还有以下操作，我们来说常用的。 > p 对匹配内容进行打印。 d 对匹配内容进行删除。这个时候就要去掉-n参数了，想想为什么。 w 将匹配内容写入到其他地方。 a,i,c等操作虽基本但使用少，不做介绍。我们依然拿一些命令来说明。 sed -n '2,5 p' file sed '2,5 d' file sed -n '2,5 w output.txt' file 我们来看一下sed命令都能干些啥，上点命令体验一下。 删除所有#开头的行和空行。 sed -e 's/#.*//' -e '/^$/ d' file 最常用的，比如下面这个。 sed -n '2p' /etc/group 表示打印group文件中的第二行。 1、参数部分 比如 -n 2、模式部分 比如'2p' 3、文件，比如/etc/group 那么我想一次执行多个命令，还不想写sed脚本文件怎么办？那就需要加-e参数。 sed的操作单元是行。 替换模式 以上是sed命令的常用匹配模式，但它还有一个强大的替换模式，意思就是查找替换其中的某些值，并输出结果。使用替换模式很少使用-n参数。 替换模式的参数有点多，但第一部分和第五部分都是可以省略的。替换后会将整个文本输出出来。 前半部分用来匹配一些范围，而后半部分执行替换的动作。 范围 这个范围和上面的范围语法类似。看下面的例子。 /sys/,+3 选择出现sys字样的行，以及后面的三行。 /\\^sys/,/mem/ 选择以sys开头的行，和出现mem字样行之间的数据。 具体命令为： sed '/sys/,+3 s/a/b/g' file sed '/^sys/,/mem/s/a/b/g' file 命令 这里的命令是指s。也就是substitute的意思。 查找匹配 查找部分会找到要被替换的字符串。这部分可以接受纯粹的字符串，也可以接受正则表达式。看下面的例子。 a 查找范围行中的字符串a。 [a,b,c] 从范围行里查找字符串a或者b或者c。 命令类似： sed 's/a/b/g' file sed 's/[a,b,c]//g' file#这个命令我们下面解释 替换 是时候把找出的字符串给替换掉了。本部分的内容将替换查找匹配部分找到的内容。 可惜的是，这部分不能使用正则。常用的就是精确替换。比如把a替换成b。 但也有高级功能。和java或者python的正则api类似，sed的替换同样有Matched Pattern的含义，同样可以得到Group，不深究。常用的替位符，就是&。 &号，再重复一遍。当它用在替换字符串中的时候，代表的是原始的查找匹配数据。 [&] 表明将查找到的数据使用[]包围起来。 “&” 表明将查找的数据使用””包围起来。 下面这条命令，将会把文件中的每一行，使用引号包围起来。 sed 's/.*/\"&\"/' file flag 参数 这些参数可以单个使用，也可以使用多个，仅介绍最常用的。 > g 默认只匹配行中第一次出现的内容，加上g，就可以全文替换了。常用。 p 当使用了-n参数，p将仅输出匹配行内容。 w 和上面的w模式类似，但是它仅仅输出有变换的行。 i 这个参数比较重要，表示忽略大小写。 e 表示将输出的每一行，执行一个命令。不建议使用，可以使用xargs配合完成这种功能。 看两个命令的语法： sed -n 's/a/b/gipw output.txt' file sed 's/^/ls -la/e' file 好玩 由于正则的关系，很多字符需要转义。你会在脚本里做些很多\\，*之类的处理。你可以使用|^@!四个字符来替换\\。 比如，下面五个命令是一样的。 sed '/aaa/s/\\/etc/\\/usr/g' file sed '/aaa/s@/etc@/usr@g' file sed '/aaa/s^/etc^/usr^g' file sed '/aaa/s|/etc|/usr|g' file sed '/aaa/s!/etc!/usr!g' file 注意：前半部分的范围是不能使用这种方式的。我习惯使用符号@。 其他 正则表达式 可以看到，正则表达式在命令行中无处不在。以下，仅做简要说明。 ^ 行首 $ 行尾 . 单个字符 * 0个或者多个匹配 + 1个或者多个匹配 ? 0个或者1个匹配 {m} 前面的匹配重复m次 {m,n} 前面的匹配重复m到n次 \\ 转义字符 [0-9] 匹配括号中的任何一个字符,or的作用 | or，或者 \\b 匹配一个单词。比如\\blucky\\b 只匹配单词lucky 参数i 上面已经简单介绍了参数i，它的作用是让操作在原文件执行。无论你执行了啥，原始文件都将会被覆盖。这是非常危险的。 通过加入一个参数，可以将原文件做个备份。 sed -i.bak 's/a/b/' file 以上命令会对原file文件生效，并生成一个file.bak文件。强烈建议使用i参数同时指定bak文件。 表演一下 我们通过两个命令，来稍微看下sed和其他命令组合起来的威力。 输出长度不小于50个字符的行 sed -n '/^.{50}/p' 统计文件中有每个单词出现了多少次 sed 's/ /\\n/g' file | sort | uniq -c 查找目录中的py文件，删掉所有行级注释 find ./ -name \"*.py\" | xargs sed -i.bak '/^[ ]*#/d' 查看第5-7行和10-13行 sed -n -e '5,7p' -e '10,13p' file 仅输出ip地址 ip route show | sed -n '/src/p' | sed -e 's/ */ /g' | cut -d' ' -f9 "},"操作系统/Linux/Linux中sed命令完全攻略.html":{"url":"操作系统/Linux/Linux中sed命令完全攻略.html","title":"Linux中sed命令完全攻略","keywords":"","body":"Linux中sed命令完全攻略 我们知道，Vim 采用的是交互式文本编辑模式，你可以用键盘命令来交互性地插入、删除或替换数据中的文本。但本节要讲的 sed 命令不同，它采用的是流编辑模式，最明显的特点是，在 sed 处理数据之前，需要预先提供一组规则，sed 会按照此规则来编辑数据。 sed 会根据脚本命令来处理文本文件中的数据，这些命令要么从命令行中输入，要么存储在一个文本文件中，此命令执行数据的顺序如下： 每次仅读取一行内容； 根据提供的规则命令匹配并修改数据。注意，sed 默认不会直接修改源文件数据，而是会将数据复制到缓冲区中，修改也仅限于缓冲区中的数据； 将执行结果输出。 当一行数据匹配完成后，它会继续读取下一行数据，并重复这个过程，直到将文件中所有数据处理完毕。 sed 命令的基本格式如下： [root@localhost ~]# sed [选项] [脚本命令] 文件名 该命令常用的选项及含义，如表 1 所示。 表 1 sed 命令常用选项及含义 选项 含义 -e 脚本命令 该选项会将其后跟的脚本命令添加到已有的命令中。 -f 脚本命令文件 该选项会将其后文件中的脚本命令添加到已有的命令中。 -n 默认情况下，sed 会在所有的脚本指定执行完毕后，会自动输出处理后的内容，而该选项会屏蔽启动输出，需使用 print 命令来完成输出。 -i 此选项会直接修改源文件，要慎用。 成功使用 sed 命令的关键在于掌握各式各样的脚本命令及格式，它能帮你定制编辑文件的规则。 sed脚本命令 sed s 替换脚本命令 此命令的基本格式为： [address]s/pattern/replacement/flags 其中，address 表示指定要操作的具体行，pattern 指的是需要替换的内容，replacement 指的是要替换的新内容。 此命令中常用的 flags 标记如表 2 所示。 表 2 sed s命令flags标记及功能 flags 标记 功能 n 1~512 之间的数字，表示指定要替换的字符串出现第几次时才进行替换，例如，一行中有 3 个 A，但用户只想替换第二个 A，这是就用到这个标记； g 对数据中所有匹配到的内容进行替换，如果没有 g，则只会在第一次匹配成功时做替换操作。例如，一行数据中有 3 个 A，则只会替换第一个 A； p 会打印与替换命令中指定的模式匹配的行。此标记通常与 -n 选项一起使用。 w file 将缓冲区中的内容写到指定的 file 文件中； & 用正则表达式匹配的内容进行替换； \\n 匹配第 n 个子串，该子串之前在 pattern 中用 \\(\\) 指定。 \\ 转义（转义替换部分包含：&、\\ 等）。 比如，可以指定 sed 用新文本替换第几处模式匹配的地方： [root@localhost ~]# sed 's/test/trial/2' data4.txt This is a test of the trial script. This is the second test of the trial script. 可以看到，使用数字 2 作为标记的结果就是，sed 编辑器只替换每行中第 2 次出现的匹配模式。 如果要用新文件替换所有匹配的字符串，可以使用 g 标记： [root@localhost ~]# sed 's/test/trial/g' data4.txt This is a trial of the trial script. This is the second trial of the trial script. 我们知道，-n 选项会禁止 sed 输出，但 p 标记会输出修改过的行，将二者匹配使用的效果就是只输出被替换命令修改过的行，例如： [root@localhost ~]# cat data5.txt This is a test line. This is a different line. [root@localhost ~]# sed -n 's/test/trial/p' data5.txt This is a trial line. w 标记会将匹配后的结果保存到指定文件中，比如： [root@localhost ~]# sed 's/test/trial/w test.txt' data5.txt This is a trial line. This is a different line. [root@localhost ~]#cat test.txt This is a trial line. 在使用 s 脚本命令时，替换类似文件路径的字符串会比较麻烦，需要将路径中的正斜线进行转义，例如： [root@localhost ~]# sed 's/\\/bin\\/bash/\\/bin\\/csh/' /etc/passwd sed d 替换脚本命令 此命令的基本格式为： [address]d 如果需要删除文本中的特定行，可以用 d 脚本命令，它会删除指定行中的所有内容。但使用该命令时要特别小心，如果你忘记指定具体行的话，文件中的所有内容都会被删除，举个例子： [root@localhost ~]# cat data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog [root@localhost ~]# sed 'd' data1.txt #什么也不输出，证明成了空文件 当和指定地址一起使用时，删除命令显然能发挥出大的功用。可以从数据流中删除特定的文本行。 address 的具体写法后续会做详细介绍，这里只给大家举几个简单的例子： 通过行号指定，比如删除 data6.txt 文件内容中的第 3 行：[root@localhost ~]# cat data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# sed '3d' data6.txt This is line number 1. This is line number 2. This is line number 4. 或者通过特定行区间指定，比如删除 data6.txt 文件内容中的第 2、3行：[root@localhost ~]# sed '2,3d' data6.txt This is line number 1. This is line number 4. 也可以使用两个文本模式来删除某个区间内的行，但这么做时要小心，你指定的第一个模式会“打开”行删除功能，第二个模式会“关闭”行删除功能，因此，sed 会删除两个指定行之间的所有行（包括指定的行），例如：[root@localhost ~]#sed '/1/,/3/d' data6.txt #删除第 1~3 行的文本数据 This is line number 4. 或者通过特殊的文件结尾字符，比如删除 data6.txt 文件内容中第 3 行开始的所有的内容：[root@localhost ~]# sed '3,$d' data6.txt This is line number 1. This is line number 2. 在此强调，在默认情况下 sed 并不会修改原始文件，这里被删除的行只是从 sed 的输出中消失了，原始文件没做任何改变。 sed a 和 i 脚本命令 a 命令表示在指定行的后面附加一行，i 命令表示在指定行的前面插入一行，这里之所以要同时介绍这 2 个脚本命令，因为它们的基本格式完全相同，如下所示 [address]a（或 i）\\新文本内容 下面分别就这 2 个命令，给读者举几个例子。比如说，将一个新行插入到数据流第三行前，执行命令如下： [root@localhost ~]# sed '3i\\ > This is an inserted line.' data6.txt This is line number 1. This is line number 2. This is an inserted line. This is line number 3. This is line number 4. 再比如说，将一个新行附加到数据流中第三行后，执行命令如下： [root@localhost ~]# sed '3a\\ > This is an appended line.' data6.txt This is line number 1. This is line number 2. This is line number 3. This is an appended line. This is line number 4. 如果你想将一个多行数据添加到数据流中，只需对要插入或附加的文本中的每一行末尾（除最后一行）添加反斜线即可，例如： [root@localhost ~]# sed '1i\\ > This is one line of new text.\\ > This is another line of new text.' data6.txt This is one line of new text. This is another line of new text. This is line number 1. This is line number 2. This is line number 3. This is line number 4. 可以看到，指定的两行都会被添加到数据流中。 sed c 替换脚本命令 c 命令表示将指定行中的所有内容，替换成该选项后面的字符串。该命令的基本格式为： [address]c\\用于替换的新文本 举个例子： [root@localhost ~]# sed '3c\\ > This is a changed line of text.' data6.txt This is line number 1. This is line number 2. This is a changed line of text. This is line number 4. 在这个例子中，sed 编辑器会修改第三行中的文本，其实，下面的写法也可以实现此目的： [root@localhost ~]# sed '/number 3/c\\ > This is a changed line of text.' data6.txt This is line number 1. This is line number 2. This is a changed line of text. This is line number 4. sed y 转换脚本命令 y 转换命令是唯一可以处理单个字符的 sed 脚本命令，其基本格式如下： [address]y/inchars/outchars/ 举个简单例子： [root@localhost ~]# sed 'y/123/789/' data8.txt This is line number 7. This is line number 8. This is line number 9. This is line number 4. This is line number 7 again. This is yet another line. This is the last line in the file. 可以看到，inchars 模式中指定字符的每个实例都会被替换成 outchars 模式中相同位置的那个字符。 转换命令是一个全局命令，也就是说，它会文本行中找到的所有指定字符自动进行转换，而不会考虑它们出现的位置，再打个比方： [root@localhost ~]# echo \"This 1 is a test of 1 try.\" | sed 'y/123/456/' This 4 is a test of 4 try. sed 转换了在文本行中匹配到的字符 1 的两个实例，我们无法限定只转换在特定地方出现的字符。 sed p 打印脚本命令 p 命令表示搜索符号条件的行，并输出该行的内容，此命令的基本格式为： [address]p p 命令常见的用法是打印包含匹配文本模式的行，例如： [root@localhost ~]# cat data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# sed -n '/number 3/p' data6.txt This is line number 3. 可以看到，用 -n 选项和 p 命令配合使用，我们可以禁止输出其他行，只打印包含匹配文本模式的行。 如果需要在修改之前查看行，也可以使用打印命令，比如与替换或修改命令一起使用。可以创建一个脚本在修改行之前显示该行，如下所示： [root@localhost ~]# sed -n '/3/{ > p > s/line/test/p > }' data6.txt This is line number 3. This is test number 3. sed 命令会查找包含数字 3 的行，然后执行两条命令。首先，脚本用 p 命令来打印出原始行；然后它用 s 命令替换文本，并用 p 标记打印出替换结果。输出同时显示了原来的行文本和新的行文本。 sed w 脚本命令 w 命令用来将文本中指定行的内容写入文件中，此命令的基本格式如下： [address]w filename 这里的 filename 表示文件名，可以使用相对路径或绝对路径，但不管是哪种，运行 sed 命令的用户都必须有文件的写权限。 下面的例子是将数据流中的前两行打印到一个文本文件中： [root@localhost ~]# sed '1,2w test.txt' data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# cat test.txt This is line number 1. This is line number 2. 当然，如果不想让行直接输出，可以用 -n 选项，再举个例子： [root@localhost ~]# cat data11.txt Blum, R Browncoat McGuiness, A Alliance Bresnahan, C Browncoat Harken, C Alliance [root@localhost ~]# sed -n '/Browncoat/w Browncoats.txt' data11.txt cat Browncoats.txt Blum, R Browncoat Bresnahan, C Browncoat 可以看到，通过使用 w 脚本命令，sed 可以实现将包含文本模式的数据行写入目标文件。 sed r 脚本命令 r 命令用于将一个独立文件的数据插入到当前数据流的指定位置，该命令的基本格式为： [address]r filename sed 命令会将 filename 文件中的内容插入到 address 指定行的后面，比如说： [root@localhost ~]# cat data12.txt This is an added line. This is the second added line. [root@localhost ~]# sed '3r data12.txt' data6.txt This is line number 1. This is line number 2. This is line number 3. This is an added line. This is the second added line. This is line number 4. 如果你想将指定文件中的数据插入到数据流的末尾，可以使用 $ 地址符，例如： [root@localhost ~]# sed '$r data12.txt' data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. This is an added line. This is the second added line. sed q 退出脚本命令 q 命令的作用是使 sed 命令在第一次匹配任务结束后，退出 sed 程序，不再进行对后续数据的处理。 比如： [root@localhost ~]# sed '2q' test.txt This is line number 1. This is line number 2. 可以看到，sed 命令在打印输出第 2 行之后，就停止了，是 q 命令造成的，再比如： [root@localhost ~]# sed '/number 1/{ s/number 1/number 0/;q; }' test.txt This is line number 0. 使用 q 命令之后，sed 命令会在匹配到 number 1 时，将其替换成 number 0，然后直接退出。 sed 脚本命令的寻址方式 前面在介绍各个脚本命令时，我们一直忽略了对 address 部分的介绍。对各个脚本命令来说，address 用来表明该脚本命令作用到文本中的具体行。 默认情况下，sed 命令会作用于文本数据的所有行。如果只想将命令作用于特定行或某些行，则必须写明 address 部分，表示的方法有以下 2 种： 以数字形式指定行区间； 用文本模式指定具体行区间。 以上两种形式都可以使用如下这 2 种格式，分别是： [address]脚本命令 或者 address { 多个脚本命令 } 以上两种形式在前面例子中都有具体实例，因此这里不再做过多赘述。 以数字形式指定行区间 当使用数字方式的行寻址时，可以用行在文本流中的行位置来引用。sed 会将文本流中的第一行编号为 1，然后继续按顺序为接下来的行分配行号。 在脚本命令中，指定的地址可以是单个行号，或是用起始行号、逗号以及结尾行号指定的一定区间范围内的行。这里举一个 sed 命令作用到指定行号的例子： [root@localhost ~]#sed '2s/dog/cat/' data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog 可以看到，sed 只修改地址指定的第二行的文本。下面的例子中使用了行地址区间： [root@localhost ~]# sed '2,3s/dog/cat/' data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy dog 在此基础上，如果想将命令作用到文本中从某行开始的所有行，可以用特殊地址——美元符（$）： [root@localhost ~]# sed '2,$s/dog/cat/' data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat 用文本模式指定行区间 sed 允许指定文本模式来过滤出命令要作用的行，格式如下： /pattern/command 注意，必须用正斜线将要指定的 pattern 封起来，sed 会将该命令作用到包含指定文本模式的行上。 举个例子，如果你想只修改用户 demo 的默认 shell，可以使用 sed 命令，执行命令如下： [root@localhost ~]# grep demo /etc/passwd demo:x:502:502::/home/Samantha:/bin/bash [root@localhost ~]# sed '/demo/s/bash/csh/' /etc/passwd root:x:0:0:root:/root:/bin/bash ... demo:x:502:502::/home/demo:/bin/csh ... 虽然使用固定文本模式能帮你过滤出特定的值，就跟上面这个用户名的例子一样，但其作用难免有限，因此，sed 允许在文本模式使用正则表达式指明作用的具体行。正则表达式允许创建高级文本模式匹配表达式来匹配各种数据。这些表达式结合了一系列通配符、特殊字符以及固定文本字符来生成能够匹配几乎任何形式文本的简练模式。 关于正则表达式，这里仅提供一个简单示例： [root@localhost ~]# cat test.txt First Wed h1Helloh1 h2Helloh2 h3Helloh3 #使用正则表示式给所有第一个的h1、h2、h3添加<>，给第二个h1、h2、h3添加 [root@localhost ~]# cat sed.sh /h[0-9]/{ s//\\/1 s//\\/2 } [root@localhost ~]# sed -f sed.sh test.txt Hello Hello Hello "},"操作系统/Linux/CPULoad指标理解.html":{"url":"操作系统/Linux/CPULoad指标理解.html","title":"CPULoad指标理解","keywords":"","body":"CPULoad指标理解 我们经常去看Linux的平均负载。 通过uptime、top、w、cat /proc/loadavg命令就可以显示出 /proc文件系统是一个虚拟的文件系统，不占用磁盘空间，它反映了当前操作系统在内存中的运行情况，查看/proc下的文件可以了解到系统的运行状态。查看系统平均负载使用“cat /proc/loadavg”命令，输出结果如下 [root@VM_45_100_centos logs]# cat /proc/loadavg 0.04 0.16 0.20 2/537 29710 前三个数字是1、5、15分钟内的平均进程数。后面的 2/537 一个的分子是正在运行的进程数，分母是进程总数；另一个是最近运行的进程ID号。 通过top获取到平均负载的内容如下： load average: 0.09, 0.05, 0.01 系统平均负载被定义为：在特定时间间隔内运行队列中(在CPU上运行或者等待运行多少进程)的平均进程数。 如果一个进程满足以下条件则其就会位于运行队列中,运行队列嘛，没有等待IO，没有WAIT，没有KILL的进程通通都进这个队列。 它没有在等待I/O操作的结果 它没有主动进入等待状态(也就是没有调用'wait') 没有被停止(例如：等待终止) 我们可以这样认为，就是正在运行的进程+准备好等待运行的进程在特定时间内（1分钟，5分钟，10分钟）的平均进程数 在Linux中，进程分为三种状态 一种是阻塞的进程blocked process， 一种是可运行的进程runnable process， 另外就是正在运行的进程running process。当进程阻塞时，进程会等待I/O设备的数据或者系统调用。 进程可运行状态时，它处在一个运行队列run queue中，与其他可运行进程争夺CPU时间。 系统的load是指正在运行running one和准备好运行runnable one的进程的总数。比如现在系统有2个正在运行的进程，3个可运行进程，那么系统的load就是5，load average就是一定时间内的load数量均值 大多数人都对平均负载有所了解：三个数字分别代表了一分钟，五分钟和十五分钟三个时间段内的CPU负载的平均值，而数字越低越好。数字越高表示系统出现了问题或机器过载。但是负载值多少才最合适？谁也说不清楚。 首先，我们从最简单的单核处理器的系统进行说明。 CPU负载有点类似于交通拥堵程度 单核CPU就像一条单行道。想象您是一名交警.有时这条单行道太忙了，有汽车在排队等待同行。想让人们知道这条路的交通如何。最直接的指标是就是在特定时间内，这条道路上等待多少辆汽车。如果没有汽车在等待，即将到来的驾驶员便知道他们可以马上驶过。如果有汽车在排队等候，则驾驶员就知道知道要耽误时间了。 所以，交警同志，你应该怎样去定义交通拥塞程度的？可以按照下面的规则： 0.00表示路上根本没有车。实际上，介于0.00和1.00之间都表示没有交通拥堵，到达的汽车可以直接同行。 1.00表示道路完全处于满负荷状态。一切都还不错，但是如果再增加一辆汽车，将会产生交通堵塞。 超过1.00表示有交通堵塞。2.00意味着当前的汽车总量需要两条车道才能保证不堵塞。 3.00意味着当前的汽车总量需要三条车道才能保证不堵塞。 这基本上就是CPU负载的含义。 “汽车”是指使用CPU时间（“通行”）或排队使用CPU的进程。 Unix将CPU负载定义为运行队列的长度：当前正在运行的进程数与正在等待（排队）的进程数之和。 就像交警一样，您希望您的汽车/进程永远不会等待。因此，理想情况下，您的CPU负载应保持在1.00以下。如果系统的负载暂时获得高于1.00的峰值，还是可以的，但是负载您始终高于1.00时，则需要进行处理了。 CPU load的理想值是1.0？ 其实不然，当CPU的 load为1.00的时候，你的系统处于满负荷运转，再来一个进程，就会高于1.00，你的系统的性能将会降低，所以系统没有流出余粮,实际工作中，很多系统管理员认为比较理想的CPU负载应该是0.7，因此我们针对线上CPU负载的处理规则如下： 0.70:需要注意并排查原因。如果平均负载保持在>0.70以上，那么应该在情况变得更糟之前进行调查。 1.00:不紧急，需要处理。如果平均负载保持在1.00以上，需要查找问题原因并立即解决。否则，你的服务器可能在任何时候出现性能问题。 5.0:紧急状态，立即处理。如果平均负载高于5.00，那么你的系统马上就要崩溃了，很有可能系统挂机或者hang死。因此需要立即处理这种情况，千万不要让你的系统负载达到5！ 多处理器？CPU负载为3：但是运行良好！ 对于四处理器系统，3.00的负载表示比较健康。 在多处理器系统上，负载是相对于可用处理器核心数量的。在单核系统上，“ 100％利用率”表示负载为1.00，在双核系统上是2.00，在四核系统上是4.00，依此类推。 如果再回到交通问题上，“1.00”实际上意味着“一个车道的交通承载量”。在单车道上，这意味着它已被填满。在单向双车道上，负载为1.00表示其交通容量只有50％时-只有一个车道占用，因此还有另一个完整车道可以使用。 与CPU相同：在单核服务器上1.00的负载表示CPU利用率为100％。在双核服务器上，负载为2.00才代表100％CPU使用率。 多核（multicore） 与 多处理器（multiprocessor） 出于性能目的，具有单个双核处理器的计算机是否基本上等同于具有两个具有一个内核的处理器的计算机？是的。大致上是一样的。但是还有很多其他微妙之，例如：高速缓存的数量，处理器之间的进程切换频率等。尽管多处理器有这些优点，但为了对于CPU负载值来说，CPU Core的总数是很重要的，因为无论怎样CPU Core是物理隔离的。 因此我们需要添加两条新的CPU 负载处理规则： “核数=最大负载”：在多核系统上，您的负载不应超过可用核数。 “Core就是Core”的经验法则：CPU Core的性能与CPU上的分布方式无关。两个四核==四个双核==八个单核。他们的性能与八个Core的性能等同。 总结 我们看下uptime命令的输出: ~ $ uptime 23:05 up 14 days, 6:08, 7 users, load averages: 0.65 0.42 0.36 这是在双核CPU的系统上运行的，所以，我们的负载还有很大的空闲资源。在负载达到并保持在1.4左右之前，我不需要做处理。 现在，那三个数字什么含义呢？ 0.65是最近一分钟的平均值，0.42是最近五分钟的平均值，而0.36是最近15分钟的平均值。这使我们想到了一个问题： 我应该观察哪个平均值？ 1、5或15分钟？ 根据我们前面讨论过的处理规则（1.00 =进行处理，依此类推），您应该查看5或15分钟的平均值。坦白说，若一分钟的CPU 负载值达到1，还是可以的。但是若15分钟的负载平均值都在1.0以上，那么你需要进行干预和处理了。（当然，对于多核处理器的系统，该值将变为1.0*CPU核心数目）。 因此，核数对于解释平均负载非常重要。 我如何知道我的系统有多少个核？ cat /proc/cpuinfo 可以获得系统的CPU信息。 若只想得到CPU核数，可以运行：grep 'model name' /proc/cpuinfo | wc -l "},"操作系统/Linux/Linux执行Shell脚本报语法错误.html":{"url":"操作系统/Linux/Linux执行Shell脚本报语法错误.html","title":"Linux执行shell脚本报语法错误","keywords":"","body":"Linux执行shell脚本报语法错误 在Windows编辑的Sheel脚本，上传至Linux服务器，执行时报错 [root@ctptest2 bin]# sh CTPKeepAlive2.sh 'TPKeepAlive2.sh: line 4: syntax error near unexpected token ` 'TPKeepAlive2.sh: line 4: `proc_num() 脚本内容如下： #!/bin/sh file_name=\"/root/apache-tomcat-7.0.72/logs/autoRestart.log\" pid=0 proc_num() { num=`ps -ef|grep java|grep -v grep|wc -l` return $num } proc_id() { pid=`ps -ef|grep java|grep -v grep|awk '{print $2}'` } proc_num number=$? if [ $number -eq 0 ] then echo \"CTP_Program is not running, restart CTP\" sh /root/apache-tomcat-7.0.72/bin/startup.sh proc_id echo ${pid}, `date` >> $file_name fi 脚本检测是否存在java进程，如果进程不存在，则启动tomcat服务。 使用命令sh CTPKeepAlive2.sh，脚本报错。 怀疑由于字符编码格式导致报错。 使用命令cat -A CTPKeepAlive2.sh，查看文件，发现结束符为^M$。 注：在Windows下换行符显示为^M$，Linux下换行符显示为$。 使用命令dos2unix CTPKeepAlive2.sh将脚本转换为Linux下的编码格式，再次执行后没有报错，脚本正常运行。 "},"操作系统/AIX/":{"url":"操作系统/AIX/","title":"AIX","keywords":"","body":"AIX AIX（Advanced Interactive eXecutive）是IBM基于AT&T Unix System V开发的一套类UNIX操作系统，运行在IBM专有的Power系列芯片设计的小型机硬件系统之上。它符合Open group的UNIX 98行业标准（The Open Group UNIX 98 Base Brand），通过全面集成对32-位和64-位应用的并行运行支持，为这些应用提供了全面的可扩展性。它可以在所有的IBM ~ p系列和IBM RS/6000工作站、服务器和大型并行超级计算机上运行。 AIX，是IBM专有UNIX操作系统的商标名。名称来自先进交互运行系统（英语：Advanced Interactive executive，缩写为）。最初的名称来自英语：Advanced IBM Unix，这个名字没有得到法律部门的允许，因此更改为\"Advanced Interactive eXecutive\"。 介绍 AIX的一些流行特性例如chuser、mkuser、rmuser命令以及相似的东西允许如同管理文件一样来进行用户管理。AIX级别的逻辑卷管理正逐渐被添加进各种自由的UNIX风格操作系统中。 AIX 5L 5.3版本操作系统可以支持： 64颗CPU 2Tb主内存 JFS2：最大16 Tb的文件系统 专用文件系统 IBM最早在1990年2月于AIX 3.1引入初始版本的JFS。这个版本的JFS现在被叫作JFS1， 是AIX在往后十多年的首选文件系统并被安装在过百万台IBM顾客的AIX系统中。JFS1和AIX的内存管理程序紧紧链接在一起[6]，这种设计经常在一些封闭源码作业系统或只支持一个作业系统的文件系统出现 [2] 。 1995年，强化JFS的工作开始展开，当中包括加强其伸延性，支持多微处理器的计算机和令其易于移植至其他作业系统。经过多年的设计、改良和测试，新的JFS在1999年4月付运于OS/2 Warp Server for eBusiness，随后亦付运在2000年10月的OS/2 Warp Client中。与此同时，，JFS开发团亦在1997年开始把开发中新版JFS移植回AIX。为和原身AIX支持的原版JFS1分开，新版JFS亦会称作JFS2 (Enhanced Journaled File System)。2001年5月，JFS2开正式可供AIX 5L使用。 1999年10月，原供OS/2并正在移植回AIX的新版JFS源码被以GNU General Public License开放给自由/开放源代码软件社群并展开了移植至Linux的工作。而第一个稳定版本的JFS for Linux亦在2001年6月推出。至2002年8月，JFS正式并入稳定版Linux核心2.4.20。 AIX操作系统使用JFS文件系统(Journal File System), JFS文件系统是一种字节级日志文件系统，借鉴了数据库保护系统的技术，以日志的形式记录文件的变化。JFS通过记录文件结构而不是数据本身的变化来保证数据的完整性。这种方式可以确保在任何时刻都能维护数据的可访问性。 该文件系统主要是为满足服务器（从单处理器系统到高级多处理器和聚类系统）的高吞吐量和可靠性需求而设计、开发的。JFS文件系统是为面向事务的高性能系统而开发的。在IBM的AIX系统上，JFS已经过较长时间的测试，结果表明它是可靠、快速和容易使用的。JFS也是一个有大量用户安装使用的企业级文件系统，具有可伸缩性和健壮性。与非日志文件系统相比，它的突出优点是快速重启能力，JFS能够在几秒或几分钟内就把文件系统恢复到一致状态。虽然JFS主要是为满足服务器（从单处理器系统到高级多处理器和聚类系统）的高吞吐量和可靠性需求而设计的，但还可以用于想得到高性能和可靠性的客户机配置，因为在系统崩溃时JFS能提供快速文件系统重启时间，所以它是因特网文件服务器的关键技术。使用数据库日志处理技术，JFS能在几秒或几分钟之内把文件系统恢复到一致状态。而在非日志文件系统中，文件恢复可能花费几小时或几天。 JFS的缺点是，使用JFS日志文件系统性能上会有一定损失，系统资源占用的比率也偏高，因为当它保存一个日志时，系统需要写许多数据。 JFS2（Enhanced Journaled File System），新的文件系统被称为JFS2，从2001年5月开始，JFS2正式可以在AIX 5L上使用 JFS2支持预定的日志记录方式，可以提高较高的性能，并实现亚秒级文件系统恢复。JFS2同时为提高性能提供了基于分区的文件分配（Extent-based allocation）。基于分区的分配 是指对一组连续的块而非单一的块进行分配。由于这些块在磁盘上是连续的，其读取和写入的性能就会更好。这种分配的另外一个优势就是可以将元数据管理最小化。按块分配磁盘空间就意味着要逐块更新元数据。而使用分区，元数据则仅需按照分区（可以代表多个块）更新。JFS2还使用了B+ 树，以便更快地查找目录和管理分区描述符。JFS2没有内部日志提交策略，而是在kupdate守护进程超时时提交。 JFS和JFS2的区别 jfs和jfs2文件系统都是文件和目录的集合，管理文件或目录在磁盘上的位置。除了文件和目录以外,jfs2类型的文件系统还包含一个超级块、分配位图和一个或多个分配组。分配组由磁盘i节点和片区（Extent）组成。一个jfs2类型的文件系统也占据一个逻辑卷。 在jfs中，超级块的大小是4096字节，偏移量是4096字节；而在jfs2中，超级块的大小仍是4096字节，但是超级块在逻辑卷中的偏移量是32768字节。 jfs2的新功能包括基于片区的（Extent）的分配、目录排序和文件系统对象的动态空间分配等。 1.基于片区（Extent）的寻址结构 片区是一个连续的可变长的文件系统块的序列，它是jfs2对象的分配单位。\"大片区\"可以跨越多个分配组。一般而言，jfs2的分配策略通过为每一个片区分配尽可能大和连续的区间来使文件系统中片区的数量达到最小，使逻辑块的分配更加连续。这样能够提供更大的i/o传输效率，达以改善性能的目的。但是在有些情况上并不能总是达到这种理想的效果。 片区是由逻辑块偏移量（logical offset）、长度（length）和物理地址（physical address）组成的三元组来描述。其中由逻辑块偏移量和长度可能计算出物理地址。基于片区的寻址结构是由片区描述、作为根的i节点和作为键值的文件内的逻辑偏移量而构成的一个子B+树。 2.可变的逻辑块大小 JFS2把磁盘空间分割成块，JFS2支持512，1024，2048和4096字节块的大小。不同的文件系统可以使用不同的块的大小，从而达到优化空间的目的，减少目录或文件内部的残片(Fragmentation). 3.动态分配磁盘i节点 JFS2给磁盘i节点动态地按需分配空间，当i节点不再需要时就会释放i节点所占用的空间。这个特点避免了在创建标准JFS时为磁盘i节点预留固定数量磁盘空间的缺点。因此，这样就不需要用户在创建文件系统时计算这个文件系统中要保存的文件和目录的最大数。 4.目录组织 JFS2提供了两种不同的目录组织.第1种目录组织适用于小目录和在一个目录的i节点中保存目录的内容.这种目录组织不需要单独的目录块i/o和单独的存储分配. 第2种目录组织适用于较大的目录，每一个目录就是一个以名字为键值的B+树.与传统的、线性的、未分级的目录组织相比，这种目录组织能够提供更快的目录查找、插入和删除的能力。 5.在线整理文件系统的空闲残片 JFS2支持已安装的文件系统（即使有进程访问这个文件系统）对残余在文件系统中的空闲空间的整理功能。一旦一个文件系统的空闲空间变成分散的残片，对这些残片的整理将会使得JFS2提供I/O效率更高的磁盘空间分配，从而避免出现一些因空闲空间不连续而不够分配的情况。 版本 AIX 7.1, 2010年发布 仅在采用POWER6或POWER7处理器技术的Power Systems服务器上受支持 AIX 6.1, 2007年11月9号 技持[工作量分区]（WPARs=操作系统层级虚拟化） 移动设备的生活应用 ... AIX 5L 5.3, 2004年8月 NFSVersion 4支持 Advanced Accounting 虚拟SCSI 虚拟以太网 SMT 微分区（Micro-Partitioning） JFS2配额（quota）支持 JFS2文件系统收缩（shrink）支持 AIX 5L 5.2, 2002年10月 支持多路IO光纤信道磁盘 动态LPAR支持 AIX 5L 5.1, 2001年5月 引入64位内核 JFS2 AIX 4.3.3, 1999年9月 增加了在线备份功能 AIX 4.3.2, 1998年10月 AIX 4.3.1, 1998年4月 AIX 4.3, 1997年10月 支持64位体系 AIX v4, 1994年 AIX v3, 1990年 引入了日志文件系统（JFSv1） AIX v3.1 AIX v2 最后一个版本为v2.2.1 AIX v1, 1986年 注：L表示同Linux的姻缘关系 "},"操作系统/AS400/":{"url":"操作系统/AS400/","title":"AS400","keywords":"","body":"AS400 AS/400商用服务器，作为IBM的中小型商用计算机系统，以其卓越性能，在全世界赢得广泛客户。自问世以来，AS/400在全球的安装量已经超过60万套，行销150个国家，广泛应用于流通、金融证券、制造、运输行业。 集成性：作为一个集成的计算机系统，AS/400将数据库、通讯、安全性等功能全部集成在操作系统当中，最大限度实现各功能间的兼容性。并且，AS/400e还集成有世界上最流行、应用最广泛的数据库系统DB2/400。 开放性：从互操作性看，AS/400能以任何形式与任何机器相联。AS/400支持绝大多数的互操作标准，支持几乎所有的通讯协议。其集成数据库DB2也支持绝大多数开放数据库的标准。 可移植性：全世界范围内，有8000家应用软件开发商在AS/400平台上从事开发工作，有28000多种应用软件，其中包括3000多种Client/Server软件。 兼容性：由于IBM的的专利技术－TIMI，独立于技术的机器界面设计，使得在AS/400性能几十倍提升的同时，而用户的应用程序可不用做任何修改，甚至不用重新编译即可在任一系列的AS/400e上运行。这就使得用户一旦投资AS/400e，便可终身享有信息产业的最先进技术。 可连接性：对于AS/400的用户来说，在使用AS/400e的功能时，可以通过任何工作平台访问到AS/400，不一定必须使用AS/400的字符终端。AS/400的用户不必关心自己所使用的操作系统，任何平台都可以作为AS/400的客户机。 可支付性：对于计算机系统的总拥有成本来说，在购买AS/400e时，用户不仅得到硬件和操作系统，同时还得到集成于AS/400上的数据库、安全性、通讯功能等，而这些功能对于其他系统来说，还必须另外花人力、财力去购买、实施和维护。 可扩充性：从小到大，AS/400e拥有全线产品，而且，AS/400还向用户提供光纤连接技术，可将多达32台AS/400连接起来，集群运作。 1) 数据描述规范(DDS data description specification) AS/400的操作系统OS/400提供一种描述数据属性的方法DDS，它可以在程序外部方便、有效地对数据属性进行描述。 AS/400有两种定义数据的方法： （1）程序描述文件：文件在记录的描述仅包含一个记录名和记录长度，任何程序使用这种方式描述的文件必须为记录中的每个字段提供字段级属性（字段名、数据类型、字段长度等）定义，此中类型文件不常用 （2）外部描述文件：文件包含记录的详细字段描述和有关文件如何被访问的信息，在程序中只要指明该文件为外部描述文件即可，当程序目标建立时，编译器自动从文件中抽取信息到程序中，且转换为高级语言适合的语法，它的显著特点之一是克服了程序描述文件的缺点，通过文件的记录字段仅一次的说明，可定义多种访问路径，多个程序使用。2) DB2 QUERY MANAGER AND SQL DEVELOPMENT KIT支持的结构化查询语言SQL/400 SQL/400是SQL的DB2/400实现，可以交互式地输入大部分SQL语句或把它们嵌入到高级语言（RPGLE、COBOL、CLE等）程序中，替代高级语言内置的读、写和修改等指令。SQL/400主要由以下部分组成： （1）SQL运行支持程序，提供对SQL 语句的分析及对运行任何SQL语句的支持功能，是OS/400的一个部分，它允许含有SQL语句的应用程序在没有安装DB2 QUERY MANAGER AND SQL DEVELOPMENT KIT特许程序的系统上运行。 （2）SQL预编译程序，处理嵌入SQL语句的应用程序 （3）SQL交互式接口，支持用交互式建立和运行SQL语句 （4）DB2 QUERY MANAGER FOR AS/400，提供菜单、填空式提示的交互式接口，允许建立、增加、维护数据，和运行报表 3) APPLICATION DEVELOPMENT TOOLSET/400(ADTS/400)开发工具包中有PDM、SEU、SDA、RLU、DFU等 PDM（PROGRAMMING DEVELOPMENT MANAGER） 可以用来处理源代码、对象和库。为程序员建立源文件成员、访问SEU和许多其他有用的工具提供方便。 STRPDM：直接到PDM菜单 WRKLIBPDM：可以指定操作哪一个库或对当前库列表进行操作 WRKOBJPDM：指定操作某一库下的所有对象（可按名称、类型选取） WRKMBRPDM：指定操作某一库下某一源文件下的所有或部分成员 SEU（SOURCE ENTRY UTILITY） 是一个全屏幕编辑工具，可以建立和编辑源文件成员，当启动时，能够输入新的源语句，修改、删除、复制、移动已存在的源语句，具有语言相关提示和语法检查功能，且具有分屏编辑/浏览功能。 STRSEU：可以对原有成员进行编辑或建立新成员，对原有成员进行编辑也可通过在WORK WITH MEMBERS USING PDM（WRKMBRPDM）屏幕上使用选项2（EDIT）功能来实现，当然，建立新成员也可以通过在WORK WITH MEMBERS USING PDM（WRKMBRPDM）屏幕上使用F6（CREATE）功能键来实现。 SDA（SCREEN DESIGN AID） 可用来交互式设计、创建和维护应用屏幕，包括显示文件和菜单，且可以将用户设计的屏幕规范地自动转换成DDS源代码，简化了菜单和显示文件的创建。 STRSDA：可以进入屏幕和菜单的编辑画面，对原有屏幕编辑也可通过在WORK WITH MEMBERS USINGPDM（WRKMBRPDM）屏幕上使用选项17（CHANGE USING SDA）功能来实现， RLU（REPORT LAYOUT UTILITY） 可用来交互式定义打印报表的格式分布，建立打印文件，且可以将用户设计的报表格式分布规范地自动转换成DDS源代码，简化了报表的设计和修改，使用它可以在屏幕上直观地设计打印报表。 STRRLU：可以进入报表编辑画面，对原有屏幕编辑也可通过在 WORK WITH MEMBERS USING PDM（WRKMBRPDM）屏幕上使用选项19（CHANGE USING RLU）功能来实现 DFU（DATA FILE UTILITY） 能够快速定义、创建面向数据录入、查询或文件维护的DFU程序，而不需要编程。对开发应用建立测试数据库尤其有用。 STRDFU：显示DFU菜单 DLTDFUPGM：删除DFU程序和文件 CHGDTA：运行DFU程序 DSPDTA：运行DFU程序，但不能修改文件中的数据记录 UPDDTA：使用临时的DFU程序更新文件，可通过在WORK WITH MEMBERS USING PDM（WRKMBRPDM）屏幕上使用选项18 （CHANGE USING DFU）来实现，它可以进行查询、增加、修改、删除记录的操作。该功能最常用。 AS400技术手册 "},"操作系统/AS400/AS400常用命令.html":{"url":"操作系统/AS400/AS400常用命令.html","title":"AS400常用命令","keywords":"","body":"AS400常用命令 一、命令技巧 命令构成： CRT* (Creat) 创建 WRK* (Work With) 操作 RMV* (Remove) 去除 DSP* (Display) 显示 ADD* (Add) 添加 CHG* (Change) 改变 DLT* (Delete) 删除 CFG* (Config) 配置 STR* (Start) 启动 EDT* (Edit) 编辑 END* (End) 停止 SND* (Send) 发送 SAV* (Save) 存储 CPY* （Copy） 拷贝 RST* (Restore) 恢复 命令查询 GO CMDLIB 查看命令列表 GO CMD* 显示一系列命令菜单 GO CMDMSG 查询和MSG有关的命令 还一种情况是记得命令开头几个字母比如WRKMB，就可用通配查询：WRKMB 界面上超过F12的按钮，用Shift+FN，比如F14=Shift+F2 二、常用命令 1、 DSPLIBL EDTLIBL 显示和编辑库列表。 2、 STRPDM（start programming development manager） 启动程序开发管理工具，提供了一个集成的开发环境。一般直接写WRKLIBPDM（Library开发管理）、WRKOBJPDM（Object开发管理）、WRKMBRPDM（Member开发管理）。 3、 STRSQL 进入sql查询引擎 4、 STRQSH 进入qshell 进入类unix的命令行，可以使用unix的命令操作os400 5、 DSPPGMREF 查找和pgm程序相关联的PF和LF 6、 DSPPGM 参数detail可以查看pgm程序的源码位置 7、 DSPDBR 查找和PF相关的LF 8、 CHGCURLIB（Change Current Library）改变当前Library，这样后期操作，比如编译等都默认是这个库了 9、 WRKSPLF 查询假脱机文件 ，一般编译出错可以去里面找 10、 STRDBG 调试 11、go licpgm 查看系统安装的软件 12、wrkdsksts 查看硬盘资源 13、wrkhdwrsc *cmn 查看网卡资源 14、wrksyssts 系统状态 15、wrkactjob 系统作业 16、netstat 端口状态 17、dspmsg qsysopr系统消息 18、cfgtcp 配置tcp 19、CRTUSRPRF、CHGUSRPRF操作系统用户的增加、删去、更改密码 "},"语言/":{"url":"语言/","title":"语言","keywords":"","body":"语言 "},"语言/Python/":{"url":"语言/Python/","title":"Python","keywords":"","body":"Python Python（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/）是一种广泛使用的解释型、高级编程、通用型编程语言，由吉多·范罗苏姆创造，第一版发布于1991年。可以视之为一种改良（加入一些其他编程语言的优点，如面向对象）的LISP。Python的设计哲学强调代码的可读性和简洁的语法（尤其是使用空格缩进划分代码块，而非使用大括号或者关键词）。相比于C++或Java，Python让开发者能够用更少的代码表达想法。不管是小型还是大型程序，该语言都试图让程序的结构清晰明了。 与Scheme、Ruby、Perl、Tcl等动态类型编程语言一样，Python拥有动态类型系统和垃圾回收功能，能够自动管理内存使用，并且支持多种编程范式，包括面向对象、命令式、函数式和过程式编程。其本身拥有一个巨大而广泛的标准库。 Python 解释器本身几乎可以在所有的操作系统中运行。Python的其中一个解释器CPython是用C语言编写的、是一个由社群驱动的自由软件，当前由Python软件基金会管理。 官网 "},"语言/Python/Python3之sublime配置.html":{"url":"语言/Python/Python3之sublime配置.html","title":"Python3之sublime配置","keywords":"","body":"Python3之sublime配置 起因：在windows中，用python3编写了一个简单的selenium脚本，在自己的mac上，使用sublime打开后，command+shift+B执行时，报错： no moduel named ‘selenium’ 由于mac上同时存在python2 和 python3 两个版本，于是执行pip3 install selenium，来安装python3的模块。 安装成功后，执行还是报同样的no moduel named ‘selenium’错误。 怀疑由于sublime默认使用python2环境。需要改为使用python3环境。 步骤： 1. 执行 where python3 或者 type -a python3，查询对应路径。 2. 修改sublime配置 打开sublime，选择Tools->Build System->New Build System，这时打开一个新的配置文件，删除所有内容后，输入如下内容： { \"cmd\": [\"/usr/local/bin/python3\",\"-u\",\"$file\"] } 注意:这里的路径一定是上面通过上述命令查询出来的 Python3 路径。 将这个配置文件命名为 python3.sublime-build，并保存到默认目录即可。 3. 重启sublime Tools->Build System中选择刚才新建的python3后，使用command+shift+B执行即可。 附： download chromedriver "},"语言/Python/Python自动监控启动进程.html":{"url":"语言/Python/Python自动监控启动进程.html","title":"Python自动监控启动进程","keywords":"","body":"Python自动监控启动进程 #!/usr/bin/python import subprocess import datetime res = subprocess.Popen(“ps -ef | grep tomcat”,stdout=subprocess.PIPE,shell=True) tomcats=res.stdout.readlines() counts=len(tomcats) if counts作用：监控tomcat进程，如果不存在，则执行startup进行启动。 可以添加为crontab定时任务: crontab -e: #每十分钟运行该脚本一次 */10 * * * * root python /root/autorestart-tomcat.py "},"语言/Python/Python实现对Linux服务器的监控.html":{"url":"语言/Python/Python实现对Linux服务器的监控.html","title":"Python实现对Linux服务器的监控","keywords":"","body":"Python实现对Linux服务器的监控 Linux 系统为管理员提供了非常好的方法，使其可以在系统运行时更改内核，而不需要重新引导内核系统，这是通过/proc 虚拟文件系统实现的。/proc 文件虚拟系统是一种内核和内核模块用来向进程（process）发送信息的机制（所以叫做“/proc”），这个伪文件系统允许与内核内部数据结构交互，获取有关进程的有用信息，在运行中（on the fly）改变设置（通过改变内核参数）。与其他文件系统不同，/proc 存在于内存而不是硬盘中。 proc 文件系统提供的信息如下： 进程信息：系统中的任何一个进程，在 proc 的子目录中都有一个同名的进程 ID，可以找到 cmdline、mem、root、stat、statm，以及 status。某些信息只有超级用户可见，例如进程根目录。每一个单独含有现有进程信息的进程有一些可用的专门链接，系统中的任何一个进程都有一个单独的自链接指向进程信息，其用处就是从进程中获取命令行信息。 系统信息：如果需要了解整个系统信息中也可以从/proc/stat 中获得，其中包括 CPU 占用情况、磁盘空间、内存对换、中断等。 CPU 信息：利用/proc/CPUinfo 文件可以获得中央处理器的当前准确信息。 负载信息：/proc/loadavg 文件包含系统负载信息。 系统内存信息：/proc/meminfo 文件包含系统内存的详细信息，其中显示物理内存的数量、可用交换空间的数量，以及空闲内存的数量等。 /proc 目录中的主要文件的说明： 文件或目录名称 相关描述 apm 高级电源管理信息 cmdline 这个文件给出了内核启动的命令行 cpuinfo 中央处理器信息 devices 可以用到的设备（块设备/字符设备） dma 显示当前使用的 DMA 通道 filesystems 核心配置的文件系统 ioports 当前使用的 I/O 端口 interrupts 这个文件的每一行都有一个保留的中断 kcore 系统物理内存映像 kmsg 核心输出的消息，被送到日志文件 mdstat 这个文件包含了由 md 设备驱动程序控制的 RAID 设备信息 loadavg 系统平均负载均衡 meminfo 存储器使用信息，包括物理内存和交换内存 modules 这个文件给出可加载内核模块的信息。lsmod 程序用这些信息显示有关模块的名称，大小，使用数目方面的信息 net 网络协议状态信息 partitions 系统识别的分区表 pci pci 设备信息 scsi scsi 设备信息 self 到查看/proc 程序进程目录的符号连接 stat 这个文件包含的信息有 CPU 利用率，磁盘，内存页，内存对换，全部中断，接触开关以及赏赐自举时间 swaps 显示的是交换分区的使用情况 uptime 这个文件给出自从上次系统自举以来的秒数，以及其中有多少秒处于空闲 version 这个文件只有一行内容，说明正在运行的内核版本。可以用标准的编程方法进行分析获得所需的系统信息 注:下面几个例子都是使用 Python 脚本读取/proc 目录中的主要文件来实现实现对 Linux 服务器的监控的。 对CPU监测 [root@node6 py]# cat cpu1.py #!/usr/bin/python from __future__ import print_function from collections import OrderedDict import pprint def CPUinfo(): ''' Return the information in /proc/CPUinfo as a dictionary in the following format: CPU_info['proc0']={...} CPU_info['proc1']={...} ''' CPUinfo=OrderedDict() procinfo=OrderedDict() nprocs = 0 with open('/proc/cpuinfo') as f: for line in f: if not line.strip(): # end of one processor CPUinfo['proc%s' % nprocs] = procinfo nprocs=nprocs+1 # Reset procinfo=OrderedDict() else: if len(line.split(':')) == 2: procinfo[line.split(':')[0].strip()] = line.split(':')[1].strip() else: procinfo[line.split(':')[0].strip()] = '' return CPUinfo if __name__=='__main__': CPUinfo = CPUinfo() for processor in CPUinfo.keys(): print(CPUinfo[processor]['model name']) 作用：读取/proc/CPUinfo 中的信息，返回 list，每核心一个 dict。其中 list 是一个使用方括号括起来的有序元素集合。List 可以作为以 0 下标开始的数组。Dict 是 Python 的内置数据类型之一, 它定义了键和值之间一对一的关系。OrderedDict 是一个字典子类，可以记住其内容增加的顺序。常规 dict 并不跟踪插入顺序，迭代处理时会根据键在散列表中存储的顺序来生成值。在 OrderedDict 中则相反，它会记住元素插入的顺序，并在创建迭代器时使用这个顺序。 可以使用 Python 命令运行脚本 cpu1.py 结果如下： [root@node6 py]# python cpu1.py Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz 也可以使用 chmod 命令添加权限收直接运行 cpu1.py结果如下: [root@node6 py]# chmod +x cpu1.py [root@node6 py]# ./cpu1.py Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz 对系统负载监测 [root@node6 py]# cat cpu2.py #!/usr/bin/python import os def load_stat(): loadavg = {} f = open(\"/proc/loadavg\") con = f.read().split() f.close() loadavg['lavg_1']=con[0] loadavg['lavg_5']=con[1] loadavg['lavg_15']=con[2] loadavg['nr']=con[3] loadavg['last_pid']=con[4] return loadavg print \"loadavg\",load_stat()['lavg_15'] 作用：读取/proc/loadavg 中的信息，import os ：Python 中 import 用于导入不同的模块，包括系统提供和自定义的模块。其基本形式为：import 模块名 [as 别名]，如果只需要导入模块中的部分或全部内容可以用形式：from 模块名 import *来导入相应的模块。OS 模块 os 模块提供了一个统一的操作系统接口函数，os 模块能在不同操作系统平台如 nt，posix 中的特定函数间自动切换，从而实现跨平台操作。 可以使用 Python 命令运行脚本 cpu2.py 结果如下： [root@node6 py]# python cpu2.py loadavg 0.10 对内存信息的获取 [root@node6 py]# cat mem.py #!/usr/bin/python from __future__ import print_function from collections import OrderedDict def meminfo(): ''' Return the information in /proc/meminfo as a dictionary ''' meminfo=OrderedDict() with open('/proc/meminfo') as f: for line in f: meminfo[line.split(':')[0]] = line.split(':')[1].strip() return meminfo if __name__=='__main__': #print(meminfo()) meminfo = meminfo() print('Total memory: {0}'.format(meminfo['MemTotal'])) print('Free memory: {0}'.format(meminfo['MemFree'])) 作用：读取 proc/meminfo 中的信息，Python 字符串的 split 方法是用的频率还是比较多的。比如我们需要存储一个很长的数据，并且按照有结构的方法存储，方便以后取数据进行处理。当然可以用 json 的形式。但是也可以把数据存储到一个字段里面，然后有某种标示符来分割。 Python 中的 strip 用于去除字符串的首位字符，最后打印出内存总数和空闲数。 可以使用 Python 命令运行脚本 mem.py 结果如下： [root@node6 py]# python mem.py Total memory: 236380 kB Free memory: 84404 kB 对网络接口的监测 [root@node6 py]# cat net.py #!/usr/bin/python import time import sys if len(sys.argv) > 1: INTERFACE = sys.argv[1] else: INTERFACE = 'eth0' STATS = [] print 'Interface:',INTERFACE def rx(): ifstat = open('/proc/net/dev').readlines() for interface in ifstat: if INTERFACE in interface: stat = float(interface.split()[1]) STATS[0:] = [stat] def tx(): ifstat = open('/proc/net/dev').readlines() for interface in ifstat: if INTERFACE in interface: stat = float(interface.split()[9]) STATS[1:] = [stat] print 'In Out' rx() tx() while True: time.sleep(1) rxstat_o = list(STATS) rx() tx() RX = float(STATS[0]) RX_O = rxstat_o[0] TX = float(STATS[1]) TX_O = rxstat_o[1] RX_RATE = round((RX - RX_O)/1024/1024,3) TX_RATE = round((TX - TX_O)/1024/1024,3) print RX_RATE ,'MB ',TX_RATE ,'MB' 作用：读取/proc/net/dev 中的信息，Python 中文件操作可以通过 open 函数，这的确很像 C 语言中的 fopen。通过 open 函数获取一个 file object，然后调用 read()，write()等方法对文件进行读写操作。另外 Python 将文本文件的内容读入可以操作的字符串变量非常容易。文件对象提供了三个“读”方法： read()、readline() 和 readlines()。每种方法可以接受一个变量以限制每次读取的数据量，但它们通常不使用变量。 .read() 每次读取整个文件，它通常用于将文件内容放到一个字符串变量中。然而 .read() 生成文件内容最直接的字符串表示，但对于连续的面向行的处理，它却是不必要的，并且如果文件大于可用内存，则不可能实现这种处理。.readline() 和 .readlines() 之间的差异是后者一次读取整个文件，象 .read() 一样。.readlines() 自动将文件内容分析成一个行的列表，该列表可以由 Python 的 for ... in ... 结构进行处理。另一方面，.readline() 每次只读取一行，通常比 .readlines() 慢得多。仅当没有足够内存可以一次读取整个文件时，才应该使用 .readline()。最后打印出网络接口的输入和输出情况。 可以使用 Python 命令运行脚本 net.py 结果如下： [root@node6 py]# python net.py Interface: eth0 In Out 0.3 MB 0.1 MB 0.4 MB 0.2 MB 0.2 MB 0.1 MB 0.6 MB 0.3 MB 0.5 MB 0.2 MB 0.9 MB 0.5 MB 0.7 MB 0.3 MB 监控Apache服务器进程的Python脚本 [root@node6 py]# cat apache.py #!/usr/bin/python import os, sys, time while True: time.sleep(4) try: ret = os.popen('ps -C apache -o pid,cmd').readlines() if len(ret) 设置文件权限为执行属性（使用命令 chmod +x apache.py），然后加入到/etc/rc.local 即可，一旦 Apache 服务器进程异常退出，该脚本自动检查并且重启。 简单说明一下脚本 5 这个脚本不是基于/proc 伪文件系统的，是基于 Python 自己提供的一些模块来实现的 。这里使用的是 Python 的内嵌 time 模板，time 模块提供各种操作时间的函数。 "},"语言/Python/Python读写Excel文件.html":{"url":"语言/Python/Python读写Excel文件.html","title":"Python读写Excel文件","keywords":"","body":"Python读写Excel文件 一、使用xlrd module从Excel读取数据 表格的内容如下： 对Excel读取操作 ```-- coding: utf-8 -- import xlrd xlsfile = r\"C:\\Users\\Administrator\\Desktop\\test\\Account.xls\"# 打开指定路径中的xls文件 book = xlrd.open_workbook(xlsfile)#得到Excel文件的book对象，实例化对象 sheet0 = book.sheet_by_index(0) # 通过sheet索引获得sheet对象 print \"1、\",sheet0 sheet_name = book.sheet_names()[0]# 获得指定索引的sheet表名字 print \"2、\",sheet_name sheet1 = book.sheet_by_name(sheet_name)# 通过sheet名字来获取，当然如果知道sheet名字就可以直接指定 nrows = sheet0.nrows # 获取行总数 print \"3、\",nrows循环打印每一行的内容 for i in range(nrows): print sheet1.row_values(i) ncols = sheet0.ncols #获取列总数 print \"4、\",ncols row_data = sheet0.row_values(0) # 获得第1行的数据列表 print row_data col_data = sheet0.col_values(0) # 获得第1列的数据列表 print \"5、\",col_data通过坐标读取表格中的数据 cell_value1 = sheet0.cell_value(0, 0) print \"6、\",cell_value1 cell_value2 = sheet0.cell_value(0, 1) print \"7、\",cell_value2 - 3. 执行的结果： ![](./images/python_02_02.png) ## 二、使用xlwt module将数据写入Excel表格 -- coding: utf-8 -- 导入xlwt模块 import xlwt 创建一个Workbook对象，这就相当于创建了一个Excel文件 book = xlwt.Workbook(encoding='utf-8', style_compression=0) ''' Workbook类初始化时有encoding和style_compression参数 encoding:设置字符编码，一般要这样设置：w = Workbook(encoding='utf-8')，就可以在excel中输出中文了。 默认是ascii。当然要记得在文件头部添加： !/usr/bin/env python -- coding: utf-8 -- style_compression:表示是否压缩，不常用。 ''' 创建一个sheet对象，一个sheet对象对应Excel文件中的一张表格。 在电脑桌面右键新建一个Excel文件，其中就包含sheet1，sheet2，sheet3三张表 sheet = book.add_sheet('test', cell_overwrite_ok=True) 其中的test是这张表的名字,cell_overwrite_ok，表示是否可以覆盖单元格，其实是Worksheet实例化的一个参数，默认值是False 向表test中添加数据 sheet.write(0, 0, 'EnglishName') # 其中的'0-行, 0-列'指定表中的单元，'EnglishName'是向该单元写入的内容 sheet.write(1, 0, 'Marcovaldo') txt1 = '中文名字' sheet.write(0, 1, txt1.decode('utf-8')) # 此处需要将中文字符串解码成unicode码，否则会报错 txt2 = '马可瓦多' sheet.write(1, 1, txt2.decode('utf-8')) 最后，将以上操作保存到指定的Excel文件中 book.save(r'e:\\test1.xls') # 在字符串前加r，声明为raw字符串，这样就不会处理其中的转义了。否则，可能会报错 ``` "},"语言/Python/Python鲜为人知的语法.html":{"url":"语言/Python/Python鲜为人知的语法.html","title":"Python鲜为人知的语法","keywords":"","body":"Python鲜为人知的语法 python 是一门用途广泛、易读、而且容易入门的编程语言。 但同时 python 语法也允许我们做一些很奇怪的事情。 使用 LAMBDA 表达式重写多行函数 众所周知 python 的 lambda 表达式不支持多行代码。但是可以模拟出多行代码的效果。 def f(): x = ‘string’ if x.endswith(‘g’): x = x[:-1] r = ” for i in xrange(len(x)): if x[i] != ‘i’: r += x[i] return r f() -> ‘strn’ 虽然看起来很奇怪，但是上面的函数可以使用下面的 lambda 表达式函数代替： (lambda: ([x for x in [‘string’]], x.endswith(‘g’) and [x for x in[x[:-1]]], [r for r in [”]], [x[i] != ‘i’ and [r for r in[r+x[i]]] for i inxrange(len(x))], r)[–1])() -> ‘strn’ 永远不要在生产环境写这样的代码 三元运算符 现代的 python 提供了更简便的语法: b if a else c 也可以通过下面的方式重写： (a and [b] or [c])[0] (b, c)[not a] 顺便说一下，下面的变体是错误的： a and b or c True and [] or [1] -> [1], but: [] if True else [1] -> [] 通过列表推导式移除重复的元素 让我们来把字符串 x = 'tteesstt' 转换成 'test' 吧。 1.在原字符串中和上一个字符比较：”.join([” if i and j == x[i-1] else j for i,j in enumerate(x)] 2.把前一个字符保存到临时变量中：”.join([(” if i == a else i, [a for a in [i]])[0] for a in [”] for i in x]) ”.join([(” if i == a.pop() else i, a.append(i))[0] for a in [[”]] for i inx]) 3.在新字符串中和上一个字符比较：[(not r.endswith(i) and [r for r in [r+i]], r)[-1] for r in [”] for i in x][-1] 4.通过 reduce 函数和 lambda 表达式：reduce(lambda a, b: a if a.endswith(b) else a + b, x) 通过列表推导式获得斐波拉契数列 1.把中间值保存在列表中[(lambda: (l[–1], l.append(l[–1] + l[–2]))[0])() for l in [[1, 1]] for x inxrange(19)] [(l[–1], l.append(l[–1] + l[–2]))[0] for l in [[1, 1]] for x in xrange(19)] 2.把中间值保存到字典中:[i for x in [(lambda: (l[‘a’], l.update({‘a’: l[‘a’] + l[‘b’]}), l[‘b’],l.update({‘b’: l[‘a’] + l[‘b’]}))[::2])() for l in [{‘a’: 1,‘b’: 1}] for x inxrange(10)] for i in x] [i for x in [(l[‘a’], l.update({‘a’: l[‘a’] + l[‘b’]}), l[‘b’], l.update({‘b’: l[‘a’]+ l[‘b’]}))[::2] for l in [{‘a’: 1, ‘b’: 1}] for xin xrange(10)] for i in x] 3.通过 reduce 函数和 lambda 表达式：reduce(lambda a, b: a + [a[–1] + a[–2]], xrange(10), [1, 1]) reduce(lambda a, b: a.append(a[–1] + a[–2]) or a, xrange(10), [1,1]) 4.速度最快的变体：[l.append(l[-1] + l[-2]) or l for l in [[1, 1]] for x in xrange(10)][0] 使用列表推导式产生死循环 [a.append(b) for a in [[None]] for b in a] 列表切片技巧 1.复制列表：l = [1, 2, 3] m = l[:] m -> [1, 2, 3] 2.移除/替换 列表中的任意元素：l = [1, 2, 3] l[1:-1] = [4, 5, 6, 7] l -> [1, 4, 5, 6, 7, 3] 3.在列表的开头添加元素：l = [1, 2, 3] l[:0] = [4, 5, 6] l -> [4, 5, 6, 1, 2, 3] 4.在列表的尾部添加元素：l = [1, 2, 3] l[–1:] = [l[–1], 4, 5, 6] l -> [1, 2, 3, 4, 5, 6] 5.反转列表：l = [1, 2, 3] l[:] = l[::-1] 替换方法字节码 Python 阻止替换类实例中的方法，因为 python 给类实例中的方法赋予了只读属性：class A(object): def x(self): print “hello” a = A() def y(self): print “world” a.x.im_func = y -> TypeError: readonly attribute 但是可以在字节码的层面上进行替换：a.x.im_func.func_code = y.func_code a.x() -> ‘world’ 注意！ 这不仅对当前的实例有影响，而且对整个类都有影响（准确的说是与这个类绑定的函数）（译者注:此处应该是笔误，推测作者原意是:准确的说是与这个函数绑定的所有类），并且所有其他的实例也会受到影响：new_a = A() new_a.x() -> ‘world’ 让可变元素作为函数参数默认值 把可变对象作为函数参数的默认值是非常危险的一件事，并且在面试中有大量关于这方面棘手的面试问题。但这一点对于缓存机制非常有帮助。 1.阶乘函数：def f(n, c={}): if n in c: return c[n] if (n 3628800 f.func_defaults ({1: 1, 2: 2, 3: 6, 4: 24, 5: 120, 6: 720, 7: 5040, 8: 40320, 9: 362880, 10: 3628800},) 2.斐波拉契数列：def fib(n, c={}): if n in c: return c[n] if (n 89 fib.func_defaults[0].values() -> [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89] "},"语言/Python/Python中matplotlib的颜色及线条控制.html":{"url":"语言/Python/Python中matplotlib的颜色及线条控制.html","title":"Python中matplotlib的颜色及线条控制","keywords":"","body":"Python中matplotlib的颜色及线条控制 代码： plt.subplots(1, 1) x= range(100) y= [i**2 for i in x] plt.plot(x, y, linewidth = '1', label = \"test\", color=' coral ', linestyle=':', marker='|') plt.legend(loc='upper left') plt.show() 结果： 说明：其实上面color=' coral '中，可以换成color=' #054E9F'，每两个十六进制数分别代表R、G、B分量 linestyle可选参数： '-' solid line style '--' dashed line style '-.' dash-dot line style ':' dotted line style marker可选参数： '.' point marker ',' pixel marker 'o' circle marker 'v' triangledown marker '^' triangle_up marker '' triangle_right marker '1' tri_down marker '2' tri_up marker '3' tri_left marker '4' tri_right marker 's' square marker 'p' pentagon marker '*' star marker 'h' hexagon1 marker 'H' hexagon2 marker '+' plus marker 'x' x marker 'D' diamond marker 'd' thin_diamond marker '|' vline marker '' hline marker matplotlib中color可用的颜色： cnames = { 'aliceblue': '#F0F8FF', 'antiquewhite': '#FAEBD7', 'aqua': '#00FFFF', 'aquamarine': '#7FFFD4', 'azure': '#F0FFFF', 'beige': '#F5F5DC', 'bisque': '#FFE4C4', 'black': '#000000', 'blanchedalmond': '#FFEBCD', 'blue': '#0000FF', 'blueviolet': '#8A2BE2', 'brown': '#A52A2A', 'burlywood': '#DEB887', 'cadetblue': '#5F9EA0', 'chartreuse': '#7FFF00', 'chocolate': '#D2691E', 'coral': '#FF7F50', 'cornflowerblue': '#6495ED', 'cornsilk': '#FFF8DC', 'crimson': '#DC143C', 'cyan': '#00FFFF', 'darkblue': '#00008B', 'darkcyan': '#008B8B', 'darkgoldenrod': '#B8860B', 'darkgray': '#A9A9A9', 'darkgreen': '#006400', 'darkkhaki': '#BDB76B', 'darkmagenta': '#8B008B', 'darkolivegreen': '#556B2F', 'darkorange': '#FF8C00', 'darkorchid': '#9932CC', 'darkred': '#8B0000', 'darksalmon': '#E9967A', 'darkseagreen': '#8FBC8F', 'darkslateblue': '#483D8B', 'darkslategray': '#2F4F4F', 'darkturquoise': '#00CED1', 'darkviolet': '#9400D3', 'deeppink': '#FF1493', 'deepskyblue': '#00BFFF', 'dimgray': '#696969', 'dodgerblue': '#1E90FF', 'firebrick': '#B22222', 'floralwhite': '#FFFAF0', 'forestgreen': '#228B22', 'fuchsia': '#FF00FF', 'gainsboro': '#DCDCDC', 'ghostwhite': '#F8F8FF', 'gold': '#FFD700', 'goldenrod': '#DAA520', 'gray': '#808080', 'green': '#008000', 'greenyellow': '#ADFF2F', 'honeydew': '#F0FFF0', 'hotpink': '#FF69B4', 'indianred': '#CD5C5C', 'indigo': '#4B0082', 'ivory': '#FFFFF0', 'khaki': '#F0E68C', 'lavender': '#E6E6FA', 'lavenderblush': '#FFF0F5', 'lawngreen': '#7CFC00', 'lemonchiffon': '#FFFACD', 'lightblue': '#ADD8E6', 'lightcoral': '#F08080', 'lightcyan': '#E0FFFF', 'lightgoldenrodyellow': '#FAFAD2', 'lightgreen': '#90EE90', 'lightgray': '#D3D3D3', 'lightpink': '#FFB6C1', 'lightsalmon': '#FFA07A', 'lightseagreen': '#20B2AA', 'lightskyblue': '#87CEFA', 'lightslategray': '#778899', 'lightsteelblue': '#B0C4DE', 'lightyellow': '#FFFFE0', 'lime': '#00FF00', 'limegreen': '#32CD32', 'linen': '#FAF0E6', 'magenta': '#FF00FF', 'maroon': '#800000', 'mediumaquamarine': '#66CDAA', 'mediumblue': '#0000CD', 'mediumorchid': '#BA55D3', 'mediumpurple': '#9370DB', 'mediumseagreen': '#3CB371', 'mediumslateblue': '#7B68EE', 'mediumspringgreen': '#00FA9A', 'mediumturquoise': '#48D1CC', 'mediumvioletred': '#C71585', 'midnightblue': '#191970', 'mintcream': '#F5FFFA', 'mistyrose': '#FFE4E1', 'moccasin': '#FFE4B5', 'navajowhite': '#FFDEAD', 'navy': '#000080', 'oldlace': '#FDF5E6', 'olive': '#808000', 'olivedrab': '#6B8E23', 'orange': '#FFA500', 'orangered': '#FF4500', 'orchid': '#DA70D6', 'palegoldenrod': '#EEE8AA', 'palegreen': '#98FB98', 'paleturquoise': '#AFEEEE', 'palevioletred': '#DB7093', 'papayawhip': '#FFEFD5', 'peachpuff': '#FFDAB9', 'peru': '#CD853F', 'pink': '#FFC0CB', 'plum': '#DDA0DD', 'powderblue': '#B0E0E6', 'purple': '#800080', 'red': '#FF0000', 'rosybrown': '#BC8F8F', 'royalblue': '#4169E1', 'saddlebrown': '#8B4513', 'salmon': '#FA8072', 'sandybrown': '#FAA460', 'seagreen': '#2E8B57', 'seashell': '#FFF5EE', 'sienna': '#A0522D', 'silver': '#C0C0C0', 'skyblue': '#87CEEB', 'slateblue': '#6A5ACD', 'slategray': '#708090', 'snow': '#FFFAFA', 'springgreen': '#00FF7F', 'steelblue': '#4682B4', 'tan': '#D2B48C', 'teal': '#008080', 'thistle': '#D8BFD8', 'tomato': '#FF6347', 'turquoise': '#40E0D0', 'violet': '#EE82EE', 'wheat': '#F5DEB3', 'white': '#FFFFFF', 'whitesmoke': '#F5F5F5', 'yellow': '#FFFF00', 'yellowgreen': '#9ACD32'} 装了seaborn扩展的话，在字典seaborn.xkcd_rgb中包含所有的xkcd crowdsourced color names。如下： plt.plot([1,2], lw=4, c=seaborn.xkcd_rgb['baby poop green']) "},"语言/Python/Python使用itchat调用微信接口.html":{"url":"语言/Python/Python使用itchat调用微信接口.html","title":"Python使用itchat调用微信接口","keywords":"","body":"Python使用itchat调用微信接口 itchat是一个开源的微信个人号接口，使用python调用微信从未如此简单。使用不到三十行的代码，你就可以完成一个能够处理所有信息的微信机器人。 安装 sudo pip install itchat 登录 itchat.auto_login() 这种方法将会通过微信扫描二维码登录，但是这种登录的方式确实短时间的登录，并不会保留登录的状态，也就是下次登录时还是需要扫描二维码，如果加上hotReload==True,那么就会保留登录的状态，至少在后面的几次登录过程中不会再次扫描二维码，该参数生成一个静态文件itchat.pkl用于存储登录状态。 退出及登录完成后调用的特定的方法 这里主要使用的是灰调函数的方法,登录完成后的方法需要赋值在 loginCallback 中退出后的方法,需要赋值在 exitCallback中.若不设置 loginCallback 的值, 将会自动删除二维码图片并清空命令行显示. import itchat, time def lc(): print(\"Finash Login!\") def ec(): print(\"exit\") itchat.auto_login(loginCallback=lc, exitCallback=ec) time.sleep() itchat.logout() #强制退出登录 获取好友 import itchat itchat.login() #爬取自己好友相关信息， 返回一个json文件 friends = itchat.get_friends(update=True)[0:] 回复消息 send send(msg=\"Text Message\", toUserName=None) 参数： msg : 文本消息内容 @fil@path_to_file : 发送文件 @img@path_to_img : 发送图片 @vid@path_to_video : 发送视频 toUserName : 发送对象, 如果留空, 将发送给自己. 返回值 True or False 实例代码 # coding-utf-8 import itchat itchat.auto_login() itchat.send(\"Hello World!\") ithcat.send(\"@fil@%s\" % '/tmp/test.text') ithcat.send(\"@img@%s\" % '/tmp/test.png') ithcat.send(\"@vid@%s\" % '/tmp/test.mkv') send_msg send_msg(msg='Text Message', toUserName=None) 参数： 其中的的msg是要发送的文本 toUserName是发送对象, 如果留空, 将发送给自己 返回值 True or False 实例代码 import itchat itchat.auto_login() itchat.send_msg(\"hello world.\") send_file send_file(fileDir, toUserName=None) 参数： fileDir是文件路径, 当文件不存在时, 将打印无此文件的提醒。 toUserName是发送对象, 如果留空, 将发送给自己 返回值 True or False 实例代码 import itchat itchat.auto_login() itchat.send_file(\"/tmp/test.txt\") send_image send_image(fileDir, toUserName=None) 参数： fileDir是文件路径, 当文件不存在时, 将打印无此文件的提醒。 toUserName是发送对象, 如果留空, 将发送给自己 返回值 True or False 实例代码 import itchat itchat.auto_login() itchat.send_img(\"/tmp/test.txt\") send_video send_video(fileDir, toUserName=None) 参数： fileDir是文件路径, 当文件不存在时, 将打印无此文件的提醒。 toUserName是发送对象, 如果留空, 将发送给自己 返回值 True or False 实例代码 import itchat itchat.auto_login() itchat.send_video(\"/tmp/test.txt\") 注册消息方法 itchat 将根据接受到的消息类型寻找对应的已注册的方法。如果一个消息类型没有对应的注册方法, 该消息将会被舍弃。在运行过程中也可以动态注册方法, 注册方式与结果不变。 注册方法 不带具体对象注册 将注册为普通消息的回复方法。 import itchat from itchat.content import * @itchat.msg_register(TEXT) #这里的TEXT表示如果有人发送文本消息，那么就会调用下面的方法 def simple_reply(msg): #这个是向发送者发送消息 itchat.send_msg('已经收到了文本消息，消息内容为%s'%msg['Text'],toUserName=msg['FromUserName']) return \"T reveived: %s\" % msg[\"Text\"] #返回的给对方的消息，msg[\"Text\"]表示消息的内容 带对象参数注册 对应消息对象将调用该方法，其中isFriendChat表示好友之间，isGroupChat表示群聊，isMapChat表示公众号 import itchat from itchat.content import * @itchat.msg_register(TEXT, isFriendChat=True, isGroupChat=True,isMpChat=True) def text_reply(msg): msg.user.send(\"%s : %s\" % (mst.type, msg.text)) 消息类型 向注册方法传入的 msg 包含微信返回的字典的所有内容.itchat 增加 Text, Type(也就是参数) 键值, 方便操作. itcaht.content 中包含所有的消息类型参数, 如下表 参数 类型 Text 键值 TEXT 文本 文本内容(文字消息) MAP 地图 位置文本(位置分享) CARD 名片 推荐人字典(推荐人的名片) SHARING 分享 分享名称(分享的音乐或者文章等) PICTURE 下载方法 图片/表情 RECORDING 语音 下载方法 ATTACHMENT 附件 下载方法 VIDEO 小视频 下载方法 FRIENDS 好友邀请 添加好友所需参数 SYSTEM 系统消息 更新内容的用户或群聊的UserName组成的列表 NOTE 通知 通知文本(消息撤回等) 附件的下载与发送 itchat 的附件下载方法存储在 msg 的 Text 键中. 发送的文件名(图片给出的默认文件名), 都存储在 msg 的 FileName 键中. 下载方法, 接受一个可用的位置参数(包括文件名), 并将文件响应的存储. 注意：下载的文件存储在指定的文件中，直接将路径与FileName连接即可，如msg[\"Text\"]('/tmp/weichat'+msg['FileName']) @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): #msg.download(msg['FileName']) #这个同样是下载文件的方式 msg['Text'](msg['FileName']) #下载文件 #将下载的文件发送给发送者 itchat.send('@%s@%s' % ('img' if msg['Type'] == 'Picture' else 'fil', msg[\"FileName\"]), msg[\"FromUserName\"]) 群消息 增加了三个键值，如下： isAt 判断是否 @ 本号 ActualNickName : 实际 NickName(昵称) Content : 实际 Content 测试程序 import itcaht from itchat.content import TEXT @itchat.msg_register(TEXT, isGroupChat=True) def text_reply(msg): if(msg.isAt): #判断是否有人@自己 #如果有人@自己，就发一个消息告诉对方我已经收到了信息 itchat.send_msg(\"我已经收到了来自{0}的消息，实际内容为{1}\".format(msg['ActualNickName'],msg['Text']),toUserName=msg['FromUserName']) itchat.auto_login() itchat.run() 注册消息的优先级 总的来说就是后面注册同种类型的消息会覆盖之前注册的消息，详情见文档https://itchat.readthedocs.io/zh/latest/ 消息内容 注意：所有的消息内容都是可以用键值对来访问的，如msg[\"FromUserName]就是查看发送者，itchat.search_friends(userName=msg['FromUserName'])['NickName']查看的是当发送者昵称 一般消息 一般的消息都遵循以下的内容： { \"FromUserName\": \"\", \"ToUserName\": \"\", \"Content\": \"\", \"StatusNotifyUserName\": \"\", \"ImgWidth\": 0, \"PlayLength\": 0, \"RecommendInfo\": {}, \"StatusNotifyCode\": 0, \"NewMsgId\": \"\", \"Status\": 0, \"VoiceLength\": 0, \"ForwardFlag\": 0, \"AppMsgType\": 0, \"Ticket\": \"\", \"AppInfo\": {}, \"Url\": \"\", \"ImgStatus\": 0, \"MsgType\": 0, \"ImgHeight\": 0, \"MediaId\": \"\", \"MsgId\": \"\", \"FileName\": \"\", \"HasProductId\": 0, \"FileSize\": \"\", \"CreateTime\": 0, \"SubMsgType\": 0 } 初始化消息 MsgType: 51 FromUserName: 自己ID ToUserName: 自己ID StatusNotifyUserName: 最近联系的联系人ID Content: # 最近联系的联系人 filehelper,xxx@chatroom,wxid_xxx,xxx,... # 朋友圈 MomentsUnreadMsgStatus 1454502365 # 未读的功能账号消息，群发助手，漂流瓶等 文本消息 MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: 消息内容 图片消息 itchat 增加了 Text 键, 键值为 下载该图片的方法. MsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取图片，用于表示每一条消息 Content: 拓展：如果想要得到Content中的具体内容可以使用正则表达式匹配出来 视频消息 *itchat 增加了 Text 键, 键值为 下载该视频的方法.* MsgType: 62 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取小视频 Content: 地理位置消息 itchat 增加了 Text 键, 键值为 该地点的文本形式. MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: http://weixin.qq.com/cgi-bin/redirectforward?args=xxx OriContent: 名片消息 itchat 增加了Text 键, 键值为 该调用 add_friend 需要的属性. MsgType: 42 FromUserName: 发送方ID ToUserName: 接收方ID Content: RecommendInfo: { \"UserName\": \"xxx\", # ID，这里的是昵称 \"Province\": \"xxx\", \"City\": \"xxx\", \"Scene\": 17, \"QQNum\": 0, \"Content\": \"\", \"Alias\": \"xxx\", # 微信号 \"OpCode\": 0, \"Signature\": \"\", \"Ticket\": \"\", \"Sex\": 0, # 1:男, 2:女 \"NickName\": \"xxx\", # 昵称 \"AttrStatus\": 4293221, \"VerifyFlag\": 0 } 下面是添加好友的测试代码 @itchat.msg_register(itchat.content.CARD,isFriendChat=True) def simply(msg): print msg['Text'] print msg['Content'] itchat.add_friend(userName=msg['Text']['UserName']) #添加推荐的好友 print msg['RecommendInfo'] print msg['RecommendInfo']['UserName'] 语音消息 itchat增加了Text键,键值为下载该语音文件的方法,下载下来的是MP3的格式 MsgType: 34 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取语音 Content: 下载方法：msg'Text' 动画表情 itchat添加了Text键，键值为下载该图片表情的方法。 注意：本人亲测对于一些微信商店提供的表情是不能下载成功的,这里的自带的表情emoji是属于TEXT类别的，因此如果将其注册为PICTURE消息类型的话是不可以监测到的 MsgType: 47 FromUserName: 发送方ID ToUserName: 接收方ID Content: 普通链接或应用分享消息 主要针对的是分享的文章等等 MsgType: 49 AppMsgType: 5 FromUserName: 发送方ID ToUserName: 接收方ID Url: 链接地址 FileName: 链接标题 Content: 5 ... 音乐链接消息 主要针对的是音乐 MsgType: 49 AppMsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID Url: 链接地址 FileName: 音乐名 AppInfo: # 分享链接的应用 { Type: 0, AppID: wx485a97c844086dc9 } Content: 3 0 0 http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;fromtag=46 http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;fromtag=46 0 http://imgcache.qq.com/music/photo/album/63/180_albumpic_143163_0.jpg 0 29 摇一摇搜歌 群消息 itchat 增加了三个群聊相关的键值: isAt : 判断是否 @ 本号 ActualNickName : 实际 NickName Content : 实际 ContentMsgType: 1 FromUserName: @@xxx ToUserName: @xxx Content: @xxx:xxx 红包消息 MsgType: 49 AppMsgType: 2001 FromUserName: 发送方ID ToUserName: 接收方ID Content: 未知 系统消息 MsgType: 10000 FromUserName: 发送方ID ToUserName: 自己ID Content: \"你已添加了 xxx ，现在可以开始聊天了。\" \"如果陌生人主动添加你为朋友，请谨慎核实对方身份。\" \"收到红包，请在手机上查看\" 账号类型 tchat 为三种账号都提供了 整体获取方法与搜索方法. 好友 get_friends itchat.get_friends() 返回完整的好友列表 每个好友为一个字典, 其中第一项为本人的账号信息; 传入 update=True, 将更新好友列表并返回, get_friends(update=True) search_friends itchat.search_friends() 好友搜索 仅获取自己的用户信息# 获取自己的用户信息，返回自己的属性字典 itchat.search_friends() 获取特定 UserName 的用户信息 # 获取特定UserName的用户信息 itchat.search_friends(userName='@abcdefg1234567') 获取发送信息的好友的详细信息 ## 获取发送信息的好友的详细信息 @itchat.msg_register(itchat.content.TEXT,isFriendChat=True) def reply(msg): print msg['FromUserName'] print itchat.search_friends(userName=msg['FromUserName']) #详细信息 print itchat.search_friends(userName=msg['FromUserName'])['NickName'] #获取昵称 获取备注,微信号, 昵称中的任何一项等于name键值的用户. (可以与下一项配置使用.) 比如在我的微信中有一个备注为autolife的人，我可以使用这个方法搜索出详细的信息 # 获取任何一项等于name键值的用户 itchat.search_friends(name='autolife') 获取备注,微信号, 昵称分别等于相应键值的用户. (可以与上一项配置使用.) # 获取分别对应相应键值的用户 itchat.search_friends(wechatAccount='littlecodersh') # 三、四项功能可以一同使用 itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh') update_friend 主要用于好友更新 特定用户: 传入用户UserName, 返回指定用户的最新信息. 用户列表: 传入 UserName 组成的列表, 返回用户最新信息组成的列表 memberList = itchat.update_friend('@abcdefg1234567') 公众号 get_mps 将返回完整的工作号列表 每个公众号为一个字典, 传入 update=True 将更新公众号列表, 并返回. search_mps 获取特定UserName的公众号 # 获取特定UserName的公众号，返回值为一个字典 itchat.search_mps(userName='@abcdefg1234567') 获取名字中还有特定字符的公众号. # 获取名字中含有特定字符的公众号，返回值为一个字典的列表 itchat.search_mps(name='LittleCoder') 当两项都有时, 将仅返回特定UserName的公众号. 群聊 get_chatrooms : 返回完整的群聊列表. search_chatrooms : 群聊搜索. update_chatroom : 获取群聊用户列表或更新该群聊. 群聊在首次获取中不会获取群聊的用户列表, 所以需要调用该命令才能获取群聊成员. 传入群聊的 UserName , 返回特定群聊的详细信息. 传入UserName组成的列表, 返回指定用户的最新信息组成的列表. memberList = itchat.update_chatroom('@@abcdefg1234567', detailedMember=True) 创建群聊,增加/删除群聊用户: 由于之前通过群聊检测是否被好友拉黑的程序, 目前这三个方法都被严格限制了使用频率. 删除群聊需要本账号为管理员, 否则无效. 将用户加入群聊有直接加入与发送邀请, 通过 useInvitation 设置. 超过 40 人的群聊无法使用直接加入的加入方式. memberList = itchat.get_frients()[1:] # 创建群聊, topic 键值为群聊名称. chatroomUserName = itchat.create_chatroom(memberList, \"test chatroom\") # 删除群聊内的用户 itchat.delete_member_from_chatroom(chatroomUserName, memberList[0]) # 增加用户进入群聊. itchat.add_member_into_chatroom(chatroomUserName, memberList[0], useInvitation=False) 方法汇总 itchat.add_friend itchat.new_instance itchat.add_member_into_chatroom itchat.originInstance itchat.auto_login itchat.returnvalues itchat.check_login itchat.run itchat.components itchat.search_chatrooms itchat.config itchat.search_friends itchat.configured_reply itchat.search_mps itchat.content itchat.send itchat.core itchat.send_file itchat.Core itchat.send_image itchat.create_chatroom itchat.send_msg itchat.delete_member_from_chatroom itchat.send_raw_msg itchat.dump_login_status itchat.send_video itchat.get_chatrooms itchat.set_alias itchat.get_contact itchat.set_chatroom_name itchat.get_friends itchat.set_logging itchat.get_head_img itchat.set_pinned itchat.get_mps itchat.show_mobile_login itchat.get_msg itchat.start_receiving itchat.get_QR itchat.storage itchat.get_QRuuid itchat.update_chatroom itchat.instanceList itchat.update_friend itchat.load_login_status itchat.upload_file itchat.log itchat.utils itchat.login itchat.VERSION itchat.logout itchat.web_init itchat.msg_register 实例 下面是写的一个程序，该程序的主要功能是监控撤回消息，并且如果有消息撤回就会撤回的消息发送给你，以后再也不用担心看不到好友的撤回的消息了，由于注释写的很详细，因此这里就不在详细的讲解了，直接贴代码 代码 # coding:utf-8 import itchat from itchat.content import TEXT from itchat.content import * import sys import time import re reload(sys) sys.setdefaultencoding('utf8') import os msg_information = {} face_bug=None #针对表情包的内容 @itchat.msg_register([TEXT, PICTURE, FRIENDS, CARD, MAP, SHARING, RECORDING, ATTACHMENT, VIDEO],isFriendChat=True, isGroupChat=True, isMpChat=True) def handle_receive_msg(msg): global face_bug msg_time_rec = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) #接受消息的时间 msg_from = itchat.search_friends(userName=msg['FromUserName'])['NickName'] #在好友列表中查询发送信息的好友昵称 msg_time = msg['CreateTime'] #信息发送的时间 msg_id = msg['MsgId'] #每条信息的id msg_content = None #储存信息的内容 msg_share_url = None #储存分享的链接，比如分享的文章和音乐 print msg['Type'] print msg['MsgId'] if msg['Type'] == 'Text' or msg['Type'] == 'Friends': #如果发送的消息是文本或者好友推荐 msg_content = msg['Text'] print msg_content #如果发送的消息是附件、视屏、图片、语音 elif msg['Type'] == \"Attachment\" or msg['Type'] == \"Video\" \\ or msg['Type'] == 'Picture' \\ or msg['Type'] == 'Recording': msg_content = msg['FileName'] #内容就是他们的文件名 msg['Text'](str(msg_content)) #下载文件 # print msg_content elif msg['Type'] == 'Card': #如果消息是推荐的名片 msg_content = msg['RecommendInfo']['NickName'] + '的名片' #内容就是推荐人的昵称和性别 if msg['RecommendInfo']['Sex'] == 1: msg_content += '性别为男' else: msg_content += '性别为女' print msg_content elif msg['Type'] == 'Map': #如果消息为分享的位置信息 x, y, location = re.search( \"\" + x.__str__() + \" 经度->\" + y.__str__() #内容为详细的地址 else: msg_content = r\"\" + location elif msg['Type'] == 'Sharing': #如果消息为分享的音乐或者文章，详细的内容为文章的标题或者是分享的名字 msg_content = msg['Text'] msg_share_url = msg['Url'] #记录分享的url print msg_share_url face_bug=msg_content #将信息存储在字典中，每一个msg_id对应一条信息 msg_information.update( { msg_id: { \"msg_from\": msg_from, \"msg_time\": msg_time, \"msg_time_rec\": msg_time_rec, \"msg_type\": msg[\"Type\"], \"msg_content\": msg_content, \"msg_share_url\": msg_share_url } } ) #这个是用于监听是否有消息撤回 @itchat.msg_register(NOTE, isFriendChat=True, isGroupChat=True, isMpChat=True) def information(msg): #这里如果这里的msg['Content']中包含消息撤回和id，就执行下面的语句 if '撤回了一条消息' in msg['Content']: old_msg_id = re.search(\"\\(.*?)\\\", msg['Content']).group(1) #在返回的content查找撤回的消息的id old_msg = msg_information.get(old_msg_id) #得到消息 print old_msg if len(old_msg_id)"},"语言/Python/Python微信库itchat的用法.html":{"url":"语言/Python/Python微信库itchat的用法.html","title":"Python微信库itchat的用法","keywords":"","body":"Python微信库itchat的用法 最简单的回复 通过如下代码，可以完成回复所有文本信息（包括群聊）。 import itchat from itchat.content import TEXT @itchat.msg_register def simple_reply(msg): if msg['Type'] == TEXT: return 'I received: %s' % msg['Content'] itchat.auto_login() itchat.run() 常用消息的配置 itchat支持所有的消息类型与群聊，下面的示例中演示了对于这些消息类型简单的配置。 #coding=utf8 import itchat from itchat.content import * @itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING]) def text_reply(msg): itchat.send('%s: %s' % (msg['Type'], msg['Text']), msg['FromUserName']) # 以下四类的消息的Text键下存放了用于下载消息内容的方法，传入文件地址即可 @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): msg['Text'](msg['FileName']) return '@%s@%s' % ({'Picture': 'img', 'Video': 'vid'}.get(msg['Type'], 'fil'), msg['FileName']) # 收到好友邀请自动添加好友 @itchat.msg_register(FRIENDS) def add_friend(msg): itchat.add_friend(**msg['Text']) # 该操作会自动将新好友的消息录入，不需要重载通讯录 itchat.send_msg('Nice to meet you!', msg['RecommendInfo']['UserName']) # 在注册时增加isGroupChat=True将判定为群聊回复 @itchat.msg_register(TEXT, isGroupChat = True) def groupchat_reply(msg): if msg['isAt']: itchat.send(u'@%s\\u2005I received: %s' % (msg['ActualNickName'], msg['Content']), msg['FromUserName']) itchat.auto_login(True) itchat.run() Login 在上一部分中你看到了基本的注册与登陆，而显然登陆使用的是itchat提供了auto_login方法，调用即可完成登录。 一般而言，我们都会在完成消息的注册后登陆。 当然这里需要特别强调的是三点，分别是短时间关闭重连、命令行二维码与自定义登陆内容。 itchat提供了登陆状态暂存，关闭程序后一定时间内不需要扫码即可登录。 为了方便在无图形界面使用itchat，程序内置了命令行二维码的显示。 * 如果你需要就登录状态就一些修改（例如更改提示语、二维码出现后邮件发送等）。 短时间关闭程序后重连 这样即使程序关闭，一定时间内重新开启也可以不用重新扫码。 最简单的用法就是给 auto_login 方法传入值为真的 hotReload 。 该方法会生成一个静态文件 itchat.pkl ，用于存储登陆的状态。 import itchat from itchat.content import TEXT @itchat.msg_register(TEXT) def simple_reply(msg): print(msg['Text']) itchat.auto_login(hotReload=True) itchat.run() itchat.dump_login_status() 通过设置statusStorageDir可以将静态文件指定为其他的值。 这一内置选项其实就相当于使用了以下两个函数的这一段程序： import itchat from itchat.content import TEXT if itchat.load_login_status(): @itchat.msg_register(TEXT) def simple_reply(msg): print(msg['Text']) itchat.run() itchat.dump_login_status() else: itchat.auto_login() itchat.dump_login_status() print('Config stored, so exit.') 其中load_login_status与dump_login_status分别对应读取与导出设置。 通过设置传入的fileDir的值可以设定导入导出的文件。 命令行二维码显示 通过以下命令可以在登陆的时候使用命令行显示二维码： itchat.auto_login(enableCmdQR=True) 部分系统可能字幅宽度有出入，可以通过将enableCmdQR赋值为特定的倍数进行调整： # 如部分的linux系统，块字符的宽度为一个字符（正常应为两字符），故赋值为2 itchat.auto_login(enableCmdQR=2) 默认控制台背景色为暗色（黑色），若背景色为浅色（白色），可以将enableCmdQR赋值为负值： itchat.auto_login(enableCmdQR=-1) 自定义登录过程 如果需要控制登录的过程，可以阅读下面的内容。 同时itchat也提供了登陆所需的每一步的方法，登陆的过程按顺序为： 获取二维码uuid->获取二维码->判断是否已经登陆成功->获取初始化数据->更新微信相关信息（通讯录、手机登陆状态）->循环扫描新信息（开启心跳） 获取二维码uuid 获取生成二维码所需的uuid，并返回。 方法名称： get_QRuuid 所需值：无 返回值：成功->uuid，失败->None 获取二维码 根据uuid获取二维码并打开，返回是否成功。 方法名称： get_QR 所需值：uuid 返回值：成功->True，失败->False 判断是否已经登陆成功 判断是否已经登陆成功，返回扫描的状态码。 方法名称： check_login 所需值：uuid 返回值：登陆成功->'200'，已扫描二维码->'201'，二维码失效->'408'，未获取到信息->'0' 获取初始化数据 获取微信用户信息以及心跳所需要的数据。 方法名称： web_init 所需值：无 返回值：存储登录微信用户信息的字典 获取微信通讯录 获取微信的所有好友信息并更新。 方法名称： get_contract 所需值：无 返回值：存储好友信息的列表 更新微信手机登陆状态 在手机上显示登录状态。 方法名称： show_mobile_login 所需值：无 返回值：无 循环扫描新信息（开启心跳） 循环扫描是否有新的消息，开启心跳包。 方法名称： start_receiving 所需值：无 返回值：无 eg.一个登录例子： import itchat, time, sys def output_info(msg): print('[INFO] %s' % msg) def open_QR(): for get_count in range(10): output_info('Getting uuid') uuid = itchat.get_QRuuid() while uuid is None: uuid = itchat.get_QRuuid();time.sleep(1) output_info('Getting QR Code') if itchat.get_QR(uuid): break elif get_count >= 9: output_info('Failed to get QR Code, please restart the program') sys.exit() output_info('Please scan the QR Code') return uuid uuid = open_QR() waitForConfirm = False while 1: status = itchat.check_login(uuid) if status == '200': break elif status == '201': if waitForConfirm: output_info('Please press confirm') waitForConfirm = True elif status == '408': output_info('Reloading QR Code') uuid = open_QR() waitForConfirm = False userInfo = itchat.web_init() itchat.show_mobile_login() itchat.get_contract() output_info('Login successfully as %s'%userInfo['NickName']) itchat.start_receiving() # Start auto-replying @itchat.msg_register def simple_reply(msg): if msg['Type'] == 'Text': return 'I received: %s' % msg['Content'] itchat.run() Register 注册消息方法 itchat将根据接收到的消息类型寻找对应的已经注册的方法。 如果一个消息类型没有对应的注册方法，该消息将会被舍弃。 在运行过程当中也可以动态注册方法，注册方式与结果不变。 注册 你可以通过两种方式注册消息方法 import itchat from itchat.content import * # 不带参数注册，所有消息类型都将调用该方法（包括群消息） @itchat.msg_register def simple_reply(msg): if msg['Type'] == 'Text': return 'I received: %s' % msg['Text'] # 带参数注册，该类消息类型将调用该方法 @itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING]) def text_reply(msg): itchat.send('%s: %s' % (msg['Type'], msg['Text']), msg['FromUserName']) 消息类型 向注册方法传入的msg包含微信返回的字典的所有内容。 本api增加Text、Type（也就是参数）键值，方便操作。 itchat.content中包含所有的消息类型参数，内容如下表所示： 比如你需要存储发送给你的附件： @itchat.msg_register(ATTACHMENT) def download_files(msg): msg['Text'](msg['FileName']) 值得注意的是，群消息增加了三个键值： isAt: 判断是否@本号 ActualNickName: 实际NickName * Content: 实际Content 可以通过本程序测试： import itchat from itchat.content import TEXT @itchat.msg_register(TEXT, isGroupChat = True) def text_reply(msg): print(msg['isAt']) print(msg['ActualNickName']) print(msg['Content']) itchat.auto_login() itchat.run() 注册消息的优先级 优先级分别为：后注册消息先于先注册消息，带参数消息先于不带参数消息。 以下面的两个程序为例： import itchat from itchat.content import * itchat.auto_login() @itchat.msg_register(TEXT) def text_reply(msg): return 'This is the old register' @itchat.msg_register(TEXT) def text_reply(msg): return 'This is a new one' itchat.run() 在私聊发送文本时将会回复This is a new one。 import itchat from itchat.content import * itchat.auto_login() @itchat.msg_register def general_reply(msg): return 'I received a %s' % msg['Type'] @itchat.msg_register(TEXT) def text_reply(msg): return 'You said to me one to one: %s' % msg['Text'] itchat.run() 仅在私聊发送文本时将会回复You said to me one to one，其余情况将会回复I received a ...。 动态注册消息 动态注册时可以选择将 itchat.run() 放入另一线程或使用 configured_reply() 方法处理消息。 两种方法分别是： # 使用另一线程，但注意不要让程序运行终止 import thread thread.start_new_thread(itchat.run, ()) # 使用configured_reply方法 while 1: itchat.configured_reply() # some other functions time.sleep(1) 以下给出一个动态注册的例子： #coding=utf8 import thread import itchat from itchat.content import * replyToGroupChat = True functionStatus = False def change_function(): if replyToGroupChat != functionStatus: if replyToGroupChat: @itchat.msg_register(TEXT, isGroupChat = True) def group_text_reply(msg): if u'关闭' in msg['Text']: replyToGroupChat = False return u'已关闭' elif u'开启' in msg['Text']: return u'已经在运行' return u'输入\"关闭\"或者\"开启\"测试功能' else: @itchat.msg_register(TEXT, isGroupChat = True) def group_text_reply(msg): if u'开启' in msg['Text']: replyToGroupChat = True return u'重新开启成功' functionStatus = replyToGroupChat thread.start_new_thread(itchat.run, ()) while 1: change_function() time.sleep(.1) Reply 回复 itchat提供五种回复方法，建议直接使用send方法。 send方法 方法： send(msg='Text Message', toUserName=None) 所需值： 1.msg：消息内容 2.'@fil@文件地址'将会被识别为传送文件，'@img@图片地址'将会被识别为传送图片，'@vid@视频地址'将会被识别为小视频 3.toUserName：发送对象，如果留空将会发送给自己 返回值：发送成功->True, 失败->False 程序示例： #coding=utf8 import itchat itchat.auto_login() itchat.send('Hello world!') # 请确保该程序目录下存在：gz.gif以及xlsx.xlsx itchat.send('@img@%s' % 'gz.gif') itchat.send('@fil@%s' % 'xlsx.xlsx') itchat.send('@vid@%s' % 'demo.mp4') send_msg方法 方法： send_msg(msg='Text Message', toUserName=None) 所需值： msg：消息内容 toUserName：发送对象，如果留空将会发送给自己 返回值：发送成功->True, 失败->False 程序示例： import itchat itchat.auto_login() itchat.send_msg('Hello world') send_file方法 方法： send_file(fileDir, toUserName=None) 所需值： fileDir：文件路径（不存在该文件时将打印无此文件的提醒） toUserName：发送对象，如果留空将会发送给自己 返回值：发送成功->True, 失败->False 程序示例： #coding=utf8 import itchat itchat.auto_login() #请确保该程序目录下存在：xlsx.xlsx itchat.send_file('xlsx.xlsx') send_img方法 方法： send_img(fileDir, toUserName=None 所需值： fileDir：文件路径（不存在该文件时将打印无此文件的提醒） toUserName：发送对象，如果留空将会发送给自己 返回值：发送成功->True, 失败->False 程序示例： #coding=utf8 import itchat itchat.auto_login() # 请确保该程序目录下存在：gz.gif itchat.send_img('gz.gif') send_video方法 方法： send_video(fileDir, toUserName=None) 所需值： fileDir：文件路径（不存在该文件时将打印无此文件的提醒） toUserName：发送对象，如果留空将会发送给自己 返回值：发送成功->True, 失败->False 需要保证发送的视频为一个实质的mp4文件 #coding=utf8 import itchat itchat.auto_login() #请确保该程序目录下存在：demo.mp4 itchat.send_file('demo.mp4') Memmber stuff 在使用个人微信的过程当中主要有三种账号需要获取，分别为： 好友 公众号 * 群聊 itchat为这三种账号都提供了整体获取方法与搜索方法。 而群聊多出获取用户列表方法以及创建群聊、增加、删除用户的方法。 这里我们分这三种分别介绍如何使用。 好友 好友的获取方法为 get_friends ，将会返回完整的好友列表。 其中每个好友为一个字典 列表的第一项为本人的账号信息 * 传入update键为True将可以更新好友列表并返回 好友的搜索方法为 search_friends ，有四种搜索方式： 1. 仅获取自己的用户信息 2. 获取特定 UserName 的用户信息 3. 获取备注、微信号、昵称中的任何一项等于 name 键值的用户 4. 获取备注、微信号、昵称分别等于相应键值的用户 其中三、四项可以一同使用，下面是示例程序： # 获取自己的用户信息，返回自己的属性字典 itchat.search_friends() # 获取特定UserName的用户信息 itchat.search_friends(userName='@abcdefg1234567') # 获取任何一项等于name键值的用户 itchat.search_friends(name='littlecodersh') # 获取分别对应相应键值的用户 itchat.search_friends(wechatAccount='littlecodersh') # 三、四项功能可以一同使用 itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh') 公众号 公众号的获取方法为 get_mps ，将会返回完整的公众号列表。 其中每个公众号为一个字典 传入update键为True将可以更新公众号列表并返回 公众号的搜索方法为 search_mps ，有两种搜索方法： 1. 获取特定 UserName 的公众号 2. 获取名字中含有特定字符的公众号 如果两项都做了特定，将会仅返回特定 UserName 的公众号，下面是示例程序： # 获取特定UserName的公众号，返回值为一个字典 itchat.search_mps(userName='@abcdefg1234567') # 获取名字中含有特定字符的公众号，返回值为一个字典的列表 itcaht.search_mps(name='LittleCoder') # 以下方法相当于仅特定了UserName itchat.search_mps(userName='@abcdefg1234567', name='LittleCoder') 群聊 群聊的获取方法为 get_chatrooms ，将会返回完整的群聊列表。 其中每个群聊为一个字典 传入update键为True将可以更新群聊列表并返回 群聊的搜索方法为 search_chatrooms ，有两种搜索方法： 1. 获取特定UserName的群聊 2. 获取名字中含有特定字符的群聊 如果两项都做了特定，将会仅返回特定UserName的群聊，下面是示例程序： # 获取特定UserName的群聊，返回值为一个字典 itchat.search_chatrooms(userName='@abcdefg1234567') # 获取名字中含有特定字符的群聊，返回值为一个字典的列表 itcaht.search_chatrooms(name='LittleCoder') # 以下方法相当于仅特定了UserName itchat.search_chatrooms(userName='@abcdefg1234567', name='LittleCoder') 群聊用户列表的获取方法为 update_chatroom 。 群聊在首次获取中不会获取群聊的用户列表，所以需要调用该命令才能获取群聊的成员 该方法需要传入群聊的UserName，返回特定群聊的用户列表 memberList = itchat.update_chatroom('@abcdefg1234567') 创建群聊、增加、删除群聊用户的方法如下所示： 由于之前通过群聊检测是否被好友拉黑的程序，目前这三个方法都被严格限制了使用频率 删除群聊需要本账号为群管理员，否则会失败 memberList = itchat.get_friends()[1:] # 创建群聊，topic键值为群聊名 chatroomUserName = itchat.create_chatroom(memberList, 'test chatroom') # 删除群聊内的用户 itchat.delete_member_from_chatroom(chatroomUserName, memberList[0]) # 增加用户进入群聊 itchat.add_member_into_chatroom(chatroomUserName, memberList[0]) QAQ Q: 为什么我在设定了itchat.auto_login()的enableCmdQR为True后还是没有办法在命令行显示二维码？ A: 这是由于没有安装可选的包 pillow ，可以使用右边的命令安装： pip install pillow eg. def signin(): # 查找公众号，进行签到 user = itchat.search_mps(name='Nulll.me') UserName = user[0]['UserName'] itchat.send(msg=u'3', toUserName=UserName) itchat.dump_login_status() pickleDumps('flag', localDay) # 如果执行成功写入标致文件 exit() if __name__ == '__main__': # 如果不是在登陆状态，就循环登陆 while not itchat.load_login_status(): sendMail() itchat.auto_login(hotReload=True) itchat.dump_login_status() signin() # 签到 time.sleep(3600) signin() # 签到 "},"语言/Java/":{"url":"语言/Java/","title":"Java","keywords":"","body":"Java Java是一种广泛使用的计算机编程语言，拥有跨平台、面向对象、泛型编程的特性，广泛应用于企业级Web应用开发和移动应用开发。 任职于太阳微系统的詹姆斯·高斯林等人于1990年代初开发Java语言的雏形，最初被命名为Oak，目标设置在家用电器等小型系统的编程语言，应用在电视机、电话、闹钟、烤面包机等家用电器的控制和通信。由于这些智能化家电的市场需求没有预期的高，太阳计算机系统（Sun公司）放弃了该项计划。随着1990年代互联网的发展，Sun公司看见Oak在互联网上应用的前景，于是改造了Oak，于1995年5月以Java的名称正式发布。Java伴随着互联网的迅猛发展而发展，逐渐成为重要的网络编程语言。 Java编程语言的风格十分接近C++语言。继承了C++语言面向对象技术的核心，舍弃了容易引起错误的指针，以引用取代；移除了C++中的运算符重载和多重继承特性，用接口取代；增加垃圾回收器功能。在Java SE 1.5版本中引入了泛型编程、类型安全的枚举、不定长参数和自动装/拆箱特性。太阳微系统对Java语言的解释是：“Java编程语言是个简单、面向对象、分布式、解释性、健壮、安全与系统无关、可移植、高性能、多线程和动态的语言” Java不同于一般的编译语言或解释型语言。它首先将源代码编译成字节码，再依赖各种不同平台上的虚拟机来解释执行字节码，从而具有“一次编写，到处运行”的跨平台特性。在早期JVM中，这在一定程度上降低了Java程序的运行效率。但在J2SE1.4.2发布后，Java的运行速度有了大幅提升。 与传统类型不同，Sun公司在推出Java时就将其作为开放的技术。全球的Java开发公司被要求所设计的Java软件必须相互兼容。“Java语言靠群体的力量而非公司的力量”是Sun公司的口号之一，并获得了广大软件开发商的认同。这与微软公司所倡导的注重精英和封闭式的模式完全不同，此外，微软公司后来推出了与之竞争的.NET平台以及模仿Java的C#语言。后来Sun公司被甲骨文公司并购，Java也随之成为甲骨文公司的产品。 现时，移动操作系统Android大部分的代码采用Java编程语言编程。 当前Java提供以下版本： Java Platform, Enterprise Edition（Java EE：Java平台企业版） Java Platform, Standard Edition（Java SE：Java平台标准版） Java Platform, Micro Edition（Java ME：Java平台微型版） Java Platform, Card Edition 语言特性 Java之所以被开发，是要达到以下五个目的： 应当使用面向对象程序设计方法学 应当允许同一程序在不同的计算机平台执行 应当包括内建的对计算机网络的支持 应当被设计成安全地执行远端代码 应当易于使用，并借鉴以前那些面向对象语言（如C++）的长处。 Java技术主要分成几个部分：Java语言、Java运行环境、类库。一般情况下说Java时并不区分指的是哪个部分。 Java在1.5版本时，做了重大改变，Sun公司并1.5版本重命名为Java 5.0。 面向对象 Java的特点之一就是面向对象，是程序设计方法的一种。“面向对象程序设计语言”的核心之一就是开发者在设计软件的时候可以使用自定义的类型和关联操作。代码和数据的实际集合体叫做“对象”。一个对象可以想象成绑定了很多“行为（代码）”和“状态（数据）”的物体。对于数据结构的改变需要和代码进行通信然后操作，反之亦然。面向对象设计让大型软件工程的计划和设计变得更容易管理，能增强工程的健康度，减少失败工程的数量。 跨平台性 跨平台性是Java主要的特性之一，跨平台使得使用用Java语言编写的程序可以在编译后不用经过任何更改，就能在任何硬件设备条件下运行。这个特性经常被称为“一次编译，到处运行”。 执行Java应用程序必须安装Java 运行时环境（Java Runtime Environment，JRE），JRE包括Java虚拟机（Java Virtual Machine，JVM），以及Java平台核心类和基础Java 平台库。通过JVM才能在电脑系统执行Java应用程序（Java Application），这与.Net Framework的情况一样，所以电脑上没有安装JVM，那么这些java程序将不能够执行。 实现跨平台性的方法是大多数编译器在进行Java语言程序的编码时候会生成一个用字节码写成的“半成品”，这个“半成品”会在Java虚拟机（解释层）的帮助下运行，虚拟机会把它转换成当前所处硬件平台的原始代码。之后，Java虚拟机会打开标准库，进行数据（图片、线程和网络）的访问工作。主要注意的是，尽管已经存在一个进行代码翻译的解释层，有些时候Java的字节码代码还是会被JIT编译器进行二次编译。 有些编译器，比如GCJ，可以自动生成原始代码而不需要解释层。但是这些编译器所生成的代码只能应用于特定平台。并且GCJ当前只支持部分的Java API。 甲骨文公司对于Java的许可是“全兼容的”，这也导致了微软和升阳关于微软的程序不支持RMI和JNI接口、并且增加特性为己所用的法律争端。升阳最终赢得了官司，获得了大约两千万美元的赔偿，法院强制要求微软执行升阳公司关于Java的许可要求。作为回应，微软不再在Windows系统中捆绑Java，最新的Windows版本，Windows Vista和Internet Explorer 7.0版本也不再提供对于Java应用程序和控件的支持。但是升阳公司和其他使用Java运行时系统的公司在Windows操作系统下对用户提供无偿的第三方插件和程序支持。 Java语言使用解释层最初是为了轻巧性。所以这些程序的运行效率比C语言和C++要低很多，用户也对此颇有微词。很多最近的调查显示Java的程序运行速度比几年前要高出许多，有些同样功能的程序的效率甚至超过了C++和C语言编写的程序。 Java语言在最开始应用的时候是没有解释层的，所有需要编译的代码都直接转换成机器的原始代码。这样做虽然使程序获得了最佳的性能，但是导致程序异常臃肿。从JIT技术开始，Java的程序都经过一次转换之后才变成机器码。很多老牌的第三方虚拟机都使用一种叫做“动态编译”的技术，也就是说虚拟机实时监测和分析程序的运行行为，同时选择性地对程序所需要的部分进行编译和优化。所有这些技术都改善了代码的运行速度，但是又不会让程序的体积变得失常。 程序的轻便性事实上是软件编写很难达到的一个目标，Java虽然成功地实现了“一次编译，到处运行”，但是由于平台和平台之间的差异，所编写的程序在转换代码的时候难免会出现微小的、不可察觉的错误和意外。有些程序员对此非常头疼，他们嘲笑Java的程序不是“一次编译，到处运行”，而是“一次编译，到处调试”。以Java AWT为例，早期Java AWT内提供的按钮、文字区等均是以计算机系统所默认的样式而显示。这令Java程序在有些没有提供图案的计算机系统产生错误（在Microsoft Windows设有窗口管理器，在一些Linux distribution则没有）。后来SUN公司针对Java AWT一些问题而推出Java Swing。 平台无关性让Java在服务器端软件领域非常成功。很多服务器端软件都使用Java或相关技术创建。 自动垃圾回收（Garbage Collection） C++语言被用户诟病的原因之一是大多数C++编译器不支持垃圾收集机制。通常使用C++编程的时候，程序员于程序中初始化对象时，会在主机存储器堆栈上分配一块存储器与地址，当不需要此对象时，进行析构或者删除的时候再释放分配的存储器地址。如果对象是在堆栈上分配的，而程序员又忘记进行删除，那么就会造成存储器泄漏（Memory Leak）。长此以往，程序运行的时候可能会生成很多不清除的垃圾，浪费了不必要的存储器空间。而且如果同一存储器地址被删除两次的话，程序会变得不稳定，甚至崩溃。因此有经验的C++程序员都会在删除之后将指针重置为NULL，然后在删除之前先判断指针是否为NULL。 C++中也可以使用“智能指针”（Smart Pointer）或者使用C++托管扩展编译器的方法来实现自动化存储器释放，智能指针可以在标准类库中找到，而C++托管扩展被微软的Visual C++ 7.0及以上版本所支持。智能指针的优点是不需引入缓慢的垃圾收集机制，而且可以不考虑线程安全的问题，但是缺点是如果不善使用智能指针的话，性能有可能不如垃圾收集机制，而且不断地分配和释放存储器可能造成存储器碎片，需要手动对堆进行压缩。除此之外，由于智能指针是一个基于模板的功能，所以没有经验的程序员在需要使用多态特性进行自动清理时也可能束手无策。 Java语言则不同，上述的情况被自动垃圾收集功能自动处理。对象的创建和放置都是在存储器堆栈上面进行的。当一个对象没有任何引用的时候，Java的自动垃圾收集机制就发挥作用，自动删除这个对象所占用的空间，释放存储器以避免存储器泄漏。 注意程序员不需要修改finalize方法，自动垃圾收集也会发生作用。但是存储器泄漏并不是就此避免了，当程序员疏忽大意地忘记解除一个对象不应该有的引用时，存储器泄漏仍然不可避免。 不同厂商、不同版本的JVM中的存储器垃圾回收机制并不完全一样，通常越新版本的存储器回收机制越快，IBM、BEA、SUN等等开发JVM的公司都曾宣称过自己制造出了世界上最快的JVM，JVM性能的世界纪录也在不断的被打破并提高。 IBM有一篇有关Java存储器回收机制比不激活垃圾收集机制的C++存储器处理快数倍的技术文章，而著名的Java技术书籍《Java编程思想》（Thinking in Java）也有一段论述Java存储器及性能达到甚至超过C++的章节。 基本语法 编写Java程序前应注意以下几点： 大小写敏感：Java是大小写敏感的，这就意味着标识符Hello与hello是不同的。 类名：对于所有的类来说，类名的首字母应该大写。如果类名由若干单词组成，那么每个单词的首字母应该大写，例如MyFirstJavaClass。 方法名：所有的方法名都应该以小写字母开头。如果方法名含有若干单词，则后面的每个单词首字母大写，例如myFirstJavaMethod。 源文件名：源文件名必须和类名相同。当保存文件的时候，你应该使用类名作为文件名保存（切记Java是大小写敏感的），文件名的后缀为.java。（如果文件名和类名不相同则会导致编译错误）。 主方法入口：所有的Java程序由public static void main(String[] args)方法开始执行。 Java关键字 下面列出了Java关键字。这些关键字不能用于常量、变量、和任何标识符的名称。 |类别| 关键字 |说明| |----|---------|-----| |访问控制| private |私有的| ||protected| 受保护的| ||public| 公共的| |类、方法和变量修饰符| abstract |声明抽象| ||class| 类| ||extends| 扩允,继承| ||final| 最终值,不可改变的| ||implements| 实现（接口）| ||interface| 接口| ||native| 本地，原生方法（非Java实现）| ||new| 新,创建| ||static| 静态| ||strictfp| 严格,精准| ||synchronized| 线程,同步| ||transient| 短暂| ||volatile| 易失| |程序控制语句| break |跳出循环| ||case| 定义一个值以供switch选择| ||continue| 继续| ||default| 默认| ||do| 运行| ||else| 否则| ||for| 循环| ||if| 如果| ||instanceof| 实例| ||return| 返回| ||switch| 根据值选择执行| ||while| 循环| |错误处理| assert |断言表达式是否为真| ||catch| 捕捉异常| ||finally| 有没有异常都执行| ||throw| 抛出一个异常对象| ||throws| 声明一个异常可能被抛出| ||try| 捕获异常| |包相关| import |引入| ||package| 包| |基本类型| boolean| 布尔型| ||byte| 字节型| ||char| 字符型| ||double| 双精度浮点| ||float| 单精度浮点| ||int| 整型| ||long| 长整型| ||short| 短整型| ||null| 空| |变量引用| super |父类,超类| ||this| 本类| ||void| 无返回值| |保留关键字| goto |是关键字，但不能使用| ||const| 是关键字，但不能使用| 注释 注释的作用：标识程序是干什么的，以及它是如何构建的。注释帮助程序员进行相互沟通以及理解程序。注释不是程序设计语言，所以编译器编译程序时忽略它们。 关于Java的批评 Java试图通过新的方式解决软件编写的复杂性。很多人认为Java语言做到了它承诺的一切。但是Java并不是一门完美的语言。 整体性问题 并不是所有的工程和环境需要企业等级的复杂性，比如一个简单的个人网站或者独自编程的程序师所写的程序。这些程序师会发现Java的复杂管理对于自己要做的程序来说过于强大了。一些人觉得Java在面向对象上面做的没有Ruby和Smalltalk纯粹。但是最新出现的用Java实现的语言Groovy解决了这些问题。 作为一种已经创建的新技术，Java显然综合了很多语言的特性，比如C++、C语言、Python等等。一些对于Java的评论认为Java的不变性在动摇。 语言问题 有些程序师不喜欢原始类型（primitive type）和类别（class）的分离，尤其是那些曾经使用过Smalltalk和Ruby的程序员。Java的代码相对于其他的代码来说过于冗长，这与它的轻便化声明相违背。 Java是一种单继承的语言。这也导致了程序师在试图使用多重继承时候的不便，而很多语言都可以使用这个特性。但是Java可以使用接口类，把多重继承可能导致的风险减少到最小。Java不支持运算符重载，这是为了防止运算符重载使得代码的功能变得不清晰。但是用Java实现的语言Groovy可以进行运算符重载。过去Java对于文本的操作和其他语言，比如Perl和PHP相比差的较多，但Java在1.4版本时候引入了正则表达式。 至Java 1.7为止，Java语言不支持闭包（closure）和混入（mixin）特性。 Java 1.8加入lambda表达式（Lambda Expressions）。 类库问题 使用Swing平台编写的带有GUI（图形用户界面）的程序和其他原始程序非常不同。选用AWT工具包编写程序的程序师看到的都是原始接口，而且也无法获得先进的GUI编程支持，如果使用的话，就要提供每个平台上面所需的API，这将是一项庞大的工程。Swing则是完全用Java语言所写的程序，避免了接口元素重复的问题，只使用所有平台都支持的最基本的绘图机制。但是很多用户不知道如何在Java风格和Windows风格之间进行转换，结果造成了Java程序的接口在很多程序中非常特殊。苹果计算机已经提供了优化过的Java运行时程序，包含了Mac OS X的经典Aqua接口风格。 在IBM捐赠给Eclipse基金会的SWT界面框架中，用户会看到熟悉的本地风格界面。但这又引起了不同喜好的开发人员之间的争论。 性能问题 由于Java编译器和虚拟机的不同对Java代码的性能影响比语言本身的影响大的多，所以统一讨论Java的程序的性能经常是有误导性的。据IBM的数据，在同样的硬件上2001年时的IBM JDK版本的性能是1996年的JDK版本的十倍左右。而即使是在同一时期，不同公司的JDK和JRE的性能也不一样，比如SUN、IBM、BEA等公司都有自己开发的JDK和JRE。 Java语言的一些特性不可避免的有额外的性能代价，例如数组范围检查、运行时类型检查等等。Java程序的性能还会因为不同的动态复杂性和垃圾处理机制使用的多少而各有不同。如果JVM的实现比较优化的话，那么这些功能甚至可以增加存储器分配的性能。这和总是使用STL或者托管C++的程序的情况类似。 尽管如此，仍然有许多人认为Java的性能低。这部分归因于Sun公司最初的JVM实现使用未优化的解释机制来运行字节码。一些新版本的JVM使用Just-In-Time（JIT）编译器，在加载字节码的时候将其编译成针对运行环境的本地代码来实现一些本地编译器的优化特性。Just-In-Time机制和本地编译的性能比较仍旧是一个有争议的话题。JIT编译需要很多时间，对于运行时间不长或者代码很多的大型程序并不适宜。但是不算JIT编译阶段的话，程序的运行性能在很多JVM下可以和本地编译的程序一争短长，甚至在一些计算比较密集的数值计算领域也是这样。当前，Java已经使用更先进的HotSpot技术来代替JIT技术，Java的性能有了更进一步的提升。另外，在使用-server选项运行Java程序时，也可以对Java进行更深入的优化，比如在运行时将调用较多的方法内联（inline）到程序中来提高运行速度，这就是所谓的“动态优化”，而本地编译器是无法做到这一点的；这也是一些Java代码比对应用C/C++等语言编写的本地代码运行的更快的原因之一。微软的.NET平台也使用JIT编译器，所以也有类似问题。 Java的设计目的主要是安全性和可携性，所以对于一些特性，比如对硬件架构和存储器地址访问的直接访问都被去除了。如果需要间接调用这些底层功能的话，就需要使用JNI（Java本地接口）来调用本地代码，而间接访问意味着频繁调用这些特性时性能损失会很大，微软的.NET平台也有这样的问题。所以到当前为止，性能敏感的代码，例如驱动程序和3D电子游戏，还是大多使用本地编译，甚至直接以不直接支持面向对象的C语言或机器代码编写。但最近已经有了许多用纯Java编写的3D游戏，其效果与用C语言编写的不相上下，例如“合金战士”（英文名：Chrome）。这主要是因为新版的Java 3D技术已经能像C++一样调用硬件加速，也就是使用显卡来加速，无论是C++还是Java语言写的3D游戏都是使用显卡及GPU来处理，从而使得CPU可以专注于其他方面的工作。 "},"语言/Java/Java中hashcode相等两个类一定相等吗.html":{"url":"语言/Java/Java中hashcode相等两个类一定相等吗.html","title":"Java中hashcode相等两个类一定相等吗","keywords":"","body":"Java中hashcode相等两个类一定相等吗 默认equals是比较地址，hashCode返回一个int的哈希码，equals判定为相同的，hashCode一定相同。equals判定为不同的，hashCode不一定不同，有可能相同。 \"柳柴\"与\"柴柕\" hashCode=851553 \"志捘\"与\"崇몈\" hashCode=786017 java中String.hashCode()方法的算法如下： str.charAt(0) * 31n-1 + str.charAt(1) * 31n-2 + ... + str.charAt(n-1) public class Test{ public static void main(String [] args){ List list=new ArrayList(); list.add(\"a\"); list.add(\"b\"); list.add(\"a\"); Set set=new HashSet(); set.add(\"a\"); set.add(\"b\"); set.add(\"a\"); System.out.println(list.size()+\",\"+set.size()); } } 输出结果：3，2 道理很简单， ArrayList可以是插重复的内容， 而Set不可以插重复的内容(String重写了equals与hashCode方法)。 hashCode是所有java对象的固有方法，如果不重载的话，返回的实际上是该对象在jvm的堆上的内存地址，而不同对象的内存地址肯定不同，所以这个hashCode也就肯定不同了。如果重载了的话，由于采用的算法的问题，有可能导致两个不同对象的hashCode相同。 而且，还需要注意一下两点： 1）hashCode和equals两个方法是有语义关联的，它们需要满足： A.equals(B)==true --> A.hashCode()==B.hashCode() 因此重载其中一个方法时也需要将另一个也重载。 2）hashCode的重载实现需要满足不变性，即一个object的hashCode不能前一会是1，过一会就变成2了。hashCode的重载实现最好依赖于对象中的final属性，从而在对象初始化构造后就不再变化。一方面是jvm便于代码优化，可以缓存这个hashCode；另一方面，在使用hashMap或hashSet的场景中，如果使用的key的hashCode会变化，将会导致bug，比如放进去时key.hashCode()=1，等到要取出来时key.hashCode()=2了，就会取不出来原先的数据。这个可以写一个简单的代码自己验证一下。 1.两个对象equals相等那么hashcode 是一定相等的。 2.两个对象equals不相等hashcode可能相等可以不相等。 因为hashCode说白了是地址值经过一系列的复杂运算得到的结果，而Object中的equals方法底层比较的就是地址值，所以equals()相等，hashCode必定相等，反equals()不等，在java底层进行哈希运算的时候有一定的几率出现相等的hashCode,所以hashCode（）可等可不等。 "},"语言/Java/Java之voliate,synchronized,AtomicInteger使用.html":{"url":"语言/Java/Java之voliate,synchronized,AtomicInteger使用.html","title":"Java之voliate,synchronized,AtomicInteger使用","keywords":"","body":"Java之voliate,synchronized,AtomicInteger使用 1.voliate 用在多线程，同步变量。 线程为了提高效率，将成员变量(如A)某拷贝了一份（如B），线程中对A的访问其实访问的是B。只在某些动作时才进行A和B的同步。因此存在A和B不一致的情况。volatile就是用来避免这种情况的。volatile告诉jvm， 它所修饰的变量不保留拷贝，直接访问主内存中的（也就是上面说的A) ，但是不能用其来进行多线程同步控制 public class Counter { public volatile static int count = 0; public static void inc() { //这里延迟5毫秒，使得结果明显 try { Thread.sleep(5); } catch (InterruptedException e) { } //synchronized(Counter.class) { count ++; //} } public static void main(String[] args) throws InterruptedException { final CountDownLatch latch = new CountDownLatch(1000); //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i 可以看到，运行结果:Counter.count=929（数字随机），但如果将注释掉的同步块synchronized打开，console输出则为1000 2.synchronized 它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。 一、当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。 二、然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。 三、尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞。 四、第三个例子同样适用其它同步代码块。也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其它线程对该object对象所有同步代码部分的访问都被暂时阻塞。 五、以上规则对其它对象锁同样适用.3.AtomicInteger 使用AtomicInteger，即使不用同步块synchronized，最后的结果也是1000，可用看出AtomicInteger的作用，用原子方式更新的int值。主要用于在高并发环境下的高效程序处理。使用非阻塞算法来实现并发控制。public class Counter { public static AtomicInteger count = new AtomicInteger(0); public static void inc() { //这里延迟1毫秒，使得结果明显 try { Thread.sleep(1); } catch (InterruptedException e) { } count.getAndIncrement(); } public static void main(String[] args) throws InterruptedException { final CountDownLatch latch = new CountDownLatch(1000); //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i "},"语言/Java/Java内存溢出OOM异常完全指南.html":{"url":"语言/Java/Java内存溢出OOM异常完全指南.html","title":"Java内存溢出OOM异常完全指南","keywords":"","body":"Java内存溢出OOM异常完全指南 1、java.lang.OutOfMemoryError:Java heap space Java应用程序在启动时会指定所需要的内存大小，它被分割成两个不同的区域：Heap space（堆空间）和Permgen（永久代）： 这两个区域的大小可以在JVM（Java虚拟机）启动时通过参数-Xmx和-XX:MaxPermSize设置，如果你没有显式设置，则将使用特定平台的默认值。 当应用程序试图向堆空间添加更多的数据，但堆却没有足够的空间来容纳这些数据时，将会触发java.lang.OutOfMemoryError: Java heap space异常。需要注意的是：即使有足够的物理内存可用，只要达到堆空间设置的大小限制，此异常仍然会被触发。 原因分析 触发java.lang.OutOfMemoryError: Java heap space最常见的原因就是应用程序需要的堆空间是XXL号的，但是JVM提供的却是S号。解决方法也很简单，提供更大的堆空间即可。除了前面的因素还有更复杂的成因： 流量/数据量峰值：应用程序在设计之初均有用户量和数据量的限制，某一时刻，当用户数量或数据量突然达到一个峰值，并且这个峰值已经超过了设计之初预期的阈值，那么以前正常的功能将会停止，并触发java.lang.OutOfMemoryError: Java heap space异常。 内存泄漏：特定的编程错误会导致你的应用程序不停的消耗更多的内存，每次使用有内存泄漏风险的功能就会留下一些不能被回收的对象到堆空间中，随着时间的推移，泄漏的对象会消耗所有的堆空间，最终触发java.lang.OutOfMemoryError: Java heap space错误。 示例 ①、简单示例 首先看一个非常简单的示例，下面的代码试图创建2 x 1024 x 1024个元素的整型数组，当你尝试编译并指定12M堆空间运行时（java -Xmx12m OOM）将会失败并抛出java.lang.OutOfMemoryError: Java heap space错误，而当你指定13M堆空间时，将正常的运行。 class OOM { static final int SIZE=2*1024*1024; public static void main(String[] a) { int[] i = new int[SIZE]; } } 运行如下： D:\\>javac OOM.java D:\\>java -Xmx12m OOM Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at OOM.main(OOM.java:4) D:\\>java -Xmx13m OOM ②、内存泄漏示例 在Java中，当开发者创建一个新对象（比如：new Integer(5)）时，不需要自己开辟内存空间，而是把它交给JVM。在应用程序整个生命周期类，JVM负责检查哪些对象可用，哪些对象未被使用。未使用对象将被丢弃，其占用的内存也将被回收，这一过程被称为垃圾回收。JVM负责垃圾回收的模块集合被称为垃圾回收器（GC）。 Java的内存自动管理机制依赖于GC定期查找未使用对象并删除它们。Java中的内存泄漏是由于GC无法识别一些已经不再使用的对象，而这些未使用的对象一直留在堆空间中，这种堆积最终会导致java.lang.OutOfMemoryError: Java heap space错误。 我们可以非常容易的写出导致内存泄漏的Java代码： public class KeylessEntry { static class Key { Integer id; Key(Integer id) { this.id = id; } @Override public int hashCode() { return id.hashCode(); } } public static void main(String[] args) { Map m = new HashMap(); while(true) { for(int i=0;i代码中HashMap为本地缓存，第一次while循环，会将10000个元素添加到缓存中。后面的while循环中，由于key已经存在于缓存中，缓存的大小将一直会维持在10000。但事实真的如此吗？由于Key实体没有实现equals()方法，导致for循环中每次执行m.containsKey(new Key(i))结果均为false，其结果就是HashMap中的元素将一直增加。 随着时间的推移，越来越多的Key对象进入堆空间且不能被垃圾收集器回收（m为局部变量，GC会认为这些对象一直可用，所以不会回收），直到所有的堆空间被占用，最后抛出java.lang.OutOfMemoryError:Java heap space。 上面的代码直接运行可能很久也不会抛出异常，可以在启动时使用-Xmx参数，设置堆内存大小，或者在for循环后打印HashMap的大小，执行后会发现HashMap的size一直再增长。 解决方法也非常简单，只要Key实现自己的equals方法即可： Override public boolean equals(Object o) { boolean response = false; if (o instanceof Key) { response = (((Key)o).id).equals(this.id); } return response; } 解决方案 第一个解决方案是显而易见的，你应该确保有足够的堆空间来正常运行你的应用程序，在JVM的启动配置中增加如下配置： -Xmx1024m 上面的配置分配1024M堆空间给你的应用程序，当然你也可以使用其他单位，比如用G表示GB，K表示KB。下面的示例都表示最大堆空间为1GB： java -Xmx1073741824 com.mycompany.MyClass java -Xmx1048576k com.mycompany.MyClass java -Xmx1024m com.mycompany.MyClass java -Xmx1g com.mycompany.MyClass 然后，更多的时候，单纯地增加堆空间不能解决所有的问题。如果你的程序存在内存泄漏，一味的增加堆空间也只是推迟java.lang.OutOfMemoryError: Java heap space错误出现的时间而已，并未解决这个隐患。除此之外，垃圾收集器在GC时，应用程序会停止运行直到GC完成，而增加堆空间也会导致GC时间延长，进而影响程序的吞吐量。 如果你想完全解决这个问题，那就好好提升自己的编程技能吧，当然运用好Debuggers, profilers, heap dump analyzers等工具，可以让你的程序最大程度的避免内存泄漏问题。 2、java.lang.OutOfMemoryError:GC overhead limit exceeded Java运行时环境（JRE）包含一个内置的垃圾回收进程，而在许多其他的编程语言中，开发者需要手动分配和释放内存。 Java应用程序只需要开发者分配内存，每当在内存中特定的空间不再使用时，一个单独的垃圾收集进程会清空这些内存空间。垃圾收集器怎样检测内存中的某些空间不再使用已经超出本文的范围，但你只需要相信GC可以做好这些工作即可。 默认情况下，当应用程序花费超过98%的时间用来做GC并且回收了不到2%的堆内存时，会抛出java.lang.OutOfMemoryError:GC overhead limit exceeded错误。具体的表现就是你的应用几乎耗尽所有可用内存，并且GC多次均未能清理干净。 原因分析 java.lang.OutOfMemoryError:GC overhead limit exceeded错误是一个信号，示意你的应用程序在垃圾收集上花费了太多时间但却没有什么卵用。默认超过98%的时间用来做GC却回收了不到2%的内存时将会抛出此错误。那如果没有此限制会发生什么呢？GC进程将被重启，100%的CPU将用于GC，而没有CPU资源用于其他正常的工作。如果一个工作本来只需要几毫秒即可完成，现在却需要几分钟才能完成，我想这种结果谁都没有办法接受。 所以java.lang.OutOfMemoryError:GC overhead limit exceeded也可以看做是一个fail-fast（快速失败）实战的实例。 示例 下面的代码初始化一个map并在无限循环中不停的添加键值对，运行后将会抛出GC overhead limit exceeded错误： public class Wrapper { public static void main(String args[]) throws Exception { Map map = System.getProperties(); Random r = new Random(); while (true) { map.put(r.nextInt(), \"value\"); } } } 正如你所预料的那样，程序不能正常的结束，事实上，当我们使用如下参数启动程序时： java -Xmx100m -XX:+UseParallelGC Wrapper 我们很快就可以看到程序抛出java.lang.OutOfMemoryError: GC overhead limit exceeded错误。但如果在启动时设置不同的堆空间大小或者使用不同的GC算法，比如这样： java -Xmx10m -XX:+UseParallelGC Wrapper 我们将看到如下错误： Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Hashtable.rehash(Unknown Source) at java.util.Hashtable.addEntry(Unknown Source) at java.util.Hashtable.put(Unknown Source) at cn.moondev.Wrapper.main(Wrapper.java:12) 使用以下GC算法：-XX:+UseConcMarkSweepGC或者-XX:+UseG1GC，启动命令如下： java -Xmx100m -XX:+UseConcMarkSweepGC Wrapper java -Xmx100m -XX:+UseG1GC Wrapper 得到的结果是这样的： Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\" 错误已经被默认的异常处理程序捕获，并且没有任何错误的堆栈信息输出。 以上这些变化可以说明，在资源有限的情况下，你根本无法无法预测你的应用是怎样挂掉的，什么时候会挂掉，所以在开发时，你不能仅仅保证自己的应用程序在特定的环境下正常运行。 解决方案 首先是一个毫无诚意的解决方案，如果你仅仅是不想看到java.lang.OutOfMemoryError:GC overhead limit exceeded的错误信息，可以在应用程序启动时添加如下JVM参数： -XX:-UseGCOverheadLimit 但是强烈建议不要使用这个选项，因为这样并没有解决任何问题，只是推迟了错误出现的时间，错误信息也变成了我们更熟悉的java.lang.OutOfMemoryError: Java heap space而已。 另一个解决方案，如果你的应用程序确实内存不足，增加堆内存会解决GC overhead limit问题，就如下面这样，给你的应用程序1G的堆内存： java -Xmx1024m com.yourcompany.YourClass 但如果你想确保你已经解决了潜在的问题，而不是掩盖java.lang.OutOfMemoryError: GC overhead limit exceeded错误，那么你不应该仅止步于此。你要记得还有profilers和memory dump analyzers这些工具，你需要花费更多的时间和精力来查找问题。还有一点需要注意，这些工具在Java运行时有显著的开销，因此不建议在生产环境中使用。 3、java.lang.OutOfMemoryError:Permgen space Java中堆空间是JVM管理的最大一块内存空间，可以在JVM启动时指定堆空间的大小，其中堆被划分成两个不同的区域：新生代（Young）和老年代（Tenured），新生代又被划分为3个区域：Eden、From Survivor、To Survivor，如下图所示。 java.lang.OutOfMemoryError: PermGen space错误就表明持久代所在区域的内存已被耗尽。 原因分析 要理解java.lang.OutOfMemoryError: PermGen space出现的原因，首先需要理解Permanent Generation Space的用处是什么。持久代主要存储的是每个类的信息，比如：类加载器引用、运行时常量池（所有常量、字段引用、方法引用、属性）、字段(Field)数据、方法(Method)数据、方法代码、方法字节码等等。我们可以推断出，PermGen的大小取决于被加载类的数量以及类的大小。 因此，我们可以得出出现java.lang.OutOfMemoryError: PermGen space错误的原因是：太多的类或者太大的类被加载到permanent generation（持久代）。 示例 ①、最简单的示例 正如前面所描述的，PermGen的使用与加载到JVM类的数量有密切关系，下面是一个最简单的示例： import javassist.ClassPool; public class MicroGenerator { public static void main(String[] args) throws Exception { for (int i = 0; i 运行时请设置JVM参数：-XX:MaxPermSize=5m，值越小越好。需要注意的是JDK8已经完全移除持久代空间，取而代之的是元空间（Metaspace），所以示例最好的JDK1.7或者1.6下运行。 代码在运行时不停的生成类并加载到持久代中，直到撑满持久代内存空间，最后抛出java.lang.OutOfMemoryError:Permgen space。代码中类的生成使用了javassist库。 ②、Redeploy-time 更复杂和实际的一个例子就是Redeploy（重新部署，你可以想象一下你开发时，点击eclipse的reploy按钮或者使用idea时按ctrl + F5时的过程）。在从服务器卸载应用程序时，当前的classloader以及加载的class在没有实例引用的情况下，持久代的内存空间会被GC清理并回收。如果应用中有类的实例对当前的classloader的引用，那么Permgen区的class将无法被卸载，导致Permgen区的内存一直增加直到出现Permgen space错误。 不幸的是，许多第三方库以及糟糕的资源处理方式（比如：线程、JDBC驱动程序、文件系统句柄）使得卸载以前使用的类加载器变成了一件不可能的事。反过来就意味着在每次重新部署过程中，应用程序所有的类的先前版本将仍然驻留在Permgen区中，你的每次部署都将生成几十甚至几百M的垃圾。 就以线程和JDBC驱动来说说。很多人都会使用线程来处理一下周期性或者耗时较长的任务，这个时候一定要注意线程的生命周期问题，你需要确保线程不能比你的应用程序活得还长。否则，如果应用程序已经被卸载，线程还在继续运行，这个线程通常会维持对应用程序的classloader的引用，造成的结果就不再多说。多说一句，开发者有责任处理好这个问题，特别是如果你是第三方库的提供者的话，一定要提供线程关闭接口来处理清理工作。 让我们想象一个使用JDBC驱动程序连接到关系数据库的示例应用程序。当应用程序部署到服务器上的时：服务器创建一个classloader实例来加载应用所有的类（包含相应的JDBC驱动）。根据JDBC规范，JDBC驱动程序（比如：com.mysql.jdbc.Driver）会在初始化时将自己注册到java.sql.DriverManager中。该注册过程中会将驱动程序的一个实例存储在DriverManager的静态字段内，代码可以参考： // com.mysql.jdbc.Driver源码 package com.mysql.jdbc; public class Driver extends NonRegisteringDriver implements java.sql.Driver { public Driver() throws SQLException { } static { try { DriverManager.registerDriver(new Driver()); } catch (SQLException var1) { throw new RuntimeException(\"Can\\'t register driver!\"); } } } // // // // // // // // // // // 再看下DriverManager对应代码 private final static CopyOnWriteArrayList registeredDrivers = new CopyOnWriteArrayList<>(); public static synchronized void registerDriver(java.sql.Driver driver,DriverAction da) throws SQLException { if(driver != null) { registeredDrivers.addIfAbsent(new DriverInfo(driver, da)); } else { throw new NullPointerException(); } } 现在，当从服务器上卸载应用程序的时候，java.sql.DriverManager仍将持有那个驱动程序的引用，进而持有用于加载应用程序的classloader的一个实例的引用。这个classloader现在仍然引用着应用程序的所有类。如果此程序启动时需要加载2000个类，占用约10MB永久代（PermGen）内存，那么只需要5~10次重新部署，就会将默认大小的永久代（PermGen）塞满，然后就会触发java.lang.OutOfMemoryError: PermGen space错误并崩溃。 解决方案 ① 解决初始化时的OutOfMemoryError 当在应用程序启动期间触发由于PermGen耗尽引起的OutOfMemoryError时，解决方案很简单。 应用程序需要更多的空间来加载所有的类到PermGen区域，所以我们只需要增加它的大小。 为此，请更改应用程序启动配置，并添加（或增加，如果存在）-XX：MaxPermSize参数，类似于以下示例： java -XX:MaxPermSize=512m com.yourcompany.YourClass ② 解决Redeploy时的OutOfMemoryError 分析dump文件：首先，找出引用在哪里被持有；其次，给你的web应用程序添加一个关闭的hook，或者在应用程序卸载后移除引用。你可以使用如下命令导出dump文件： jmap -dump:format=b,file=dump.hprof 如果是你自己代码的问题请及时修改，如果是第三方库，请试着搜索一下是否存在\"关闭\"接口，如果没有给开发者提交一个bug或者issue吧。 ③ 解决运行时OutOfMemoryError 首先你需要检查是否允许GC从PermGen卸载类，JVM的标准配置相当保守，只要类一创建，即使已经没有实例引用它们，其仍将保留在内存中，特别是当应用程序需要动态创建大量的类但其生命周期并不长时，允许JVM卸载类对应用大有助益，你可以通过在启动脚本中添加以下配置参数来实现： -XX:+CMSClassUnloadingEnabled 默认情况下，这个配置是未启用的，如果你启用它，GC将扫描PermGen区并清理已经不再使用的类。但请注意，这个配置只在UseConcMarkSweepGC的情况下生效，如果你使用其他GC算法，比如：ParallelGC或者Serial GC时，这个配置无效。所以使用以上配置时，请配合： -XX:+UseConcMarkSweepGC 如果你已经确保JVM可以卸载类，但是仍然出现内存溢出问题，那么你应该继续分析dump文件，使用以下命令生成dump文件： jmap -dump:file=dump.hprof,format=b 当你拿到生成的堆转储文件，并利用像Eclipse Memory Analyzer Toolkit这样的工具来寻找应该卸载却没被卸载的类加载器，然后对该类加载器加载的类进行排查，找到可疑对象，分析使用或者生成这些类的代码，查找产生问题的根源并解决它。 4、java.lang.OutOfMemoryError:Metaspace 前文已经提过，PermGen区域用于存储类的名称和字段，类的方法，方法的字节码，常量池，JIT优化等，但从Java8开始，Java中的内存模型发生了重大变化：引入了称为Metaspace的新内存区域，而删除了PermGen区域。请注意：不是简单的将PermGen区所存储的内容直接移到Metaspace区，PermGen区中的某些部分，已经移动到了普通堆里面。 OOM-example-metaspace 原因分析 Java8做出如此改变的原因包括但不限于： 应用程序所需要的PermGen区大小很难预测，设置太小会触发PermGen OutOfMemoryError错误，过度设置导致资源浪费。 提升GC性能，在HotSpot中的每个垃圾收集器需要专门的代码来处理存储在PermGen中的类的元数据信息。从PermGen分离类的元数据信息到Metaspace，由于Metaspace的分配具有和Java Heap相同的地址空间，因此Metaspace和Java Heap可以无缝的管理，而且简化了FullGC的过程，以至将来可以并行的对元数据信息进行垃圾收集，而没有GC暂停。 支持进一步优化，比如：G1并发类的卸载，也算为将来做准备吧 正如你所看到的，元空间大小的要求取决于加载的类的数量以及这种类声明的大小。 所以很容易看到java.lang.OutOfMemoryError: Metaspace主要原因：太多的类或太大的类加载到元空间。 示例 正如上文中所解释的，元空间的使用与加载到JVM中的类的数量密切相关。 下面的代码是最简单的例子： public class Metaspace { static javassist.ClassPool cp = javassist.ClassPool.getDefault(); public static void main(String[] args) throws Exception{ for (int i = 0; ; i++) { Class c = cp.makeClass(\"eu.plumbr.demo.Generated\" + i).toClass(); System.out.println(i); } } } 程序运行中不停的生成新类，所有的这些类的定义将被加载到Metaspace区，直到空间被完全占用并且抛出java.lang.OutOfMemoryError:Metaspace。当使用-XX：MaxMetaspaceSize = 32m启动时，大约加载30000多个类时就会死机。 31023 31024 Exception in thread \"main\" javassist.CannotCompileException: by java.lang.OutOfMemoryError: Metaspace at javassist.ClassPool.toClass(ClassPool.java:1170) at javassist.ClassPool.toClass(ClassPool.java:1113) at javassist.ClassPool.toClass(ClassPool.java:1071) at javassist.CtClass.toClass(CtClass.java:1275) at cn.moondev.book.Metaspace.main(Metaspace.java:12) ..... 解决方案 第一个解决方案是显而易见的，既然应用程序会耗尽内存中的Metaspace区空间，那么应该增加其大小，更改启动配置增加如下参数： // 告诉JVM：Metaspace允许增长到512，然后才能抛出异常 -XX：MaxMetaspaceSize = 512m 另一个方法就是删除此参数来完全解除对Metaspace大小的限制（默认是没有限制的）。默认情况下，对于64位服务器端JVM，MetaspaceSize默认大小是21M（初始限制值），一旦达到这个限制值，FullGC将被触发进行类卸载，并且这个限制值将会被重置，新的限制值依赖于Metaspace的剩余容量。如果没有足够空间被释放，这个限制值将会上升，反之亦然。在技术上Metaspace的尺寸可以增长到交换空间，而这个时候本地内存分配将会失败（更具体的分析，可以参考：Java PermGen 去哪里了?）。 你可以通过修改各种启动参数来“快速修复”这些内存溢出错误，但你需要正确区分你是否只是推迟或者隐藏了java.lang.OutOfMemoryError的症状。如果你的应用程序确实存在内存泄漏或者本来就加载了一些不合理的类，那么所有这些配置都只是推迟问题出现的时间而已，实际也不会改善任何东西。 5、java.lang.OutOfMemoryError:Unable to create new native thread 一个思考线程的方法是将线程看着是执行任务的工人，如果你只有一个工人，那么他同时只能执行一项任务，但如果你有十几个工人，就可以同时完成你几个任务。就像这些工人都在物理世界，JVM中的线程完成自己的工作也是需要一些空间的，当有足够多的线程却没有那么多的空间时就会像这样： 出现java.lang.OutOfMemoryError:Unable to create new native thread就意味着Java应用程序已达到其可以启动线程数量的极限了。 原因分析 当JVM向OS请求创建一个新线程时，而OS却无法创建新的native线程时就会抛出Unable to create new native thread错误。一台服务器可以创建的线程数依赖于物理配置和平台，建议运行下文中的示例代码来测试找出这些限制。总体上来说，抛出此错误会经过以下几个阶段： 运行在JVM内的应用程序请求创建一个新的线程 JVM向OS请求创建一个新的native线程 OS尝试创建一个新的native线程，这时需要分配内存给新的线程 OS拒绝分配内存给线程，因为32位Java进程已经耗尽内存地址空间（2-4GB内存地址已被命中）或者OS的虚拟内存已经完全耗尽 Unable to create new native thread错误将被抛出示例 下面的示例不能的创建并启动新的线程。当代码运行时，很快达到OS的线程数限制，并抛出Unable to create new native thread错误。 while(true){ new Thread(new Runnable(){ public void run() { try { Thread.sleep(10000000); } catch(InterruptedException e) { } } }).start(); } 解决方案 有时，你可以通过在OS级别增加线程数限制来绕过这个错误。如果你限制了JVM可在用户空间创建的线程数，那么你可以检查并增加这个限制： // macOS 10.12上执行 $ ulimit -u 709 当你的应用程序产生成千上万的线程，并抛出此异常，表示你的程序已经出现了很严重的编程错误，我不觉得应该通过修改参数来解决这个问题，不管是OS级别的参数还是JVM启动参数。更可取的办法是分析你的应用是否真的需要创建如此多的线程来完成任务？是否可以使用线程池或者说线程池的数量是否合适？是否可以更合理的拆分业务来实现..... 6、java.lang.OutOfMemoryError:Out of swap space? Java应用程序在启动时会指定所需要的内存大小，可以通过-Xmx和其他类似的启动参数来指定。在JVM请求的总内存大于可用物理内存的情况下，操作系统会将内存中的数据交换到磁盘上去。 Out of swap space?表示交换空间也将耗尽，并且由于缺少物理内存和交换空间，再次尝试分配内存也将失败。 原因分析 当应用程序向JVM native heap请求分配内存失败并且native heap也即将耗尽时，JVM会抛出Out of swap space错误。该错误消息中包含分配失败的大小（以字节为单位）和请求失败的原因。 Native Heap Memory是JVM内部使用的Memory，这部分的Memory可以通过JDK提供的JNI的方式去访问，这部分Memory效率很高，但是管理需要自己去做，如果没有把握最好不要使用，以防出现内存泄露问题。JVM 使用Native Heap Memory用来优化代码载入（JTI代码生成），临时对象空间申请，以及JVM内部的一些操作。 这个问题往往发生在Java进程已经开始交换的情况下，现代的GC算法已经做得足够好了，当时当面临由于交换引起的延迟问题时，GC暂停的时间往往会让大多数应用程序不能容忍。 java.lang.OutOfMemoryError:Out of swap space?往往是由操作系统级别的问题引起的，例如： 操作系统配置的交换空间不足。 系统上的另一个进程消耗所有内存资源。 还有可能是本地内存泄漏导致应用程序失败，比如：应用程序调用了native code连续分配内存，但却没有被释放。 解决方案 解决这个问题有几个办法，通常最简单的方法就是增加交换空间，不同平台实现的方式会有所不同，比如在Linux下可以通过如下命令实现： # 原作者使用，由于我手里并没有Linux环境，所以并未测试 # 创建并附加一个大小为640MB的新交换文件 swapoff -a dd if=/dev/zero of=swapfile bs=1024 count=655360 mkswap swapfile swapon swapfile Java GC会扫描内存中的数据，如果是对交换空间运行垃圾回收算法会使GC暂停的时间增加几个数量级，因此你应该慎重考虑使用上文增加交换空间的方法。 如果你的应用程序部署在JVM需要同其他进程激烈竞争获取资源的物理机上，建议将服务隔离到单独的虚拟机中 但在许多情况下，您唯一真正可行的替代方案是： 升级机器以包含更多内存 优化应用程序以减少其内存占用 当您转向优化路径时，使用内存转储分析程序来检测内存中的大分配是一个好的开始。 7、java.lang.OutOfMemoryError:Requested array size exceeds VM limit Java对应用程序可以分配的最大数组大小有限制。不同平台限制有所不同，但通常在1到21亿个元素之间。 当你遇到Requested array size exceeds VM limit错误时，意味着你的应用程序试图分配大于Java虚拟机可以支持的数组。 原因分析 该错误由JVM中的native code抛出。 JVM在为数组分配内存之前，会执行特定于平台的检查：分配的数据结构是否在此平台中是可寻址的。 你很少见到这个错误是因为Java数组的索引是int类型。 Java中的最大正整数为2 ^ 31 - 1 = 2,147,483,647。 并且平台特定的限制可以非常接近这个数字，例如：我的环境上(64位macOS，运行Jdk1.8)可以初始化数组的长度高达2,147,483,645（Integer.MAX_VALUE-2）。如果再将数组的长度增加1到Integer.MAX_VALUE-1会导致熟悉的OutOfMemoryError： Exception in thread \"main\" java.lang.OutOfMemoryError: Requested array size exceeds VM limit 但是，在使用OpenJDK 6的32位Linux上，在分配具有大约11亿个元素的数组时，您将遇到Requested array size exceeded VM limit的错误。 要理解你的特定环境的限制，运行下文中描述的小测试程序。 示例 for (int i = 3; i >= 0; i--) { try { int[] arr = new int[Integer.MAX_VALUE-i]; System.out.format(\"Successfully initialized an array with %,d elements.\\n\", Integer.MAX_VALUE-i); } catch (Throwable t) { t.printStackTrace(); } } 该示例重复四次，并在每个回合中初始化一个长原语数组。 该程序尝试初始化的数组的大小在每次迭代时增加1，最终达到Integer.MAX_VALUE。 现在，当使用Hotspot 7在64位Mac OS X上启动代码片段时，应该得到类似于以下内容的输出： java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8) java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8) java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8) java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8) 注意，在出现Requested array size exceeded VM limit之前，出现了更熟悉的java.lang.OutOfMemoryError: Java heap space。 这是因为初始化2 ^ 31-1个元素的数组需要腾出8G的内存空间，大于JVM使用的默认值。 解决方案 java.lang.OutOfMemoryError:Requested array size exceeds VM limit可能会在以下任一情况下出现： 数组增长太大，最终大小在平台限制和Integer.MAX_INT之间 你有意分配大于2 ^ 31-1个元素的数组 在第一种情况下，检查你的代码库，看看你是否真的需要这么大的数组。也许你可以减少数组的大小，或者将数组分成更小的数据块，然后分批处理数据。 在第二种情况下，记住Java数组是由int索引的。因此，当在平台中使用标准数据结构时，数组不能超过2 ^ 31-1个元素。事实上，在编译时就会出错：error：integer number too large。 8、Out of memory:Kill process or sacrifice child 为了理解这个错误，我们需要补充一点操作系统的基础知识。操作系统是建立在进程的概念之上，这些进程在内核中作业，其中有一个非常特殊的进程，名叫“内存杀手（Out of memory killer）”。当内核检测到系统内存不足时，OOM killer被激活，然后选择一个进程杀掉。哪一个进程这么倒霉呢？选择的算法和想法都很朴实：谁占用内存最多，谁就被干掉。如果你对OOM Killer感兴趣的话，建议你阅读参考资料2中的文章。 当可用虚拟虚拟内存(包括交换空间)消耗到让整个操作系统面临风险时，就会产生Out of memory:Kill process or sacrifice child错误。在这种情况下，OOM Killer会选择“流氓进程”并杀死它。 原因分析 默认情况下，Linux内核允许进程请求比系统中可用内存更多的内存，但大多数进程实际上并没有使用完他们所分配的内存。这就跟现实生活中的宽带运营商类似，他们向所有消费者出售一个100M的带宽，远远超过用户实际使用的带宽，一个10G的链路可以非常轻松的服务100个(10G/100M)用户，但实际上宽带运行商往往会把10G链路用于服务150人或者更多，以便让链路的利用率更高，毕竟空闲在那儿也没什么意义。 Linux内核采用的机制跟宽带运营商差不多，一般情况下都没有问题，但当大多数应用程序都消耗完自己的内存时，麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。就如同上面的例子中，如果150人都占用100M的带宽，那么总的带宽肯定超过了10G这条链路能承受的范围。 示例 当你在Linux上运行如下代码： public static void main(String[] args){ List l = new java.util.ArrayList(); for (int i = 10000; i 在Linux的系统日志中/var/log/kern.log会出现以下日志： Jun 4 07:41:59 plumbr kernel: [70667120.897649] Out of memory: Kill process 29957 (java) score 366 or sacrifice child Jun 4 07:41:59 plumbr kernel: [70667120.897701] Killed process 29957 (java) total-vm:2532680kB, anon-rss:1416508kB, file-rss:0kB 注意：你可能需要调整交换文件和堆大小，否则你将很快见到熟悉的Java heap space异常。在原作者的测试用例中，使用-Xmx2g指定的2g堆，并具有以下交换配置： # 注意：原作者使用，由于我手里并没有Linux环境，所以并未测试 swapoff -a dd if=/dev/zero of=swapfile bs=1024 count=655360 mkswap swapfile swapon swapfile 解决方案 解决这个问题最有效也是最直接的方法就是升级内存，其他方法诸如：调整OOM Killer配置、水平扩展应用，将内存的负载分摊到若干小实例上..... 我们不建议的做法是增加交换空间，具体原因已经在前文说过。 "},"语言/Java/Java之JVM虚拟机GC.html":{"url":"语言/Java/Java之JVM虚拟机GC.html","title":"Java之JVM虚拟机GC","keywords":"","body":"Java之JVM虚拟机GC 前言 与C语言不同，Java内存（堆内存）的分配与回收由JVM垃圾收集器自动完成，这个特性深受大家欢迎，能够帮助程序员更好的编写代码，本文以HotSpot虚拟机为例，说一说Java GC的那些事。 Java堆内存 我们知道Java堆是被所有线程共享的一块内存区域，所有对象实例和数组都在堆上进行内存分配。为了进行高效的垃圾回收，虚拟机把堆内存划分成新生代（Young Generation）、老年代（Old Generation）和永久代（Permanent Generation）3个区域。 新生代 新生代由 Eden 与 Survivor Space（S0，S1）构成，大小通过-Xmn参数指定，Eden 与 Survivor Space 的内存大小比例默认为8:1，可以通过-XX:SurvivorRatio 参数指定，比如新生代为10M 时，Eden分配8M，S0和S1各分配1M。 Eden：希腊语，意思为伊甸园，在圣经中，伊甸园含有乐园的意思，根据《旧约·创世纪》记载，上帝耶和华照自己的形像造了第一个男人亚当，再用亚当的一个肋骨创造了一个女人夏娃，并安置他们住在了伊甸园。 大多数情况下，对象在Eden中分配，当Eden没有足够空间时，会触发一次Minor GC，虚拟机提供了-XX:+PrintGCDetails参数，告诉虚拟机在发生垃圾回收时打印内存回收日志。 Survivor：意思为幸存者，是新生代和老年代的缓冲区域。 当新生代发生GC（Minor GC）时，会将存活的对象移动到S0内存区域，并清空Eden区域，当再次发生Minor GC时，将Eden和S0中存活的对象移动到S1内存区域。 存活对象会反复在S0和S1之间移动，当对象从Eden移动到Survivor或者在Survivor之间移动时，对象的GC年龄自动累加，当GC年龄超过默认阈值15时，会将该对象移动到老年代，可以通过参数-XX:MaxTenuringThreshold 对GC年龄的阈值进行设置。 老年代 老年代的空间大小即-Xmx 与-Xmn 两个参数之差，用于存放经过几次Minor GC之后依旧存活的对象。当老年代的空间不足时，会触发Major GC/Full GC，速度一般比Minor GC慢10倍以上。 永久代 在JDK8之前的HotSpot实现中，类的元数据如方法数据、方法信息（字节码，栈和变量大小）、运行时常量池、已确定的符号引用和虚方法表等被保存在永久代中，32位默认永久代的大小为64M，64位默认为85M，可以通过参数-XX:MaxPermSize进行设置，一旦类的元数据超过了永久代大小，就会抛出OOM异常。 虚拟机团队在JDK8的HotSpot中，把永久代从Java堆中移除了，并把类的元数据直接保存在本地内存区域（堆外内存），称之为元空间。 这样做有什么好处？ 有经验的同学会发现，对永久代的调优过程非常困难，永久代的大小很难确定，其中涉及到太多因素，如类的总数、常量池大小和方法数量等，而且永久代的数据可能会随着每一次Full GC而发生移动。 而在JDK8中，类的元数据保存在本地内存中，元空间的最大可分配空间就是系统可用内存空间，可以避免永久代的内存溢出问题，不过需要监控内存的消耗情况，一旦发生内存泄漏，会占用大量的本地内存。 ps：JDK7之前的HotSpot，字符串常量池的字符串被存储在永久代中，因此可能导致一系列的性能问题和内存溢出错误。在JDK8中，字符串常量池中只保存字符串的引用。 如何判断对象是否存活 GC动作发生之前，需要确定堆内存中哪些对象是存活的，一般有两种方法：引用计数法和可达性分析法。 1、引用计数法 在对象上添加一个引用计数器，每当有一个对象引用它时，计数器加1，当使用完该对象时，计数器减1，计数器值为0的对象表示不可能再被使用。 引用计数法实现简单，判定高效，但不能解决对象之间相互引用的问题。 public class GCtest { private Object instance = null; private static final int _10M = 10 * 1 通过添加-XX:+PrintGC参数，运行结果： [GC (System.gc()) [PSYoungGen: 26982K->1194K(75776K)] 26982K->1202K(249344K), 0.0010103 secs] 从GC日志中可以看出objA和objB虽然相互引用，但是它们所占的内存还是被垃圾收集器回收了。 2、可达性分析法 通过一系列称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，搜索路径称为 “引用链”，以下对象可作为GC Roots： 本地变量表中引用的对象 方法区中静态变量引用的对象 方法区中常量引用的对象 Native方法引用的对象 当一个对象到 GC Roots 没有任何引用链时，意味着该对象可以被回收。 在可达性分析法中，判定一个对象objA是否可回收，至少要经历两次标记过程： 1、如果对象objA到 GC Roots没有引用链，则进行第一次标记。 2、如果对象objA重写了finalize()方法，且还未执行过，那么objA会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其finalize()方法。finalize()方法是对象逃脱死亡的最后机会，GC会对队列中的对象进行第二次标记，如果objA在finalize()方法中与引用链上的任何一个对象建立联系，那么在第二次标记时，objA会被移出“即将回收”集合。 看看具体实现 public class FinalizerTest { public static FinalizerTest object; public void isAlive() { System.out.println(\"I'm alive\"); } @Override protected void finalize() throws Throwable { super.finalize(); System.out.println(\"method finalize is running\"); object = this; } public static void main(String[] args) throws Exception { object = new FinalizerTest(); // 第一次执行，finalize方法会自救 object = null; System.gc(); Thread.sleep(500); if (object != null) { object.isAlive(); } else { System.out.println(\"I'm dead\"); } // 第二次执行，finalize方法已经执行过 object = null; System.gc(); Thread.sleep(500); if (object != null) { object.isAlive(); } else { System.out.println(\"I'm dead\"); } } } 执行结果： method finalize is running I'm alive I'm dead 从执行结果可以看出： 第一次发生GC时，finalize方法的确执行了，并且在被回收之前成功逃脱； 第二次发生GC时，由于finalize方法只会被JVM调用一次，object被回收。 当然了，在实际项目中应该尽量避免使用finalize方法。 收集算法 垃圾收集算法主要有：标记-清除、复制和标记-整理。 1、标记-清除算法 对待回收的对象进行标记。 算法缺点：效率问题，标记和清除过程效率都很低；空间问题，收集之后会产生大量的内存碎片，不利于大对象的分配。 2、复制算法 复制算法将可用内存划分成大小相等的两块A和B，每次只使用其中一块，当A的内存用完了，就把存活的对象复制到B，并清空A的内存，不仅提高了标记的效率，因为只需要标记存活的对象，同时也避免了内存碎片的问题，代价是可用内存缩小为原来的一半。 3、标记-整理算法 在老年代中，对象存活率较高，复制算法的效率很低。在标记-整理算法中，标记出所有存活的对象，并移动到一端，然后直接清理边界以外的内存。 对象标记过程 在可达性分析过程中，为了准确找出与GC Roots相关联的对象，必须要求整个执行引擎看起来像是被冻结在某个时间点上，即暂停所有运行中的线程，不可以出现对象的引用关系还在不断变化的情况。 如何快速枚举GC Roots？ GC Roots主要在全局性的引用（常量或类静态属性）与执行上下文（本地变量表中的引用）中，很多应用仅仅方法区就上百兆，如果进行遍历查找，效率会非常低下。 在HotSpot中，使用一组称为OopMap的数据结构进行实现。类加载完成时，HotSpot把对象内什么偏移量上是什么类型的数据计算出来存储到OopMap中，通过JIT编译出来的本地代码，也会记录下栈和寄存器中哪些位置是引用。GC发生时，通过扫描OopMap的数据就可以快速标识出存活的对象。 如何安全的GC？ 线程运行时，只有在到达安全点（Safe Point）才能停顿下来进行GC。 基于OopMap数据结构，HotSpot可以快速完成GC Roots的遍历，不过HotSpot并不会为每条指令都生成对应的OopMap，只会在Safe Point处记录这些信息。 所以Safe Point的选择很重要，如果太少可能导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会选择一些执行时间较长的指令作为Safe Point，如方法调用、循环跳转和异常跳转等。 发生GC时，如何让所有线程跑到最近的Safe Point再暂停？ 当发生GC时，不直接对线程进行中断操作，而是简单的设置一个中断标志，每个线程运行到Safe Point的时候，主动去轮询这个中断标志，如果中断标志为真，则将自己进行中断挂起。 这里忽略了一个问题，当发生GC时，运行中的线程可以跑到Safe Point后进行挂起，而那些处于Sleep或Blocked状态的线程在此时无法响应JVM的中断请求，无法到Safe Point处进行挂起，针对这种情况，可以使用安全区域（Safe Region）进行解决。 Safe Region是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的。 1、当线程运行到Safe Region的代码时，首先标识已经进入了Safe Region，如果这段时间内发生GC，JVM会忽略标识为Safe Region状态的线程； 2、当线程即将离开Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开Safe Region的信号为止；垃圾收集器 Java虚拟机规范并没有规定垃圾收集器应该如何实现，用户可以根据系统特点对各个区域所使用的收集器进行组合使用。 1、Serial收集器（串行GC） Serial 是一个采用单个线程并基于复制算法工作在新生代的收集器，进行垃圾收集时，必须暂停其他所有的工作线程。对于单CPU环境来说，Serial由于没有线程交互的开销，可以很高效的进行垃圾收集动作，是Client模式下新生代默认的收集器。 2、ParNew收集器（并行GC） ParNew其实是serial的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为与Serial一样。 3、Parallel Scavenge收集器（并行回收GC） Parallel Scavenge是一个采用多线程基于复制算法并工作在新生代的收集器，其关注点在于达到一个可控的吞吐量，经常被称为“吞吐量优先”的收集器。 吞吐量 = 用户代码运行时间 /（用户代码运行时间 + 垃圾收集时间） Parallel Scavenge提供了两个参数用于精确控制吞吐量： -XX：MaxGCPauseMillis 设置垃圾收集的最大停顿时间 -XX：GCTimeRatio 设置吞吐量大小4、Serial Old收集器（串行GC） Serial Old 是一个采用单线程基于标记-整理算法并工作在老年代的收集器，是Client模式下老年代默认的收集器。5、Parallel Old收集器（并行GC） Parallel Old是一个采用多线程基于标记-整理算法并工作在老年代的收集器。在注重吞吐量以及CPU资源敏感的场合，可以优先考虑Parallel Scavenge和Parallel Old的收集器组合。6、CMS收集器（并发GC） CMS(Concurrent Mark Sweep)是一种以获取最短回收停顿时间为目标的收集器，工作在老年代，基于“标记-清除”算法实现，整个过程分为以下4步： 初始标记：这个过程只是标记以下GC Roots能够直接关联的对象，但是仍然会Stop The World； 并发标记：进行GC Roots Tracing的过程，可以和用户线程一起工作。 重新标记：用于修正并发标记期间由于用户程序继续运行而导致标记产生变动的那部分记录，这个过程会暂停所有线程，但其停顿时间远比并发标记的时间短； 并发清理：可以和用户线程一起工作。CMS收集器的缺点： 对CPU资源比较敏感，在并发阶段，虽然不会导致用户线程停顿，但是会占用一部分线程资源，降低系统的总吞吐量。 无法处理浮动垃圾，在并发清理阶段，用户线程的运行依然会产生新的垃圾对象，这部分垃圾只能在下一次GC时收集。 CMS是基于标记-清除算法实现的，意味着收集结束后会造成大量的内存碎片，可能导致出现老年代剩余空间很大，却无法找到足够大的连续空间分配当前对象，不得不提前触发一次Full GC。 JDK1.5实现中，当老年代空间使用率达到68%时，就会触发CMS收集器，如果应用中老年代增长不是太快，可以通过-XX:CMSInitiatingOccupancyFraction参数提高触发百分比，从而降低内存回收次数提高系统性能。 JDK1.6实现中，触发CMS收集器的阈值已经提升到92%，要是CMS运行期间预留的内存无法满足用户线程需要，会出现一次”Concurrent Mode Failure”失败，这是虚拟机会启动Serial Old收集器对老年代进行垃圾收集，当然，这样应用的停顿时间就更长了，所以这个阈值也不能设置的太高，如果导致了”Concurrent Mode Failure”失败，反而会降低性能，至于如何设置这个阈值，还得长时间的对老年代空间的使用情况进行监控。 7、G1收集器 G1（Garbage First）是JDK1.7提供的一个工作在新生代和老年代的收集器，基于“标记-整理”算法实现，在收集结束后可以避免内存碎片问题。 G1优点： 并行与并发：充分利用多CPU来缩短Stop The World的停顿时间； 分代收集：不需要其他收集配合就可以管理整个Java堆，采用不同的方式处理新建的对象、已经存活一段时间和经历过多次GC的对象获取更好的收集效果; 空间整合：与CMS的”标记-清除”算法不同，G1在运行期间不会产生内存空间碎片，有利于应用的长时间运行，且分配大对象时，不会导致由于无法申请到足够大的连续内存而提前触发一次Full GC; 停顿预测：G1中可以建立可预测的停顿时间模型，能让使用者明确指定在M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 使用G1收集器时，Java堆的内存布局与其他收集器有很大区别，整个Java堆会被划分为多个大小相等的独立区域Region，新生代和老年代不再是物理隔离了，都是一部分Region（不需要连续）的集合。G1会跟踪各个Region的垃圾收集情况（回收空间大小和回收消耗的时间），维护一个优先列表，根据允许的收集时间，优先回收价值最大的Region，避免在整个Java堆上进行全区域的垃圾回收，确保了G1收集器可以在有限的时间内尽可能收集更多的垃圾。 不过问题来了：使用G1收集器，一个对象分配在某个Region中，可以和Java堆上任意的对象有引用关系，那么如何判定一个对象是否存活，是否需要扫描整个Java堆？其实这个问题在之前收集器中也存在，如果回收新生代的对象时，不得不同时扫描老年代的话，会大大降低Minor GC的效率。 针对这种情况，虚拟机提供了一个解决方案：G1收集器中Region之间的对象引用关系和其他收集器中新生代与老年代之间的对象引用关系被保存在Remenbered Set数据结构中，用来避免全堆扫描。G1中每个Region都有一个对应的Remenbered Set，当虚拟机发现程序对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于相同的Region中，如果不是，则通过CardTable把相关引用信息记录到被引用对象所属Region的Remenbered Set中。 "},"语言/Java/Java之jvm性能调优工具jcmd.html":{"url":"语言/Java/Java之jvm性能调优工具jcmd.html","title":"Java之jvm性能调优工具jcmd","keywords":"","body":"Java之jvm性能调优工具jcmd 概述 在JDK1.7以后，新增了一个命令行工具 jcmd。他是一个多功能的工具，可以用它来导出堆、查看Java进程、导出线程信息、执行GC、还可以进行采样分析（jmc 工具的飞行记录器）。 命令格式 jcmd jcmd -l jcmd -h描述 pid：接收诊断命令请求的进程ID。 main class ：接收诊断命令请求的进程的main类。匹配进程时，main类名称中包含指定子字符串的任何进程均是匹配的。如果多个正在运行的Java进程共享同一个main类，诊断命令请求将会发送到所有的这些进程中。 command：接收诊断命令请求的进程的main类。匹配进程时，main类名称中包含指定子字符串的任何进程均是匹配的。如果多个正在运行的Java进程共享同一个main类，诊断命令请求将会发送到所有的这些进程中。 Perfcounter.print：打印目标Java进程上可用的性能计数器。性能计数器的列表可能会随着Java进程的不同而产生变化。 -f file：从文件file中读取命令，然后在目标Java进程上调用这些命令。在file中，每个命令必须写在单独的一行。以\"#\"开头的行会被忽略。当所有行的命令被调用完毕后，或者读取到含有stop关键字的命令，将会终止对file的处理。 -l：查看所有的进程列表信息。 -h：查看帮助信息。（同 -help） 注意: 如果任何参数含有空格，你必须使用英文的单引号或双引号将其包围起来。 此外，你必须使用转义字符来转移参数中的单引号或双引号，以阻止操作系统shell处理这些引用标记。当然，你也可以在参数两侧加上单引号，然后在参数内使用双引号(或者，在参数两侧加上双引号，在参数中使用单引号)。 查看进程 jcmd -l 命令：jcmd -l 描述：查看 当前机器上所有的 jvm 进程信息 jcmd jcmd -l jps 这三个命令的效果是一样的 查看性能统计 命令：jcmd pid PerfCounter.print 描述：查看指定进程的性能统计信息。 C:\\Windows\\system32>jcmd 9592 PerfCounter.print 9592: java.ci.totalTime=16704 java.cls.loadedClasses=438 java.cls.sharedLoadedClasses=0 java.cls.sharedUnloadedClasses=0 java.cls.unloadedClasses=0 java.property.java.class.path=\"D:\\work\\git\\test\\target\\classes\" java.property.java.endorsed.dirs=\"D:\\Program Files\\Java\\jre1.8.0_91\\lib\\endorsed\" java.property.java.ext.dirs=\"D:\\Program Files\\Java\\jre1.8.0_91\\lib\\ext;C:\\Windows\\Sun\\Java\\lib\\ext\" java.property.java.home=\"D:\\Program Files\\Java\\jre1.8.0_91\" ... 列出当前运行的 java 进程可以执行的操作 命令：jcmd PID help C:\\Windows\\system32>jcmd 9592 help 9592: The following commands are available: JFR.stop JFR.start JFR.dump JFR.check VM.native_memory VM.check_commercial_features VM.unlock_commercial_features ManagementAgent.stop ManagementAgent.start_local ManagementAgent.start GC.rotate_log Thread.print GC.class_stats GC.class_histogram GC.heap_dump GC.run_finalization GC.run VM.uptime VM.flags VM.system_properties VM.command_line VM.version help 查看具体命令的选项 如果想查看命令的选项，比如想查看 JFR.dump 命令选项，可以通过如下命令: jcmd 11772 help JFR.dump JRF 相关命令 JRF 功能跟 jmc.exe 工具的飞行记录器的功能一样的。 要使用 JRF 相关的功能，必须使用 VM.unlock_commercial_features 参数取消锁定商业功能 。 jmc.exe 显示的提示 启动JFR 执行命令：jcmd $PID JFR.start name=abc,duration=120s Dump JFR 等待至少duration（本文设定120s）后，执行命令：jcmd PID JFR.dump name=abc,duration=120s filename=abc.jfr（注意，文件名必须为.jfr后缀） 检查JFR状态 执行命令：jcmd $PID JFR.check name=abc,duration=120s 停止JFR 执行命令：jcmd $PID JFR.stop name=abc,duration=120s JMC分析 切回开发机器，下载步骤3中生成的abc.jfr，打开jmc，导入abc.jfr即可进行可视化分析 VM.uptime 命令：jcmd PID VM.uptime 描述：查看 JVM 的启动时长： GC.class_histogram 命令：jcmd PID GC.class_histogram 描述：查看系统中类统计信息 这里和jmap -histo pid的效果是一样的 这个可以查看每个类的实例数量和占用空间大小。 Thread.print 命令：jcmd PID Thread.print 描述：查看线程堆栈信息。 该命令同 jstack命令。 GC.heap_dump 命令：jcmd PID GC.heap_dump FILE_NAME 描述：查看 JVM 的Heap Dump C:\\Users\\jjs>jcmd 10576 GC.heap_dump d:\\dump.hprof 10576: Heap dump file created 跟 jmap命令：jmap -dump:format=b,file=heapdump.phrof pid 效果一样。 导出的 dump 文件，可以使用MAT 或者 Visual VM 等工具进行分析。 注意：如果只指定文件名，默认会生成在启动 JVM 的目录里。 VM.system_properties 命令：jcmd PID VM.system_properties 描述：查看 JVM 的属性信息 C:\\Users\\jjs>jcmd 10576 VM.system_properties 10576: #Wed Jan 31 22:30:20 CST 2018 java.vendor=Oracle Corporation osgi.bundles.defaultStartLevel=4 ...... os.version=10.0 osgi.arch=x86_64 path.separator=; java.vm.version=25.91-b15 org.osgi.supports.framework.fragment=true user.variant= osgi.framework.shape=jar java.awt.printerjob=sun.awt.windows.WPrinterJob osgi.instance.area.default=file\\:/C\\:/Users/jjs/eclipse-workspace/ sun.io.unicode.encoding=UnicodeLittle org.osgi.framework.version=1.8.0 ...... VM.flags 命令：jcmd PID VM.flags 描述：查看 JVM 的启动参数 C:\\Users\\jjs>jcmd 10576 VM.flags 10576: -XX:CICompilerCount=3 -XX:ConcGCThreads=1 -XX:G1HeapRegionSize=1048576 -XX:InitialHeapSize=268435456 -XX:MarkStackSize=4194304 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=643825664 -XX:MinHeapDeltaBytes=1048576 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseG1GC -XX:-UseLargePagesIndividualAllocation -XX:+UseStringDeduplication VM.command_line 命令：jcmd PID VM.command_line 描述：查看 JVM 的启动命令行 C:\\Users\\jjs>jcmd 10576 VM.command_line 10576: VM Arguments: jvm_args: -Dosgi.requiredJavaVersion=1.8 -Dosgi.instance.area.default=@user.home/eclipse-workspace -XX:+UseG1GC -XX:+UseStringDeduplication -Dosgi.requiredJavaVersion=1.8 -Xms256m -Xmx1024m java_command: java_class_path (initial): D:\\tool\\...\\org.eclipse.equinox.launcher.jar GC.run_finalization 命令：jcmd PID GC.run_finalization 描述： 对 JVM 执行 java.lang.System.runFinalization() C:\\Users\\jjs>jcmd 10576 GC.run_finalization 10576: Command executed successfully 执行一次finalization操作，相当于执行java.lang.System.runFinalization() GC.run 命令：jcmd PID GC.run 描述：对 JVM 执行 java.lang.System.gc() C:\\Users\\jjs>jcmd 10576 GC.run 10576: Command executed successfully 告诉垃圾收集器打算进行垃圾收集，而垃圾收集器进不进行收集是不确定的。 PerfCounter.print 命令：jcmd PID PerfCounter.print 描述：查看 JVM 性能相关的参数 C:\\Users\\jjs>jcmd 10576 PerfCounter.print 10576: java.ci.totalTime=93024843 java.cls.loadedClasses=18042 java.cls.sharedLoadedClasses=0 java.cls.sharedUnloadedClasses=0 java.cls.unloadedClasses=3 ...... VM.version 命令：jcmd PID VM.version 描述：查看目标jvm进程的版本信息 C:\\Users\\jjs>jcmd 10576 VM.version 10576: Java HotSpot(TM) 64-Bit Server VM version 25.91-b15 JDK 8.0_91 "},"语言/Java/使用Java编写Tuxedo应用.html":{"url":"语言/Java/使用Java编写Tuxedo应用.html","title":"使用Java编写Tuxedo应用","keywords":"","body":"使用Java编写Tuxedo应用 Oracle Tuxedo Java编程介绍 简介 Oracle Tuxedo服务可以使用纯java来编写。使用java实现的服务的功能和其他Tuxedo服务实现是一样的。你可以使用客户端或者Tuxedo服务器通过ATMI接口来调用Tuxedo Java Server（TMJSVASVR）对外提供的服务；你也在java实现的服务中通过TJATMI接口来调用Tuxedo server提供的服务。 另外，你可以使用任何类型的Tuxedo客户端调用java实现的服务，比如本地客户端，/WS客户端和Jolt客户端。 可以使用TJATMI接口、JATMI类型缓冲、POLO java对象等主流Java技术来实现Tuxedo服务。 编程方针 Java服务类，实现Java服务，需要继承TuxedoJavaServer类；Java服务类应该有一个默认的构造函数 Java服务类中的Java方法会被向外提供成Java服务，应该声明为public, 并将TPSVCINFO接口作为唯一的输入参数 Java服务类应该实现tpsvrinit()方法，在Tuxedo Java服务启动时会被调用 Java服务类应该实现tpsvrdone()方法，在Tuxedo Java服务关闭时会被调用 Java服务可以使用Tuxedo Java ATMI接口（例如tpcall,tpbegin等） Java服务可以使用tpreturn向客户端返回结果，或者通过抛出异常退出 Tuxedo Java 服务器线程与Java类实例模型 Tuxedo Java服务使用传统的Tuxedo多线程模型，必须运行在多线程模式下 一旦启动，Tuxedo Java服务为每一个定义在配置文件中的类创建一个全局对象（实例），处理Java服务时工作线程共享全局对象（实例） Tudexo Java服务器 tpsvrinit()/tpsvrdone()处理 tpsvrinit()处理： 用户需要实现tpsvrinit()方法。由于该方法会在服务启动时调用，最好在该方法中完成类的初始化。如果一个类的tpsvrinit()方法失败，用户日志中会报告一条警告信息，Java服务会继续执行。 tpsvrdone()处理： 用户需要实现tpsvrinit()方法。该方法在服务关闭时调用，推荐将类范围的清理工作放入这个方法中。 Tuxedo Java服务器tpreturn()处理 Java服务的tpreturn()并不会立即结束Java服务方法的执行，而是向Tuxedo Java服务器返回一个结果。 Java 服务的tpreturn()的行为与现有Tuxedo系统的tpreturn()行为不同： 当现有Tuxedo系统调用tpreturn()时，流控制自动转向Tuxedo 当Java服务调用tpreturn()时，tpreturn()之后的语句依旧会被执行。用户必须保证tpreturn()是Java服务中最后一条执行的语句。如果不是，建议在tpreturn()之后加上return；否则tpreturn()不会自动将流控制转向Tuxedo系统 注意：不建议在Java服务中前面没有tpreturn()时使用return。这种用法会使Java服务器返回rcode为0的TPFAIL到相关的客户端。 Tuxedo Java服务器异常处理 Java服务执行期间可以抛出任何的异常然后退出Java服务。这种情况下Java服务器会返回TPFAIL到其客户端，其中rcode设置为0 所有的异常信息会记录在$APPDIR/stderr文件中。编程环境 更新UBB配置文件 你需要配置一个路径，通过该路径Tuxdeo Java服务器可以找到CLOPT中Java实现的服务的配置文件。 由于ATMI Java服务器是一个多线程服务器，你还需要指名线程分配的限制。可以查看Defining the Server Dispatch Threads一章获取更多关于多线程服务配置的信息。 清单2-1 显示了ATMI Java服务器的UBB配置文件示例： 清单2-1 *SERVERS TMJAVASVR SRVGRP=TJSVRGRP SRVID=3 CLOPT=\"-- -c /home/oracle/app/javaserver/TJSconfig.xml\" MINDISPATCHTHREADS=2 MAXDISPATCHTHREADS=3 注意：UBBCONFIG中为Java服务器指明的MAXDISPATCHTHREADS最小值为2。 ATMI Java Server 用户接口 TuxedoJavaServer TuxedoJavaServer是一个抽象类，所有用户定义的实现服务的类都应该继承它。 表3-1 TuxedoJavaServer接口 函数 描述 tpsvrinit 抽象方法，子类实现时做一些初始化的工作 tpsvrdone 抽象方法，子类实现时做一些清理工作 getTuxAppContext 用来取回当前连接的Tuxedo应用Java上下文 Oracle Tuxedo Java上下文 为了获取Oracle Tuxedo Java Server提供的TJATMI原始功能，你需要获取一个TuxAppContext对象，该对象实现了所有的TJATMI功能 因为服务类继承自TuxedoJavaServer，你可以在服务中调用getTuxAppContext()方法获取上下文对象。然而，你不能在tpsvrinit()中或其TuxAppContext，因为此时TuxAppContext没有准备好。如果你在tpsvrinit()中尝试获取TuxAppContext，tpsvrinit()会出错并抛出异常。 Tuxedo Java 应用中的TJATMI功能 TJATMI是原生功能的集合，提供客户端和服务器端的通信功能，比如调用服务，开始和结束事务，获取到数据源的连接，日志等等。更多信息参考Java Server Javadoc. 表3-2 TJATMI功能 名字 操作 tpcall 用于在请求/应答通信中同步调用Oracle Tuxedo服务 tpreturn 用于在Tuxedo Java Server中设置返回值 tpbegin 开始事务 tpcommit 提交当前事务 tpabort 终止当前事务 tpgetlev 检查事务是否正在执行 getConnection 获取到已配置的数据源的连接 userlog 在Tuxedo用户日志文件中打印日志 注意：在tpreturn结束执行后服务依旧在运行。推荐把tpreturn作为服务中最后执行的语句。 Tuxedo Java应用的类型缓冲 ATMI Java server 重用了Oracle WebLogic Tuxedo Connector TypedBuffers 作为相应的Oracle Tuxedo类型缓冲。消息通过类型缓冲传入 server 。ATMI Java server提供的类型缓冲见表3-3: 表3-3 类型缓冲 缓冲类型 描述 TypedString 数据是以null字符作为结束的字符数组时使用。Oracle Tuxedo 等价类型：STRING TypedCArray 数据是未定义字符数组（字节数组），任一字节都有可能是null。Oracle Tuxedo等价类型：CARRAY TypedFML 数据自定义时使用。每个数据域携带自己的标识，事件数，有可能有长度指示器。Oracle Tuxedo等价类型：FML TypedFML32 类似于TypedFML但是允许更大的字符范围和域，更大的缓冲。Oracle Tuxedo等价类型：FML32 TypedXML 数据是基于XML的消息。Oracle Tuxedo等价类型：XML TypedView 应用使用Java结构，使用视图描述文件来定义缓冲结构。Oracle Tuxedo等价类型：VIEW TypedView32 类似于View，允许更大的字符范围、域、缓冲。Oracle Tuxedo等价类型：VIEW32 更多关于类型缓冲的信息，参见\"weblogic.wtc.jatmi\" 类型缓冲支持的限制 TypedFML32中Fldid()/Fname()嵌套在另一个TypedFML32中时无法工作。为了应对这种情况，你可以使用fieldtable类传输name/id。 目前weblogic.wtc.gwt.XmlViewCnv/XmlFmlCnv类无法使用。 获取/设置服务信息 使用TPSVCINFO类通过客户端获取/设置服务信息 表3-4 Getter函数 函数 描述 getServiceData 用来返回Oracle Tuxedo客户端发送过来的服务数据 getServiceFlags 用来返回客户端发送过来的服务标识 getServiceName 用来返回调用的服务名 getAppKey 获取程序认证客户端密钥 getClientID 获取客户端标识符 使用TuxATMIReply从服务请求中获取回应数据和元数据 表3-5 用于回应的Getter函数 函数 描述 getReplyBuffer 返回从服务返回的类型缓冲（可能是null） gettpurcode 返回从服务返回的tpurcode 异常 你需要捕获服务中JATMI原语抛出的异常，比如tpcall()。JATMI可能抛出两种类型的异常： TuxATMITPException：该异常抛出表明TJATMI出错 TuxATMITPReplyException：如果服务出错（TPESVCFAIL或者TPSVCERROR）该异常抛出，用户数据关联到异常中。跟踪 你还需要导出TMTRACE=atmi:ulog，正如你使用传统ATMI那样。TJATMI API跟踪信息被写入ULOG。 在Oracle Tuxedo Java Server 中实现服务 典型过程 定义一个继承自 TuxedoJavaServer的类 提供一个默认的构造函数 实现tpsvrinit()和tpsvrdone()方法 实现服务方法，该方法应该使用TPSVCINFO作为唯一的参数 使用getTuxAppContext()获取TuxAppContext对象 使用TPSVCINFO.getServiceData()从TPSVCINFO对象中获取客户端请求数据 如果配置了数据源，使用TuxAppContext.getConnection()方法获取到数据源的连接 完成商业逻辑，比如使用TuxAppContext.tpcall()调用其他服务，操纵数据库等 分配新的类型缓冲，把应答数据放入类型缓冲中 调用TuxAppContext.tpreturn()将应答数据返回客户端实例：没有事务的Java服务实现 如下实例是实现TOUPPER服务的简单示例。 定义Java类 import weblogic.wtc.jatmi.TypedBuffer; import weblogic.wtc.jatmi.TypedString; import com.oracle.tuxedo.tjatmi.*; public class MyTuxedoJavaServer extends TuxedoJavaServer { public MyTuxedoJavaServer() { return; } public int tpsvrinit() throws TuxException { System.out.println(\"MyTuxedoJavaServer.tpsvrinit()\"); return 0; } public void tpsvrdone() { System.out.println(\"MyTuxedoJavaServer.tpsvrdone()\"); return; } public void JAVATOUPPER(TPSVCINFO rqst) throws TuxException { TypedBuffer svcData; TuxAppContext myAppCtxt = null; TuxATMIReply myTuxReply = null; TypedBuffer replyTb = null; /* Get TuxAppContext first */ myAppCtxt = getTuxAppContext(); svcData = rqst.getServiceData(); TypedString TbString = (TypedString)svcData; myAppCtxt.userlog(\"Handling in JAVATOUPPER()\"); myAppCtxt.userlog(\"Received string is:\" + TbString.toString()); String newStr = TbString.toString(); newStr = newStr.toUpperCase(); TypedString replyTbString = new TypedString(newStr); /* Return new string to client */ myAppCtxt.tpreturn(TPSUCCESS, 0, replyTbString, 0); } public void JAVATOUPPERFORWARD(TPSVCINFO rqst) throws TuxException { TypedBuffer svcData; TuxAppContext myAppCtxt = null; TuxATMIReply myTuxReply = null; TypedBuffer replyTb = null; long flags = TPSIGRSTRT; /* Get TuxAppContext first */ myAppCtxt = getTuxAppContext(); svcData = rqst.getServiceData(); TypedString TbString = (TypedString)svcData; myAppCtxt.userlog(\"Handling in JAVATOUPPERFORWARD()\"); myAppCtxt.userlog(\"Received string is:\" + TbString.toString()); /* Call another service \"TOUPPER\" which may be implemented by another Tuxedo Server */ try { myTuxReply = myAppCtxt.tpcall(\"TOUPPER\", svcData, flags); /* If success, get reply buffer */ replyTb = myTuxReply.getReplyBuffer(); TypedString replyTbStr = (TypedString)replyTb; myAppCtxt.userlog(\"Replied string from TOUPPER:\" + replyTbStr.toString()); /* Return the replied buffer to client */ myAppCtxt.tpreturn(TPSUCCESS, 0, replyTb, 0); } catch (TuxATMITPReplyException tre) { myAppCtxt.userlog(\"TuxATMITPReplyException:\" + tre); myAppCtxt.tpreturn(TPFAIL, 0, null, 0); } catch (TuxATMITPException te) { myAppCtxt.userlog(\"TuxATMITPException:\" + te); myAppCtxt.tpreturn(TPFAIL, 0, null, 0); } } } 创建Java Server配置文件 清单4-2显示了配置示例，将MyTuxedoJavaServer.JAVATOUPPER()方法导出成Tuxedo 服务JAVATOUPPER，将MyTuxedoJavaServer.JAVATOUPPERFORWARD()方法导出成Tuxedo 服务JAVATOUPPERFORWARD。 清单4-2 更新UBB配置文件 清单4-3 UBB配置文件 *GROUPS TJSVRGRP LMID=simple GRPNO=2 *SERVERS TMJAVASVR SRVGRP= TJSVRGRP SRVID=4 CLOPT=\"-- -c TJSconfig.xml\" MINDISPATCHTHREADS=2 MAXDISPATCHTHREADS=2 实例：带有事务的Java Service实现 清单4-4给出了一个示例，实现WRITEDB_SVCTRN_COMMIT服务，该服务将用户请求字符串插入表TUXJ_TRAN_TEST中。 定义Java类 清单4-4 import weblogic.wtc.jatmi.TypedBuffer; import weblogic.wtc.jatmi.TypedString; import com.oracle.tuxedo.tjatmi.*; import java.sql.SQLException; /* MyTuxedoTransactionServer is user defined class */ public class MyTuxedoTransactionServer extends TuxedoJavaServer{ public MyTuxedoTransactionServer () { return; } public int tpsvrinit() throws TuxException { System.out.println(\"In MyTuxedoTransactionServer.tpsvrinit()\"); return 0; } public void tpsvrdone() { System.out.println(\"In MyTuxedoTransactionServer.tpsvrdone()\"); return; } public void WRITEDB_SVCTRN_COMMIT(TPSVCINFO rqst) throws TuxException { TuxAppContext myAppCtxt; TypedBuffer rplyBuf = null; String strType = \"STRING\"; String ulogMsg; TypedString rqstMsg; Connection connDB = null; Statement stmtDB = null; String stmtSQL; int trnLvl, trnStrtInSVC; int trnRtn; int rc = TPSUCCESS; rqstMsg = (TypedString)rqst.getServiceData(); myAppCtxt = getTuxAppContext(); myAppCtxt.userlog(\"JAVA-INFO: Request Message Is \\\"\" + rqstMsg.toString() + \"\\\"\"); rplyBuf = new TypedString(\"This Is a Simple Transaction Test from Tuxedo Java Service\"); long trnFlags = 0; try { trnStrtInSVC = 0; trnLvl = myAppCtxt.tpgetlev(); if (0 == trnLvl) { long trnTime = 6000; myAppCtxt.userlog(\"JAVA-INFO: Start a transaction...\"); trnRtn = myAppCtxt.tpbegin(trnTime, trnFlags); myAppCtxt.userlog(\"JAVA-INFO: tpbegin return \" + trnRtn); trnStrtInSVC = 1; } connDB = myAppCtxt.getConnection(); if (null != connDB) { myAppCtxt.userlog(\"JAVA-INFO: Get connection: (\" + connDB.toString() + \").\"); } stmtDB = connDB.createStatement(); if (null != stmtDB) { myAppCtxt.userlog(\"JAVA-INFO: Create statement: (\" + stmtDB.toString() + \").\"); } stmtSQL = \"INSERT INTO TUXJ_TRAN_TEST VALUES ('\" + rqstMsg.toString() + \"')\"; myAppCtxt.userlog(\"JAVA-INFO: Start to execute sql (\" + stmtSQL + \")...\"); stmtDB.execute(stmtSQL); myAppCtxt.userlog(\"JAVA-INFO: End to execute sql (\" + stmtSQL + \").\"); if (1 == trnStrtInSVC) { myAppCtxt.userlog(\"JAVA-INFO: tpcommit current transaction...\"); trnRtn = myAppCtxt.tpcommit(trnFlags); myAppCtxt.userlog(\"JAVA-INFO: tpcommit return \" + trnRtn); trnStrtInSVC = 0; if (-1 == trnRtn ) { rc = TPFAIL; } } } catch (TuxATMIRMException e) { String errMsg = \"ERROR: TuxATMIRMException: (\" + e.getMessage() + \").\"; myAppCtxt.userlog(\"JAVA-ERROR: \" + errMsg); rc = TPFAIL; } catch (TuxATMITPException e) { String errMsg = \"ERROR: TuxATMITPException: (\" + e.getMessage() + \").\"; myAppCtxt.userlog(\"JAVA-ERROR: \" + errMsg); rc = TPFAIL; } catch (SQLException e) { String errMsg = \"ERROR: SQLException: (\" + e.getMessage() + \").\"; myAppCtxt.userlog(\"JAVA-ERROR: \" + errMsg); rc = TPFAIL; } catch (Exception e) { String errMsg = \"ERROR: Exception: (\" + e.getMessage() + \").\"; myAppCtxt.userlog(\"JAVA-ERROR: \" + errMsg); rc = TPFAIL; } catch (Throwable e) { String errMsg = \"ERROR: Throwable: (\" + e.getMessage() + \").\"; myAppCtxt.userlog(\"JAVA-ERROR: \" + errMsg); rc = TPFAIL; } finally { if (null != stmtDB) { try { stmtDB.close(); } catch (SQLException e) {} } } myAppCtxt.tpreturn(rc, 0, rplyBuf, 0); } } 创建Java 服务配置文件 表4-5 /home/oracle/app/oracle/product/11.2.0/dbhome_2/ucp/lib/ucp.jar /home/oracle/app/oracle/product/11.2.0/dbhome_2/jdbc/lib/ojdbc6.jar oracle.jdbc.xa.client.OracleXADataSource jdbc:oracle:thin:@//10.182.54.144:1521/javaorcl 更新UBB配置文件 清单4-6 *GROUPS ORASVRGRP LMID=simple GRPNO=1 OPENINFO=\"Oracle_XA:Oracle_XA+Acc=P/scott/triger+SesTm=120+MaxCur=5+LogDir=.+SqlNet=javaorcl\" TMSNAME=TMSORA TMSCOUNT=2 *SERVERS TMJAVASVR SRVGRP=ORASVRGRP SRVID=3 CLOPT=\"-- -c TJSconfig.xml\" MINDISPATCHTHREADS=2 MAXDISPATCHTHREADS=4 "},"语言/Java/JVM原理讲解和调优.html":{"url":"语言/Java/JVM原理讲解和调优.html","title":"JVM原理讲解和调优","keywords":"","body":"JVM原理讲解和调优 一、什么是JVM JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 Java语言的一个非常重要的特点就是与平台的无关性。而使用Java虚拟机是实现这一特点的关键。一般的高级语言如果要在不同的平台上运行，至少需要编译成不同的目标代码。而引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。这就是Java的能够“一次编译，到处运行”的原因。 从Java平台的逻辑结构上来看，我们可以从下图来了解JVM： 从上图能清晰看到Java平台包含的各个逻辑模块，也能了解到JDK与JRE的区别，对于JVM自身的物理结构，我们可以从下图鸟瞰一下： 二、JAVA代码编译和执行过程 Java代码编译是由Java源码编译器来完成，流程图如下所示： Java字节码的执行是由JVM执行引擎来完成，流程图如下所示： ava代码编译和执行的整个过程包含了以下三个重要的机制： Java源码编译机制 类加载机制 类执行机制Java源码编译机制 Java 源码编译由以下三个过程组成： 分析和输入到符号表 注解处理 语义分析和生成class文件 流程图如下所示： 最后生成的class文件由以下部分组成： 结构信息。包括class文件格式版本号及各部分的数量与大小的信息 元数据。对应于Java源码中声明与常量的信息。包含类/继承的超类/实现的接口的声明信息、域与方法声明信息和常量池 方法信息。对应Java源码中语句和表达式对应的信息。包含字节码、异常处理器表、求值栈与局部变量区大小、求值栈的类型记录、调试符号信息类加载机制 JVM的类加载是通过ClassLoader及其子类来完成的，类的层次关系和加载顺序可以由下图来描述： 1）Bootstrap ClassLoader 负责加载$JAVA_HOME中jre/lib/rt.jar里所有的class，由C++实现，不是ClassLoader子类 2）Extension ClassLoader 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar或-Djava.ext.dirs指定目录下的jar包 3）App ClassLoader 负责记载classpath中指定的jar包及目录中class 4）Custom ClassLoader 属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现ClassLoader加载过程中会先检查类是否被已加载，检查顺序是自底向上，从Custom ClassLoader到BootStrap ClassLoader逐层检查，只要某个classloader已加载就视为已加载此类，保证此类只所有ClassLoader加载一次。而加载的顺序是自顶向下，也就是由上层来逐层尝试加载此类。 类执行机制 JVM是基于栈的体系结构来执行class字节码的。线程创建后，都会产生程序计数器（PC）和栈（Stack），程序计数器存放下一条要执行的指令在方法内的偏移量，栈中存放一个个栈帧，每个栈帧对应着每个方法的每次调用，而栈帧又是有局部变量区和操作数栈两部分组成，局部变量区用于存放方法中的局部变量和参数，操作数栈中用于存放方法执行过程中产生的中间结果。栈的结构如下图所示： 三、JVM内存管理和垃圾回收 JVM内存组成结构 JVM栈由堆、栈、本地方法栈、方法区等部分组成，结构图如下所示： 1）堆 所有通过new创建的对象的内存都在堆中分配，堆的大小可以通过-Xmx和-Xms来控制。堆被划分为新生代和旧生代，新生代又被进一步划分为Eden和Survivor区，最后Survivor由From Space和To Space组成，结构图如下所示： 新生代。新建的对象都是用新生代分配内存，Eden空间不足的时候，会把存活的对象转移到Survivor中，新生代大小可以由-Xmn来控制，也可以用-XX:SurvivorRatio来控制Eden和Survivor的比例 旧生代。用于存放新生代中经过多次垃圾回收仍然存活的对象 持久带（Permanent Space）实现方法区，主要存放所有已加载的类信息，方法信息，常量池等等。可通过-XX:PermSize和-XX:MaxPermSize来指定持久带初始化值和最大值。Permanent Space并不等同于方法区，只不过是Hotspot JVM用Permanent Space来实现方法区而已，有些虚拟机没有Permanent Space而用其他机制来实现方法区。 -Xmx:最大堆内存,如：-Xmx512m -Xms:初始时堆内存,如：-Xms256m -XX:MaxNewSize:最大年轻区内存 -XX:NewSize:初始时年轻区内存.通常为 Xmx 的 1/3 或 1/4。新生代 = Eden + 2 个 Survivor 空间。实际可用空间为 = Eden + 1 个 Survivor，即 90% -XX:MaxPermSize:最大持久带内存 -XX:PermSize:初始时持久带内存 -XX:+PrintGCDetails。打印 GC 信息 -XX:NewRatio 新生代与老年代的比例，如 –XX:NewRatio=2，则新生代占整个堆空间的1/3，老年代占2/3 -XX:SurvivorRatio 新生代中 Eden 与 Survivor 的比值。默认值为 8。即 Eden 占新生代空间的 8/10，另外两个 Survivor 各占 1/102）栈 每个线程执行每个方法的时候都会在栈中申请一个栈帧，每个栈帧包括局部变量区和操作数栈，用于存放此次方法调用过程中的临时变量、参数和中间结果。 -xss:设置每个线程的堆栈大小. JDK1.5+ 每个线程堆栈大小为 1M，一般来说如果栈不是很深的话， 1M 是绝对够用了的。 3）本地方法栈 用于支持native方法的执行，存储了每个native方法调用的状态 4）方法区 存放了要加载的类信息、静态变量、final类型的常量、属性和方法信息。JVM用持久代（Permanet Generation）来存放方法区，可通过-XX:PermSize和-XX:MaxPermSize来指定最小值和最大值 垃圾回收按照基本回收策略分 引用计数（Reference Counting）: 比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。 标记-清除（Mark-Sweep）: 此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。 复制（Copying）: 此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍内存空间。 标记-整理（Mark-Compact）: 此算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。 JVM分别对新生代和旧生代采用不同的垃圾回收机制 新生代的GC： 新生代通常存活时间较短，因此基于Copying算法来进行回收，所谓Copying算法就是扫描出存活的对象，并复制到一块新的完全未使用的空间中，对应于新生代，就是在Eden和From Space或To Space之间copy。新生代采用空闲指针的方式来控制GC触发，指针保持最后一个分配的对象在新生代区间的位置，当有新的对象要分配内存时，用于检查空间是否足够，不够就触发GC。当连续分配对象时，对象会逐渐从eden到survivor，最后到旧生代。 在执行机制上JVM提供了串行GC（Serial GC）、并行回收GC（Parallel Scavenge）和并行GC（ParNew） 1）串行GC 在整个扫描和复制过程采用单线程的方式来进行，适用于单CPU、新生代空间较小及对暂停时间要求不是非常高的应用上，是client级别默认的GC方式，可以通过-XX:+UseSerialGC来强制指定 2）并行回收GC 在整个扫描和复制过程采用多线程的方式来进行，适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式，可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数 3）并行GC 与旧生代的并发GC配合使用 旧生代的GC： 旧生代与新生代不同，对象存活的时间比较长，比较稳定，因此采用标记（Mark）算法来进行回收，所谓标记就是扫描出存活的对象，然后再进行回收未被标记的对象，回收后对用空出的空间要么进行合并，要么标记出来便于下次进行分配，总之就是要减少内存碎片带来的效率损耗。在执行机制上JVM提供了串行GC（Serial MSC）、并行GC（parallel MSC）和并发GC（CMS），具体算法细节还有待进一步深入研究。 以上各种GC机制是需要组合使用的，指定方式由下表所示： 指定方式 新生代GC方式 旧生代GC方式 -XX:+UseSerialGC 串行GC 串行GC -XX:+UseParallelGC 并行回收GC 并行GC -XX:+UseConeMarkSweepGC 并行GC 并发GC -XX:+UseParNewGC 并行GC 串行GC -XX:+UseParallelOldGC 并行回收GC 并行GC -XX:+ UseConeMarkSweepGC -XX:+UseParNewGC 串行GC 并发GC 不支持的组合 1、-XX:+UseParNewGC -XX:+UseParallelOldGC 2、-XX:+UseParNewGC -XX:+UseSerialGC 四、JVM内存调优 首先需要注意的是在对JVM内存调优的时候不能只看操作系统级别Java进程所占用的内存，这个数值不能准确的反应堆内存的真实占用情况，因为GC过后这个值是不会变化的，因此内存调优的时候要更多地使用JDK提供的内存查看工具，比如JConsole和Java VisualVM。 对JVM内存的系统级的调优主要的目的是减少GC的频率和Full GC的次数，过多的GC和Full GC是会占用很多的系统资源（主要是CPU），影响系统的吞吐量。特别要关注Full GC，因为它会对整个堆进行整理，导致Full GC一般由于以下几种情况： 旧生代空间不足 调优时尽量让对象在新生代GC时被回收、让对象在新生代多存活一段时间和不要创建过大的对象及数组避免直接在旧生代创建对象 Pemanet Generation空间不足 增大Perm Gen空间，避免太多静态对象 统计得到的GC后晋升到旧生代的平均大小大于旧生代剩余空间 控制好新生代和旧生代的比例 System.gc()被显示调用 垃圾回收不要手动触发，尽量依靠JVM自身的机制 调优手段主要是通过控制堆内存的各个部分的比例和GC策略来实现，下面来看看各部分比例不良设置会导致什么后果 1）新生代设置过小 一是新生代GC次数非常频繁，增大系统消耗； 二是导致大对象直接进入旧生代，占据了旧生代剩余空间，诱发Full GC 2）新生代设置过大 一是新生代设置过大会导致旧生代过小（堆总量一定），从而诱发Full GC；二是新生代GC耗时大幅度增加 一般说来新生代占整个堆1/3比较合适 3）Survivor设置过小 导致对象从eden直接到达旧生代，降低了在新生代的存活时间 4）Survivor设置过大 导致eden过小，增加了GC频率 另外，通过-XX:MaxTenuringThreshold=n来控制新生代存活时间，尽量让对象在新生代被回收 由内存管理和垃圾回收可知新生代和旧生代都有多种GC策略和组合搭配，选择这些策略对于我们这些开发人员是个难题，JVM提供两种较为简单的GC策略的设置方式 1）吞吐量优先 JVM以吞吐量为指标，自行选择相应的GC策略及控制新生代与旧生代的大小比例，来达到吞吐量指标。这个值可由-XX:GCTimeRatio=n来设置 2）暂停时间优先 JVM以暂停时间为指标，自行选择相应的GC策略及控制新生代与旧生代的大小比例，尽量保证每次GC造成的应用停止时间都在指定的数值范围内完成。这个值可由-XX:MaxGCPauseRatio=n来设置 最后汇总一下JVM常见配置 堆设置 -Xms:初始堆大小 -Xmx:最大堆大小 -XX:NewSize=n:设置年轻代大小 -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5 -XX:MaxPermSize=n:设置持久代大小收集器设置 -XX:+UseSerialGC:设置串行收集器 -XX:+UseParallelGC:设置并行收集器 -XX:+UseParalledlOldGC:设置并行年老代收集器 -XX:+UseConcMarkSweepGC:设置并发收集器垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename并行收集器设置 -XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间 -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)并发收集器设置 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 "},"语言/Java/Java调优经验谈.html":{"url":"语言/Java/Java调优经验谈.html","title":"Java调优经验谈","keywords":"","body":"Java调优经验谈 目录 调优准备 性能分析 性能调优 其他优化建议 JVM参数进阶 对于调优这个事情来说，一般就是三个过程： 性能监控：问题没有发生，你并不知道你需要调优什么。此时需要一些系统、应用的监控工具来发现问题。 性能分析：问题已经发生，但是你并不知道问题到底出在哪里。此时就需要使用工具、经验对系统、应用进行瓶颈分析，以求定位到问题原因。 性能调优：经过上一步的分析定位到了问题所在，需要对问题进行解决，使用代码、配置等手段进行优化。 Java调优也不外乎这三步。 此外，本文所讲的性能分析、调优等是抛开以下因素的： 系统底层环境：硬件、操作系统等 数据结构和算法的使用 外部系统如数据库、缓存的使用调优准备 调优是需要做好准备工作的，毕竟每一个应用的业务目标都不尽相同，性能瓶颈也不会总在同一个点上。在业务应用层面，我们需要： 需要了解系统的总体架构，明确压力方向。比如系统的哪一个接口、模块是使用率最高的，面临高并发的挑战。 需要构建测试环境来测试应用的性能，使用ab、loadrunner、jmeter都可以。 对关键业务数据量进行分析，这里主要指的是对一些数据的量化分析，如数据库一天的数据量有多少；缓存的数据量有多大等 了解系统的响应速度、吞吐量、TPS、QPS等指标需求，比如秒杀系统对响应速度和QPS的要求是非常高的。 了解系统相关软件的版本、模式和参数等，有时候限于应用依赖服务的版本、模式等，性能也会受到一定的影响。性能分析 在系统层面能够影响应用性能的一般包括三个因素：CPU、内存和IO，可以从这三方面进行程序的性能瓶颈分析。CPU分析 当程序响应变慢的时候，首先使用top、vmstat、ps等命令查看系统的cpu使用率是否有异常，从而可以判断出是否是cpu繁忙造成的性能问题。其中，主要通过us（用户进程所占的%）这个数据来看异常的进程信息。当us接近100%甚至更高时，可以确定是cpu繁忙造成的响应缓慢。一般说来，cpu繁忙的原因有以下几个： 线程中有无限空循环、无阻塞、正则匹配或者单纯的计算 发生了频繁的gc 多线程的上下文切换 确定好cpu使用率最高的进程之后就可以使用jstack来打印出异常进程的堆栈信息：jstack [pid] 接下来需要注意的一点是，Linux下所有线程最终还是以轻量级进程的形式存在系统中的，而使用jstack只能打印出进程的信息，这些信息里面包含了此进程下面所有线程（轻量级进程-LWP）的堆栈信息。因此，进一步的需要确定是哪一个线程耗费了大量CPU，此时可以使用top -p [processId] -H来查看，也可以直接通过ps -Le来显示所有进程,包括LWP的资源耗费信息。最后，通过在jstack的输出文件中查找对应的LWP的id即可以定位到相应的堆栈信息。其中需要注意的是线程的状态：RUNNABLE、WAITING等。对于Runnable的进程需要注意是否有耗费cpu的计算。对于Waiting的线程一般是锁的等待操作。 也可以使用jstat来查看对应进程的gc信息，以判断是否是gc造成了cpu繁忙。 jstat -gcutil [pid] 还可以通过vmstat，通过观察内核状态的上下文切换(cs)次数，来判断是否是上下文切换造成的cpu繁忙。 vmstat 1 5 此外，有时候可能会由jit引起一些cpu飚高的情形，如大量方法编译等。这里可以使用-XX:+PrintCompilation这个参数输出jit编译情况，以排查jit编译引起的cpu问题。 内存分析 对Java应用来说，内存主要是由堆外内存和堆内内存组成。 堆外内存 堆外内存主要是JNI、Deflater/Inflater、DirectByteBuffer（nio中会用到）使用的。对于这种堆外内存的分析，还是需要先通过vmstat、sar、top、pidstat(这里的sar,pidstat以及iostat都是sysstat软件套件的一部分，需要单独安装)等查看swap和物理内存的消耗状况再做判断的。此外，对于JNI、Deflater这种调用可以通过Google-preftools来追踪资源使用状况。 堆内内存 此部分内存为Java应用主要的内存区域。通常与这部分内存性能相关的有： 创建的对象：这个是存储在堆中的，需要控制好对象的数量和大小，尤其是大的对象很容易进入老年代 全局集合：全局集合通常是生命周期比较长的，因此需要特别注意全局集合的使用 缓存：缓存选用的数据结构不同，会很大程序影响内存的大小和gc ClassLoader：主要是动态加载类容易造成永久代内存不足 多线程：线程分配会占用本地内存，过多的线程也会造成内存不足 以上使用不当很容易造成： 频繁GC -> Stop the world，使你的应用响应变慢 OOM，直接造成内存溢出错误使得程序退出。OOM又可以分为以下几种： Heap space：堆内存不足 PermGen space：永久代内存不足 Native thread：本地线程没有足够内存可分配 排查堆内存问题的常用工具是jmap，是jdk自带的。一些常用用法如下： 查看jvm内存使用状况：jmap -heap 查看jvm内存存活的对象：jmap -histo:live 把heap里所有对象都dump下来，无论对象是死是活：jmap -dump:format=b,file=xxx.hprof 先做一次full GC，再dump，只包含仍然存活的对象信息：jmap -dump:format=b,live,file=xxx.hprof 此外，不管是使用jmap还是在OOM时产生的dump文件，可以使用Eclipse的MAT(MEMORY ANALYZER TOOL)来分析，可以看到具体的堆栈和内存中对象的信息。当然jdk自带的jhat也能够查看dump文件(启动web端口供开发者使用浏览器浏览堆内对象的信息)。此外，VisualVM也能够打开hprof文件，使用它的heap walker查看堆内存信息。 IO分析 通常与应用性能相关的包括：文件IO和网络IO。文件IO 可以使用系统工具pidstat、iostat、vmstat来查看io的状况。这里可以看一张使用vmstat的结果图。 这里主要注意bi和bo这两个值，分别表示块设备每秒接收的块数量和块设备每秒发送的块数量，由此可以判定io繁忙状况。进一步的可以通过使用strace工具定位对文件io的系统调用。通常，造成文件io性能差的原因不外乎： 大量的随机读写 设备慢 文件太大网络IO 查看网络io状况，一般使用的是netstat工具。可以查看所有连接的状况、数目、端口信息等。例如：当time_wait或者close_wait连接过多时，会影响应用的相应速度。netstat -anp 此外，还可以使用tcpdump来具体分析网络io的数据。当然，tcpdump出的文件直接打开是一堆二进制的数据，可以使用wireshark阅读具体的连接以及其中数据的内容。tcpdump -i eth0 -w tmp.cap -tnn dst port 8080 #监听8080端口的网络请求并打印日志到tmp.cap中 还可以通过查看/proc/interrupts来获取当前系统使用的中断的情况。 各个列依次是：irq的序号， 在各自cpu上发生中断的次数，可编程中断控制器，设备名称（request_irq的dev_name字段） 通过查看网卡设备的终端情况可以判断网络io的状况。其他分析工具 上面分别针对CPU、内存以及IO讲了一些系统/JDK自带的分析工具。除此之外，还有一些综合分析工具或者框架可以更加方便我们对Java应用性能的排查、分析、定位等。VisualVM 这个工具应该是Java开发者们非常熟悉的一款java应用监测工具，原理是通过jmx接口来连接jvm进程，从而能够看到jvm上的线程、内存、类等信息。 进一步查看gc情况，可以安装visual gc插件。此外，visualvm也有btrace的插件，可以可视化直观的编写btrace代码并查看输出日志。 与VisualVm类似的，jconsole也是通过jmx查看远程jvm信息的一款工具，更进一步的，通过它还可以显示具体的线程堆栈信息以及内存中各个年代的占用情况，也支持直接远程执行MBEAN。当然，visualvm通过安装jconsole插件也可以拥有这些功能 但由于这俩工具都是需要ui界面的，因此一般都是通过本地远程连接服务器jvm进程。服务器环境下，一般并不用此种方式。Java Mission Control(jmc) 此工具是jdk7 u40开始自带的，原来是JRockit上的工具，是一款采样型的集诊断、分析和监控与一体的非常强大的工具: https://docs.oracle.com/javacomponents/jmc-5-5/jmc-user-guide/toc.htm。但是此工具是基于JFR(jcmd JFR.start name=test duration=60s settings=template.jfc filename=output.jfr)的，而开启JFR需要商业证书：jcmd VM.unlock_commercial_features。 Btrace 这里不得不提的是btrace这个神器，它使用java attach api+ java agent + instrument api能够实现jvm的动态追踪。在不重启应用的情况下可以加入拦截类的方法以打印日志等。具体的用法可以参考Btrace入门到熟练小工完全指南。Jwebap Jwebap是一款JavaEE性能检测框架，基于asm增强字节码实现。支持：http请求、jdbc连接、method的调用轨迹跟踪以及次数、耗时的统计。由此可以获取最耗时的请求、方法，并可以查看jdbc连接的次数、是否关闭等。但此项目是2006年的一个项目，已经将近10年没有更新。根据笔者使用，已经不支持jdk7编译的应用。如果要使用，建议基于原项目二次开发，同时也可以加入对redis连接的轨迹跟踪。当然，基于字节码增强的原理，也可以实现自己的JavaEE性能监测框架。 上图来自二次开发过的jwebap，已经支持jdk8和redis连接追踪。 useful-scripts 开源项目：https://github.com/superhj1987/useful-scripts 封装了很多常用的性能分析命令，比如上文讲的打印繁忙java线程堆栈信息，只需要执行一个脚本即可。 性能调优 与性能分析相对应，性能调优同样分为三部分。 CPU调优 不要存在一直运行的线程(无限while循环)，可以使用sleep休眠一段时间。这种情况普遍存在于一些pull方式消费数据的场景下，当一次pull没有拿到数据的时候建议sleep一下，再做下一次pull。 轮询的时候可以使用wait/notify机制 避免循环、正则表达式匹配、计算过多，包括使用String的format、split、replace方法(可以使用apache的commons-lang里的StringUtils对应的方法)，使用正则去判断邮箱格式(有时候会造成死循环)、序列/反序列化等。 结合jvm和代码，避免产生频繁的gc，尤其是full GC。 此外，使用多线程的时候，还需要注意以下几点： 使用线程池，减少线程数以及线程的切换 多线程对于锁的竞争可以考虑减小锁的粒度(使用ReetrantLock)、拆分锁(类似ConcurrentHashMap分bucket上锁), 或者使用CAS、ThreadLocal、不可变对象等无锁技术。此外，多线程代码的编写最好使用jdk提供的并发包、Executors框架以及ForkJoin等，此外Discuptor和Actor在合适的场景也可以使用。内存调优 内存的调优主要就是对jvm的调优。 合理设置各个代的大小。避免新生代设置过小(不够用，经常minor gc并进入老年代)以及过大(会产生碎片)，同样也要避免Survivor设置过大和过小。 选择合适的GC策略。需要根据不同的场景选择合适的gc策略。这里需要说的是，cms并非全能的。除非特别需要再设置，毕竟cms的新生代回收策略parnew并非最快的，且cms会产生碎片。此外，G1直到jdk8的出现也并没有得到广泛应用，并不建议使用。 jvm启动参数配置-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:[log_path]，以记录gc日志，便于排查问题。 其中，对于第一点，具体的还有一点建议： 年轻代大小选择：响应时间优先的应用，尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生gc的频率是最小的。同时，也能够减少到达年老代的对象。吞吐量优先的应用，也尽可能的设置大，因为对响应时间没有要求，垃圾收集可以并行进行，建议适合8CPU以上的应用使用。 年老代大小选择：响应时间优先的应用，年老代一般都是使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得： 并发垃圾收集信息 持久代并发收集次数 传统GC信息 花在年轻代和年老代回收上的时间比例 一般吞吐量优先的应用都应该有一个很大的年轻代和一个较小的年老代。这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代存放长期存活对象。 此外，较小堆引起的碎片问题：因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：-XX:+UseCMSCompactAtFullCollection，使用并发收集器时，开启对年老代的压缩。同时使用-XX:CMSFullGCsBeforeCompaction=xx设置多少次Full GC后，对年老代进行压缩。 其余对于jvm的优化问题可见后面JVM参数进阶一节。 代码上，也需要注意： 避免保存重复的String对象，同时也需要小心String.subString()与String.intern()的使用，尤其是后者其底层数据结构为StringTable，当字符串大量不重复时，会使得StringTable非常大(一个固定大小的hashmap，可以由参数-XX:StringTableSize=N设置大小)，从而影响young gc的速度。在jackson和fastjson中使用了此方法，某些场景下会引起gc问题: YGC越来越慢，为什么。 尽量不要使用finalizer 释放不必要的引用：ThreadLocal使用完记得释放以防止内存泄漏，各种stream使用完也记得close。 使用对象池避免无节制创建对象，造成频繁gc。但不要随便使用对象池，除非像连接池、线程池这种初始化/创建资源消耗较大的场景， 缓存失效算法，可以考虑使用SoftReference、WeakReference保存缓存对象 谨慎热部署/加载的使用，尤其是动态加载类等 不要用Log4j输出文件名、行号，因为Log4j通过打印线程堆栈实现，生成大量String。此外，使用log4j时，建议此种经典用法，先判断对应级别的日志是否打开，再做操作，否则也会生成大量String。if (logger.isInfoEnabled()) { logger.info(msg); } IO调优 文件IO上需要注意： 考虑使用异步写入代替同步写入，可以借鉴redis的aof机制。 利用缓存，减少随机读 尽量批量写入，减少io次数和寻址 使用数据库代替文件存储 网络IO上需要注意： 和文件IO类似，使用异步IO、多路复用IO/事件驱动IO代替同步阻塞IO 批量进行网络IO,减少IO次数 使用缓存，减少对网络数据的读取 使用协程: Quasar其他优化建议 算法、逻辑上是程序性能的首要，遇到性能问题，应该首先优化程序的逻辑处理 优先考虑使用返回值而不是异常表示错误 查看自己的代码是否对内联是友好的: 你的Java代码对JIT编译友好么？ 此外，jdk7、8在jvm的性能上做了一些增强： 通过-XX:+TieredCompilation开启JDK7的多层编译（tiered compilation）支持。多层编译结合了客户端C1编译器和服务端C2编译器的优点(客户端编译能够快速启动和及时优化，服务器端编译可以提供更多的高级优化)，是一个非常高效利用资源的切面方案。在开始时先进行低层次的编译，同时收集信息，在后期再进一步进行高层次的编译进行高级优化。需要注意的一点：这个参数会消耗比较多的内存资源，因为同一个方法被编译了多次，存在多份native内存拷贝，建议把code cache调大一点儿（-XX:+ReservedCodeCacheSize，InitialCodeCacheSize）。否则有可能由于code cache不足，jit编译的时候不停的尝试清理code cache，丢弃无用方法，消耗大量资源在jit线程上。 Compressed Oops：压缩指针在jdk7中的server模式下已经默认开启。 Zero-Based Compressed Ordinary Object Pointers：当使用了上述的压缩指针时，在64位jvm上，会要求操作系统保留从一个虚拟地址0开始的内存。如果操作系统支持这种请求，那么就开启了Zero-Based Compressed Oops。这样可以使得无须在java堆的基地址添加任何地址补充即可把一个32位对象的偏移解码成64位指针。 逃逸分析(Escape Analysis): Server模式的编译器会根据代码的情况，来判断相关对象的逃逸类型，从而决定是否在堆中分配空间，是否进行标量替换(在栈上分配原子类型局部变量)。此外，也可以根据调用情况来决定是否自动消除同步控制，如StringBuffer。这个特性从Java SE 6u23开始就默认开启。 NUMA Collector Enhancements：这个重要针对的是The Parallel Scavenger垃圾回收器。使其能够利用NUMA (Non Uniform Memory Access，即每一个处理器核心都有本地内存，能够低延迟、高带宽访问) 架构的机器的优势来更快的进行gc。可以通过-XX:+UseNUMA开启支持。 此外，网上还有很多过时的建议，不要再盲目跟随: 变量用完设置为null，加快内存回收，这种用法大部分情况下并没有意义。一种情况除外：如果有个Java方法没有被JIT编译但里面仍然有代码会执行比较长时间，那么在那段会执行长时间的代码前显式将不需要的引用类型局部变量置null是可取的。具体的可以见R大的解释：https://www.zhihu.com/question/48059457/answer/113538171 方法参数设置为final，这种用法也没有太大的意义，尤其在jdk8中引入了effective final，会自动识别final变量。JVM参数进阶 jvm的参数设置一直是比较理不清的地方，很多时候都搞不清都有哪些参数可以配置，参数是什么意思，为什么要这么配置等。这里主要针对这些做一些常识性的说明以及对一些容易让人进入陷阱的参数做一些解释。 以下所有都是针对Oracle/Sun JDK 6来讲 启动参数默认值 Java有很多的启动参数，而且很多版本都并不一样。但是现在网上充斥着各种资料，如果不加辨别的全部使用，很多是没有效果或者本来就是默认值的。一般的，我们可以通过使用java -XX:+PrintFlagsInitial来查看所有可以设置的参数以及其默认值。也可以在程序启动的时候加入-XX:+PrintCommandLineFlags来查看与默认值不相同的启动参数。如果想查看所有启动参数(包括和默认值相同的)，可以使用-XX:+PrintFlagsFinal。 输出里“=”表示使用的是初始默认值，而“:=”表示使用的不是初始默认值，可能是命令行传进来的参数、配置文件里的参数或者是ergonomics自动选择了别的值。 此外，还可以使用jinfo命令显示启动的参数。 jinfo -flags [pid] #查看目前启动使用的有效参数 jinfo -flag [flagName] [pid] #查看对应参数的值 这里需要指出的是，当你配置jvm参数时，最好是先通过以上命令查看对应参数的默认值再确定是否需要设置。也最好不要配置你搞不清用途的参数，毕竟默认值的设置是有它的合理之处的。 动态设置参数 当Java应用启动后，定位到了是GC造成的性能问题，但是你启动的时候并没有加入打印gc的参数，很多时候的做法就是重新加参数然后重启应用。但这样会造成一定时间的服务不可用。最佳的做法是能够在不重启应用的情况下，动态设置参数。使用jinfo可以做到这一点(本质上还是基于jmx的)。jinfo -flag [+/-][flagName] [pid] #启用/禁止某个参数 jinfo -flag [flagName=value] [pid] #设置某个参数 对于上述的gc的情况，就可以使用以下命令打开heap dump并设置dump路径。jinfo -flag +HeapDumpBeforeFullGC [pid] jinfo -flag +HeapDumpAfterFullGC [pid] jinfo -flag HeapDumpPath=/home/dump/dir [pid] 同样的也可以动态关闭。jinfo -flag -HeapDumpBeforeFullGC [pid] jinfo -flag -HeapDumpAfterFullGC [pid] 其他的参数设置类似。 -verbose:gc 与 -XX:+PrintGCDetails 很多gc推荐设置都同时设置了这两个参数，其实，只要打开了-XX:+PrintGCDetails，前面的选项也会同时打开，无须重复设置。 -XX:+DisableExplicitGC 这个参数的作用就是使得system.gc变为空调用，很多推荐设置里面都是建议开启的。但是，如果你用到了NIO或者其他使用到堆外内存的情况，使用此选项会造成oom。可以用XX:+ExplicitGCInvokesConcurrent或XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses(配合CMS使用，使得system.gc触发一次并发gc)代替。 此外，还有一个比较有意思的地方。如果你不设置此选项的话，当你使用了RMI的时候，会周期性地来一次full gc。这个现象是由于分布式gc造成的，为RMI服务。具体的可见此链接内容中与dgc相关的：http://docs.oracle.com/javase/6/docs/technotes/guides/rmi/sunrmiproperties.html MaxDirectMemorySize 此参数是设置的堆外内存的上限值。当不设置的时候为-1，此值为-Xmx减去一个survivor space的预留大小。 由于遗留原因，作用相同的参数 -Xss 与 -XX:ThreadStackSize -Xmn 与 -XX:NewSize，此外这里需要注意的是设置了-Xmn的话，NewRatio就没作用了。 -XX:MaxTenuringThreshold 使用工具查看此值默认值为15，但是选择了CMS的时候，此值会变成4。当此值设置为0时，所有eden里的活对象在经历第一次minor GC的时候就会直接晋升到old gen，survivor space直接就没用。还有值得注意的一点，当使用并行回收器时，此值是没有作用的，并行回收器默认是自动调整这些参数以求达到吞吐量最大的。此外，即使是使用CMS等回收器，晋升到老年代的age也不是不变的，当某一age的对象的大小达到年轻代的50%时，这个age会被动态调整为晋升年龄。 -XX:HeapDumpPath 使用此参数可以指定-XX:+HeapDumpBeforeFullGC、-XX:+HeapDumpAfterFullGC、-XX:+HeapDumpOnOutOfMemoryError触发heap dump文件的存储位置。 -XX:+UseAdaptiveSizePolicy 此参数在并行回收器时是默认开启的，会根据应用运行状况做自我调整，如MaxTenuringThreshold、survivor区大小等。其中第一次晋升老年代的年龄以InitialTenuringThreshold（默认为7）开始，后续会自动调整。如果希望跟踪每次minor GC后新的存活周期的阈值，可在启动参数上增加：-XX:+PrintTenuringDistribution。如果想要可以配置这些参数，可以关闭此选项，但paralle的性能很难达到最佳。其他垃圾回收期则慎重开启此开关。 "},"语言/C/":{"url":"语言/C/","title":"C","keywords":"","body":"C C语言 C是一种通用的编程语言，广泛用于系统软件与应用软件的开发。于1969年至1973年间，为了移植与开发UNIX操作系统，由丹尼斯·里奇与肯·汤普逊，以B语言为基础，在贝尔实验室设计、开发出来。 C语言具有高效、灵活、功能丰富、表达力强和较高的可移植性等特点，在程序设计中备受青睐，成为最近25年使用最为广泛的编程语言。当前，C语言编译器普遍存在于各种不同的操作系统中，例如Microsoft Windows、macOS、Linux、Unix等。C语言的设计影响了众多后来的编程语言，例如C++、Objective-C、Java、C#等。 二十世纪八十年代，为了避免各开发厂商用的C语言的语法产生差异，由美国国家标准局为C语言订定了一套完整的国际标准语法，称为ANSI C，作为C语言的标准。二十世纪八十年代至今的有关程序开发工具，一般都支持符合ANSI C的语法。 C语言设计目标是提供一种能以简易的方式编译、处理低级存储器、产生少量的机器代码以及不需要任何运行环境支持便能运行的编程语言。C语言也很适合搭配汇编语言来使用。尽管C语言提供许多低级处理的功能，但仍保持良好跨平台的特性，以一个标准规格写出的C语言程序可在许多电脑平台上进行编译，甚至包含一些嵌入式处理器（微控制器或称MCU）以及超级电脑等作业平台。 特性 C语言是一个有结构化程序设计、具有变量作用域（variable scope）以及递归功能的过程式语言。 C语言传递参数均是以值传递（pass by value）[3]，另外也可以传递指针（a pointer passed by value）。 不同的变量类型可以用结构体（struct）组合在一起。 只有32个保留字（reserved keywords），使变量、函数命名有更多弹性。 部分的变量类型可以转换，例如整型和字符型变量。 透过指针（pointer），C语言可以容易的对存储器进行低级控制。 编译预处理（preprocessor）让C语言的编译更具有弹性。 C语言中的运算符号 符号 含义 ()、 []、 -> 、 .、 !、 ++、 -- 圆括号、方括号、指针、成员、逻辑非、自加、自减 ++ 、 -- 、 * 、 & 、 ~ 、 ! 、 + 、 - 、 sizeof、(cast) 单目运算符 * 、 / 、 %、== 算术运算符 + 、 - 算术运算符 > 位运算符 、 >= 关系运算符 == 、 != 关系运算符号 & 位与 ^ 位异或 \\ 位或 && 逻辑与 \\ \\ 逻辑或 ? : 条件运算符 = 、 += 、 -= 、 *= 、 /= 、 %= 、 &= 、 \\ = 、 ^= 赋值运算符 , 顺序运算符 比较特别的是，比特右移（>>）运算符可以是算术（左端补最高有效位）或是逻辑（左端补 0）位移。例如，将 11100011 右移 3 比特，算术右移后成为 11111100，逻辑右移则为 00011100。因算术比特右移较适于处理带负号整数，所以几乎所有的编译器都是算术比特右移。 运算符的优先级从高到低大致是：单目运算符、算术运算符、关系运算符、逻辑运算符、条件运算符、赋值运算符（=）和逗号运算符。 安全性 符号 安全性 符号 安全性 符号 安全性 符号 安全性 + 溢出,包裹,循环 -= 溢出,包裹,循环,截裁 >> 无 >= 无 - 溢出,包裹,循环 *= 溢出,包裹,循环,截裁 & 无 == 无 * 溢出,包裹,循环 /= 溢出,截裁 ~ 无 != 无 % 溢出 溢出,包裹,循环,截裁 ! 无 && 无 ++ >>= 截裁 un+ 无 \\ \\ 无 -- &= 截裁 un- 溢出,包裹,截裁 ?: 无 = \\ = 截裁 无 += 溢出,包裹,截裁 > 无 基础数据类型 关键字 位长(字节) 范围 格式化字符串 char 1 bytes -128..127（或0..255，与体系结构相关） %c unsigned char 1bytes 0..255 %c, %hhu signed char 1bytes -128..127 %c, %hhd, %hhi int 2bytes(16位系统) 或4bytes -32768..32767 或-2147483648..2147483647 %i, %d unsigned int 2bytes 或 4 bytes 0..65535 或0..4294967295 %u signed int 2bytes 或4bytes -32768..32767 或-2147483648..2147483647 %i, %d short int 2bytes -32768..32767 %hi, %hd unsigned short 2 bytes 0..65535 %hu signed short 2bytes -32768..32767 %hi, %hd long int 4bytes 或8bytes -2147483648..2147483647 或-9223372036854775808..9223372036854775807 %li, %ld unsigned long 4bytes 或8 bytes 0..4294967295 或0..18446744073709551615 %lu signed long 4 bytes或8bytes -2147483648..2147483647 或-9223372036854775808..9223372036854775807 %li, %ld long long 8bytes -9223372036854775808..9223372036854775807 %lli, %lld unsigned long long 8bytes 0..18446744073709551615 %llu float 4bytes 2.939x10−38..3.403x10+38 (7 sf) %f, %e, %g double 8bytes 5.563x10−309..1.798x10+308 (15 sf) %lf, %e, %g long double 10bytes或16bytes 7.065x10-9865..1.415x109864 (18 sf或33 sf) %Lf, %Le, %Lg 内存管理 C语言的特色之一是：程序员必须亲自处理内存的分配细节。 C语言使用栈（Stack）来保存函数返回地址／栈帧基址、完成函数的参数传递和函数局部变量的存储。 如果程序需要在运行的过程中动态分配内存，可以利用堆（Heap）来实现。 基本上C程序的元素存储在内存的时候有3种分配策略： 静态分配 如果一个变量声明为全局变量或者是函数的静态变量，这个变量的存储将使用静态分配方式。静态分配的内存一般会被编译器放在数据段或代码段来存储，具体取决于实现。这样做的前提是，在编译时就必须确定变量的大小。 以IA32的x86平台及gcc编译器为例，全局及静态变量放在数据段的低端；全局及静态常量放在代码段的高端。 自动分配 函数的自动局部变量应该随着函数的返回会自动释放（失效），这个要求在一般的体系中都是利用栈（Stack）来满足的。相比于静态分配，这时候，就不必绝对要求这个变量在编译时就必须确定变量的大小，运行时才决定也不迟，但是C89仍然要求在编译时就要确定，而C99放松了这个限制。但无论是C89还是C99，都不允许一个已经分配的自动变量运行时改变大小。 所以说C函数永远不应该返回一个局部变量的地址。 要指出的是，自动分配也属于动态分配，甚至可以用alloca函数来像分配堆（Heap）一样进行分配，而且释放是自动的。 动态分配 还有一种更加特殊的情况，变量的大小在运行时有可能改变，或者虽然单个变量大小不变，变量的数目却有很大弹性，不能静态分配或者自动分配，这时候可以使用堆（Heap）来满足要求。ANSI C定义的堆操作函数是malloc、calloc、realloc和free。 使用堆（Heap）内存将带来额外的开销和风险。 安全问题 C语言的特色之一是：语言不负责内存边界检查。此特性容易导致缓冲区溢出问题。 工具软件 工具软件可以帮助程序设计者避免一些程序中潜藏或容易出现的问题，例如常会造成程序未预期动作或是运行期错误的代码。 许多语言都有自动源代码检查及审计工具，C语言也有类似工具，像是Lint。可以在程序刚写好时用Lint找出可能有问题的程序，通过Lint后再用C编译器进行编译，许多编译器也可以设置是否要针对一些可能有问题的代码提出警告。MISRA C是一套针对嵌入式系统的法则，可主要也是避免一些可能有问题的代码。 也有一些编译器、程序库或操作系统可以处理一些非标准C语言的功能，例如边界值检查、缓存溢出侦测、序列化及自动垃圾回收功能。 使用像Valgrind或IBM Rational Purify等软件工具，或者链接有特别malloc函数的程序库，有助于找出一些运行期存储器使用的问题。 保留关键字 以下是C语言的保留关键字： char short int unsigned long float double struct union void enum signed const volatile typedef auto register static extern break case continue default do else for goto if return switch while sizeof C99新增关键字 _Bool _Complex _Imaginary inline restrict C11新增关键字 _Alignas _Alignof _Atomic _Generic _Noreturn _Static_assert _Thread_local "},"语言/C/C生成身份证号.html":{"url":"语言/C/C生成身份证号.html","title":"C生成身份证号","keywords":"","body":"C生成身份证号 char AreaCode[7]; char Date[9]; char ID[19]; char*IDgenerate(); char*randomAreaCode(); char*randomDate(); char getVerifyID(const char *pczID); char*IDgenerate() { char srandomNumber[4]; int randomNumber=rand()%899+100; *ID=NULL; *srandomNumber=NULL; *AreaCode=NULL; randomAreaCode(); strcat(ID,AreaCode); *Date=NULL; randomDate(); strcat(ID,Date); strcat(ID,itoa(randomNumber,srandomNumber,10)); sprintf(ID,\"%s%c\",ID,getVerifyID(ID)); return ID; } //随机生成前六位区域号 char*randomAreaCode() { char a[][7]={\"110000\",\"110100\",\"110101\",\"110102\",\"110103\",\"110104\",\"110105\",\"110106\",\"110107\",\"110108\",\"110109\",\"110111\",\"110112\",\"110113\",\"110114\",\"110115\",\"110116\",\"110117\",\"110200\",\"110228\",\"110229\",\"120000\",\"120100\",\"120101\",\"120102\",\"120103\",\"120104\",\"120105\",\"120106\",\"120110\",\"120111\",\"120112\",\"120113\",\"120114\",\"120115\",\"120200\",\"120221\",\"120223\",\"120225\",\"130000\",\"130100\",\"130101\",\"130102\",\"130103\",\"130104\",\"130105\",\"130107\",\"130108\",\"130121\",\"130123\",\"130124\",\"130125\",\"130126\",\"130127\",\"130128\",\"130129\",\"130130\",\"130131\",\"130132\",\"130133\",\"130181\",\"130182\",\"130183\",\"130184\",\"130185\",\"130200\",\"130201\",\"130202\",\"130203\",\"130204\",\"130205\",\"130207\",\"130208\",\"130223\",\"130224\",\"130225\",\"130227\",\"130229\",\"130230\",\"130281\",\"130283\",\"130300\",\"130301\",\"130302\",\"130303\",\"130304\",\"130321\",\"130322\",\"130323\",\"130324\",\"130400\",\"130401\",\"130402\",\"130403\",\"130404\",\"130406\",\"130421\",\"130423\",\"130424\",\"130425\",\"130426\",\"130427\",\"130428\",\"130429\",\"130430\",\"130431\",\"130432\",\"130433\",\"130434\",\"130435\",\"130481\",\"130500\",\"130501\",\"130502\",\"130503\",\"130521\",\"130522\",\"130523\",\"130524\",\"130525\",\"130526\",\"130527\",\"130528\",\"130529\",\"130530\",\"130531\",\"130532\",\"130533\",\"130534\",\"130535\",\"130581\",\"130582\",\"130600\",\"130601\",\"130602\",\"130603\",\"130604\",\"130621\",\"130622\",\"130623\",\"130624\",\"130625\",\"130626\",\"130627\",\"130628\",\"130629\",\"130630\",\"130631\",\"130632\",\"130633\",\"130634\",\"130635\",\"130636\",\"130637\",\"130638\",\"130681\",\"130682\",\"130683\",\"130684\",\"130700\",\"130701\",\"130702\",\"130703\",\"130705\",\"130706\",\"130721\",\"130722\",\"130723\",\"130724\",\"130725\",\"130726\",\"130727\",\"130728\",\"130729\",\"130730\",\"130731\",\"130732\",\"130733\",\"130800\",\"130801\",\"130802\",\"130803\",\"130804\",\"130821\",\"130822\",\"130823\",\"130824\",\"130825\",\"130826\",\"130827\",\"130828\",\"130900\",\"130901\",\"130902\",\"130903\",\"130921\",\"130922\",\"130923\",\"130924\",\"130925\",\"130926\",\"130927\",\"130928\",\"130929\",\"130930\",\"130981\",\"130982\",\"130983\",\"130984\",\"131000\",\"131001\",\"131002\",\"131003\",\"131022\",\"131023\",\"131024\",\"131025\",\"131026\",\"131028\",\"131081\",\"131082\",\"131100\",\"131101\",\"131102\",\"131121\",\"131122\",\"131123\",\"131124\",\"131125\",\"131126\",\"131127\",\"131128\",\"131181\",\"131182\",\"140000\",\"140100\",\"140101\",\"140105\",\"140106\",\"140107\",\"140108\",\"140109\",\"140110\",\"140121\",\"140122\",\"140123\",\"140181\",\"140200\",\"140201\",\"140202\",\"140203\",\"140211\",\"140212\",\"140221\",\"140222\",\"140223\",\"140224\",\"140225\",\"140226\",\"140227\",\"140300\",\"140301\",\"140302\",\"140303\",\"140311\",\"140321\",\"140322\",\"140400\",\"140401\",\"140402\",\"140411\",\"140421\",\"140423\",\"140424\",\"140425\",\"140426\",\"140427\",\"140428\",\"140429\",\"140430\",\"140431\",\"140481\",\"140500\",\"140501\",\"140502\",\"140521\",\"140522\",\"140524\",\"140525\",\"140581\",\"140600\",\"140601\",\"140602\",\"140603\",\"140621\",\"140622\",\"140623\",\"140624\",\"140700\",\"140701\",\"140702\",\"140721\",\"140722\",\"140723\",\"140724\",\"140725\",\"140726\",\"140727\",\"140728\",\"140729\",\"140781\",\"140800\",\"140801\",\"140802\",\"140821\",\"140822\",\"140823\",\"140824\",\"140825\",\"140826\",\"140827\",\"140828\",\"140829\",\"140830\",\"140881\",\"140882\",\"140900\",\"140901\",\"140902\",\"140921\",\"140922\",\"140923\",\"140924\",\"140925\",\"140926\",\"140927\",\"140928\",\"140929\",\"140930\",\"140931\",\"140932\",\"140981\",\"141000\",\"141001\",\"141002\",\"141021\",\"141022\",\"141023\",\"141024\",\"141025\",\"141026\",\"141027\",\"141028\",\"141029\",\"141030\",\"141031\",\"141032\",\"141033\",\"141034\",\"141081\",\"141082\",\"141100\",\"141101\",\"141102\",\"141121\",\"141122\",\"141123\",\"141124\",\"141125\",\"141126\",\"141127\",\"141128\",\"141129\",\"141130\",\"141181\",\"141182\",\"150000\",\"150100\",\"150101\",\"150102\",\"150103\",\"150104\",\"150105\",\"150121\",\"150122\",\"150123\",\"150124\",\"150125\",\"150200\",\"150201\",\"150202\",\"150203\",\"150204\",\"150205\",\"150206\",\"150207\",\"150221\",\"150222\",\"150223\",\"150300\",\"150301\",\"150302\",\"150303\",\"150304\",\"150400\",\"150401\",\"150402\",\"150403\",\"150404\",\"150421\",\"150422\",\"150423\",\"150424\",\"150425\",\"150426\",\"150428\",\"150429\",\"150430\",\"150500\",\"150501\",\"150502\",\"150521\",\"150522\",\"150523\",\"150524\",\"150525\",\"150526\",\"150581\",\"150600\",\"150601\",\"150602\",\"150621\",\"150622\",\"150623\",\"150624\",\"150625\",\"150626\",\"150627\",\"150700\",\"150701\",\"150702\",\"150721\",\"150722\",\"150723\",\"150724\",\"150725\",\"150726\",\"150727\",\"150781\",\"150782\",\"150783\",\"150784\",\"150785\",\"150800\",\"150801\",\"150802\",\"150821\",\"150822\",\"150823\",\"150824\",\"150825\",\"150826\",\"150900\",\"150901\",\"150902\",\"150921\",\"150922\",\"150923\",\"150924\",\"150925\",\"150926\",\"150927\",\"150928\",\"150929\",\"150981\",\"152200\",\"152201\",\"152202\",\"152221\",\"152222\",\"152223\",\"152224\",\"152500\",\"152501\",\"152502\",\"152522\",\"152523\",\"152524\",\"152525\",\"152526\",\"152527\",\"152528\",\"152529\",\"152530\",\"152531\",\"152900\",\"152921\",\"152922\",\"152923\",\"210000\",\"210100\",\"210101\",\"210102\",\"210103\",\"210104\",\"210105\",\"210106\",\"210111\",\"210112\",\"210113\",\"210114\",\"210122\",\"210123\",\"210124\",\"210181\",\"210200\",\"210201\",\"210202\",\"210203\",\"210204\",\"210211\",\"210212\",\"210213\",\"210224\",\"210281\",\"210282\",\"210283\",\"210300\",\"210301\",\"210302\",\"210303\",\"210304\",\"210311\",\"210321\",\"210323\",\"210381\",\"210400\",\"210401\",\"210402\",\"210403\",\"210404\",\"210411\",\"210421\",\"210422\",\"210423\",\"210500\",\"210501\",\"210502\",\"210503\",\"210504\",\"210505\",\"210521\",\"210522\",\"210600\",\"210601\",\"210602\",\"210603\",\"210604\",\"210624\",\"210681\",\"210682\",\"210700\",\"210701\",\"210702\",\"210703\",\"210711\",\"210726\",\"210727\",\"210781\",\"210782\",\"210800\",\"210801\",\"210802\",\"210803\",\"210804\",\"210811\",\"210881\",\"210882\",\"210900\",\"210901\",\"210902\",\"210903\",\"210904\",\"210905\",\"210911\",\"210921\",\"210922\",\"211000\",\"211001\",\"211002\",\"211003\",\"211004\",\"211005\",\"211011\",\"211021\",\"211081\",\"211100\",\"211101\",\"211102\",\"211103\",\"211121\",\"211122\",\"211200\",\"211201\",\"211202\",\"211204\",\"211221\",\"211223\",\"211224\",\"211281\",\"211282\",\"211300\",\"211301\",\"211302\",\"211303\",\"211321\",\"211322\",\"211324\",\"211381\",\"211382\",\"211400\",\"211401\",\"211402\",\"211403\",\"211404\",\"211421\",\"211422\",\"211481\",\"220000\",\"220100\",\"220101\",\"220102\",\"220103\",\"220104\",\"220105\",\"220106\",\"220112\",\"220122\",\"220181\",\"220182\",\"220183\",\"220200\",\"220201\",\"220202\",\"220203\",\"220204\",\"220211\",\"220221\",\"220281\",\"220282\",\"220283\",\"220284\",\"220300\",\"220301\",\"220302\",\"220303\",\"220322\",\"220323\",\"220381\",\"220382\",\"220400\",\"220401\",\"220402\",\"220403\",\"220421\",\"220422\",\"220500\",\"220501\",\"220502\",\"220503\",\"220521\",\"220523\",\"220524\",\"220581\",\"220582\",\"220600\",\"220601\",\"220602\",\"220605\",\"220621\",\"220622\",\"220623\",\"220681\",\"220700\",\"220701\",\"220702\",\"220721\",\"220722\",\"220723\",\"220724\",\"220800\",\"220801\",\"220802\",\"220821\",\"220822\",\"220881\",\"220882\",\"222400\",\"222401\",\"222402\",\"222403\",\"222404\",\"222405\",\"222406\",\"222424\",\"222426\",\"230000\",\"230100\",\"230101\",\"230102\",\"230103\",\"230104\",\"230108\",\"230109\",\"230110\",\"230111\",\"230123\",\"230124\",\"230125\",\"230126\",\"230127\",\"230128\",\"230129\",\"230182\",\"230183\",\"230184\",\"230200\",\"230201\",\"230202\",\"230203\",\"230204\",\"230205\",\"230206\",\"230207\",\"230208\",\"230221\",\"230223\",\"230224\",\"230225\",\"230227\",\"230229\",\"230230\",\"230231\",\"230281\",\"230300\",\"230301\",\"230302\",\"230303\",\"230304\",\"230305\",\"230306\",\"230307\",\"230321\",\"230381\",\"230382\",\"230400\",\"230401\",\"230402\",\"230403\",\"230404\",\"230405\",\"230406\",\"230407\",\"230421\",\"230422\",\"230500\",\"230501\",\"230502\",\"230503\",\"230505\",\"230506\",\"230521\",\"230522\",\"230523\",\"230524\",\"230600\",\"230601\",\"230602\",\"230603\",\"230604\",\"230605\",\"230606\",\"230621\",\"230622\",\"230623\",\"230624\",\"230700\",\"230701\",\"230702\",\"230703\",\"230704\",\"230705\",\"230706\",\"230707\",\"230708\",\"230709\",\"230710\",\"230711\",\"230712\",\"230713\",\"230714\",\"230715\",\"230716\",\"230722\",\"230781\",\"230800\",\"230801\",\"230803\",\"230804\",\"230805\",\"230811\",\"230822\",\"230826\",\"230828\",\"230833\",\"230881\",\"230882\",\"230900\",\"230901\",\"230902\",\"230903\",\"230904\",\"230921\",\"231000\",\"231001\",\"231002\",\"231003\",\"231004\",\"231005\",\"231024\",\"231025\",\"231081\",\"231083\",\"231084\",\"231085\",\"231100\",\"231101\",\"231102\",\"231121\",\"231123\",\"231124\",\"231181\",\"231182\",\"231200\",\"231201\",\"231202\",\"231221\",\"231222\",\"231223\",\"231224\",\"231225\",\"231226\",\"231281\",\"231282\",\"231283\",\"232700\",\"232721\",\"232722\",\"232723\",\"310000\",\"310100\",\"310101\",\"310103\",\"310104\",\"310105\",\"310106\",\"310107\",\"310108\",\"310109\",\"310110\",\"310112\",\"310113\",\"310114\",\"310115\",\"310116\",\"310117\",\"310118\",\"310120\",\"310200\",\"310230\",\"320000\",\"320100\",\"320101\",\"320102\",\"320103\",\"320104\",\"320105\",\"320106\",\"320107\",\"320111\",\"320113\",\"320114\",\"320115\",\"320116\",\"320124\",\"320125\",\"320200\",\"320201\",\"320202\",\"320203\",\"320204\",\"320205\",\"320206\",\"320211\",\"320281\",\"320282\",\"320300\",\"320301\",\"320302\",\"320303\",\"320304\",\"320305\",\"320311\",\"320321\",\"320322\",\"320323\",\"320324\",\"320381\",\"320382\",\"320400\",\"320401\",\"320402\",\"320404\",\"320405\",\"320411\",\"320412\",\"320481\",\"320482\",\"320500\",\"320501\",\"320502\",\"320503\",\"320504\",\"320505\",\"320506\",\"320507\",\"320581\",\"320582\",\"320583\",\"320584\",\"320585\",\"320600\",\"320601\",\"320602\",\"320611\",\"320621\",\"320623\",\"320681\",\"320682\",\"320684\",\"320700\",\"320701\",\"320703\",\"320705\",\"320706\",\"320721\",\"320722\",\"320723\",\"320724\",\"320800\",\"320801\",\"320802\",\"320803\",\"320804\",\"320811\",\"320826\",\"320829\",\"320830\",\"320831\",\"320900\",\"320901\",\"320902\",\"320903\",\"320921\",\"320922\",\"320923\",\"320924\",\"320925\",\"320981\",\"320982\",\"321000\",\"321001\",\"321002\",\"321003\",\"321011\",\"321023\",\"321081\",\"321084\",\"321088\",\"321100\",\"321101\",\"321102\",\"321111\",\"321112\",\"321181\",\"321182\",\"321183\",\"321200\",\"321201\",\"321202\",\"321203\",\"321281\",\"321282\",\"321283\",\"321284\",\"321300\",\"321301\",\"321302\",\"321311\",\"321322\",\"321323\",\"321324\",\"330000\",\"330100\",\"330101\",\"330102\",\"330103\",\"330104\",\"330105\",\"330106\",\"330108\",\"330109\",\"330110\",\"330122\",\"330127\",\"330182\",\"330183\",\"330185\",\"330200\",\"330201\",\"330203\",\"330204\",\"330205\",\"330206\",\"330211\",\"330212\",\"330225\",\"330226\",\"330281\",\"330282\",\"330283\",\"330300\",\"330301\",\"330302\",\"330303\",\"330304\",\"330322\",\"330324\",\"330326\",\"330327\",\"330328\",\"330329\",\"330381\",\"330382\",\"330400\",\"330401\",\"330402\",\"330411\",\"330421\",\"330424\",\"330481\",\"330482\",\"330483\",\"330500\",\"330501\",\"330502\",\"330503\",\"330521\",\"330522\",\"330523\",\"330600\",\"330601\",\"330602\",\"330621\",\"330624\",\"330681\",\"330682\",\"330683\",\"330700\",\"330701\",\"330702\",\"330703\",\"330723\",\"330726\",\"330727\",\"330781\",\"330782\",\"330783\",\"330784\",\"330800\",\"330801\",\"330802\",\"330803\",\"330822\",\"330824\",\"330825\",\"330881\",\"330900\",\"330901\",\"330902\",\"330903\",\"330921\",\"330922\",\"331000\",\"331001\",\"331002\",\"331003\",\"331004\",\"331021\",\"331022\",\"331023\",\"331024\",\"331081\",\"331082\",\"331100\",\"331101\",\"331102\",\"331121\",\"331122\",\"331123\",\"331124\",\"331125\",\"331126\",\"331127\",\"331181\",\"340000\",\"340100\",\"340101\",\"340102\",\"340103\",\"340104\",\"340111\",\"340121\",\"340122\",\"340123\",\"340200\",\"340201\",\"340202\",\"340203\",\"340207\",\"340208\",\"340221\",\"340222\",\"340223\",\"340300\",\"340301\",\"340302\",\"340303\",\"340304\",\"340311\",\"340321\",\"340322\",\"340323\",\"340400\",\"340401\",\"340402\",\"340403\",\"340404\",\"340405\",\"340406\",\"340421\",\"340500\",\"340501\",\"340502\",\"340503\",\"340504\",\"340521\",\"340600\",\"340601\",\"340602\",\"340603\",\"340604\",\"340621\",\"340700\",\"340701\",\"340702\",\"340703\",\"340711\",\"340721\",\"340800\",\"340801\",\"340802\",\"340803\",\"340811\",\"340822\",\"340823\",\"340824\",\"340825\",\"340826\",\"340827\",\"340828\",\"340881\",\"341000\",\"341001\",\"341002\",\"341003\",\"341004\",\"341021\",\"341022\",\"341023\",\"341024\",\"341100\",\"341101\",\"341102\",\"341103\",\"341122\",\"341124\",\"341125\",\"341126\",\"341181\",\"341182\",\"341200\",\"341201\",\"341202\",\"341203\",\"341204\",\"341221\",\"341222\",\"341225\",\"341226\",\"341282\",\"341300\",\"341301\",\"341302\",\"341321\",\"341322\",\"341323\",\"341324\",\"341400\",\"341401\",\"341402\",\"341421\",\"341422\",\"341423\",\"341424\",\"341500\",\"341501\",\"341502\",\"341503\",\"341521\",\"341522\",\"341523\",\"341524\",\"341525\",\"341600\",\"341601\",\"341602\",\"341621\",\"341622\",\"341623\",\"341700\",\"341701\",\"341702\",\"341721\",\"341722\",\"341723\",\"341800\",\"341801\",\"341802\",\"341821\",\"341822\",\"341823\",\"341824\",\"341825\",\"341881\",\"350000\",\"350100\",\"350101\",\"350102\",\"350103\",\"350104\",\"350105\",\"350111\",\"350121\",\"350122\",\"350123\",\"350124\",\"350125\",\"350128\",\"350181\",\"350182\",\"350200\",\"350201\",\"350203\",\"350205\",\"350206\",\"350211\",\"350212\",\"350213\",\"350300\",\"350301\",\"350302\",\"350303\",\"350304\",\"350305\",\"350322\",\"350400\",\"350401\",\"350402\",\"350403\",\"350421\",\"350423\",\"350424\",\"350425\",\"350426\",\"350427\",\"350428\",\"350429\",\"350430\",\"350481\",\"350500\",\"350501\",\"350502\",\"350503\",\"350504\",\"350505\",\"350521\",\"350524\",\"350525\",\"350526\",\"350527\",\"350581\",\"350582\",\"350583\",\"350600\",\"350601\",\"350602\",\"350603\",\"350622\",\"350623\",\"350624\",\"350625\",\"350626\",\"350627\",\"350628\",\"350629\",\"350681\",\"350700\",\"350701\",\"350702\",\"350721\",\"350722\",\"350723\",\"350724\",\"350725\",\"350781\",\"350782\",\"350783\",\"350784\",\"350800\",\"350801\",\"350802\",\"350821\",\"350822\",\"350823\",\"350824\",\"350825\",\"350881\",\"350900\",\"350901\",\"350902\",\"350921\",\"350922\",\"350923\",\"350924\",\"350925\",\"350926\",\"350981\",\"350982\",\"360000\",\"360100\",\"360101\",\"360102\",\"360103\",\"360104\",\"360105\",\"360111\",\"360121\",\"360122\",\"360123\",\"360124\",\"360200\",\"360201\",\"360202\",\"360203\",\"360222\",\"360281\",\"360300\",\"360301\",\"360302\",\"360313\",\"360321\",\"360322\",\"360323\",\"360400\",\"360401\",\"360402\",\"360403\",\"360421\",\"360423\",\"360424\",\"360425\",\"360426\",\"360427\",\"360428\",\"360429\",\"360430\",\"360481\",\"360500\",\"360501\",\"360502\",\"360521\",\"360600\",\"360601\",\"360602\",\"360622\",\"360681\",\"360700\",\"360701\",\"360702\",\"360721\",\"360722\",\"360723\",\"360724\",\"360725\",\"360726\",\"360727\",\"360728\",\"360729\",\"360730\",\"360731\",\"360732\",\"360733\",\"360734\",\"360735\",\"360781\",\"360782\",\"360800\",\"360801\",\"360802\",\"360803\",\"360821\",\"360822\",\"360823\",\"360824\",\"360825\",\"360826\",\"360827\",\"360828\",\"360829\",\"360830\",\"360881\",\"360900\",\"360901\",\"360902\",\"360921\",\"360922\",\"360923\",\"360924\",\"360925\",\"360926\",\"360981\",\"360982\",\"360983\",\"361000\",\"361001\",\"361002\",\"361021\",\"361022\",\"361023\",\"361024\",\"361025\",\"361026\",\"361027\",\"361028\",\"361029\",\"361030\",\"361100\",\"361101\",\"361102\",\"361121\",\"361122\",\"361123\",\"361124\",\"361125\",\"361126\",\"361127\",\"361128\",\"361129\",\"361130\",\"361181\",\"370000\",\"370100\",\"370101\",\"370102\",\"370103\",\"370104\",\"370105\",\"370112\",\"370113\",\"370124\",\"370125\",\"370126\",\"370181\",\"370200\",\"370201\",\"370202\",\"370203\",\"370205\",\"370211\",\"370212\",\"370213\",\"370214\",\"370281\",\"370282\",\"370283\",\"370284\",\"370285\",\"370300\",\"370301\",\"370302\",\"370303\",\"370304\",\"370305\",\"370306\",\"370321\",\"370322\",\"370323\",\"370400\",\"370401\",\"370402\",\"370403\",\"370404\",\"370405\",\"370406\",\"370481\",\"370500\",\"370501\",\"370502\",\"370503\",\"370521\",\"370522\",\"370523\",\"370600\",\"370601\",\"370602\",\"370611\",\"370612\",\"370613\",\"370634\",\"370681\",\"370682\",\"370683\",\"370684\",\"370685\",\"370686\",\"370687\",\"370700\",\"370701\",\"370702\",\"370703\",\"370704\",\"370705\",\"370724\",\"370725\",\"370781\",\"370782\",\"370783\",\"370784\",\"370785\",\"370786\",\"370800\",\"370801\",\"370802\",\"370811\",\"370826\",\"370827\",\"370828\",\"370829\",\"370830\",\"370831\",\"370832\",\"370881\",\"370882\",\"370883\",\"370900\",\"370901\",\"370902\",\"370911\",\"370921\",\"370923\",\"370982\",\"370983\",\"371000\",\"371001\",\"371002\",\"371081\",\"371082\",\"371083\",\"371100\",\"371101\",\"371102\",\"371103\",\"371121\",\"371122\",\"371200\",\"371201\",\"371202\",\"371203\",\"371300\",\"371301\",\"371302\",\"371311\",\"371312\",\"371321\",\"371322\",\"371323\",\"371324\",\"371325\",\"371326\",\"371327\",\"371328\",\"371329\",\"371400\",\"371401\",\"371402\",\"371421\",\"371422\",\"371423\",\"371424\",\"371425\",\"371426\",\"371427\",\"371428\",\"371481\",\"371482\",\"371500\",\"371501\",\"371502\",\"371521\",\"371522\",\"371523\",\"371524\",\"371525\",\"371526\",\"371581\",\"371600\",\"371601\",\"371602\",\"371621\",\"371622\",\"371623\",\"371624\",\"371625\",\"371626\",\"371700\",\"371701\",\"371702\",\"371721\",\"371722\",\"371723\",\"371724\",\"371725\",\"371726\",\"371727\",\"371728\",\"410000\",\"410100\",\"410101\",\"410102\",\"410103\",\"410104\",\"410105\",\"410106\",\"410108\",\"410122\",\"410181\",\"410182\",\"410183\",\"410184\",\"410185\",\"410200\",\"410201\",\"410202\",\"410203\",\"410204\",\"410205\",\"410211\",\"410221\",\"410222\",\"410223\",\"410224\",\"410225\",\"410300\",\"410301\",\"410302\",\"410303\",\"410304\",\"410305\",\"410306\",\"410311\",\"410322\",\"410323\",\"410324\",\"410325\",\"410326\",\"410327\",\"410328\",\"410329\",\"410381\",\"410400\",\"410401\",\"410402\",\"410403\",\"410404\",\"410411\",\"410421\",\"410422\",\"410423\",\"410425\",\"410481\",\"410482\",\"410500\",\"410501\",\"410502\",\"410503\",\"410505\",\"410506\",\"410522\",\"410523\",\"410526\",\"410527\",\"410581\",\"410600\",\"410601\",\"410602\",\"410603\",\"410611\",\"410621\",\"410622\",\"410700\",\"410701\",\"410702\",\"410703\",\"410704\",\"410711\",\"410721\",\"410724\",\"410725\",\"410726\",\"410727\",\"410728\",\"410781\",\"410782\",\"410800\",\"410801\",\"410802\",\"410803\",\"410804\",\"410811\",\"410821\",\"410822\",\"410823\",\"410825\",\"410882\",\"410883\",\"410900\",\"410901\",\"410902\",\"410922\",\"410923\",\"410926\",\"410927\",\"410928\",\"411000\",\"411001\",\"411002\",\"411023\",\"411024\",\"411025\",\"411081\",\"411082\",\"411100\",\"411101\",\"411102\",\"411103\",\"411104\",\"411121\",\"411122\",\"411200\",\"411201\",\"411202\",\"411221\",\"411222\",\"411224\",\"411281\",\"411282\",\"411300\",\"411301\",\"411302\",\"411303\",\"411321\",\"411322\",\"411323\",\"411324\",\"411325\",\"411326\",\"411327\",\"411328\",\"411329\",\"411330\",\"411381\",\"411400\",\"411401\",\"411402\",\"411403\",\"411421\",\"411422\",\"411423\",\"411424\",\"411425\",\"411426\",\"411481\",\"411500\",\"411501\",\"411502\",\"411503\",\"411521\",\"411522\",\"411523\",\"411524\",\"411525\",\"411526\",\"411527\",\"411528\",\"411600\",\"411601\",\"411602\",\"411621\",\"411622\",\"411623\",\"411624\",\"411625\",\"411626\",\"411627\",\"411628\",\"411681\",\"411700\",\"411701\",\"411702\",\"411721\",\"411722\",\"411723\",\"411724\",\"411725\",\"411726\",\"411727\",\"411728\",\"411729\",\"419001\",\"420000\",\"420100\",\"420101\",\"420102\",\"420103\",\"420104\",\"420105\",\"420106\",\"420107\",\"420111\",\"420112\",\"420113\",\"420114\",\"420115\",\"420116\",\"420117\",\"420200\",\"420201\",\"420202\",\"420203\",\"420204\",\"420205\",\"420222\",\"420281\",\"420300\",\"420301\",\"420302\",\"420303\",\"420321\",\"420322\",\"420323\",\"420324\",\"420325\",\"420381\",\"420500\",\"420501\",\"420502\",\"420503\",\"420504\",\"420505\",\"420506\",\"420525\",\"420526\",\"420527\",\"420528\",\"420529\",\"420581\",\"420582\",\"420583\",\"420600\",\"420601\",\"420602\",\"420606\",\"420607\",\"420624\",\"420625\",\"420626\",\"420682\",\"420683\",\"420684\",\"420700\",\"420701\",\"420702\",\"420703\",\"420704\",\"420800\",\"420801\",\"420802\",\"420804\",\"420821\",\"420822\",\"420881\",\"420900\",\"420901\",\"420902\",\"420921\",\"420922\",\"420923\",\"420981\",\"420982\",\"420984\",\"421000\",\"421001\",\"421002\",\"421003\",\"421022\",\"421023\",\"421024\",\"421081\",\"421083\",\"421087\",\"421100\",\"421101\",\"421102\",\"421121\",\"421122\",\"421123\",\"421124\",\"421125\",\"421126\",\"421127\",\"421181\",\"421182\",\"421200\",\"421201\",\"421202\",\"421221\",\"421222\",\"421223\",\"421224\",\"421281\",\"421300\",\"421301\",\"421303\",\"421381\",\"422800\",\"422801\",\"422802\",\"422822\",\"422823\",\"422825\",\"422826\",\"422827\",\"422828\",\"429000\",\"429004\",\"429005\",\"429006\",\"429021\",\"430000\",\"430100\",\"430101\",\"430102\",\"430103\",\"430104\",\"430105\",\"430111\",\"430121\",\"430122\",\"430124\",\"430181\",\"430200\",\"430201\",\"430202\",\"430203\",\"430204\",\"430211\",\"430221\",\"430223\",\"430224\",\"430225\",\"430281\",\"430300\",\"430301\",\"430302\",\"430304\",\"430321\",\"430381\",\"430382\",\"430400\",\"430401\",\"430405\",\"430406\",\"430407\",\"430408\",\"430412\",\"430421\",\"430422\",\"430423\",\"430424\",\"430426\",\"430481\",\"430482\",\"430500\",\"430501\",\"430502\",\"430503\",\"430511\",\"430521\",\"430522\",\"430523\",\"430524\",\"430525\",\"430527\",\"430528\",\"430529\",\"430581\",\"430600\",\"430601\",\"430602\",\"430603\",\"430611\",\"430621\",\"430623\",\"430624\",\"430626\",\"430681\",\"430682\",\"430700\",\"430701\",\"430702\",\"430703\",\"430721\",\"430722\",\"430723\",\"430724\",\"430725\",\"430726\",\"430781\",\"430800\",\"430801\",\"430802\",\"430811\",\"430821\",\"430822\",\"430900\",\"430901\",\"430902\",\"430903\",\"430921\",\"430922\",\"430923\",\"430981\",\"431000\",\"431001\",\"431002\",\"431003\",\"431021\",\"431022\",\"431023\",\"431024\",\"431025\",\"431026\",\"431027\",\"431028\",\"431081\",\"431100\",\"431101\",\"431102\",\"431103\",\"431121\",\"431122\",\"431123\",\"431124\",\"431125\",\"431126\",\"431127\",\"431128\",\"431129\",\"431200\",\"431201\",\"431202\",\"431221\",\"431222\",\"431223\",\"431224\",\"431225\",\"431226\",\"431227\",\"431228\",\"431229\",\"431230\",\"431281\",\"431300\",\"431301\",\"431302\",\"431321\",\"431322\",\"431381\",\"431382\",\"433100\",\"433101\",\"433122\",\"433123\",\"433124\",\"433125\",\"433126\",\"433127\",\"433130\",\"440000\",\"440100\",\"440101\",\"440103\",\"440104\",\"440105\",\"440106\",\"440111\",\"440112\",\"440113\",\"440114\",\"440115\",\"440116\",\"440183\",\"440184\",\"440200\",\"440201\",\"440203\",\"440204\",\"440205\",\"440222\",\"440224\",\"440229\",\"440232\",\"440233\",\"440281\",\"440282\",\"440300\",\"440301\",\"440303\",\"440304\",\"440305\",\"440306\",\"440307\",\"440308\",\"440400\",\"440401\",\"440402\",\"440403\",\"440404\",\"440500\",\"440501\",\"440507\",\"440511\",\"440512\",\"440513\",\"440514\",\"440515\",\"440523\",\"440600\",\"440601\",\"440604\",\"440605\",\"440606\",\"440607\",\"440608\",\"440700\",\"440701\",\"440703\",\"440704\",\"440705\",\"440781\",\"440783\",\"440784\",\"440785\",\"440800\",\"440801\",\"440802\",\"440803\",\"440804\",\"440811\",\"440823\",\"440825\",\"440881\",\"440882\",\"440883\",\"440900\",\"440901\",\"440902\",\"440903\",\"440923\",\"440981\",\"440982\",\"440983\",\"441200\",\"441201\",\"441202\",\"441203\",\"441223\",\"441224\",\"441225\",\"441226\",\"441283\",\"441284\",\"441300\",\"441301\",\"441302\",\"441303\",\"441322\",\"441323\",\"441324\",\"441400\",\"441401\",\"441402\",\"441421\",\"441422\",\"441423\",\"441424\",\"441426\",\"441427\",\"441481\",\"441500\",\"441501\",\"441502\",\"441521\",\"441523\",\"441581\",\"441600\",\"441601\",\"441602\",\"441621\",\"441622\",\"441623\",\"441624\",\"441625\",\"441700\",\"441701\",\"441702\",\"441721\",\"441723\",\"441781\",\"441800\",\"441801\",\"441802\",\"441821\",\"441823\",\"441825\",\"441826\",\"441827\",\"441881\",\"441882\",\"441900\",\"442000\",\"445100\",\"445101\",\"445102\",\"445121\",\"445122\",\"445200\",\"445201\",\"445202\",\"445221\",\"445222\",\"445224\",\"445281\",\"445300\",\"445301\",\"445302\",\"445321\",\"445322\",\"445323\",\"445381\",\"450000\",\"450100\",\"450101\",\"450102\",\"450103\",\"450105\",\"450107\",\"450108\",\"450109\",\"450122\",\"450123\",\"450124\",\"450125\",\"450126\",\"450127\",\"450200\",\"450201\",\"450202\",\"450203\",\"450204\",\"450205\",\"450221\",\"450222\",\"450223\",\"450224\",\"450225\",\"450226\",\"450300\",\"450301\",\"450302\",\"450303\",\"450304\",\"450305\",\"450311\",\"450321\",\"450322\",\"450323\",\"450324\",\"450325\",\"450326\",\"450327\",\"450328\",\"450329\",\"450330\",\"450331\",\"450332\",\"450400\",\"450401\",\"450403\",\"450404\",\"450405\",\"450421\",\"450422\",\"450423\",\"450481\",\"450500\",\"450501\",\"450502\",\"450503\",\"450512\",\"450521\",\"450600\",\"450601\",\"450602\",\"450603\",\"450621\",\"450681\",\"450700\",\"450701\",\"450702\",\"450703\",\"450721\",\"450722\",\"450800\",\"450801\",\"450802\",\"450803\",\"450804\",\"450821\",\"450881\",\"450900\",\"450901\",\"450902\",\"450921\",\"450922\",\"450923\",\"450924\",\"450981\",\"451000\",\"451001\",\"451002\",\"451021\",\"451022\",\"451023\",\"451024\",\"451025\",\"451026\",\"451027\",\"451028\",\"451029\",\"451030\",\"451031\",\"451100\",\"451101\",\"451102\",\"451121\",\"451122\",\"451123\",\"451200\",\"451201\",\"451202\",\"451221\",\"451222\",\"451223\",\"451224\",\"451225\",\"451226\",\"451227\",\"451228\",\"451229\",\"451281\",\"451300\",\"451301\",\"451302\",\"451321\",\"451322\",\"451323\",\"451324\",\"451381\",\"451400\",\"451401\",\"451402\",\"451421\",\"451422\",\"451423\",\"451424\",\"451425\",\"451481\",\"460000\",\"460100\",\"460101\",\"460105\",\"460106\",\"460107\",\"460108\",\"460200\",\"460201\",\"469000\",\"469001\",\"469002\",\"469003\",\"469005\",\"469006\",\"469007\",\"469021\",\"469022\",\"469023\",\"469024\",\"469025\",\"469026\",\"469027\",\"469028\",\"469029\",\"469030\",\"469031\",\"469032\",\"469033\",\"500000\",\"500100\",\"500101\",\"500102\",\"500103\",\"500104\",\"500105\",\"500106\",\"500107\",\"500108\",\"500109\",\"500110\",\"500111\",\"500112\",\"500113\",\"500114\",\"500115\",\"500116\",\"500117\",\"500118\",\"500119\",\"500200\",\"500222\",\"500223\",\"500224\",\"500225\",\"500226\",\"500227\",\"500228\",\"500229\",\"500230\",\"500231\",\"500232\",\"500233\",\"500234\",\"500235\",\"500236\",\"500237\",\"500238\",\"500240\",\"500241\",\"500242\",\"500243\",\"510000\",\"510100\",\"510101\",\"510104\",\"510105\",\"510106\",\"510107\",\"510108\",\"510112\",\"510113\",\"510114\",\"510115\",\"510121\",\"510122\",\"510124\",\"510129\",\"510131\",\"510132\",\"510181\",\"510182\",\"510183\",\"510184\",\"510300\",\"510301\",\"510302\",\"510303\",\"510304\",\"510311\",\"510321\",\"510322\",\"510400\",\"510401\",\"510402\",\"510403\",\"510411\",\"510421\",\"510422\",\"510500\",\"510501\",\"510502\",\"510503\",\"510504\",\"510521\",\"510522\",\"510524\",\"510525\",\"510600\",\"510601\",\"510603\",\"510623\",\"510626\",\"510681\",\"510682\",\"510683\",\"510700\",\"510701\",\"510703\",\"510704\",\"510722\",\"510723\",\"510724\",\"510725\",\"510726\",\"510727\",\"510781\",\"510800\",\"510801\",\"510802\",\"510811\",\"510812\",\"510821\",\"510822\",\"510823\",\"510824\",\"510900\",\"510901\",\"510903\",\"510904\",\"510921\",\"510922\",\"510923\",\"511000\",\"511001\",\"511002\",\"511011\",\"511024\",\"511025\",\"511028\",\"511100\",\"511101\",\"511102\",\"511111\",\"511112\",\"511113\",\"511123\",\"511124\",\"511126\",\"511129\",\"511132\",\"511133\",\"511181\",\"511300\",\"511301\",\"511302\",\"511303\",\"511304\",\"511321\",\"511322\",\"511323\",\"511324\",\"511325\",\"511381\",\"511400\",\"511401\",\"511402\",\"511421\",\"511422\",\"511423\",\"511424\",\"511425\",\"511500\",\"511501\",\"511502\",\"511521\",\"511522\",\"511523\",\"511524\",\"511525\",\"511526\",\"511527\",\"511528\",\"511529\",\"511600\",\"511601\",\"511602\",\"511621\",\"511622\",\"511623\",\"511681\",\"511700\",\"511701\",\"511702\",\"511721\",\"511722\",\"511723\",\"511724\",\"511725\",\"511781\",\"511800\",\"511801\",\"511802\",\"511821\",\"511822\",\"511823\",\"511824\",\"511825\",\"511826\",\"511827\",\"511900\",\"511901\",\"511902\",\"511921\",\"511922\",\"511923\",\"512000\",\"512001\",\"512002\",\"512021\",\"512022\",\"512081\",\"513200\",\"513221\",\"513222\",\"513223\",\"513224\",\"513225\",\"513226\",\"513227\",\"513228\",\"513229\",\"513230\",\"513231\",\"513232\",\"513233\",\"513300\",\"513321\",\"513322\",\"513323\",\"513324\",\"513325\",\"513326\",\"513327\",\"513328\",\"513329\",\"513330\",\"513331\",\"513332\",\"513333\",\"513334\",\"513335\",\"513336\",\"513337\",\"513338\",\"513400\",\"513401\",\"513422\",\"513423\",\"513424\",\"513425\",\"513426\",\"513427\",\"513428\",\"513429\",\"513430\",\"513431\",\"513432\",\"513433\",\"513434\",\"513435\",\"513436\",\"513437\",\"520000\",\"520100\",\"520101\",\"520102\",\"520103\",\"520111\",\"520112\",\"520113\",\"520114\",\"520121\",\"520122\",\"520123\",\"520181\",\"520200\",\"520201\",\"520203\",\"520221\",\"520222\",\"520300\",\"520301\",\"520302\",\"520303\",\"520321\",\"520322\",\"520323\",\"520324\",\"520325\",\"520326\",\"520327\",\"520328\",\"520329\",\"520330\",\"520381\",\"520382\",\"520400\",\"520401\",\"520402\",\"520421\",\"520422\",\"520423\",\"520424\",\"520425\",\"522200\",\"522201\",\"522222\",\"522223\",\"522224\",\"522225\",\"522226\",\"522227\",\"522228\",\"522229\",\"522230\",\"522300\",\"522301\",\"522322\",\"522323\",\"522324\",\"522325\",\"522326\",\"522327\",\"522328\",\"522400\",\"522401\",\"522422\",\"522423\",\"522424\",\"522425\",\"522426\",\"522427\",\"522428\",\"522600\",\"522601\",\"522622\",\"522623\",\"522624\",\"522625\",\"522626\",\"522627\",\"522628\",\"522629\",\"522630\",\"522631\",\"522632\",\"522633\",\"522634\",\"522635\",\"522636\",\"522700\",\"522701\",\"522702\",\"522722\",\"522723\",\"522725\",\"522726\",\"522727\",\"522728\",\"522729\",\"522730\",\"522731\",\"522732\",\"530000\",\"530100\",\"530101\",\"530102\",\"530103\",\"530111\",\"530112\",\"530113\",\"530121\",\"530122\",\"530124\",\"530125\",\"530126\",\"530127\",\"530128\",\"530129\",\"530181\",\"530300\",\"530301\",\"530302\",\"530321\",\"530322\",\"530323\",\"530324\",\"530325\",\"530326\",\"530328\",\"530381\",\"530400\",\"530401\",\"530402\",\"530421\",\"530422\",\"530423\",\"530424\",\"530425\",\"530426\",\"530427\",\"530428\",\"530500\",\"530501\",\"530502\",\"530521\",\"530522\",\"530523\",\"530524\",\"530600\",\"530601\",\"530602\",\"530621\",\"530622\",\"530623\",\"530624\",\"530625\",\"530626\",\"530627\",\"530628\",\"530629\",\"530630\",\"530700\",\"530701\",\"530702\",\"530721\",\"530722\",\"530723\",\"530724\",\"530800\",\"530801\",\"530802\",\"530821\",\"530822\",\"530823\",\"530824\",\"530825\",\"530826\",\"530827\",\"530828\",\"530829\",\"530900\",\"530901\",\"530902\",\"530921\",\"530922\",\"530923\",\"530924\",\"530925\",\"530926\",\"530927\",\"532300\",\"532301\",\"532322\",\"532323\",\"532324\",\"532325\",\"532326\",\"532327\",\"532328\",\"532329\",\"532331\",\"532500\",\"532501\",\"532502\",\"532522\",\"532523\",\"532524\",\"532525\",\"532526\",\"532527\",\"532528\",\"532529\",\"532530\",\"532531\",\"532532\",\"532600\",\"532621\",\"532622\",\"532623\",\"532624\",\"532625\",\"532626\",\"532627\",\"532628\",\"532800\",\"532801\",\"532822\",\"532823\",\"532900\",\"532901\",\"532922\",\"532923\",\"532924\",\"532925\",\"532926\",\"532927\",\"532928\",\"532929\",\"532930\",\"532931\",\"532932\",\"533100\",\"533102\",\"533103\",\"533122\",\"533123\",\"533124\",\"533300\",\"533321\",\"533323\",\"533324\",\"533325\",\"533400\",\"533421\",\"533422\",\"533423\",\"540000\",\"540100\",\"540101\",\"540102\",\"540121\",\"540122\",\"540123\",\"540124\",\"540125\",\"540126\",\"540127\",\"542100\",\"542121\",\"542122\",\"542123\",\"542124\",\"542125\",\"542126\",\"542127\",\"542128\",\"542129\",\"542132\",\"542133\",\"542200\",\"542221\",\"542222\",\"542223\",\"542224\",\"542225\",\"542226\",\"542227\",\"542228\",\"542229\",\"542231\",\"542232\",\"542233\",\"542300\",\"542301\",\"542322\",\"542323\",\"542324\",\"542325\",\"542326\",\"542327\",\"542328\",\"542329\",\"542330\",\"542331\",\"542332\",\"542333\",\"542334\",\"542335\",\"542336\",\"542337\",\"542338\",\"542400\",\"542421\",\"542422\",\"542423\",\"542424\",\"542425\",\"542426\",\"542427\",\"542428\",\"542429\",\"542430\",\"542500\",\"542521\",\"542522\",\"542523\",\"542524\",\"542525\",\"542526\",\"542527\",\"542600\",\"542621\",\"542622\",\"542623\",\"542624\",\"542625\",\"542626\",\"542627\",\"610000\",\"610100\",\"610101\",\"610102\",\"610103\",\"610104\",\"610111\",\"610112\",\"610113\",\"610114\",\"610115\",\"610116\",\"610122\",\"610124\",\"610125\",\"610126\",\"610200\",\"610201\",\"610202\",\"610203\",\"610204\",\"610222\",\"610300\",\"610301\",\"610302\",\"610303\",\"610304\",\"610322\",\"610323\",\"610324\",\"610326\",\"610327\",\"610328\",\"610329\",\"610330\",\"610331\",\"610400\",\"610401\",\"610402\",\"610403\",\"610404\",\"610422\",\"610423\",\"610424\",\"610425\",\"610426\",\"610427\",\"610428\",\"610429\",\"610430\",\"610431\",\"610481\",\"610500\",\"610501\",\"610502\",\"610521\",\"610522\",\"610523\",\"610524\",\"610525\",\"610526\",\"610527\",\"610528\",\"610581\",\"610582\",\"610600\",\"610601\",\"610602\",\"610621\",\"610622\",\"610623\",\"610624\",\"610625\",\"610626\",\"610627\",\"610628\",\"610629\",\"610630\",\"610631\",\"610632\",\"610700\",\"610701\",\"610702\",\"610721\",\"610722\",\"610723\",\"610724\",\"610725\",\"610726\",\"610727\",\"610728\",\"610729\",\"610730\",\"610800\",\"610801\",\"610802\",\"610821\",\"610822\",\"610823\",\"610824\",\"610825\",\"610826\",\"610827\",\"610828\",\"610829\",\"610830\",\"610831\",\"610900\",\"610901\",\"610902\",\"610921\",\"610922\",\"610923\",\"610924\",\"610925\",\"610926\",\"610927\",\"610928\",\"610929\",\"611000\",\"611001\",\"611002\",\"611021\",\"611022\",\"611023\",\"611024\",\"611025\",\"611026\",\"620000\",\"620100\",\"620101\",\"620102\",\"620103\",\"620104\",\"620105\",\"620111\",\"620121\",\"620122\",\"620123\",\"620200\",\"620201\",\"620300\",\"620301\",\"620302\",\"620321\",\"620400\",\"620401\",\"620402\",\"620403\",\"620421\",\"620422\",\"620423\",\"620500\",\"620501\",\"620502\",\"620503\",\"620521\",\"620522\",\"620523\",\"620524\",\"620525\",\"620600\",\"620601\",\"620602\",\"620621\",\"620622\",\"620623\",\"620700\",\"620701\",\"620702\",\"620721\",\"620722\",\"620723\",\"620724\",\"620725\",\"620800\",\"620801\",\"620802\",\"620821\",\"620822\",\"620823\",\"620824\",\"620825\",\"620826\",\"620900\",\"620901\",\"620902\",\"620921\",\"620922\",\"620923\",\"620924\",\"620981\",\"620982\",\"621000\",\"621001\",\"621002\",\"621021\",\"621022\",\"621023\",\"621024\",\"621025\",\"621026\",\"621027\",\"621100\",\"621101\",\"621102\",\"621121\",\"621122\",\"621123\",\"621124\",\"621125\",\"621126\",\"621200\",\"621201\",\"621202\",\"621221\",\"621222\",\"621223\",\"621224\",\"621225\",\"621226\",\"621227\",\"621228\",\"622900\",\"622901\",\"622921\",\"622922\",\"622923\",\"622924\",\"622925\",\"622926\",\"622927\",\"623000\",\"623001\",\"623021\",\"623022\",\"623023\",\"623024\",\"623025\",\"623026\",\"623027\",\"630000\",\"630100\",\"630101\",\"630102\",\"630103\",\"630104\",\"630105\",\"630121\",\"630122\",\"630123\",\"632100\",\"632121\",\"632122\",\"632123\",\"632126\",\"632127\",\"632128\",\"632200\",\"632221\",\"632222\",\"632223\",\"632224\",\"632300\",\"632321\",\"632322\",\"632323\",\"632324\",\"632500\",\"632521\",\"632522\",\"632523\",\"632524\",\"632525\",\"632600\",\"632621\",\"632622\",\"632623\",\"632624\",\"632625\",\"632626\",\"632700\",\"632721\",\"632722\",\"632723\",\"632724\",\"632725\",\"632726\",\"632800\",\"632801\",\"632802\",\"632821\",\"632822\",\"632823\",\"640000\",\"640100\",\"640101\",\"640104\",\"640105\",\"640106\",\"640121\",\"640122\",\"640181\",\"640200\",\"640201\",\"640202\",\"640205\",\"640221\",\"640300\",\"640301\",\"640302\",\"640303\",\"640323\",\"640324\",\"640381\",\"640400\",\"640401\",\"640402\",\"640422\",\"640423\",\"640424\",\"640425\",\"640500\",\"640501\",\"640502\",\"640521\",\"640522\",\"650000\",\"650100\",\"650101\",\"650102\",\"650103\",\"650104\",\"650105\",\"650106\",\"650107\",\"650109\",\"650121\",\"650200\",\"650201\",\"650202\",\"650203\",\"650204\",\"650205\",\"652100\",\"652101\",\"652122\",\"652123\",\"652200\",\"652201\",\"652222\",\"652223\",\"652300\",\"652301\",\"652302\",\"652323\",\"652324\",\"652325\",\"652327\",\"652328\",\"652700\",\"652701\",\"652722\",\"652723\",\"652800\",\"652801\",\"652822\",\"652823\",\"652824\",\"652825\",\"652826\",\"652827\",\"652828\",\"652829\",\"652900\",\"652901\",\"652922\",\"652923\",\"652924\",\"652925\",\"652926\",\"652927\",\"652928\",\"652929\",\"653000\",\"653001\",\"653022\",\"653023\",\"653024\",\"653100\",\"653101\",\"653121\",\"653122\",\"653123\",\"653124\",\"653125\",\"653126\",\"653127\",\"653128\",\"653129\",\"653130\",\"653131\",\"653200\",\"653201\",\"653221\",\"653222\",\"653223\",\"653224\",\"653225\",\"653226\",\"653227\",\"654000\",\"654002\",\"654003\",\"654021\",\"654022\",\"654023\",\"654024\",\"654025\",\"654026\",\"654027\",\"654028\",\"654200\",\"654201\",\"654202\",\"654221\",\"654223\",\"654224\",\"654225\",\"654226\",\"654300\",\"654301\",\"654321\",\"654322\",\"654323\",\"654324\",\"654325\",\"654326\",\"659000\",\"659001\",\"659002\",\"659003\",\"659004\",\"710000\",\"810000\",\"820000\"}; strcpy(AreaCode, a[rand()%3515]); return AreaCode; } //随机生成日期 char*randomDate() { char syear[5],smouth[3],sday[3]; int year=rand()%100+1910; int mouth=rand()%12+1; int day=rand()%31+1; strcat(Date,itoa(year,syear,10)); if(mouth如果要使用loadrunner工具在压测中使用，参考一下步骤： 1.将上述代码保存为IDgenerate.h，移动到lr脚本目录中。 2.在globals.h中添加# include \"IDgenerate.h\"。 3.在action中使用IDgenerate()函数调用生成。 补充：原代码存在的问题 问题1.由于年月日随机生成，而且没有判断闰年月份等信息，在使用的过程中会出现校验不合法的问题。 /* 随机生成年份，月份，判断月份为一三五七八十腊，则日期最大为31天 如果月份为2月，则对年份进行判断，闰年二月最大29天，其他平年最大28天 其他月份均为最大30天 */ year=rand()%119+1900; mouth=rand()%12+1; if(mouth==1||mouth==3||mouth==5||mouth==7||mouth==8||mouth==10||mouth==12){ day=rand()%31+1; }else{ if(mouth==2){ if((year%4==0&&year%100!=0)||year%400==0){ day=rand()%29+1; }else{ day=rand()%28+1; } }else{ day=rand()%30+1; } } 问题2.在多次执行的过程中，生成的证件号重复，原因为rand()方法为伪随机，生成同一个随机数。 //在使用随机数rand()之前添加srand((unsigned)time(NULL));使用时间初始化随机种子 //如果代码中有for循环，该语句应该放在循环外。 //由于使用精确到秒的时间作为随机种子，在同一时间还会存在生成一样的随机数的问题 srand((unsigned)time(NULL)); 最终修改后的代码 IDgenerateDll.cpp： #include #include #include #include \"stdio.h\" #include \"IDgenerateDll.h\" char*IDgenerate(); char getVerifyID(const char *pczID); char*IDgenerate() { static char IDNo[20]; char *AreaCode = (char *)malloc(7*sizeof(char)); char *Date =(char *)malloc(10*sizeof(char)); char *srandomNumber = (char *)malloc(4*sizeof(char)); char a[][7]={\"110000\",\"110100\",\"110101\",\"110102\",\"110103\",\"110104\",\"110105\",\"110106\",\"110107\",\"110108\",\"110109\", \"110111\",\"110112\",\"110113\",\"110114\",\"110115\",\"110116\",\"110117\",\"110200\",\"110228\",\"110229\",\"120000\",\"120100\",\"120101\", \"120102\",\"120103\",\"120104\",\"120105\",\"120106\",\"120110\",\"120111\",\"120112\",\"120113\",\"120114\",\"120115\",\"120200\",\"120221\", \"120223\",\"120225\",\"130000\",\"130100\",\"130101\",\"130102\",\"130103\",\"130104\",\"130105\",\"130107\",\"130108\",\"130121\",\"130123\", \"130124\",\"130125\",\"130126\",\"130127\",\"130128\",\"130129\",\"130130\",\"130131\",\"130132\",\"130133\",\"130181\",\"130182\",\"130183\", \"130184\",\"130185\",\"130200\",\"130201\",\"130202\",\"130203\",\"130204\",\"130205\",\"130207\",\"130208\",\"130223\",\"130224\",\"130225\", \"130227\",\"130229\",\"130230\",\"130281\",\"130283\",\"130300\",\"130301\",\"130302\",\"130303\",\"130304\",\"130321\",\"130322\",\"130323\", \"130324\",\"130400\",\"130401\",\"130402\",\"130403\",\"130404\",\"130406\",\"130421\",\"130423\",\"130424\",\"130425\",\"130426\",\"130427\", \"130428\",\"130429\",\"130430\",\"130431\",\"130432\",\"130433\",\"130434\",\"130435\",\"130481\",\"130500\",\"130501\",\"130502\",\"130503\", \"130521\",\"130522\",\"130523\",\"130524\",\"130525\",\"130526\",\"130527\",\"130528\",\"130529\",\"130530\",\"130531\",\"130532\",\"130533\", \"130534\",\"130535\",\"130581\",\"130582\",\"130600\",\"130601\",\"130602\",\"130603\",\"130604\",\"130621\",\"130622\",\"130623\",\"130624\", \"130625\",\"130626\",\"130627\",\"130628\",\"130629\",\"130630\",\"130631\",\"130632\",\"130633\",\"130634\",\"130635\",\"130636\",\"130637\", \"130638\",\"130681\",\"130682\",\"130683\",\"130684\",\"130700\",\"130701\",\"130702\",\"130703\",\"130705\",\"130706\",\"130721\",\"130722\", \"130723\",\"130724\",\"130725\",\"130726\",\"130727\",\"130728\",\"130729\",\"130730\",\"130731\",\"130732\",\"130733\",\"130800\",\"130801\", \"130802\",\"130803\",\"130804\",\"130821\",\"130822\",\"130823\",\"130824\",\"130825\",\"130826\",\"130827\",\"130828\",\"130900\",\"130901\", \"130902\",\"130903\",\"130921\",\"130922\",\"130923\",\"130924\",\"130925\",\"130926\",\"130927\",\"130928\",\"130929\",\"130930\",\"130981\", \"130982\",\"130983\",\"130984\",\"131000\",\"131001\",\"131002\",\"131003\",\"131022\",\"131023\",\"131024\",\"131025\",\"131026\",\"131028\", \"131081\",\"131082\",\"131100\",\"131101\",\"131102\",\"131121\",\"131122\",\"131123\",\"131124\",\"131125\",\"131126\",\"131127\",\"131128\", \"131181\",\"131182\",\"140000\",\"140100\",\"140101\",\"140105\",\"140106\",\"140107\",\"140108\",\"140109\",\"140110\",\"140121\",\"140122\", \"140123\",\"140181\",\"140200\",\"140201\",\"140202\",\"140203\",\"140211\",\"140212\",\"140221\",\"140222\",\"140223\",\"140224\",\"140225\", \"140226\",\"140227\",\"140300\",\"140301\",\"140302\",\"140303\",\"140311\",\"140321\",\"140322\",\"140400\",\"140401\",\"140402\",\"140411\", \"140421\",\"140423\",\"140424\",\"140425\",\"140426\",\"140427\",\"140428\",\"140429\",\"140430\",\"140431\",\"140481\",\"140500\",\"140501\", \"140502\",\"140521\",\"140522\",\"140524\",\"140525\",\"140581\",\"140600\",\"140601\",\"140602\",\"140603\",\"140621\",\"140622\",\"140623\", \"140624\",\"140700\",\"140701\",\"140702\",\"140721\",\"140722\",\"140723\",\"140724\",\"140725\",\"140726\",\"140727\",\"140728\",\"140729\", \"140781\",\"140800\",\"140801\",\"140802\",\"140821\",\"140822\",\"140823\",\"140824\",\"140825\",\"140826\",\"140827\",\"140828\",\"140829\", \"140830\",\"140881\",\"140882\",\"140900\",\"140901\",\"140902\",\"140921\",\"140922\",\"140923\",\"140924\",\"140925\",\"140926\",\"140927\", \"140928\",\"140929\",\"140930\",\"140931\",\"140932\",\"140981\",\"141000\",\"141001\",\"141002\",\"141021\",\"141022\",\"141023\",\"141024\", \"141025\",\"141026\",\"141027\",\"141028\",\"141029\",\"141030\",\"141031\",\"141032\",\"141033\",\"141034\",\"141081\",\"141082\",\"141100\", \"141101\",\"141102\",\"141121\",\"141122\",\"141123\",\"141124\",\"141125\",\"141126\",\"141127\",\"141128\",\"141129\",\"141130\",\"141181\", \"141182\",\"150000\",\"150100\",\"150101\",\"150102\",\"150103\",\"150104\",\"150105\",\"150121\",\"150122\",\"150123\",\"150124\",\"150125\", \"150200\",\"150201\",\"150202\",\"150203\",\"150204\",\"150205\",\"150206\",\"150207\",\"150221\",\"150222\",\"150223\",\"150300\",\"150301\", \"150302\",\"150303\",\"150304\",\"150400\",\"150401\",\"150402\",\"150403\",\"150404\",\"150421\",\"150422\",\"150423\",\"150424\",\"150425\", \"150426\",\"150428\",\"150429\",\"150430\",\"150500\",\"150501\",\"150502\",\"150521\",\"150522\",\"150523\",\"150524\",\"150525\",\"150526\", \"150581\",\"150600\",\"150601\",\"150602\",\"150621\",\"150622\",\"150623\",\"150624\",\"150625\",\"150626\",\"150627\",\"150700\",\"150701\", \"150702\",\"150721\",\"150722\",\"150723\",\"150724\",\"150725\",\"150726\",\"150727\",\"150781\",\"150782\",\"150783\",\"150784\",\"150785\", \"150800\",\"150801\",\"150802\",\"150821\",\"150822\",\"150823\",\"150824\",\"150825\",\"150826\",\"150900\",\"150901\",\"150902\",\"150921\", \"150922\",\"150923\",\"150924\",\"150925\",\"150926\",\"150927\",\"150928\",\"150929\",\"150981\",\"152200\",\"152201\",\"152202\",\"152221\", \"152222\",\"152223\",\"152224\",\"152500\",\"152501\",\"152502\",\"152522\",\"152523\",\"152524\",\"152525\",\"152526\",\"152527\",\"152528\", \"152529\",\"152530\",\"152531\",\"152900\",\"152921\",\"152922\",\"152923\",\"210000\",\"210100\",\"210101\",\"210102\",\"210103\",\"210104\", \"210105\",\"210106\",\"210111\",\"210112\",\"210113\",\"210114\",\"210122\",\"210123\",\"210124\",\"210181\",\"210200\",\"210201\",\"210202\", \"210203\",\"210204\",\"210211\",\"210212\",\"210213\",\"210224\",\"210281\",\"210282\",\"210283\",\"210300\",\"210301\",\"210302\",\"210303\", \"210304\",\"210311\",\"210321\",\"210323\",\"210381\",\"210400\",\"210401\",\"210402\",\"210403\",\"210404\",\"210411\",\"210421\",\"210422\", \"210423\",\"210500\",\"210501\",\"210502\",\"210503\",\"210504\",\"210505\",\"210521\",\"210522\",\"210600\",\"210601\",\"210602\",\"210603\", \"210604\",\"210624\",\"210681\",\"210682\",\"210700\",\"210701\",\"210702\",\"210703\",\"210711\",\"210726\",\"210727\",\"210781\",\"210782\", \"210800\",\"210801\",\"210802\",\"210803\",\"210804\",\"210811\",\"210881\",\"210882\",\"210900\",\"210901\",\"210902\",\"210903\",\"210904\", \"210905\",\"210911\",\"210921\",\"210922\",\"211000\",\"211001\",\"211002\",\"211003\",\"211004\",\"211005\",\"211011\",\"211021\",\"211081\", \"211100\",\"211101\",\"211102\",\"211103\",\"211121\",\"211122\",\"211200\",\"211201\",\"211202\",\"211204\",\"211221\",\"211223\",\"211224\", \"211281\",\"211282\",\"211300\",\"211301\",\"211302\",\"211303\",\"211321\",\"211322\",\"211324\",\"211381\",\"211382\",\"211400\",\"211401\", \"211402\",\"211403\",\"211404\",\"211421\",\"211422\",\"211481\",\"220000\",\"220100\",\"220101\",\"220102\",\"220103\",\"220104\",\"220105\", \"220106\",\"220112\",\"220122\",\"220181\",\"220182\",\"220183\",\"220200\",\"220201\",\"220202\",\"220203\",\"220204\",\"220211\",\"220221\", \"220281\",\"220282\",\"220283\",\"220284\",\"220300\",\"220301\",\"220302\",\"220303\",\"220322\",\"220323\",\"220381\",\"220382\",\"220400\", \"220401\",\"220402\",\"220403\",\"220421\",\"220422\",\"220500\",\"220501\",\"220502\",\"220503\",\"220521\",\"220523\",\"220524\",\"220581\", \"220582\",\"220600\",\"220601\",\"220602\",\"220605\",\"220621\",\"220622\",\"220623\",\"220681\",\"220700\",\"220701\",\"220702\",\"220721\", \"220722\",\"220723\",\"220724\",\"220800\",\"220801\",\"220802\",\"220821\",\"220822\",\"220881\",\"220882\",\"222400\",\"222401\",\"222402\", \"222403\",\"222404\",\"222405\",\"222406\",\"222424\",\"222426\",\"230000\",\"230100\",\"230101\",\"230102\",\"230103\",\"230104\",\"230108\", \"230109\",\"230110\",\"230111\",\"230123\",\"230124\",\"230125\",\"230126\",\"230127\",\"230128\",\"230129\",\"230182\",\"230183\",\"230184\", \"230200\",\"230201\",\"230202\",\"230203\",\"230204\",\"230205\",\"230206\",\"230207\",\"230208\",\"230221\",\"230223\",\"230224\",\"230225\", \"230227\",\"230229\",\"230230\",\"230231\",\"230281\",\"230300\",\"230301\",\"230302\",\"230303\",\"230304\",\"230305\",\"230306\",\"230307\", \"230321\",\"230381\",\"230382\",\"230400\",\"230401\",\"230402\",\"230403\",\"230404\",\"230405\",\"230406\",\"230407\",\"230421\",\"230422\", \"230500\",\"230501\",\"230502\",\"230503\",\"230505\",\"230506\",\"230521\",\"230522\",\"230523\",\"230524\",\"230600\",\"230601\",\"230602\", \"230603\",\"230604\",\"230605\",\"230606\",\"230621\",\"230622\",\"230623\",\"230624\",\"230700\",\"230701\",\"230702\",\"230703\",\"230704\", \"230705\",\"230706\",\"230707\",\"230708\",\"230709\",\"230710\",\"230711\",\"230712\",\"230713\",\"230714\",\"230715\",\"230716\",\"230722\", \"230781\",\"230800\",\"230801\",\"230803\",\"230804\",\"230805\",\"230811\",\"230822\",\"230826\",\"230828\",\"230833\",\"230881\",\"230882\", \"230900\",\"230901\",\"230902\",\"230903\",\"230904\",\"230921\",\"231000\",\"231001\",\"231002\",\"231003\",\"231004\",\"231005\",\"231024\", \"231025\",\"231081\",\"231083\",\"231084\",\"231085\",\"231100\",\"231101\",\"231102\",\"231121\",\"231123\",\"231124\",\"231181\",\"231182\", \"231200\",\"231201\",\"231202\",\"231221\",\"231222\",\"231223\",\"231224\",\"231225\",\"231226\",\"231281\",\"231282\",\"231283\",\"232700\", \"232721\",\"232722\",\"232723\",\"310000\",\"310100\",\"310101\",\"310103\",\"310104\",\"310105\",\"310106\",\"310107\",\"310108\",\"310109\", \"310110\",\"310112\",\"310113\",\"310114\",\"310115\",\"310116\",\"310117\",\"310118\",\"310120\",\"310200\",\"310230\",\"320000\",\"320100\", \"320101\",\"320102\",\"320103\",\"320104\",\"320105\",\"320106\",\"320107\",\"320111\",\"320113\",\"320114\",\"320115\",\"320116\",\"320124\", \"320125\",\"320200\",\"320201\",\"320202\",\"320203\",\"320204\",\"320205\",\"320206\",\"320211\",\"320281\",\"320282\",\"320300\",\"320301\", \"320302\",\"320303\",\"320304\",\"320305\",\"320311\",\"320321\",\"320322\",\"320323\",\"320324\",\"320381\",\"320382\",\"320400\",\"320401\", \"320402\",\"320404\",\"320405\",\"320411\",\"320412\",\"320481\",\"320482\",\"320500\",\"320501\",\"320502\",\"320503\",\"320504\",\"320505\", \"320506\",\"320507\",\"320581\",\"320582\",\"320583\",\"320584\",\"320585\",\"320600\",\"320601\",\"320602\",\"320611\",\"320621\",\"320623\", \"320681\",\"320682\",\"320684\",\"320700\",\"320701\",\"320703\",\"320705\",\"320706\",\"320721\",\"320722\",\"320723\",\"320724\",\"320800\", \"320801\",\"320802\",\"320803\",\"320804\",\"320811\",\"320826\",\"320829\",\"320830\",\"320831\",\"320900\",\"320901\",\"320902\",\"320903\", \"320921\",\"320922\",\"320923\",\"320924\",\"320925\",\"320981\",\"320982\",\"321000\",\"321001\",\"321002\",\"321003\",\"321011\",\"321023\", \"321081\",\"321084\",\"321088\",\"321100\",\"321101\",\"321102\",\"321111\",\"321112\",\"321181\",\"321182\",\"321183\",\"321200\",\"321201\", \"321202\",\"321203\",\"321281\",\"321282\",\"321283\",\"321284\",\"321300\",\"321301\",\"321302\",\"321311\",\"321322\",\"321323\",\"321324\", \"330000\",\"330100\",\"330101\",\"330102\",\"330103\",\"330104\",\"330105\",\"330106\",\"330108\",\"330109\",\"330110\",\"330122\",\"330127\", \"330182\",\"330183\",\"330185\",\"330200\",\"330201\",\"330203\",\"330204\",\"330205\",\"330206\",\"330211\",\"330212\",\"330225\",\"330226\", \"330281\",\"330282\",\"330283\",\"330300\",\"330301\",\"330302\",\"330303\",\"330304\",\"330322\",\"330324\",\"330326\",\"330327\",\"330328\", \"330329\",\"330381\",\"330382\",\"330400\",\"330401\",\"330402\",\"330411\",\"330421\",\"330424\",\"330481\",\"330482\",\"330483\",\"330500\", \"330501\",\"330502\",\"330503\",\"330521\",\"330522\",\"330523\",\"330600\",\"330601\",\"330602\",\"330621\",\"330624\",\"330681\",\"330682\", \"330683\",\"330700\",\"330701\",\"330702\",\"330703\",\"330723\",\"330726\",\"330727\",\"330781\",\"330782\",\"330783\",\"330784\",\"330800\", \"330801\",\"330802\",\"330803\",\"330822\",\"330824\",\"330825\",\"330881\",\"330900\",\"330901\",\"330902\",\"330903\",\"330921\",\"330922\", \"331000\",\"331001\",\"331002\",\"331003\",\"331004\",\"331021\",\"331022\",\"331023\",\"331024\",\"331081\",\"331082\",\"331100\",\"331101\", \"331102\",\"331121\",\"331122\",\"331123\",\"331124\",\"331125\",\"331126\",\"331127\",\"331181\",\"340000\",\"340100\",\"340101\",\"340102\", \"340103\",\"340104\",\"340111\",\"340121\",\"340122\",\"340123\",\"340200\",\"340201\",\"340202\",\"340203\",\"340207\",\"340208\",\"340221\", \"340222\",\"340223\",\"340300\",\"340301\",\"340302\",\"340303\",\"340304\",\"340311\",\"340321\",\"340322\",\"340323\",\"340400\",\"340401\", \"340402\",\"340403\",\"340404\",\"340405\",\"340406\",\"340421\",\"340500\",\"340501\",\"340502\",\"340503\",\"340504\",\"340521\",\"340600\", \"340601\",\"340602\",\"340603\",\"340604\",\"340621\",\"340700\",\"340701\",\"340702\",\"340703\",\"340711\",\"340721\",\"340800\",\"340801\", \"340802\",\"340803\",\"340811\",\"340822\",\"340823\",\"340824\",\"340825\",\"340826\",\"340827\",\"340828\",\"340881\",\"341000\",\"341001\", \"341002\",\"341003\",\"341004\",\"341021\",\"341022\",\"341023\",\"341024\",\"341100\",\"341101\",\"341102\",\"341103\",\"341122\",\"341124\", \"341125\",\"341126\",\"341181\",\"341182\",\"341200\",\"341201\",\"341202\",\"341203\",\"341204\",\"341221\",\"341222\",\"341225\",\"341226\", \"341282\",\"341300\",\"341301\",\"341302\",\"341321\",\"341322\",\"341323\",\"341324\",\"341400\",\"341401\",\"341402\",\"341421\",\"341422\", \"341423\",\"341424\",\"341500\",\"341501\",\"341502\",\"341503\",\"341521\",\"341522\",\"341523\",\"341524\",\"341525\",\"341600\",\"341601\", \"341602\",\"341621\",\"341622\",\"341623\",\"341700\",\"341701\",\"341702\",\"341721\",\"341722\",\"341723\",\"341800\",\"341801\",\"341802\", \"341821\",\"341822\",\"341823\",\"341824\",\"341825\",\"341881\",\"350000\",\"350100\",\"350101\",\"350102\",\"350103\",\"350104\",\"350105\", \"350111\",\"350121\",\"350122\",\"350123\",\"350124\",\"350125\",\"350128\",\"350181\",\"350182\",\"350200\",\"350201\",\"350203\",\"350205\", \"350206\",\"350211\",\"350212\",\"350213\",\"350300\",\"350301\",\"350302\",\"350303\",\"350304\",\"350305\",\"350322\",\"350400\",\"350401\", \"350402\",\"350403\",\"350421\",\"350423\",\"350424\",\"350425\",\"350426\",\"350427\",\"350428\",\"350429\",\"350430\",\"350481\",\"350500\", \"350501\",\"350502\",\"350503\",\"350504\",\"350505\",\"350521\",\"350524\",\"350525\",\"350526\",\"350527\",\"350581\",\"350582\",\"350583\", \"350600\",\"350601\",\"350602\",\"350603\",\"350622\",\"350623\",\"350624\",\"350625\",\"350626\",\"350627\",\"350628\",\"350629\",\"350681\", \"350700\",\"350701\",\"350702\",\"350721\",\"350722\",\"350723\",\"350724\",\"350725\",\"350781\",\"350782\",\"350783\",\"350784\",\"350800\", \"350801\",\"350802\",\"350821\",\"350822\",\"350823\",\"350824\",\"350825\",\"350881\",\"350900\",\"350901\",\"350902\",\"350921\",\"350922\", \"350923\",\"350924\",\"350925\",\"350926\",\"350981\",\"350982\",\"360000\",\"360100\",\"360101\",\"360102\",\"360103\",\"360104\",\"360105\", \"360111\",\"360121\",\"360122\",\"360123\",\"360124\",\"360200\",\"360201\",\"360202\",\"360203\",\"360222\",\"360281\",\"360300\",\"360301\", \"360302\",\"360313\",\"360321\",\"360322\",\"360323\",\"360400\",\"360401\",\"360402\",\"360403\",\"360421\",\"360423\",\"360424\",\"360425\", \"360426\",\"360427\",\"360428\",\"360429\",\"360430\",\"360481\",\"360500\",\"360501\",\"360502\",\"360521\",\"360600\",\"360601\",\"360602\", \"360622\",\"360681\",\"360700\",\"360701\",\"360702\",\"360721\",\"360722\",\"360723\",\"360724\",\"360725\",\"360726\",\"360727\",\"360728\", \"360729\",\"360730\",\"360731\",\"360732\",\"360733\",\"360734\",\"360735\",\"360781\",\"360782\",\"360800\",\"360801\",\"360802\",\"360803\", \"360821\",\"360822\",\"360823\",\"360824\",\"360825\",\"360826\",\"360827\",\"360828\",\"360829\",\"360830\",\"360881\",\"360900\",\"360901\", \"360902\",\"360921\",\"360922\",\"360923\",\"360924\",\"360925\",\"360926\",\"360981\",\"360982\",\"360983\",\"361000\",\"361001\",\"361002\", \"361021\",\"361022\",\"361023\",\"361024\",\"361025\",\"361026\",\"361027\",\"361028\",\"361029\",\"361030\",\"361100\",\"361101\",\"361102\", \"361121\",\"361122\",\"361123\",\"361124\",\"361125\",\"361126\",\"361127\",\"361128\",\"361129\",\"361130\",\"361181\",\"370000\",\"370100\", \"370101\",\"370102\",\"370103\",\"370104\",\"370105\",\"370112\",\"370113\",\"370124\",\"370125\",\"370126\",\"370181\",\"370200\",\"370201\", \"370202\",\"370203\",\"370205\",\"370211\",\"370212\",\"370213\",\"370214\",\"370281\",\"370282\",\"370283\",\"370284\",\"370285\",\"370300\", \"370301\",\"370302\",\"370303\",\"370304\",\"370305\",\"370306\",\"370321\",\"370322\",\"370323\",\"370400\",\"370401\",\"370402\",\"370403\", \"370404\",\"370405\",\"370406\",\"370481\",\"370500\",\"370501\",\"370502\",\"370503\",\"370521\",\"370522\",\"370523\",\"370600\",\"370601\", \"370602\",\"370611\",\"370612\",\"370613\",\"370634\",\"370681\",\"370682\",\"370683\",\"370684\",\"370685\",\"370686\",\"370687\",\"370700\", \"370701\",\"370702\",\"370703\",\"370704\",\"370705\",\"370724\",\"370725\",\"370781\",\"370782\",\"370783\",\"370784\",\"370785\",\"370786\", \"370800\",\"370801\",\"370802\",\"370811\",\"370826\",\"370827\",\"370828\",\"370829\",\"370830\",\"370831\",\"370832\",\"370881\",\"370882\", \"370883\",\"370900\",\"370901\",\"370902\",\"370911\",\"370921\",\"370923\",\"370982\",\"370983\",\"371000\",\"371001\",\"371002\",\"371081\", \"371082\",\"371083\",\"371100\",\"371101\",\"371102\",\"371103\",\"371121\",\"371122\",\"371200\",\"371201\",\"371202\",\"371203\",\"371300\", \"371301\",\"371302\",\"371311\",\"371312\",\"371321\",\"371322\",\"371323\",\"371324\",\"371325\",\"371326\",\"371327\",\"371328\",\"371329\", \"371400\",\"371401\",\"371402\",\"371421\",\"371422\",\"371423\",\"371424\",\"371425\",\"371426\",\"371427\",\"371428\",\"371481\",\"371482\", \"371500\",\"371501\",\"371502\",\"371521\",\"371522\",\"371523\",\"371524\",\"371525\",\"371526\",\"371581\",\"371600\",\"371601\",\"371602\", \"371621\",\"371622\",\"371623\",\"371624\",\"371625\",\"371626\",\"371700\",\"371701\",\"371702\",\"371721\",\"371722\",\"371723\",\"371724\", \"371725\",\"371726\",\"371727\",\"371728\",\"410000\",\"410100\",\"410101\",\"410102\",\"410103\",\"410104\",\"410105\",\"410106\",\"410108\", \"410122\",\"410181\",\"410182\",\"410183\",\"410184\",\"410185\",\"410200\",\"410201\",\"410202\",\"410203\",\"410204\",\"410205\",\"410211\", \"410221\",\"410222\",\"410223\",\"410224\",\"410225\",\"410300\",\"410301\",\"410302\",\"410303\",\"410304\",\"410305\",\"410306\",\"410311\", \"410322\",\"410323\",\"410324\",\"410325\",\"410326\",\"410327\",\"410328\",\"410329\",\"410381\",\"410400\",\"410401\",\"410402\",\"410403\", \"410404\",\"410411\",\"410421\",\"410422\",\"410423\",\"410425\",\"410481\",\"410482\",\"410500\",\"410501\",\"410502\",\"410503\",\"410505\", \"410506\",\"410522\",\"410523\",\"410526\",\"410527\",\"410581\",\"410600\",\"410601\",\"410602\",\"410603\",\"410611\",\"410621\",\"410622\", \"410700\",\"410701\",\"410702\",\"410703\",\"410704\",\"410711\",\"410721\",\"410724\",\"410725\",\"410726\",\"410727\",\"410728\",\"410781\", \"410782\",\"410800\",\"410801\",\"410802\",\"410803\",\"410804\",\"410811\",\"410821\",\"410822\",\"410823\",\"410825\",\"410882\",\"410883\", \"410900\",\"410901\",\"410902\",\"410922\",\"410923\",\"410926\",\"410927\",\"410928\",\"411000\",\"411001\",\"411002\",\"411023\",\"411024\", \"411025\",\"411081\",\"411082\",\"411100\",\"411101\",\"411102\",\"411103\",\"411104\",\"411121\",\"411122\",\"411200\",\"411201\",\"411202\", \"411221\",\"411222\",\"411224\",\"411281\",\"411282\",\"411300\",\"411301\",\"411302\",\"411303\",\"411321\",\"411322\",\"411323\",\"411324\", \"411325\",\"411326\",\"411327\",\"411328\",\"411329\",\"411330\",\"411381\",\"411400\",\"411401\",\"411402\",\"411403\",\"411421\",\"411422\", \"411423\",\"411424\",\"411425\",\"411426\",\"411481\",\"411500\",\"411501\",\"411502\",\"411503\",\"411521\",\"411522\",\"411523\",\"411524\", \"411525\",\"411526\",\"411527\",\"411528\",\"411600\",\"411601\",\"411602\",\"411621\",\"411622\",\"411623\",\"411624\",\"411625\",\"411626\", \"411627\",\"411628\",\"411681\",\"411700\",\"411701\",\"411702\",\"411721\",\"411722\",\"411723\",\"411724\",\"411725\",\"411726\",\"411727\", \"411728\",\"411729\",\"419001\",\"420000\",\"420100\",\"420101\",\"420102\",\"420103\",\"420104\",\"420105\",\"420106\",\"420107\",\"420111\", \"420112\",\"420113\",\"420114\",\"420115\",\"420116\",\"420117\",\"420200\",\"420201\",\"420202\",\"420203\",\"420204\",\"420205\",\"420222\", \"420281\",\"420300\",\"420301\",\"420302\",\"420303\",\"420321\",\"420322\",\"420323\",\"420324\",\"420325\",\"420381\",\"420500\",\"420501\", \"420502\",\"420503\",\"420504\",\"420505\",\"420506\",\"420525\",\"420526\",\"420527\",\"420528\",\"420529\",\"420581\",\"420582\",\"420583\", \"420600\",\"420601\",\"420602\",\"420606\",\"420607\",\"420624\",\"420625\",\"420626\",\"420682\",\"420683\",\"420684\",\"420700\",\"420701\", \"420702\",\"420703\",\"420704\",\"420800\",\"420801\",\"420802\",\"420804\",\"420821\",\"420822\",\"420881\",\"420900\",\"420901\",\"420902\", \"420921\",\"420922\",\"420923\",\"420981\",\"420982\",\"420984\",\"421000\",\"421001\",\"421002\",\"421003\",\"421022\",\"421023\",\"421024\", \"421081\",\"421083\",\"421087\",\"421100\",\"421101\",\"421102\",\"421121\",\"421122\",\"421123\",\"421124\",\"421125\",\"421126\",\"421127\", \"421181\",\"421182\",\"421200\",\"421201\",\"421202\",\"421221\",\"421222\",\"421223\",\"421224\",\"421281\",\"421300\",\"421301\",\"421303\", \"421381\",\"422800\",\"422801\",\"422802\",\"422822\",\"422823\",\"422825\",\"422826\",\"422827\",\"422828\",\"429000\",\"429004\",\"429005\", \"429006\",\"429021\",\"430000\",\"430100\",\"430101\",\"430102\",\"430103\",\"430104\",\"430105\",\"430111\",\"430121\",\"430122\",\"430124\", \"430181\",\"430200\",\"430201\",\"430202\",\"430203\",\"430204\",\"430211\",\"430221\",\"430223\",\"430224\",\"430225\",\"430281\",\"430300\", \"430301\",\"430302\",\"430304\",\"430321\",\"430381\",\"430382\",\"430400\",\"430401\",\"430405\",\"430406\",\"430407\",\"430408\",\"430412\", \"430421\",\"430422\",\"430423\",\"430424\",\"430426\",\"430481\",\"430482\",\"430500\",\"430501\",\"430502\",\"430503\",\"430511\",\"430521\", \"430522\",\"430523\",\"430524\",\"430525\",\"430527\",\"430528\",\"430529\",\"430581\",\"430600\",\"430601\",\"430602\",\"430603\",\"430611\", \"430621\",\"430623\",\"430624\",\"430626\",\"430681\",\"430682\",\"430700\",\"430701\",\"430702\",\"430703\",\"430721\",\"430722\",\"430723\", \"430724\",\"430725\",\"430726\",\"430781\",\"430800\",\"430801\",\"430802\",\"430811\",\"430821\",\"430822\",\"430900\",\"430901\",\"430902\", \"430903\",\"430921\",\"430922\",\"430923\",\"430981\",\"431000\",\"431001\",\"431002\",\"431003\",\"431021\",\"431022\",\"431023\",\"431024\", \"431025\",\"431026\",\"431027\",\"431028\",\"431081\",\"431100\",\"431101\",\"431102\",\"431103\",\"431121\",\"431122\",\"431123\",\"431124\", \"431125\",\"431126\",\"431127\",\"431128\",\"431129\",\"431200\",\"431201\",\"431202\",\"431221\",\"431222\",\"431223\",\"431224\",\"431225\", \"431226\",\"431227\",\"431228\",\"431229\",\"431230\",\"431281\",\"431300\",\"431301\",\"431302\",\"431321\",\"431322\",\"431381\",\"431382\", \"433100\",\"433101\",\"433122\",\"433123\",\"433124\",\"433125\",\"433126\",\"433127\",\"433130\",\"440000\",\"440100\",\"440101\",\"440103\", \"440104\",\"440105\",\"440106\",\"440111\",\"440112\",\"440113\",\"440114\",\"440115\",\"440116\",\"440183\",\"440184\",\"440200\",\"440201\", \"440203\",\"440204\",\"440205\",\"440222\",\"440224\",\"440229\",\"440232\",\"440233\",\"440281\",\"440282\",\"440300\",\"440301\",\"440303\", \"440304\",\"440305\",\"440306\",\"440307\",\"440308\",\"440400\",\"440401\",\"440402\",\"440403\",\"440404\",\"440500\",\"440501\",\"440507\", \"440511\",\"440512\",\"440513\",\"440514\",\"440515\",\"440523\",\"440600\",\"440601\",\"440604\",\"440605\",\"440606\",\"440607\",\"440608\", \"440700\",\"440701\",\"440703\",\"440704\",\"440705\",\"440781\",\"440783\",\"440784\",\"440785\",\"440800\",\"440801\",\"440802\",\"440803\", \"440804\",\"440811\",\"440823\",\"440825\",\"440881\",\"440882\",\"440883\",\"440900\",\"440901\",\"440902\",\"440903\",\"440923\",\"440981\", \"440982\",\"440983\",\"441200\",\"441201\",\"441202\",\"441203\",\"441223\",\"441224\",\"441225\",\"441226\",\"441283\",\"441284\",\"441300\", \"441301\",\"441302\",\"441303\",\"441322\",\"441323\",\"441324\",\"441400\",\"441401\",\"441402\",\"441421\",\"441422\",\"441423\",\"441424\", \"441426\",\"441427\",\"441481\",\"441500\",\"441501\",\"441502\",\"441521\",\"441523\",\"441581\",\"441600\",\"441601\",\"441602\",\"441621\", \"441622\",\"441623\",\"441624\",\"441625\",\"441700\",\"441701\",\"441702\",\"441721\",\"441723\",\"441781\",\"441800\",\"441801\",\"441802\", \"441821\",\"441823\",\"441825\",\"441826\",\"441827\",\"441881\",\"441882\",\"441900\",\"442000\",\"445100\",\"445101\",\"445102\",\"445121\", \"445122\",\"445200\",\"445201\",\"445202\",\"445221\",\"445222\",\"445224\",\"445281\",\"445300\",\"445301\",\"445302\",\"445321\",\"445322\", \"445323\",\"445381\",\"450000\",\"450100\",\"450101\",\"450102\",\"450103\",\"450105\",\"450107\",\"450108\",\"450109\",\"450122\",\"450123\", \"450124\",\"450125\",\"450126\",\"450127\",\"450200\",\"450201\",\"450202\",\"450203\",\"450204\",\"450205\",\"450221\",\"450222\",\"450223\", \"450224\",\"450225\",\"450226\",\"450300\",\"450301\",\"450302\",\"450303\",\"450304\",\"450305\",\"450311\",\"450321\",\"450322\",\"450323\", \"450324\",\"450325\",\"450326\",\"450327\",\"450328\",\"450329\",\"450330\",\"450331\",\"450332\",\"450400\",\"450401\",\"450403\",\"450404\", \"450405\",\"450421\",\"450422\",\"450423\",\"450481\",\"450500\",\"450501\",\"450502\",\"450503\",\"450512\",\"450521\",\"450600\",\"450601\", \"450602\",\"450603\",\"450621\",\"450681\",\"450700\",\"450701\",\"450702\",\"450703\",\"450721\",\"450722\",\"450800\",\"450801\",\"450802\", \"450803\",\"450804\",\"450821\",\"450881\",\"450900\",\"450901\",\"450902\",\"450921\",\"450922\",\"450923\",\"450924\",\"450981\",\"451000\", \"451001\",\"451002\",\"451021\",\"451022\",\"451023\",\"451024\",\"451025\",\"451026\",\"451027\",\"451028\",\"451029\",\"451030\",\"451031\",\"451100\",\"451101\",\"451102\",\"451121\",\"451122\",\"451123\",\"451200\",\"451201\",\"451202\",\"451221\",\"451222\",\"451223\",\"451224\",\"451225\",\"451226\",\"451227\",\"451228\",\"451229\",\"451281\",\"451300\",\"451301\",\"451302\",\"451321\",\"451322\",\"451323\",\"451324\", \"451381\",\"451400\",\"451401\",\"451402\",\"451421\",\"451422\",\"451423\",\"451424\",\"451425\",\"451481\",\"460000\",\"460100\",\"460101\",\"460105\",\"460106\",\"460107\",\"460108\",\"460200\",\"460201\",\"469000\",\"469001\",\"469002\",\"469003\",\"469005\",\"469006\",\"469007\",\"469021\",\"469022\",\"469023\",\"469024\",\"469025\",\"469026\",\"469027\",\"469028\",\"469029\",\"469030\",\"469031\",\"469032\",\"469033\",\"500000\",\"500100\",\"500101\",\"500102\",\"500103\",\"500104\",\"500105\",\"500106\",\"500107\",\"500108\",\"500109\",\"500110\",\"500111\",\"500112\",\"500113\",\"500114\",\"500115\",\"500116\",\"500117\",\"500118\",\"500119\",\"500200\",\"500222\",\"500223\",\"500224\",\"500225\",\"500226\",\"500227\",\"500228\",\"500229\",\"500230\",\"500231\",\"500232\",\"500233\",\"500234\",\"500235\",\"500236\",\"500237\",\"500238\",\"500240\",\"500241\",\"500242\",\"500243\",\"510000\",\"510100\",\"510101\",\"510104\",\"510105\",\"510106\",\"510107\",\"510108\",\"510112\",\"510113\",\"510114\",\"510115\",\"510121\",\"510122\",\"510124\",\"510129\",\"510131\",\"510132\",\"510181\",\"510182\",\"510183\",\"510184\",\"510300\",\"510301\",\"510302\",\"510303\",\"510304\",\"510311\",\"510321\",\"510322\",\"510400\",\"510401\",\"510402\",\"510403\",\"510411\",\"510421\",\"510422\",\"510500\",\"510501\",\"510502\",\"510503\",\"510504\",\"510521\",\"510522\",\"510524\",\"510525\",\"510600\",\"510601\",\"510603\",\"510623\",\"510626\",\"510681\",\"510682\",\"510683\",\"510700\",\"510701\",\"510703\",\"510704\",\"510722\",\"510723\",\"510724\",\"510725\",\"510726\",\"510727\",\"510781\",\"510800\",\"510801\", \"510802\",\"510811\",\"510812\",\"510821\",\"510822\",\"510823\",\"510824\",\"510900\",\"510901\",\"510903\",\"510904\",\"510921\",\"510922\",\"510923\",\"511000\",\"511001\",\"511002\",\"511011\",\"511024\",\"511025\",\"511028\",\"511100\",\"511101\",\"511102\",\"511111\",\"511112\",\"511113\",\"511123\",\"511124\",\"511126\",\"511129\",\"511132\",\"511133\",\"511181\",\"511300\",\"511301\",\"511302\",\"511303\",\"511304\",\"511321\",\"511322\",\"511323\",\"511324\",\"511325\",\"511381\",\"511400\",\"511401\",\"511402\",\"511421\",\"511422\",\"511423\",\"511424\",\"511425\",\"511500\",\"511501\",\"511502\",\"511521\",\"511522\",\"511523\",\"511524\",\"511525\",\"511526\",\"511527\",\"511528\",\"511529\",\"511600\",\"511601\",\"511602\",\"511621\",\"511622\",\"511623\",\"511681\",\"511700\",\"511701\",\"511702\",\"511721\",\"511722\",\"511723\",\"511724\",\"511725\",\"511781\",\"511800\",\"511801\",\"511802\",\"511821\",\"511822\",\"511823\",\"511824\",\"511825\",\"511826\",\"511827\",\"511900\",\"511901\",\"511902\",\"511921\",\"511922\",\"511923\",\"512000\",\"512001\",\"512002\",\"512021\",\"512022\",\"512081\",\"513200\",\"513221\",\"513222\",\"513223\",\"513224\",\"513225\",\"513226\",\"513227\",\"513228\",\"513229\",\"513230\",\"513231\",\"513232\",\"513233\",\"513300\",\"513321\",\"513322\",\"513323\",\"513324\",\"513325\",\"513326\",\"513327\",\"513328\",\"513329\",\"513330\",\"513331\",\"513332\",\"513333\",\"513334\",\"513335\",\"513336\",\"513337\",\"513338\",\"513400\",\"513401\",\"513422\",\"513423\",\"513424\",\"513425\",\"513426\",\"513427\",\"513428\",\"513429\",\"513430\",\"513431\",\"513432\", \"513433\",\"513434\",\"513435\",\"513436\",\"513437\",\"520000\",\"520100\",\"520101\",\"520102\",\"520103\",\"520111\",\"520112\",\"520113\",\"520114\",\"520121\",\"520122\",\"520123\",\"520181\",\"520200\",\"520201\",\"520203\",\"520221\",\"520222\",\"520300\",\"520301\",\"520302\",\"520303\",\"520321\",\"520322\",\"520323\",\"520324\",\"520325\",\"520326\",\"520327\",\"520328\",\"520329\",\"520330\",\"520381\",\"520382\",\"520400\",\"520401\",\"520402\",\"520421\",\"520422\",\"520423\",\"520424\",\"520425\",\"522200\",\"522201\",\"522222\",\"522223\",\"522224\",\"522225\",\"522226\",\"522227\",\"522228\",\"522229\",\"522230\",\"522300\",\"522301\",\"522322\",\"522323\",\"522324\",\"522325\",\"522326\",\"522327\",\"522328\",\"522400\",\"522401\",\"522422\",\"522423\",\"522424\",\"522425\",\"522426\",\"522427\",\"522428\",\"522600\",\"522601\",\"522622\",\"522623\",\"522624\",\"522625\",\"522626\",\"522627\",\"522628\",\"522629\",\"522630\",\"522631\",\"522632\",\"522633\",\"522634\",\"522635\",\"522636\",\"522700\",\"522701\",\"522702\",\"522722\",\"522723\",\"522725\",\"522726\",\"522727\",\"522728\",\"522729\",\"522730\",\"522731\",\"522732\",\"530000\",\"530100\",\"530101\",\"530102\",\"530103\",\"530111\",\"530112\",\"530113\",\"530121\",\"530122\",\"530124\",\"530125\",\"530126\",\"530127\",\"530128\",\"530129\",\"530181\",\"530300\",\"530301\",\"530302\",\"530321\",\"530322\",\"530323\",\"530324\",\"530325\",\"530326\",\"530328\",\"530381\",\"530400\",\"530401\",\"530402\",\"530421\",\"530422\",\"530423\",\"530424\",\"530425\",\"530426\",\"530427\",\"530428\",\"530500\",\"530501\",\"530502\",\"530521\", \"530522\",\"530523\",\"530524\",\"530600\",\"530601\",\"530602\",\"530621\",\"530622\",\"530623\",\"530624\",\"530625\",\"530626\",\"530627\",\"530628\",\"530629\",\"530630\",\"530700\",\"530701\",\"530702\",\"530721\",\"530722\",\"530723\",\"530724\",\"530800\",\"530801\",\"530802\",\"530821\",\"530822\",\"530823\",\"530824\",\"530825\",\"530826\",\"530827\",\"530828\",\"530829\",\"530900\",\"530901\",\"530902\",\"530921\",\"530922\",\"530923\",\"530924\",\"530925\",\"530926\",\"530927\",\"532300\",\"532301\",\"532322\",\"532323\",\"532324\",\"532325\",\"532326\",\"532327\",\"532328\",\"532329\",\"532331\",\"532500\",\"532501\",\"532502\",\"532522\",\"532523\",\"532524\",\"532525\",\"532526\",\"532527\",\"532528\",\"532529\",\"532530\",\"532531\",\"532532\",\"532600\",\"532621\",\"532622\",\"532623\",\"532624\",\"532625\",\"532626\",\"532627\",\"532628\",\"532800\",\"532801\",\"532822\",\"532823\",\"532900\",\"532901\",\"532922\",\"532923\",\"532924\",\"532925\",\"532926\",\"532927\",\"532928\",\"532929\",\"532930\",\"532931\",\"532932\",\"533100\",\"533102\",\"533103\",\"533122\",\"533123\",\"533124\",\"533300\",\"533321\",\"533323\",\"533324\",\"533325\",\"533400\",\"533421\",\"533422\",\"533423\",\"540000\",\"540100\",\"540101\",\"540102\",\"540121\",\"540122\",\"540123\",\"540124\",\"540125\",\"540126\",\"540127\",\"542100\",\"542121\",\"542122\",\"542123\",\"542124\",\"542125\",\"542126\",\"542127\",\"542128\",\"542129\",\"542132\",\"542133\",\"542200\",\"542221\",\"542222\",\"542223\",\"542224\",\"542225\",\"542226\",\"542227\",\"542228\",\"542229\",\"542231\",\"542232\",\"542233\",\"542300\",\"542301\", \"542322\",\"542323\",\"542324\",\"542325\",\"542326\",\"542327\",\"542328\",\"542329\",\"542330\",\"542331\",\"542332\",\"542333\",\"542334\",\"542335\",\"542336\",\"542337\",\"542338\",\"542400\",\"542421\",\"542422\",\"542423\",\"542424\",\"542425\",\"542426\",\"542427\",\"542428\",\"542429\",\"542430\",\"542500\",\"542521\",\"542522\",\"542523\",\"542524\",\"542525\",\"542526\",\"542527\",\"542600\",\"542621\",\"542622\",\"542623\",\"542624\",\"542625\",\"542626\",\"542627\",\"610000\",\"610100\",\"610101\",\"610102\",\"610103\",\"610104\",\"610111\",\"610112\",\"610113\",\"610114\",\"610115\",\"610116\",\"610122\",\"610124\",\"610125\",\"610126\",\"610200\",\"610201\",\"610202\",\"610203\",\"610204\",\"610222\",\"610300\",\"610301\",\"610302\",\"610303\",\"610304\",\"610322\",\"610323\",\"610324\",\"610326\",\"610327\",\"610328\",\"610329\",\"610330\",\"610331\",\"610400\",\"610401\",\"610402\",\"610403\",\"610404\",\"610422\",\"610423\",\"610424\",\"610425\",\"610426\",\"610427\",\"610428\",\"610429\",\"610430\",\"610431\",\"610481\",\"610500\",\"610501\",\"610502\",\"610521\",\"610522\",\"610523\",\"610524\",\"610525\",\"610526\",\"610527\",\"610528\",\"610581\",\"610582\",\"610600\",\"610601\",\"610602\",\"610621\",\"610622\",\"610623\",\"610624\",\"610625\",\"610626\",\"610627\",\"610628\",\"610629\",\"610630\",\"610631\",\"610632\",\"610700\",\"610701\",\"610702\",\"610721\",\"610722\",\"610723\",\"610724\",\"610725\",\"610726\",\"610727\",\"610728\",\"610729\",\"610730\",\"610800\",\"610801\",\"610802\",\"610821\",\"610822\",\"610823\",\"610824\",\"610825\",\"610826\",\"610827\",\"610828\",\"610829\", \"610830\",\"610831\",\"610900\",\"610901\",\"610902\",\"610921\",\"610922\",\"610923\",\"610924\",\"610925\",\"610926\",\"610927\",\"610928\",\"610929\",\"611000\",\"611001\",\"611002\",\"611021\",\"611022\",\"611023\",\"611024\",\"611025\",\"611026\",\"620000\",\"620100\",\"620101\",\"620102\",\"620103\",\"620104\",\"620105\",\"620111\",\"620121\",\"620122\",\"620123\",\"620200\",\"620201\",\"620300\",\"620301\",\"620302\",\"620321\",\"620400\",\"620401\",\"620402\",\"620403\",\"620421\",\"620422\",\"620423\",\"620500\",\"620501\",\"620502\",\"620503\",\"620521\",\"620522\",\"620523\",\"620524\",\"620525\",\"620600\",\"620601\",\"620602\",\"620621\",\"620622\",\"620623\",\"620700\",\"620701\",\"620702\",\"620721\",\"620722\",\"620723\",\"620724\",\"620725\",\"620800\",\"620801\",\"620802\",\"620821\",\"620822\",\"620823\",\"620824\",\"620825\",\"620826\",\"620900\",\"620901\",\"620902\",\"620921\",\"620922\",\"620923\",\"620924\",\"620981\",\"620982\",\"621000\",\"621001\",\"621002\",\"621021\",\"621022\",\"621023\",\"621024\",\"621025\",\"621026\",\"621027\",\"621100\",\"621101\",\"621102\",\"621121\",\"621122\",\"621123\",\"621124\",\"621125\",\"621126\",\"621200\",\"621201\",\"621202\",\"621221\",\"621222\",\"621223\",\"621224\",\"621225\",\"621226\",\"621227\",\"621228\",\"622900\",\"622901\",\"622921\",\"622922\",\"622923\",\"622924\",\"622925\",\"622926\",\"622927\",\"623000\",\"623001\",\"623021\",\"623022\",\"623023\",\"623024\",\"623025\",\"623026\",\"623027\",\"630000\",\"630100\",\"630101\",\"630102\",\"630103\",\"630104\",\"630105\",\"630121\",\"630122\",\"630123\",\"632100\",\"632121\",\"632122\", \"632123\",\"632126\",\"632127\",\"632128\",\"632200\",\"632221\",\"632222\",\"632223\",\"632224\",\"632300\",\"632321\",\"632322\",\"632323\",\"632324\",\"632500\",\"632521\",\"632522\",\"632523\",\"632524\",\"632525\",\"632600\",\"632621\",\"632622\",\"632623\",\"632624\",\"632625\",\"632626\",\"632700\",\"632721\",\"632722\",\"632723\",\"632724\",\"632725\",\"632726\",\"632800\",\"632801\",\"632802\",\"632821\",\"632822\",\"632823\",\"640000\",\"640100\",\"640101\",\"640104\",\"640105\",\"640106\",\"640121\",\"640122\",\"640181\",\"640200\",\"640201\",\"640202\",\"640205\",\"640221\",\"640300\",\"640301\",\"640302\",\"640303\",\"640323\",\"640324\",\"640381\",\"640400\",\"640401\",\"640402\",\"640422\",\"640423\",\"640424\",\"640425\",\"640500\",\"640501\",\"640502\",\"640521\",\"640522\",\"650000\",\"650100\",\"650101\",\"650102\",\"650103\",\"650104\",\"650105\",\"650106\",\"650107\",\"650109\",\"650121\",\"650200\",\"650201\",\"650202\",\"650203\",\"650204\",\"650205\",\"652100\",\"652101\",\"652122\",\"652123\",\"652200\",\"652201\",\"652222\",\"652223\",\"652300\",\"652301\",\"652302\",\"652323\",\"652324\",\"652325\",\"652327\",\"652328\",\"652700\",\"652701\",\"652722\",\"652723\",\"652800\",\"652801\",\"652822\",\"652823\",\"652824\",\"652825\",\"652826\",\"652827\",\"652828\",\"652829\",\"652900\",\"652901\",\"652922\",\"652923\",\"652924\",\"652925\",\"652926\",\"652927\",\"652928\",\"652929\",\"653000\",\"653001\",\"653022\",\"653023\",\"653024\",\"653100\",\"653101\",\"653121\",\"653122\",\"653123\",\"653124\",\"653125\",\"653126\",\"653127\",\"653128\",\"653129\",\"653130\",\"653131\",\"653200\", \"653201\",\"653221\",\"653222\",\"653223\",\"653224\",\"653225\",\"653226\",\"653227\",\"654000\",\"654002\",\"654003\",\"654021\",\"654022\",\"654023\",\"654024\",\"654025\",\"654026\",\"654027\",\"654028\",\"654200\",\"654201\",\"654202\",\"654221\",\"654223\",\"654224\",\"654225\",\"654226\",\"654300\",\"654301\",\"654321\",\"654322\",\"654323\",\"654324\",\"654325\",\"654326\",\"659000\",\"659001\",\"659002\",\"659003\",\"659004\",\"710000\",\"810000\",\"820000\"}; char syear[5]={0}; char smouth[3]={0}; char sday[3]={0}; int year=0; int mouth=0; int day=0; int randomNumber=0; srand((unsigned)time(NULL)); randomNumber=rand()%899+100; year=rand()%119+1900; mouth=rand()%12+1; if(mouth==1||mouth==3||mouth==5||mouth==7||mouth==8||mouth==10||mouth==12){ day=rand()%31+1; }else{ if(mouth==2){ if((year%4==0&&year%100!=0)||year%400==0){ day=rand()%29+1; }else{ day=rand()%28+1; } }else{ day=rand()%30+1; } } strcpy(AreaCode, a[rand()%3515]); strcpy(Date,itoa(year,syear,10)); if(mouthIDgenerateDll.h extern \"C\" _declspec(dllexport) char*IDgenerate(); 使用工具打包成dll文件后，在loadrunner中可以直接调用。 lr_load_dll(\"IDgenerateDll.dll\"); lr_output_message(\"%s\",(char *)IDgenerate()); "},"语言/C/Linux下几款C++程序中的内存泄露检查工具.html":{"url":"语言/C/Linux下几款C++程序中的内存泄露检查工具.html","title":"Linux下几款C++程序中的内存泄露检查工具","keywords":"","body":"Linux下几款C++程序中的内存泄露检查工具 Linux下编写C或者C++程序，有很多工具，但是主要编译器仍然是gcc和g++。最近用到STL中的List编程，为了检测写的代码是否会发现内存泄漏，了解了一下相关的知识。 所有使用动态内存分配(dynamic memory allocation)的程序都有机会遇上内存泄露(memory leakage)问题，在Linux里有三种常用工具来检测内存泄露的情況，包括： 参见 http://elinux.org/Memory_Debuggers 内存泄露检测工具比较 工具 描述 valgrind 一个强大开源的程序检测工具 mtrace GNU扩展，用来跟踪malloc，mtrace为内存分配函数(malloc,rellaoc,memalign,free)安装hook函数 dmalloc 用于检查C/C++内存泄漏的工具，即是检查是否存在程序运行结束还没有释放的内存，以一个运行库发布 memwatch 和dmalloc一样，它能检测未释放的内存、同一段内存被释放多次、位址存取错误及不当使用未分配之内存区域 mpatrol 一个跨平台的 C++ 内存泄漏检测器 dbgmem 也是一个动态库发布的形式，优点类似dmalloc，但是相比之下，可能特点少了一些 Electric Fence 不仅仅能够跟踪malloc()和free(),同时能够检查读访问以及写入，能够准确指出导致错误的指令 Linux程序内存空间布局 代码段(.text):这里存放的是CPU要执行的指令，代码是可共享的，相同的代码在内存中只有一份拷贝，同时这个段是只读的，防止程序由于错误而修改自身指令 初始化数据段（.data）。这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：int val=100。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用exec函数启动该程序时从源程序文件中读入。 未初始化数据段（.bss）。位于这一段中的数据，内核在执行该程序前，将其初始化为0或者null。例如出现在任何函数之外的全局变量：int sum;以及未初始化或初值为0的全局变量和静态局部变量 堆（Heap）。这个段用于在程序中进行动态内存申请，例如经常用到的malloc，new系列函数就是从这个段中申请内存。 已初始化且初值非0的全局变量和静态局部变量 栈（Stack）。函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中。可执行代码、字符串字面值、只读变量。内存检查原理 Memcheck检测内存问题的原理图： 1.Valid-value表： 对于进程的整个地址空间中的每一字节(byte),都有与之对应的8个bits，对于CPU的每个寄存器，也有一个与之对应的bit向量。这些bits负责记录该字节或者寄存器值是否具有有效 的、已经初始化的值2.Valid-Address表 对于进程整个地址空间中的 么一个字节（byte),还有与 之对应的1bit，负责记录该地址是否能够被读写。检测原理 当要读写内存中的某个字节时，首先检查这个字节对应的A bit。如果该A bit显示该位置是无效位置，memcheck则报告读写错误。 内核（core）类似于一个虚拟的CPU的环境，这样当内存中的某个字节被加载到真实的CPU中时，该字节对应的V bit也被加载到虚拟的CPU环境中，一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序的输出，则memcheck会检查对应的vbits，如果该值尚未初始化，则会报告使用未初始化内存错误。 Valgrind Valgrind包括以下一些工具： Memcheck:这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够给发现开发中绝大多数的内存错误使用的情况，比如：使用未初始化 callgrind：它主要用来检查程序中函数中调用过程中出现的问题 cachegrind：它主要用来检查程序中缓存使用出现的问题 Helgrind：它主要用来检查多线程中出现的竞争问题 Massif:它主要用来检查程序中堆栈使用中出现的问题 Extension:可以使用core提供的 功能，自己编写特定的内存调试工具 安装 下载地址 解压安装包 tar -jxvf valgrind-3.11.0.tar.bz2 -C /usr/local/src 进入目录安装 cd /usr/local/src/valgrind-3.11.0 运行./autogen.sh设置环境（需要标准的autoconf工具） ./autogen.sh 配置Valgrind，生成MakeFile文件 ./configure --prefix=/usr/local 编译和安装valgrind make && make install 安装后，输入 valgrind ls -l 验证一下该工具是否工作正常（这是README里面的方法，实际上是验证一下对ls -l命令的内存检测），如果你看到一堆的信息说明你的工具可以使用了。 使用 准备好程序 为了valgrind发现的错误更精确，如能够定位到源代码的行，建议在编译时加上-g参数，编译优化选项选择O0(不要优化) 在valgrind下，运行可执行程序 利用valgrind调试内存问题，不需要重新编译源程序，它的输入就是二进制的可执行程序。调用Valgrind的通用格式是：valgrind [valgrind-options] your-prog [your-prog-options]> Valgrind 的参数分为两类，一类是 core 的参数，它对所有的工具都适用；另外一类就是具体某个工具如 memcheck 的参数。Valgrind 默认的工具就是 memcheck，也可以通过“–tool=tool name”指定其他的工具。Valgrind 提供了大量的参数满足你特定的调试需求，具体可参考其用户手册。 编译程序 g++ -g -o leak leak.c 被检测程序加入 –g -fno-inline 编译选项保留调试信息, 否则后面的valgrind不能显示到出错行号。 valgrind被设计成非侵入式的，它直接工作于可执行文件上，因此在检查前不需要重新编译、连接和修改你的程序。要检查一个程序很简单，只需要执行下面的命令就可以了。 valgrind --tool=tool_name program_name 比如我们要对ls -l命令做内存检查，只需要执行下面的命令就可以了 valgrind --tool=memcheck ls -l 小提示 如果不知道有哪些参数, 可以先输入valgrind –tool=, 然后狂按两次tab, 会输出linux系统的只能提示, 同样,如果你输入了valgrind –tool=mem再狂按两次tab,linux系统会为你自动补全 使用valgrind检测Memcheck 下面我们就可以用valgrind对我们的程序检测leak valgrind --tool=memcheck --leak-check=full --show-reachable=yes --trace-children=yes ./leak 其中–leak-check=full 指的是完全检查内存泄漏， –show-reachable=yes是显示内存泄漏的地点， –trace-children=yes是跟入子进程。 当程序正常退出的时候valgrind自然会输出内存泄漏的信息原理： mtrace检测内存泄露 mtrace其实是GNU扩展函数，用来跟踪malloc。 mtrace为内存分配函数（malloc, realloc, memalign, free）安装hook函数。这些hook函数记录内存的申请和释放的trace信息。 在程序中，这些trace信息可以被用来发现内存泄漏和释放不是申请的内存。 当调用mtrace，mtrace会检查环境变量MALLOC_TRACE。该环境变量应该包含记录trace信息的文件路径。如果文件可以被成功打开，它的大小被截断为0。 如果MALLOC_TRACE没有设置，或者设置的文件不可用或者不可写，那么将不会安装hook函数，mtrace不生效。 详细说明可参考man page：man 3 mtrace mtrace使用 mtrace能监测程序是否内存泄露 在程序的起始处包含头文件 #include 更改环境变量：export MALLOC_TRACE=”mtrace.out”可以加入如下代码 setenv(\"MALLOC_TRACE\", \"mtrace.out\", 1); 调用函数mtrace() mtrace() 编译程序带上 -g 选项 gcc -g -c leak_mtrace.c -o leak_mtrace.o -std=gnu9x -Wall 运行程序一次，尽量调用所有程序内的函数。这时调试信息就已经被写入我们指定的mtrace.out文件中 ./leak_mtrace mtrace a.out mtrace.out查看内存监测情况 mtrace a.out mtrace.out dmalloc dmalloc是一种用于检查C/C++内存泄露(leak)的工具，即检查是否存在直到程序运行结束还没有释放的内存，并且能够精确指出在哪个源文件的第几行。 Linux内核的Kmemleak Kmemleak检测工具介绍 Kmemleak工作于内核态是内核自带的内核泄露检测工具, 其源代码位于mm/kmemleak.c Kmemleak工作于内核态，Kmemleak 提供了一种可选的内核泄漏检测，其方法类似于跟踪内存收集器。当独立的对象没有被释放时，其报告记录在 /sys/kernel/debug/kmemleak中，Kmemcheck能够帮助定位大多数内存错误的上下文。 Kmemleak使用过程概述 首先`CONFIG_DEBUG_KMEMLEAK在Kernel hacking中被使能. 查看内核打印信息详细过程如下： 挂载debugfs文件系统 mount -t debugfs nodev /sys/kernel/debug/ 开启内核自动检测线程 echo scan > /sys/kernel/debug/kmemleak 查看打印信息 cat /sys/kernel/debug/kmemleak 清除内核检测报告，新的内存泄露报告将重新写入/sys/kernel/debug/kmemleak echo clear > /sys/kernel/debug/kmemleak 内存扫描参数可以进行修改通过向/sys/kernel/debug/kmemleak 文件写入。 参数使用如下 off 禁用kmemleak（不可逆） stack=on 启用任务堆栈扫描(default) stack=off 禁用任务堆栈扫描 scan=on 启动自动记忆扫描线程(default) scan=off 停止自动记忆扫描线程 scan= 设置n秒内自动记忆扫描 scan 开启内核扫描 clear 清除内存泄露报告 dump= 转存信息对象在 通过“kmemleak = OFF”，也可以在启动时禁用Kmemleak在内核命令行。在初始化kmemleak之前，内存的分配或释放这些动作被存储在一个前期日志缓冲区。这个缓冲区的大小通过配CONFIG_DEBUG_KMEMLEAK_EARLY_LOG_SIZE设置。 Kmemleak动态检测原理 通过的kmalloc、vmalloc、kmem_cache_alloc等内存分配会跟踪其指针，连同其他的分配大小和堆栈跟踪信息，存储在PRIO搜索树。相应的释放函数调用跟踪和指针就会从kmemleak数据结构中移除。 分配的内存块，被认为是独立的，如果没有指针指向它起始地址或块的内部的任何位置，可以发现扫描内存（包括已保存的寄存器）。这意味着，有可能没有办法为内核通过所分配的地址传递块到一个释放函数，因此，该块被认为是一个内存泄漏。 扫描算法步骤： 标记的所有分配对象为白色（稍后将剩余的白色物体考虑独立的） 扫描存储器与所述数据片段和栈开始，检查对地址的值存储在PRIO搜索树。如果一个白色的对象的指针被发现，该对象将被添加到灰名单 扫描的灰色对象匹配的地址（一些白色物体可以变成灰色，并添加结束时的灰名单），直到黑色集结束 剩下的白色物体被认为是独立儿，并报告写入/sys/kernel/debug/kmemleak。 一些分配的内存块的指针在内核的内部数据结构和它们不能被检测为孤儿。对避免这种情况，kmemleak也可以存储的数量的值，指向一个内的块的地址范围内的地址，需要找到使块不被认为是泄漏. kmem相关函数 从kernel源代码中的目录include /linux/kmemleak.h中可查看函数原型的头 函数 功能 kmemleak_init 初始化kmemleak kmemleak_alloc 一个内存块分配的通知 kmemleak_alloc_percpu 通知的一个percpu的内存块分配 kmemleak_free 通知的内存块释放 kmemleak_free_part 通知释放部分内存块 kmemleak_free_percpu 一个percpu内存块释放的通知 kmemleak_not_leak 当不是泄露时，标记对象 kmemleak_ignore 当泄漏时不扫描或报告对象 kmemleak_scan_area 添加扫描区域内的内存块 kmemleak_no_scan 不扫描的内存块 kmemleak_erase 删除一个指针变量的旧值 kmemleak_alloc_recursive 为kmemleak_alloc，只检查递归 kmemleak_free_recursive 为kmemleak_free，只检查递归 "},"语言/Shell/":{"url":"语言/Shell/","title":"Shell","keywords":"","body":"Shell "},"语言/Shell/使用SSH远程连接发送命令.html":{"url":"语言/Shell/使用SSH远程连接发送命令.html","title":"使用SSH远程连接发送命令","keywords":"","body":"使用SSH远程连接发送命令 Shell远程执行： 经常需要远程到其他节点上执行一些shell命令，如果分别ssh到每台主机上再去执行很麻烦，因此能有个集中管理的方式就好了。以下介绍两种shell命令远程执行的方法。 对于脚本的方式： 有些远程执行的命令内容较多，单一命令无法完成，考虑脚本方式实现： #!/bin/bash ssh user@remoteNode > /dev/null 2>&1 远程执行的内容在“ 重定向目的在于不显示远程的输出了 在结束前，加exit退出远程节点 SSH命令格式 usage: ssh [-1246AaCfgKkMNnqsTtVvXxYy] [-b bind_address] [-c cipher_spec] [-D [bind_address:]port] [-e escape_char] [-F configfile] [-I pkcs11] [-i identity_file] [-L [bind_address:]port:host:hostport] [-l login_name] [-m mac_spec] [-O ctl_cmd] [-o option] [-p port] [-R [bind_address:]port:host:hostport] [-S ctl_path] [-W host:port] [-w local_tun[:remote_tun]] [user@]hostname [command] 主要参数说明 -l 指定登入用户 -p 设置端口号 -f 后台运行，并推荐加上 -n 参数 -n 将标准输入重定向到 /dev/null，防止读取标准输入。如果在后台运行ssh的话（-f选项），就需要这个选项。 -N 不执行远程命令，只做端口转发 -q 安静模式，忽略一切对话和错误提示 -T 禁用伪终端配置 -t （tty）为远程系统上的ssh进程分配一个伪tty（终端）。如果没有使用这个选项，当你在远程系统上运行某条命令的时候，ssh不会为该进程分配tty（终端）。相反，ssh将会把远端进程的标准输入和标准输出附加到ssh会话上去，这通常就是你所希望的（但并非总是如此）。这个选项将强制ssh在远端系统上分配tty，这样那些需要tty的程序就能够正常运行。 -v verbose）显示与连接和传送有关的调试信息。如果命令运行不太正常的话，这个选项就会非常有用。 ssh控制远程主机，远程执行命令步骤 第一步，设置ssh免认证，免认证就是不用密码认证就可以直接登录，这在写脚本服务器控制时特别有用。 每二步，就是到远端服务器上去执行命令 准备工作 基于公私钥认证（可参考：Linux配置SSH密钥登录详解及客户端测试使用无密码登录）或者用户名密码认证（可参考：SSH使用expect自动输入密码、命令实现非交互式密码授权）能确保登录到远程服务器 cmd如果是脚本，注意绝对路径问题（相对路径在远程执行时就是坑） 基于公私钥认证远程登录可能存在的不足 这个可以满足我们大多数的需求，但是通常运维部署很多东西的时候需要root权限，但是有几处限制： 远程服务器禁止root用户登录 在远程服务器脚本里转换身份用expect需要send密码，这样不够安全 ssh 执行远程命令格式 ssh [options] [user@]host [command] 其中，host为想要连接到的OpenSSH服务器（远程系统）的名称，它是惟一的必需参数。host可以是某个本地系统的名称，也可以是因特网上某个系统的FQDN（参见术语表）或者是一个IP地址。命令ssh host登录到远程系统host，使用的用户名与正在本地系统上使用的用户名完全相同。如果希望登录的用户名与正在本地系统上使用的用户名不同，那么就应该包含user@。根据服务器设置的不同，可能还需要提供口令。 打开远程shell 如果没有提供command参数，ssh就会让你登录到host上去。远程系统显示一个shell提示符，然后就能够在host上运行命令。命令exit将会关闭与host的连接，并返回到本地系统的提示符。 例：命令行执行登录并且在目标服务器上执行命令 ssh user@remoteNode \"cd /home ; ls\" 基本能完成常用的对于远程节点的管理了，几个注意的点： 如果想在远程机器上连续执行多条命令，可以用单引号或者双引号将这些命令括起来。如果不加单引号或者双引号，第二个ls命令在本地执行。例如 ssh user@node cd /local ls 则 ls 只会执行 cd /local 命令，ls命令在本地执行，加了双引号或者单引号，则被括起来的命令被当做ssh命令的一个参数，所以会在远程连续执行。 分号，两个命令之间用分号隔开 例：在目标服务器上执行批量的命令。 #!/bin/bash ssh root@192.168.0.23 远程执行的内容在\" 如果不想日志文件在本机出现可以修改配置 ssh root@192.168.0.23 > /dev/null 2>&1 ssh的-t参数 -t Force pseudo-tty allocation. This can be used to execute arbitrary screen-based programs on a remote machine, which can be very useful, e.g. when implementing menu services. Multiple -t options force tty allocation, even if ssh has no local tty.中文翻译一下：就是可以提供一个远程服务器的虚拟tty终端，加上这个参数我们就可以在远程服务器的虚拟终端上输入自己的提权密码了，非常安全 命令格式 ssh -t -p $port $user@$ip 'cmd' 示例脚本 #!/bin/bash #变量定义 ip_array=(\"192.168.1.1\" \"192.168.1.2\" \"192.168.1.3\") user=\"test1\" remote_cmd=\"/home/test/1.sh\" #本地通过ssh执行远程服务器的脚本 for ip in ${ip_array[*]} do if [ $ip = \"192.168.1.1\" ]; then port=\"7777\" else port=\"22\" fi ssh -t -p $port $user@$ip \"remote_cmd\" done 这个方法还是很方便的，-t虚拟出一个远程服务器的终端，在多台服务器同时部署时确实节约了不少时间啊！ 例：查看远程服务器的cpu信息 假设远程服务器IP是192.168.110.34 ssh -l www-online 192.168.110.34 “cat /proc/cpuinfo” 例：执行远程服务器的sh文件 首先在远程服务器的/home/www-online/下创建一个uptimelog.sh脚本 #!/bin/bash uptime >> 'uptime.log' exit 0 使用chmod增加可执行权限 chmod u+x uptimelog.sh 在本地调用远程的uptimelog.sh ssh -l www-online 192.168.110.34 \"/home/www-online/uptimelog.sh\" 执行完成后,在远程服务器的/home/www-online/中会看到uptime.log文件，显示uptime内容 www-online@nmgwww34:~$ tail -f uptime.log 21:07:34 up 288 days, 8:07, 1 user, load average: 0.05, 0.19, 0.31 例：执行远程后台运行sh 首先把uptimelog.sh修改一下,修改成循环执行的命令。作用是每一秒把uptime写入uptime.log #!/bin/bash while : do uptime >> 'uptime.log' sleep 1 done exit 0 我们需要这个sh在远程服务器以后台方式运行，命令如下： ssh -l www-online 192.168.110.34 “/home/www-online/uptimelog.sh &” www-online@onlinedev01:~$ ssh -l www-online 192.168.110.34 \"/home/www-online/uptimelog.sh &\" www-online@192.168.110.34's password: 输入密码后，发现一直停住了，而在远程服务器可以看到，程序已经以后台方式运行了。 www-online@nmgwww34:~$ ps aux|grep uptimelog.sh 1007 20791 0.0 0.0 10720 1432 ? S 21:25 0:00 /bin/bash /home/www-online/uptimelog.sh 原因是因为uptimelog.sh一直在运行，并没有任何返回，因此调用方一直处于等待状态。 我们先kill掉远程服务器的uptimelog.sh进程，然后对应此问题进行解决。 ssh 调用远程命令后不能自动退出解决方法 可以将标准输出与标准错误输出重定向到/dev/null，这样就不会一直处于等待状态。 ssh -l www-online 192.168.110.34 “/home/www-online/uptimelog.sh > /dev/null 2>&1 &” www-online@onlinedev01:~$ ssh -l www-online 192.168.110.34 \"/home/www-online/uptimelog.sh > /dev/null 2>&1 &\" www-online@192.168.110.34's password: www-online@onlinedev01:~$ 但这个ssh进程会一直运行在后台，浪费资源，因此我们需要自动清理这些进程。 实际上，想ssh退出，我们可以在ssh执行完成后kill掉ssh这个进程来实现。 首先，创建一个sh执行ssh的命令,这里需要用到ssh的 -f 与 -n 参数，因为我们需要ssh也以后台方式运行，这样才可以获取到进程号进行kill操作。 创建ssh_uptimelog.sh，脚本如下 #!/bin/bash ssh -f -n -l www-online 192.168.110.34 \"/home/www-online/uptimelog.sh &\" # 后台运行ssh pid=$(ps aux | grep \"ssh -f -n -l www-online 192.168.110.34 /home/www-online/uptimelog.sh\" | awk '{print $2}' | sort -n | head -n 1) # 获取进程号 echo \"ssh command is running, pid:${pid}\" sleep 3 && kill ${pid} && echo \"ssh command is complete\" # 延迟3秒后执行kill命令，关闭ssh进程，延迟时间可以根据调用的命令不同调整 exit 0 可以看到，3秒后会自动退出 www-online@onlinedev01:~$ ./ssh_uptimelog.sh www-online@192.168.110.34's password: ssh command is running, pid:10141 ssh command is complete www-online@onlinedev01:~$ 然后查看远程服务器，可以见到 uptimelog.sh 在后台正常执行。 www-online@nmgwww34:~$ ps aux|grep uptime 1007 28061 0.1 0.0 10720 1432 ? S 22:05 0:00 /bin/bash /home/www-online/uptimelog.sh 查看uptime.log，每秒都有uptime数据写入。 www-online@nmgwww34:~$ tail -f uptime.log 22:05:44 up 288 days, 9:05, 1 user, load average: 0.01, 0.03, 0.08 22:05:45 up 288 days, 9:05, 1 user, load average: 0.01, 0.03, 0.08 22:05:46 up 288 days, 9:05, 1 user, load average: 0.01, 0.03, 0.08 22:05:47 up 288 days, 9:05, 1 user, load average: 0.01, 0.03, 0.08 22:05:48 up 288 days, 9:05, 1 user, load average: 0.01, 0.03, 0.08 附录： 1、单引号和双引号在ssh命令中的区别： 以一个例子来说明问题， 假设本地机器上配置了JAVA环境变量，在本地执行 echo $JAVA_HOME=/opt/jdk 假若我想查看远程机器上的JAVA环境变量，则只能使用单引号了，ssh user@node ‘ echo $JAVA ‘, 则是’ ‘ 中的$JAVA不会被shell解析，而是当做一个字符串，此时参数 echo $JAVA 传递给了 ssh； 如果我们使用 ssh user@node ” echo $JAVA “，则 shell 首先会解析$JAVA,得到它的值，则该命令就变成了 ssh user@node ‘ echo /opt/jdk ‘ 了 2、可能遇到的问题 问题：远程登录主机时出现Pseudo-terminal will not be allocated because stdin is not a terminal. 错误 解决方案：字面意思是伪终端将无法分配，因为标准输入不是终端。 所以需要增加-t -t参数来强制伪终端分配，即使标准输入不是终端。 to force pseudo-tty allocation even if stdin isn’t a terminal. 参考样例如下: ssh -t -t user1@host1 -p 9527 "},"语言/Assembly-on-macOS-master/":{"url":"语言/Assembly-on-macOS-master/","title":"汇编语言","keywords":"","body":"macOS上的汇编入门 这一系列文章的目标群体是使用macOS系统的，希望入门汇编语言的人群。 目录 macOS上的汇编入门（一）——引言 macOS上的汇编入门（二）——数学基础 macOS上的汇编入门（三）——硬件基础 macOS上的汇编入门（四）——操作系统基础 macOS上的汇编入门（五）——第一个汇编程序 macOS上的汇编入门（六）——汇编语言初识 macOS上的汇编入门（七）——字面量与局部变量 macOS上的汇编入门（八）——寻址方式与全局变量 macOS上的汇编入门（九）——跳转与函数 macOS上的汇编入门（十）——再探函数 macOS上的汇编入门（十一）——系统调用 macOS上的汇编入门（十二）——调试 macOS上的汇编入门（十三）——从编译到执行 源码 文章中提到的大部分代码都在目录source-code中。 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（一）——引言.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（一）——引言.html","title":"macOS上的汇编入门（一）——引言","keywords":"","body":"我最近一个阶段都在学习汇编语言，但是，当我想使用我的Mac编写汇编语言的时候，发现了许多问题。比如说，大多数实体的教材都采用的是32位甚至是16位的处理器，在如今仅支持64位架构的macOS 10.15上根本不能原生运行；再者，基于XNU这种类Unix内核的macOS系统，汇编语言的部分细节，如系统调用号等等与Linux不同，调用约定也与Windows不同。但现在网络上基于macOS来入门汇编语言的文章非常少，涉及到macOS汇编的也基本上不是用来入门的文章。因此，我打算利用这个暑假来写一写如何在macOS上入门汇编语言。 需要的背景知识 阅读我写的这一系列文章需要的背景知识并不多，包括： 能看懂C语言 一点点的计组知识 一点点的命令行知识（至少应当会在终端下进入指定的目录） 这系列文章究竟讲了什么 那么，我打算讲的是在macOS上利用GAS语法，也就是AT&T语法进行x86-64汇编的入门。 下一篇文章：macOS上的汇编入门（二）——数学基础 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（二）——数学基础.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（二）——数学基础.html","title":"macOS上的汇编入门（二）——数学基础","keywords":"","body":"在正式介绍汇编语言之前，我会先用几篇文章讲一些数学基础和硬件基础。如果读者已经具备了一定的知识基础，可以直接跳过这些文章去汇编语言部分。 二进制，八进制与十六进制 在计算机底层的软件层面，我们通常采用二进制，八进制或十六进制来记录数字，其中最常用的是十六进制。所谓$n$进制，就是从0开始数，逢$n$进1. 比如说二进制，就是从0开始数，到1，然后到2的时候进1变成10. 八进制也是类似，但是到了十六进制就犯了难，我们的数字只有0到9这十个，并不能表示出16个呀，于是，我们默认使用了a到f这六个字母来分别表示10到15这六个数。也就是说，十进制数10对应的十六进制数是a, 十进制数26对应的十六进制数是1a. 在计算机底层，通常用0x开头表示十六进制，用0开头表示八进制，而没有前缀来表示十进制。因此，比如说以下的汇编代码（并不需要理解实际含义） movq $0x1a, %rax 与 movq $26, %rax 相同。 十进制数与十六进制数的转化可以在搜索引擎上找到，这里不再赘述。而八进制，十六进制数与二进制数的转换则十分简单。一个八进制数的一位代表一个二进制数的三位，比如说八进制数的一位5就代表二进制数的三位011; 同理，一个十六进制数的一位就代表二进制数的四位。因此，十六进制数0x2000001就代表二进制数0010000000000000000000000001. 我们知道，之所以使用二进制数，是因为计算机底层采用高电平/低电平这种方法来表示数。那么，我们为什么要使用八进制、十六进制呢？我们知道，如今的计算机大多采用64位系统，意思是说，任何一个地址都是一个64位二进制数。那么，如果我们只采用二进制来表示一个地址，那么得有64个0或者1, 这不仅让我们看花眼了，而且也极大的浪费了电脑的显示资源。而刚才讲到的十六进制数则帮我们解决了这个问题。我们知道，十六进制数的一位对应二进制数的4位。因此，一个$n$位二进制数，只需要$\\lceil\\frac{n}{4}\\rceil$位十六进制数即可。也就是说，我们要表示64位的地址，只需要16位十六进制数即可。 补码 进制问题解决了在计算机底层软件中数的表示问题，接下来还需要解决的是记录问题，也就是说，如何把数实际存储在64位寄存器中。我们想要解决两个问题： 如何记录负数 可以使用加法器计算减法么 天才般的先行者，使用了补码来一举解决了这两个问题。 想要解决第二个问题，一个想法自然出现了，既然$a-b=a+(-b)$, 那可以在加法器中输入一个正数和一个负数来实现减法呀。 然而，我们知道，在计算机中，一个存储单位存储的数据大小是有上限的。比如说在64位CPU中，每个寄存器有64位，因此可以存储64位二进制数。因此，在CPU的加法器中，实际上使用了模$2^{64}$加法。也就是说，加法器做的，就是对于输入的两个64位二进制数$a$和$b$, 输出64位二进制数$(a+b)\\bmod{2^{64}}$. 因此，我们只有找到合适的将负数记录成64位二进制数的方法，才能将加法器转化为减法器。 注意到 $$ a-b\\equiv a+\\left(2^{64}-b\\right)\\pmod{2^{64}} $$ 而由于$b$是64位二进制数，因此，$2^{64}-b$必然是一个正数，而正数的记录方法我们是知道的。因此，我们可以使用$2^{64}-b$来记录$-b$, 其参与的减法就可以变成相应的加法。 但是，还有一个细节需要注意。比如说，我们想要记录的二进制数是0xfffffffffffffffe, 那么根据刚刚讨论的，我们可以将其记录为0x1. 这就出现了问题，如何区分0x1和0xfffffffffffffffe呢？我们采用这种方法只是为了方便减法，并不打算将正数和负数混同啊。 因此，在实际操作中，当出现负数时，能够允许的负数的绝对值最大值是$2^{63}$. 换句话说，其记录值最高位0表示正数，1表示负数。这种记录方法叫做补码。也就是说，对于小于$2^{63}$的正数，采用其二进制表示为其实际记录；对于不低于$-2^{63}$的负数，将其加上$2^{64}$后的正数的二进制表示为其实际记录。如果采用补码，那么可以表示$-2^{63}\\sim2^{63}-1$的整数。因此，采用补码记录的数称为有符号整数。反之，如果直接使用其二进制表示为其记录的话，那么只能表示$0\\sim 2^{64}-1$的整数。因此，这种数的记录形式称为无符号整数。 逻辑运算 除了加减乘除以外，二进制数还有独特的运算——逻辑运算。分别是与(and), 或(or), 非(not)和异或(xor). 与或非大家都很熟悉了，异或就是当且仅当两个操作数不同时输出1, 相同时输出0. 上一篇文章：macOS上的汇编入门（一）——引言 下一篇文章：macOS上的汇编入门（三）——硬件基础 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（三）——硬件基础.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（三）——硬件基础.html","title":"macOS上的汇编入门（三）——硬件基础","keywords":"","body":"在上一篇文章中，我们讲了关于进制、补码和逻辑运算的数学基础。在这篇文章中，我们主要讨论的是硬件基础。由于汇编语言实际上是底层硬件的一个抽象，因此，我并不想太多地涉及底层硬件，只想大致讲一下硬盘-内存-CPU的这个三级结构。但这里要指出的是，实际上硬件层面远不止这么简单，还有一二三级缓存等复杂的结构。 CPU、内存与硬盘 打开我们的Mac的系统信息，我们可以看到处理器和内存型号： 在磁盘工具中，我们也可以看到硬盘的型号： 处理器（即CPU）、内存和硬盘，这三者究竟有什么关系呢？ 通过一个简单的计算我们可以知道，一块硬盘的大小为251GB, 那么一共有251,000,000,000个存储单元，也就是约10的11次方个存储单元；一块内存的大小为8GB, 那么一共有8,000,000,000个存储单元，也就是约10的9次方个存储单元；而一块Intel Core i5的CPU，由于采用x86-64架构，因此一共有16个通用寄存器。 因此，一块硬盘的存储容量是一块内存的100倍，是一个CPU的10,000,000,000倍！ 那么，我们为什么要有这样的区分呢？能不能整个电脑的存储全用CPU的寄存器来做呢？答案是：理论上能，但实际上人类科技水平达不到，而且即使做出来也太贵了。我们从一个只有CPU，存储全靠寄存器的电脑入手，看如何能降低科技要求，削减开支。 CPU的功能是什么？是将寄存器中存储的值放到各种运算单元中进行处理。那么，我们在运行一个程序的时候，可能这个程序会有数以千计个变量，但是，在一段时间内参与运算的变量的个数却是非常少的，许多变量在参与运算后的很长一段时间内都不会再次参与运算。那么，我们不如只在CPU中保留少量的寄存器，用于存储当前参与运算的变量。然后将大部分不参与运算的变量存储在别的地方，在需要它们的时候再把它们导入到寄存器中。这就是内存(Memory)的功能。换句话说，CPU的功能主要是在寄存器中存储当前需要参与运算的变量，并可以用极高的速度将这些变量进行运算（从硬件层面上来讲，寄存器直连各种运算的器件）。当需要参与的变量不在寄存器中时，向内存发出访问申请，内存将变量导入CPU的寄存器中（这个时间与CPU寄存器参与运算的时间而言较慢）再参与运算。因此，内存的存储单元的速度可以比CPU的寄存器的慢一些，所以造价也就可以便宜一些。 那么运算全靠CPU，存储全靠内存，行不行呢？我们知道，在电脑中，不止有正在运行的程序，还有一些用于长期存储的文件。这些文件几乎很长时间才会运行一次。但是，CPU申请访问这些文件和申请访问那些经常运行的程序的优先级是相同的。这样的话，就会造成浪费。同时，CPU和内存也可以做到每次通电（也就是电脑启动）以后才会开始读写，一旦掉电（也就是电脑关机）那么所有数据就会消失。因此，我们将一些用于长期存储、电脑关机以后仍然需要保存的数据放到了硬盘(Disk)中，在程序运行的时候，将硬盘中的数据加载到内存中，再在CPU中参与运算。这样，硬盘的读写速度可以再进一步降低，成本也就进一步下降。 打个比方来说，硬盘、内存和CPU的关系就像是衣橱、工作台和针的关系。衣橱中存放的是已经编织好的衣服和一些毛线。当我们需要编织的时候，将毛线放在工作台上，然后用针穿起需要织的那一根线，进行编织。 存储单元 在内存和硬盘中，数据的存储的基本单位都是字节(Byte)。我们知道，在硬件中表示数据都是采用的二进制位，也就是0和1. 我们称每一位这样的二进制位为一个比特(Bit). 而一个字节，就是连续的八个比特。我们在汇编语言中，大部分情况下需要处理的最小的单位就是字节。一个字节，也可以看作是一个8位二进制数，或者一个2位16进制数。1字节常记做1B, 1比特常记做1b. 我们常用的单位还有KB(Kilobyte), KiB(Kibibyte)与GB(Gigabyte), GiB(Gibibyte). 严格来说，1KB=1000B, 1KiB=1024B, 1GB=1000KB, 1GiB=1024KiB. 在macOS以及iOS中采用的是这种标准的记法（可参考iOS 和 macOS 如何报告储存容量）。 内存和硬盘都是顺序编址。也就是说，我们要访问内存或者硬盘中的一个存储单元，那么就像我们想找人一样，首先要有它的名字。内存和硬盘给了每个存储单元（也就是一个字节）一个地址。相邻的存储单元的地址相邻。但是，内存和硬盘不同的一点在于，内存是随机访问(random access)的，也就是说，我想访问地址0x0123456789abcdef, 那么可以直接选择到这个地址，而不需要从0号地址开始向后找。最早期的硬盘则是要求顺序访问，也就是从某个特定的编号开始向后找。但后期的闪存技术可以弥补这一缺点。顺便提一句，内存这一随机访问的特点保证了线性表的O(1)的查找复杂度。 x86-64架构下的CPU中，通用寄存器都是64位，也就是8个字节。由于CPU是老大，因此，程序啊什么的都是跟着CPU来的。因此，在x86-64架构下，有的数据的大小是64位。这在CPU内部的运算中没什么问题，但遇到与内存交互时就犯了难。比如说，我有一个数据0x0123456789abcdef, 如果要从CPU中导到内存中，内存是按字节编址，也就是1个字节对应1个地址。那么，这个数据应该怎么存储在内存中呢？是01 23 45 67 89 ab cd ef还是ef cd ab 89 67 45 23 01呢？我编写了一个简单的程序来验证：我将0x0123456789abcdef这个数据导入了内存中地址为0x00007ffeefbff7c8的存储单元中。 这个结果告诉我们，我们现在通用的x86-64架构的处理器，将数据的高位放在高地址中。这种方法称为小端法(little-endian). CPU架构 我们常见的电脑上的CPU，有Intel Core i5, Intel Core i7, Intel Core i9等等，手机上的CPU，有苹果的A系列，还有高通的骁龙、华为的麒麟等等。这分属于两大阵营：电脑端处理器以x86架构为主，而手机端处理器以ARM架构为主。虽然处理器多种多样，性能有好有坏，但属于同一架构的CPU, 其各种基本属性都是差不多的。比如说通用寄存器数量、基础指令集等等。以前的CPU有16位、32位，意思是说通用寄存器的大小是16比特还是32比特。而现在常用的CPU都是64位的，属于x86-64架构。不同架构下的汇编语言也不同，所以我主要介绍的是x86-64的汇编语言。 上一篇文章：macOS上的汇编入门（二）——数学基础 下一篇文章：macOS上的汇编入门（四）——操作系统基础 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（四）——操作系统基础.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（四）——操作系统基础.html","title":"macOS上的汇编入门（四）——操作系统基础","keywords":"","body":"当我们学习汇编的时候，除了数学基础以及硬件基础以外，操作系统的基础也是一个至关重要的环节。汇编语言本质上就是机器码的human-readable的版本，而硬件相同，则同一个程序的机器码一定相同。那么我们为什么还要研究操作系统呢？这是因为，我们通过汇编语言，最终得到的可执行文件是与操作系统有关的，是操作系统来决定我们如何装载、执行这些可执行文件。此外，不同操作系统提供的库、系统调用并不完全相同。因此，只有了解了操作系统以后，才能更好地编写汇编语言。 Darwin与XNU macOS的基本结构如下： macOS建立在Darwin操作系统之上，以Aqua为图形化界面。Darwin操作系统的内核是XNU. 我们可以通过在终端下键入 uname -a 来查看Darwin和XNU的版本号。我在macOS 10.15 public beta下的结果如下： Darwin操作系统是开源的，Aqua图形化界面是在Apple专利下的。 简单来讲就是，我们用的macOS里各种图案、交互都是Apple专利下的，而系统的运行、内存的分配等等底层的操作系统都是开源的。事实上，国外也有社区在提供基于Darwin操作系统的开源的系统，如PureDarwin. 接下来，我们重点关注的是Darwin操作系统的内核——XNU. 正如上面macOS的基本结构的图中所示，XNU位于macOS的最底层——Kernel and Device Drivers. 下图在维基百科中用于描述XNU内核的构造（其中OSFMK 7.3指的就是Mach）： 总的来说，XNU是一个混合型内核，包括FreeBSD和Mach两层，是一个类Unix内核。 我们并不需要太过深入地了解XNU内核，只需要大致知道其分为FreeBSD和Mach两层。 系统调用 说了这么多，操作系统究竟能为我们做什么呢？更具体地说，我们在汇编语言中有什么可以利用操作系统的呢？事实上，操作系统可以为我们提供许多有用的「系统调用」(System call)。比如说，我们知道，一个进程由操作系统发起，由操作系统结束，那么，我们怎么在程序内部让操作系统来结束这个进程呢？再比如说，文件系统是由操作系统管理的，那么文件的读取和写入在用户层面怎么实现呢？这一切，都是由操作系统来提供的。从某种意义上来说，操作系统就和我们在高级编程中使用的Cocoa, React等一样，是一种「框架」(Framework)。我们在编程的时候，可以直接使用框架提供的API. 同样地，我们在编写汇编程序的时候，也可以直接使用操作系统提供的系统调用。就像是我们在用毛线织衣服的时候，并不需要自己来养蚕缫丝，只需要在毛线不够的时候向毛线的提供者说一句，然后就由毛线的提供者工作来提供毛线。关于系统调用，我们之后在汇编语言中还会详细阐释。 内存虚拟化 在上一篇「硬件基础」中，我们提到，所有进程都是在内存中运行的。现在常用的操作系统都采用了一个策略「内存虚拟化」，将逻辑地址与物理地址进行区分。我们知道，内存中的存储单元是以字节编址的，相邻的存储单元的地址相邻。这里实际指的是「物理地址」，也就是CPU在向内存发出访问请求时用到的地址。我们在编程中，遇到的地址都是「逻辑地址」。在一个进程启动时，操作系统会为每个进程分配64位逻辑地址空间，并在MMU(Memory Management Unit, 内存管理单元)中维护一个逻辑地址向物理地址的映射。也就是说，在我们编程时，物理地址对于程序员是透明的，程序员接触到的只会是物理地址。更具体地说，操作系统将地址分为4KiB, 也就是4096B大小的页(Page), 将逻辑地址的页与物理地址的页进行映射。在一个页内相邻的逻辑地址对应的物理地址是相邻的，但是页之间的物理地址的关系是不确定的。 64位逻辑地址空间，有多大呢？大约是18EB. EB是一种和KB, GB一样的单位，1EB是10的18次方字节。而据估算，2011年整个互联网的容量总和不超过525EB。因此，64位逻辑地址空间是非常非常大的，其总的大小远远大于实际的物理内存的大小。macOS为了解决这个问题，将一部分逻辑地址对应的页储存在硬盘上，准确地说，是/boot目录内。也就是说，当MMU在用逻辑地址向物理地址转化时，发现该逻辑地址在内存中没有对应物理地址，则将/boot目录内一部分数据调入内存中，作为那部分逻辑地址对应的存储空间。 Mach-O文件结构 对于任何一个在macOS上的可执行文件，我们可以用file命令行工具检查它的格式： 由此可知，在macOS上的可执行文件，都是Mach-O格式的文件。 关于Mach-O文件，详细可参考Apple官方文档Mach-O Programming Topics. 这里我们只是简单介绍一下。 如图所示，Mach-O文件由头(Header)、装载指令(Load commands)和数据(Data)组成。我们可以通过MachOView软件进行查看。其中，最重要的组成部分就是Data. 我们可以从图中看到，Data可以分为多个段(Segment), 每个段又可以分为多个节(Section). 从逻辑角度来看，每个段内的节存储的数据都有类似的目的。如__TEXT段内存储的有汇编源代码、字符串等，__DATA段内存储非常量初始化变量等。从内存管理角度来看，每个段的大小被要求是页大小的倍数，也就是4096B的倍数。当程序加载时，就可以正好将一个段加载到一个页内。 栈 当程序运行时，系统会自动给这个进程分配一个栈。这里的栈的数据结构就是数据结构中所说的栈，也就是先进后出的线性表。在x86-64架构下，栈是向下生长的。也就是说，每向栈中PUSH一个数据，栈顶的指针就会向逻辑地址减小的方向移动。 ASLR 从Mac OS X 10.5开始，Apple引入了地址空间配置随机加载(ASLR)机制。在每次程序执行的过程中，程序在内存中的开始地址，堆、栈、库的地址都会随机化，这样可以更好地保护不受攻击者攻击。 我们知道，在C语言中，局部变量是在栈上分配的。那么，我们有如下C语言程序： //test.c #include int main() { int a = 0; printf(\"The address in the stack is:\\t0x%x\\n\", &a); return 0; } 我们在终端下用clang对其编译 clang test.c -o test 然后运行三次： 我们可以发现，每次运行时，a的逻辑地址都不同。似乎是一个随机值加上一个固定的偏移量。这就是ASLR的作用。 PIE 在ASLR中我们可以看到，大部分变量在每次运行时的逻辑地址都不一样。那么，我们在汇编层面访问这些变量时，就不能直接访问一个固定的逻辑地址。因此，我们在汇编语言中有许多技巧可以生成位置无关代码(Position Independent Code, PIC). 这些代码中没有一处会直接访问固定的逻辑地址。由位置无关代码编译生成的可执行文件称为位置无关可执行文件(Position Independent Executable, PIE). 在我们在macOS上的汇编语言学习过程中，大多数编写的都是PIC. 上一篇文章：macOS上的汇编入门（三）——硬件基础 下一篇文章：macOS上的汇编入门（五）——第一个汇编程序 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（五）——第一个汇编程序.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（五）——第一个汇编程序.html","title":"macOS上的汇编入门（五）——第一个汇编程序","keywords":"","body":"通过前几篇文章，我们逐步建立了学习汇编语言之前需要的基础知识。接下来，在这篇文章中，我们开始编写我们的第一个汇编程序了。 编辑器，汇编器与链接器 工欲善其事，必先利其器。我们编写汇编语言，至少需要编辑器、汇编器和链接器。编辑器，就是提供语法高亮、智能缩进、自动补全等功能的文本编辑软件，汇编器与链接器则是汇编语言需要的核心装备，其功能我会在接下来的几篇文章中提到。我使用的编辑器是Visual Studio Code, 汇编器是自带的as, 链接器也是自带的ld. 第一个程序 我们在编辑器中输入如下语句，并在自己的目录下保存为exit.s. # exit.s .section __TEXT,__text .globl _main _main: movq $0, %rax retq 然后在终端下进入该目录，键入如下命令： as exit.s -o exit.o 然后再键入 ld exit.o -o exit -lSystem 此时该目录下应该会有一个叫exit的可执行文件，我们在终端下运行它： ./exit 然后，什么都没有发生，程序自动退出了。大功告成！ 关于这个程序的解释，我决定下篇文章再讲。这篇文章接下来的篇幅，我打算谈一谈汇编器与汇编语法。 汇编语法 汇编语言是机器码的human-readable版本。虽说如此，汇编语法现在的主流也有两大阵营：Intel语法与GAS语法。其最显著的区别就在于，Intel语法的组成是「指令+目的+源」，而GAS语法的组成是「指令+源+目的」。就比如说，同样的意思，Intel语法是“给小明一个粉笔”，而GAS语法则是“把一个粉笔给小明”。这两种语法并没有优劣，在这一系列文章中，我主要介绍的是GAS语法。 Intel语法是在Windows上进行汇编语言编程时主要使用的，而GAS语法，又称为AT&T语法，则主要是在Linux和类Unix上进行汇编语言时会用到。这里并不是说在不同操作系统上必须用不同的语法，在类Unix的macOS上也能用Intel语法，只不过是大家都偏好这么用罢了。 GCC与LLVM 我们知道，对于一门编程语言来说，它有对应的编译器和调试器。对于编译器来说，在类Unix系统上主要有两大阵营：GCC和LLVM. GCC包括C编译器gcc、调试器gdb等，LLVM项目包括C编译器clang、调试器lldb等。对于编译器，GCC的思路是对于每一个CPU架构、每一种操作系统，都开发一个对应的编译器，将代码直接编译成对应的可执行文件；而LLVM项目的思路则是将编译过程分为前端和后端，无论是在什么平台、什么CPU架构下，编译器前端都是相同的，将源代码编译成llvm中间码(IR). 而后端则是将IR再翻译成对应操作系统中对应CPU架构下的可执行文件。因此，如果有a种语言，b个操作系统和c个CPU架构，那么GCC一共需要abc种编译器，而LLVM项目则一共需要a种前端和bc种后端，最终效果是只需要a+bc种编译器代码。 对于高级编程语言，GCC与LLVM的竞争主要在于编译的优化、效率等，但是对于汇编语言，由于其可以直译机器码，所以并不存在汇编器优化，因此，在机器码层面，GCC和LLVM是等效的。在这一系列文章中我使用的汇编器as是\"Mac OS X Mach-O GNU-based assemblers\", 调试器是LLVM的lldb. GCC套件是GNU操作系统的一个部分，GNU是开源的、社区驱动的。而LLVM项目也是开源的，现在主要是Apple在投资运行。因此，既然在macOS上，我就主要用的是LLVM系的工具。 上一篇文章：macOS上的汇编入门（四）——操作系统基础 下一篇文章：macOS上的汇编入门（六）——汇编语言初识 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（六）——汇编语言初识.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（六）——汇编语言初识.html","title":"macOS上的汇编入门（六）——汇编语言初识","keywords":"","body":"上一篇文章中初步介绍了汇编语言的编辑器、汇编器与链接器，又让大家尝试了第一个程序。在本篇文章中，我们主要解释一下第一个程序。 # exit.s .section __TEXT, __text .globl _main _main: movq $0, %rax retq 注释 程序的第一行是注释。在macOS的as汇编器语法下，注释由#开头，在进行汇编的时候会自动将其处理为空白字符。 我们习惯上将注释写在语句的上方（如例程）或后方，如： movq $0, %rax # mov 0 to register rax 缩进 在最古老的机器上，汇编代码的文本包含四列：标签、助记符、操作数与注释。汇编器通过识别一个文本在哪个列来判断该文本有什么作用。现代的汇编器已经抛弃了这种方法，采用先进的词法分析技术来判断。但是，我们最好仍然按照这种格式来缩进。 汇编器指令(Directive) \"Directive\"是汇编语言中一个重要的组成部分，然而它的中文译名似乎还不固定，这里暂且叫它汇编器指令。在汇编语言中，以.开头的都是汇编器指令，如例程中的.section, .globl等。由汇编器指令开头的语句，一般不会被直接翻译成机器码。汇编器指令并不是告诉汇编器做什么, 而是告诉汇编器如何做。就比如说例程中，movq $0, %rax会被汇编器直接翻译为机器码，最终会由CPU直接执行，而.section __TEXT,__text, 则不会被翻译成机器码，在最终的可执行文件中也不会找到这句话的踪影。它的作用是告诉汇编器如何汇编。下面，就介绍一下.section的作用 .section 我们之前在操作系统基础中提到，mach-o可执行文件的Data部分拥有许多段(Segment), 每个段又有许多节(section). 同一个段的作用往往是类似的，同时在执行的时候一个段会被分配到一个页之中。而.section最常用的格式，就是 .section segname, sectname 其中segment是段名，sectname是节名。我们目前编写的第一个汇编语言程序，只包含纯代码。在macho中，纯代码被放在了__TEXT段的__text节中，因此，我们在文件的第二行写了 .section __TEXT, __text 代表之后的语句都是__TEXT段的__text节中。 此外，由于这个节过于常用，因此，汇编器给予了我们一个简单的记号：.text. 我们可以直接用.text代替.section __TEXT, __text. 在以后的程序中，我也都会用这种记号。 除了__TEXT段__text节后，还有许多段和节。常用的段和节的名称和作用可参见Assembler Directives. 我们之后更复杂的程序中也会用到更多的段和节。 .globl 我们在由汇编语言翻译机器码的时候，得到的文件并不仅仅包含操作的指令，还需要包含一些名字和记号。比如说，C语言中，程序执行的起点是main函数。那么，这个函数的名字main就要包含在文件中，使得程序执行的时候知道执行哪个函数。 _main macOS中，汇编语言程序执行的起点是_main函数。关于函数与下一行的_main:标签，我会在之后的文章中提到。是谁决定它叫这个名字的呢，是链接器。如果我们写的程序想把它主函数叫做_start, 那么只需要在链接的时候写上 ld -e _start exit.o -o exit -lSystem 即可。 movq movq是我们遇到的第一个真正的指令。在汇编语言中，这种能直接翻译成机器码的指令被称作助记符(mnemonic). 之前我们也提到过，在GAS语法下，一条指令是助记符+源+目的，也就是说，它后面紧跟的是源操作数，然后是目的操作数。在x86-64架构下所有的可以被识别的助记符可以参考64-ia-32-architectures-software-developer-instruction-set-reference-manual, 但值得注意的是，这份官方的参考文档是用的Intel语法，我们只需要把源和目的颠倒过来看就行。 首先我们先要理解mov. 这是一个在汇编语言中很常见的指令，意思是赋值。mov a b就是将a赋值给b. 它可以将立即数赋值给寄存器、内存，可以把寄存器赋值给寄存器、内存，把内存赋值给寄存器。 接下来，我们需要理解q. 我们思考一下一个场景：我们在C语言中用long a;在一块内存上存储了一个64位整型数a，又用int b;在一块内存上存储了一个32位整型数b。那么，每次我们给a赋值的时候，实质上都是将数放入a的地址对应的内存中。因此，就是一个mov指令。但是，如果只有mov指令的话，那么a = 0x114514;和b = 0x114514;这两个C语句翻译成汇编语言的话并没有区别，都是将一个数赋值给一块内存地址。然而我们知道，在x86-64架构下采用小端法，因此，在a的内存区域中实际应该存储的是14 45 11 00 00 00 00 00, b的内存区域中存储的是14 45 11 00. 这看上去似乎没有什么区别。然而，在向a赋值的时候，实际上是把整个8个字节的高位都清零，而b仅仅是把4个字节的高位清零。然而，汇编层面并不认得long, int的变量之类，因此，就必须扩展助记符来完成这个事情。 在GAS语法中，会在助记符后加上b, w, l或q, 分别表示操作的是1个，2个，4个或8个字节。因此，long的赋值可以用movq, int的赋值可以用movl. $0 接着movq的，是$0, 作为其源操作数。在GAS语法下，一个数字前加上$表示这个数本身。如果不加的话，则表示0这个地址里存储的数。此外，我们也可以在前面加0x来表示16进制数，如 movq $0x2000001, %rax %rax 我们之前提到，在x86-64架构下，CPU中一共有16个64位通用寄存器，它们的名字依次是rax, rbx, rcx, rdx, rdi, rsi, rbp, rsp, r8, r9, r10, r11, r12, r13, r14, r15. 当我们用这些名字的时候，指的就是这16个64位通用寄存器。此外，对于前8个通用寄存器，也就是名字不是数字的寄存器，还可以用eax, ebx, ecx, edx, edi, esi, ebp, esp指代其低32位，用ax, bx, cx, dx, di, si, bp, sp指代其低16位。而对于rax, rbx, rcx, rdx这四个通用寄存器而言，还可以单独引用它低16位中的高8位和低8位，如对ax而言，ah指代其高8位，al指代其低8位。 在GAS语法中，寄存器名字前面一定要跟着%. retq 关于这个，我会在之后的函数部分的文章中提到。 总结 因此，根据以上的讨论，我们可以将第一个汇编程序翻译成C程序了： // exit.c int main() { return 0; } 这就是我们第一个汇编程序的作用，也就是将main函数返回0. 至于为什么要将0传入rax寄存器而不是别的寄存器，后面关于调用约定的文章中会提及。在终端下，我们可以先运行这个程序exit: ./exit 什么都没出现，它正确退出了。接着，我们可以用 echo $? 来查看上一个程序的返回结果。不出所料，它返回的是0. 我们也可以通过修改第一个汇编程序，将不同的数赋值给rax寄存器，那么，最终main函数返回的值也会不同，我们通过echo $?查看的结果也会不同。这也是我们初期不用调试器时查看汇编程序结果的一个简单的方法。 上一篇文章：macOS上的汇编入门（五）——第一个汇编程序 下一篇文章：macOS上的汇编入门（七）——字面量与局部变量 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（七）——字面量与局部变量.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（七）——字面量与局部变量.html","title":"macOS上的汇编入门（七）——字面量与局部变量","keywords":"","body":"在上一篇文章中，我们分析了第一个汇编程序。 # exit.s .section __TEXT,__text .globl _main _main: movq $0, %rax retq 这个汇编程序是我们所有汇编程序的框架，因为它实现了程序进入和程序退出的功能。我们接下来所有的程序都是在这个程序的基础上进行修改。 在这篇文章中，我主要介绍的是汇编语言中变量的使用。在x86-64架构下，寄存器的数量很少。而且，寄存器的作用往往是用于运算而不是用于存储。那么，我们在程序中该如何使用变量呢？ .equ定义字面量 最简单的定义变量的方式，是利用汇编器指令.equ. 这类似于C语言中的#define. 比如说，我在程序开头写上 .equ maxCount, 0x114514 那么，我在之后的程序里就可以写 movq $maxCount, %rax 来表示将0x114514赋值给rax寄存器。 同时这里应当指出，这个指令是汇编器指令，在汇编的时候，会自动将所有的maxCount直接用0x114514替代。比如说，我有以下程序： .text .globl _main .equ maxCount, 0x114514 _main: movq $maxCount, %rax retq 我们通过汇编、链接以后，得到一个test可执行文件。我们可以用之前提到的MachOView软件，或者在终端中键入 otool -v -t ./test 来查看生成的可执行文件中__TEXT段__text节的内容： 由此可知，最终生成的文件中，是直接替换得到的。 此外，.equ还有一个比较方便的地方在于，它可以支持简单的算术运算，如加减乘除等。比如说，我可以写.equ maxCount, 1919-810, 那么接下来所有出现maxCount的地方，都会用1109来替代。 但是，正如C语言中的#define定义的宏一样，.equ定义的变量只是一个简单的替换，并不支持对这个变量重新赋值之类的操作。这个变量也没有其地址，只是一个字面量。 局部变量 栈 我们知道，在C语言中，局部变量在栈上分配。在汇编语言中也是这样。因此，我们来回忆一下「栈」的概念。 在操作系统基础中，我们谈到，在一个程序运行的时候，系统会自动给这个程序分配一个栈区。这个栈区和数据结构中所说的栈类似，也支持压栈和弹栈的操作。栈区在逻辑地址空间里是一块连续的空间，栈底是固定的，每次压栈，都会使栈顶向逻辑地址减小的方向移动。 在几个寄存器中，有一个寄存器和栈的关系非常大，那就是rsp寄存器。从它的名字就可以看出来，stack pointer, 它存储的值永远是栈顶的地址，所以它又被叫做栈顶指针。我们可以用(%rsp)来获取栈顶存储的值，通过a(%rsp), 其中a是任何一个整数，来获取地址是rsp存储的值加a处的内存单元的值。比如说，2(%rsp)就是栈顶上方（逻辑地址增大方向）2个字节处的值，-2(%rsp)就是栈顶下方（逻辑地址减小方向）2个字节处的值。关于这个记号，我也会在之后的寻址方式中提到。 在汇编语言中，压栈和弹栈的助记符分别是push和pop. 这两个操作均有一个操作数。push的操作是将栈顶指针向下移动（也就是将rsp内的值减小），并将移动后rsp对应位置内存区域的值赋为其操作数，而pop则相反。这里“向下移动”的距离是根据push后面跟着的字母决定的，如pushq就是把rsp内的值减8. 此外，如果是想获得栈顶的值，而不弹栈，可以直接用mov来实现。如popq %rax是将栈顶的8个字节内存储的值赋给rax, 并且栈顶指针向上移动8个字节。而movq (%rsp), %rax则是只将栈顶的8个字节内存储的值赋给rax, 不涉及栈顶指针的移动。而如果只想弹栈却不想赋值，那么直接对rsp进行add即可。如想把栈顶的8个字节的数据弹栈，就直接addq $8, %rsp. 同时，对于push而言，如果我们一下子准备把许多值压入栈内，那么可以先用sub指令减小rsp, 再用mov移动。比如说： # method 1 pushq $0x114514 pushq $0x1919 pushq $0x810 # method 2 subq $24, %rsp movq $0x114514, 16(%rsp) movq $0x1919, 8(%rsp) movq $0x810, (%rsp) 方法一和方法二的最终效果是一样的。但是，我们建议使用方法二，也就是“先sub, 再mov”，因为这样更高效。 使用局部变量 讲完了栈的概念，接下来就是如何使用局部变量了。使用局部变量非常简单，就是将局部变量放到栈上，然后使用的时候直接去访问栈上对应的地址空间就行。然后在返回之前，把栈恢复即可。 但是，这里有一个常用的技巧。像上面的例子中写的，我们是通过对rsp中存储的地址加偏移量去访问局部变量，但是，如果我们之后又有了压栈、弹栈的操作，那么，偏移量就会改变。这种不稳定性十分不利于我们编程。因此，我们又用了另一个寄存器rbp来解决这个问题。rbp, 顾名思义，base pointer, 基地址指针，一般是用来使用偏移量寻址的。我们使用的技巧是，先将rbppush进栈（之所以保留我会在后面的调用约定里说到），然后利用之前的手法对rspsub. 然后，利用rbp的偏移量来引用局部变量。最后在返回前，将rbp赋值给rsp, 此时栈顶指针指向的是最初对rbppush之后的位置，然后将栈顶pop出来给rbp，最后返回。 比如说，我有以下C程序： int main() { int a = 0x114514; int b = 0x1919; int c = 0x810; return 0; } 那么，它对应的汇编程序如下： _main: pushq %rbp movq %rsp, %rbp subq $24, %rsp movq $0x114514, -8(%rbp) movq $0x1919, -16(%rbp) movq $0x810, -24(%rbp) movq $0, %rax movq %rbp, %rsp popq %rbp retq 它对应的栈的变化如图所示： 由此可见，在执行完popq %rbp之后，栈又恢复为最初进入时的模样。 我们在使用rbp+偏移量来访问局部变量的时候，有时候会觉得要把变量对应的偏移量记住，这会比较麻烦。我们可以结合上面讲到的.equ定义字面量来解决这一问题： _main: .equ a, -8 .equ b, -16 .equ c, -24 pushq %rbp movq %rsp, %rbp subq $24, %rsp movq $0x114514, a(%rbp) movq $0x1919, b(%rbp) movq $0x810, c(%rbp) movq $0, %rax movq %rbp, %rsp popq %rbp retq 这样，我们只需要之后用a(%rbp)就可以指代a了。 上一篇文章：macOS上的汇编入门（六）——汇编语言初识 下一篇文章：macOS上的汇编入门（八）——寻址方式与全局变量 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（八）——寻址方式与全局变量.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（八）——寻址方式与全局变量.html","title":"macOS上的汇编入门（八）——寻址方式与全局变量","keywords":"","body":"在上一篇文章中，我们讨论了汇编语言中如何定义字面量与局部变量。在这篇文章中，我们将继续讨论，如何在汇编语言中定义C语言中的全局变量。在讨论全局变量之前，我们首先需要介绍一下寻址方式。 寻址方式 所谓寻址方式，就是已知地址如何获得该地址对应的内存单元内的值。在上一篇文章中，我们实质已经用到了寻址方式。比如说，已知栈顶的地址存储在rsp内，那么我们是通过(%rsp)获得对应位置的内存单元的值的。一般来说，我们寻址方式需要记得下图： 这个记号代表地址为基址+指标*倍数+偏移量处的内存单元中存储的值。 其中，以$开头的都是数字（但注意我们真正写的时候不需要加上$符号），以%开头的都是寄存器。也就是说，在偏移量、倍数的位置上，不能写寄存器，在基址、指标的位置上，不能写数字。此外，倍数只能是1, 2, 4, 8中的一个。 这四个位置都可以省略，省略的位置将用0代替。比如说，偏移量(基址)就相当于基址+偏移量, 偏移量(, 指标, 倍数)就相当于指标*倍数+偏移量. 这样设计寻址方式是由其原因的。偏移量和基址存在的原因，就是为了解决像我们之前那样通过rsp或者rbp加上偏移量来访问栈上元素的问题。而指标存在的原因，一是在于，我们不仅可以通过寄存器+数字的方式寻址，也希望通过寄存器+寄存器的方式寻址，也就是(基址, 指标, 1)这样的方式实现寄存器+寄存器寻址；此外，当我们在某些循环操作时，可以每次递减或递增指标，然后实现对一块连续内存的访问。而倍数存在的原因，则是由于存数的时候可能是占1个字节，也可能是2个，4个或8个字节。 在了解了寻址方式之后，相信大家就会很容易地理解我们之前通过-8(%rbp)这样的方式获得栈上元素了。我们可以通过如 movq -8(%rbp), %rax 这样的方式，将内存上的值付给寄存器。但是，值得注意的是， movq -8(%rbp), -16(%rbp) # wrong 这样的方式在x86-64架构下是不支持的，也就是不能直接将一块内存赋给另一块内存。 通过这种寻址方式，我们可以直接获得复杂地址对应的值。那么，有没有一种方式可以让我们获得这个复杂地址本身呢？答案是有的，使用lea. lea是load effective address的简称，其拥有两个操作数。我们可以像这样使用： leaq -8(%rbp), %rax 表示将-8(%rbp)的地址赋给rax. 我们知道，在64位处理器下，地址都是64位的。因此，lea后面一定是q, 而不能是别的东西。 全局变量 在讲完了寻址方式之后，就可以解决如何在汇编语言中实现C语言中的全局变量了。 在汇编语言中，除了__TEXT段以外，还有__DATA段，用于存放数据。我们知道，当mach-o可执行文件被执行的时候，一个段对应整数个页，因此，__DATA是在逻辑地址空间中是单独的页，这里存放的数据和字面量不同，拥有自己的地址；和栈上分配的数据不同，可以被所有函数访问。在__DATA段中，__data节存放所有非const的已经被初始化过的变量，__bss节存放所有未被初始化的static的变量，__common节存放所有未被初始化过的外部全局变量。类似于.text，我们可以用.data来代替.section __DATA, __data, 用.bss代替.section __DATA, __bss. 因此，我们如果想在汇编语言中拥有一个全局的数0x114514, 把它放在.data节里。但是，这样就行了吗？ .data 0x114514 这样是不行的。因为，我们之前在讲mov的时候提到过，必须跟着b, w, l或q来表示数据所占的字节数。在这里也是一样。我们在__DATA段中存储数据，需要告诉汇编器这个数据占多少字节，也就是说多少字节的高位要被清零。因此，我们引入汇编器指令.byte, .short, .long, .quad. 它们分别代表1字节，2字节，4字节和8字节。比如说，我如果想告诉汇编器我们要存放的数据0x114514占8个字节，那么就可以写 .data .quad 0x114514 我们汇编、链接之后得到可执行文件test. 再通过MachOView，或者通过在终端下键入 otool -v -s __DATA __data test 来查看test的__DATA段__data节的数据如下： 由此可以看到，汇编器把它整个8个字节的高位都清零了。 此外，我们如果想定义多个变量，只需要写一个汇编器指令就够了。比如说， .data .quad 0x114514, 0x1919, 0x810 就代表.quad后面所有的数，都占有8个字节。其效果为： 我们需要注意的是，这些数是“紧挨”在一起的。比如说，我如果把.quad改为.long, 也就是这三个数每个都是占4个字节，那么效果就变成了 这样完成以后，又有一个新的问题出现了，我们在代码中怎样能访问到这些数据呢？ 这时，就需要标签(label). 关于标签，我会在之后跳转与标签中提到。这里我们只需要了解，标签在定义的时候，后面跟着一个冒号，在使用的时候，不要冒号，同时这个标签就代表它所在的地址。如： .data a: .quad 0x114514, 0x1919, 0x810 这里a:就定义了一个标签。这里定义标签并不会对__DATA段__data节产生影响，otool查看的结果仍然和之前一样。但是，如果我们在代码中使用到a时，就会被替换为0x114514这个数据开头的逻辑地址。那么，0x1919这个数据的地址就可以用a+8来访问，0x810就是a+16. 那我们直接写一个程序： # dataTest.s .data a: .quad 0x114514 .text .globl _main _main: movq a, %rax retq 这样行不行呢？ 我们在终端下用as进行汇编： as dataTest.s -o dataTest.o 结果报错了！ \"32-bit absolute addressing is not supported in 64-bit mode\". 这是为什么呢？ 我们回忆一下之前在操作系统基础中提到的ASLR与PIE. macOS中程序的加载默认是使用ASLR的，也就是说，在程序执行的时候，所有数据的地址都会加上一个随机化的偏移量。可是，a是0x114514在mach-o可执行文件中的地址，是在汇编链接后就确定的，而ASLR则是在执行时才会使用。因此，我们这样写并不是position independent的。所以，我们要使用一个小技巧——PC-relative寻址。 所谓PC，就是program counter. 在x86-64架构下，是存储在寄存器rip中的值。rip寄存器，全称是instruction pointer, 顾名思义，在程序执行一条汇编指令的时候，rip中的值就是下一条汇编指令在内存中，也就是逻辑地址空间中的值。注意到这个值是执行时的，也就是ASLR后的值。考虑到即使经过ASLR, __DATA段和__TEXT段之间的距离是没有变的。因此，无论是执行时还是汇编时，__DATA段的某个数据的地址与当前指令的地址之间的差值是不变的。我们可以利用这一点来实现PIC. 汇编器也对此专门做了优化。当我们使用寻址方式标签(%rip)时，汇编器不会将其看作rip + 标签，而是会在汇编时就计算出标签距离此指令的下一条指令的地址的距离，然后用距离替换标签。比如说： # dataTest.s .data a: .quad 0x114514 .text .globl _main _main: movq a(%rip), %rax retq 我们对这个程序汇编、链接之后得到可执行文件dataTest. 我们分别查看其__Data段__data节和__TEXT段__text节如下： 可以看出，我们要访问的数0x114514的逻辑地址是0x0000000100001000, 而movq a(%rip), %rax的地址是0x0000000100000fb0, 下一条指令地址是0x0000000100000fb7. 因此，当程序在执行movq a(%rip), %rax时，rip寄存器中的值是下一条指令地址，而其与我们要访问的数的逻辑地址之间的距离恰好是0x49. 因此，0x49(%rip)无论在汇编时还是在执行时，都会对应于我们要访问的数。 上一篇文章：macOS上的汇编入门（七）——字面量与局部变量 下一篇文章：macOS上的汇编入门（九）——跳转与函数 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（九）——跳转与函数.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（九）——跳转与函数.html","title":"macOS上的汇编入门（九）——跳转与函数","keywords":"","body":"通过之前的几篇文章，我们了解了汇编语言的基本语法和变量的使用、寻址方式等，但我们的程序到目前为止，都只局限在_main内，既没有函数调用，也没有控制结构，进了_main以后一条路走到retq. 在这篇文章中，我主要介绍的是汇编语言中的控制结构——跳转，与函数调用。不过在介绍这两个之前，首先需要介绍的是跳转与函数调用的基础——标签。 标签 标签(Label), 是汇编语言中一个重要的组成部分。我们之前在__DATA段__data节里定义变量的时候，就使用了标签。我们通常使用的标签，定义时是以冒号:结尾的一个标识符，且开头不能是数字。LBB0:, a:, _func:, _main:都是标签的定义。 我们可以在.data段，也可以在.text段定义标签，只需要在那里写上标签加上:即可。比如说， loop_begin: movq $0x114514, %rax jmp loop_begin 就定义了一个标签loop_begin, 并且在下一条指令中使用了它. 接下来任何一个地方使用到loop_begin, 就代表这个指令所处的地址。 一般来说，定义的标签只能在同一个汇编文件中使用，如果一个汇编文件想使用另一个汇编文件定义的标签，需要另一个汇编文件用.globl声明标签是全局可见的，比如说.globl _main. 跳转 在介绍完标签之后，就可以解释跳转了。跳转分为无条件跳转与条件跳转。我们首先介绍无条件跳转。 无条件跳转 无条件跳转对应的助记符是jmp. 其操作数是标签。jmp loop_begin就是跳转到loop_begin标记的位置。这里就有一个问题，这样的跳转，是不是position indenpendent的呢？答案是是的。但是和之前PC-relative的技巧不同，这里PIC的方法不是程序员做的，而是汇编器做的。汇编器会直接将jmp翻译成相对跳转的机器码，对程序员来说是透明的。所以，我们并不需要太过关心这里的PIC. 我们使用无条件跳转的时候要特别注意，因为极易造成死循环。比如说我们上面的那两行代码，就是死循环。 条件跳转 相比于无条件跳转，我们更常用的是条件跳转。无条件跳转相当于C语言中的goto, 而条件跳转则是我们更常见的if, while等控制语句。下面的例子给我们演示了条件跳转： cmp $0x114514, %rax je loop_begin cmp, 就是compare, 比较的意思。je中的e, 就是equate, 相等。我们可以大致理解一下这个的意思：如果%rax内的值与0x114514相等，那么就跳转到loop_begin这个标签处。那么，这是如何做到的呢？ 我们利用lldb查看在执行cmp $0x114514, %rax之前和之后，寄存器的变化（关于lldb的使用我会在之后的文章中提到）。 在执行cmp $0x114514, %rax之前，寄存器的值为： 在执行cmp $0x114514, %rax之后，寄存器的值为： 对比两张图，我们发现，除了存有当前指令地址的rip寄存器内的值发生了变化以外，还有一个寄存器的值发生了变化，那就是rflags. 这是什么寄存器呢？这又是根据什么变化的呢？ 这就是先行者们一个很妙的设计了。事实上，无论是cmp还是别的什么指令，其实大多数都有一个副作用——影响rflags寄存器。rflags寄存器，全称是状态标志寄存器。我们看它不能用十六进制看，要用二进制看。 在执行cmp之前，rflags的值是0x246, 它的二进制表示是1001000110. 执行之后，rflags的值是0x287, 它的二进制表示是1010000111. 这意味着什么呢？事实上，rflags中某些位是由特定的作用的。我们主要关注其低16位： 每一个以F结尾的都代表一个flag, 比如说CF就是carry flag, 是否进位。而我们的cmp指令，若两数相等，则会把ZF位置1，否则置0. 而je指令，则是当ZF位为1时再跳转，否则什么事也不做。 那么一个指令究竟会影响多少位呢，这个在指令集(64-ia-32-architectures-software-developer-instruction-set-reference-manual)中会有详细说明，这里不再赘述。只强调一点，在做运算时，往往都会涉及标志位的改变。结果是否为零、是否进位、是否溢出等等，都是决定各个标志位的因素。 而依据不同的标志位，有不同的条件跳转指令。比如说，依据ZF, 有je（ZF=1时跳转），jne（ZF=0时跳转）；依据CF, 有jc（CF=1时跳转），jnc（CF=0时跳转）。此外，还有依据多个标志位的跳转指令。但是，我们实际上并不太需要记得跳转指令对应的标志位情况，我们需要记住的是跳转指令对应的逻辑情况，比如说，je代表相等时跳转，jne代表不相等时跳转；jg代表大于时跳转，jge代表大于等于时跳转；jl代表小于时跳转，jle代表小于等于时跳转。这里还要强调一下，“大于”、“小于”究竟是谁大谁小。在我们cmp a, b时，实际上执行的是b-a, 比较的是b和a. b>a，会是jg的跳转，而ba会是jl的跳转。 此外，我们还需要记得大部分非跳转指令对应的标志位的改变。比如说，add指令涉及的标志位就有OF, SF, ZF, AF, CF和PF. 函数 大略地讲完了跳转之后，就涉及到了函数。我们知道，在跳转时，有一个特点，那就是跳转了就回不来了。除非我们在跳转指令之后再加上一个标签，然后在跳转去的部分中找到合适的位置跳转回来。这是比较麻烦的。所以，跳转指令一般指适用在控制语句中，并不会用于函数的调用。当我们进行函数调用时，应该使用全新的指令——call和ret. call指令和jmp指令一样，接受一个标签作为操作数，直观上看和jmp的效果也类似，直接跳转到该标签所在的指令。但是，call指令还干了一件事——把当前的rip寄存器push到栈区里。这实际上和我们利用jmp解决跳出去回不来的问题的方法类似，把返回的地址放到栈上。然后，call就没事儿了。 在我们执行完函数的运算之后，想要返回之前调用函数的地方，这该怎么办呢？就用到了ret. ret无操作数，默认当前栈顶，也就是rsp指向的位置，存储的是当初call时push到栈区的地址，然后直接跳转，并且把那个地址弹栈。因此，在之前提到局部变量的时候，我们在最后恢复了rsp, 让其还是指向最初的位置，目的就是这个。 call和ret都可以加上一个q，形成callq和retq. 这和call和ret实际上是没有区别的，只是强调那个地址是8个字节的地址。 总结 我们来看一个迭代法计算大于3的数对应的Fibonacci数列的简单的程序： # Fibonacci.s .text .globl _main _main: movq $13, %rdi callq _Fibonacci retq _Fibonacci: movq $1, %rax movq $1, %rbx compare: cmp $2, %rdi jg loop_continue retq loop_continue: movq %rax, %rcx addq %rbx, %rax movq %rcx, %rbx decq %rdi jmp compare 这个简单的程序计算了第13项斐波那契数列，并且也用到了这篇文章中所讲的跳转与函数。大家可以仔细研究这个程序。 我们在命令行中键入 as Fibonacci.s -o Fibonacci.o 进行汇编，再键入 ld Fibonacci.o -o Fibonacci -lSystem 进行链接。并使用 ./Fibonacci 来执行函数，最后用 echo $? 来查看结果。最终结果如下： 结果正确。 至于这个程序中为什么采用rdi进行参数传递，以及rax作为返回值，还有一些不足和缺陷，我会在下篇文章中提到。 上一篇文章：macOS上的汇编入门（八）——寻址方式与全局变量 下一篇文章：macOS上的汇编入门（十）——再探函数 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（十）——再探函数.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（十）——再探函数.html","title":"macOS上的汇编入门（十）——再探函数","keywords":"","body":"在上一篇文章中，我们简要地谈了在汇编语言中是如何实现函数功能的，即用call和ret. 在这篇文章中，我们将更深入地探讨关于汇编语言中函数的话题。 调用约定 汇编语言中的函数，实质只是一个标签所代表的内存地址。它不像其他高级语言一样，有完整的函数原型体系。比如说，在C语言中，int func(int a, char *b)可以让我们知道，这个函数接受两个参数，第一个是int类型的，第二个是char *类型的，同时这个函数也返回一个int类型的值。但是，汇编语言中并没有这样的体系。在我们自己写的程序中，如果调用自己写的函数，那我既可以往rdi里传参数，也可以把参数压入栈里，然后函数再弹栈获得参数；函数返回既可以返回到rax里，也可以多返回到几个寄存器内实现多返回值。这一切都是我们自己约定好的。但是，写程序不只是自己用自己的，也需要用他人的函数，也需要被他人的函数用。那么，我们就应该与他人达成一个约定，如何调用函数，函数会不会改变某些寄存器的值等等。这叫做调用约定(Calling Convention). 关于调用约定，一定要看的是System V x86-64 psABI. 这个和之前我提到的Intel的x86-64架构官方文档64-ia-32-architectures-software-developer-instruction-set-reference-manual一样，都是学习汇编语言一定要多看的文档，建议翻烂。 参数传递 调用约定包含很多方面。首先，我们来谈谈参数传递。这里传递的参数默认是INTEGER类的，比如说int, long, short, char, 以及指针等，也就是除了double这种我们在汇编中需要特殊对待的类型以外。 参数传递按从左至右的顺序依次是：rdi, rsi, rdx, rcx, r8, r9. 如果参数多于6个，则将多于6个的部分按从右往左的顺序压入栈内。 比如说，我有如下C程序： // test.c int func(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8) { return 3; } int main() { func(1, 2, 3, 4, 5, 6, 7, 8); return 0; } 我们在终端下键入 clang test.c -S 可以生成一个由test.c编译出的汇编代码test.s. 我们找到其中参数传递的部分，汇编代码如下： movl $1, %edi movl $2, %esi movl $3, %edx movl $4, %ecx movl $5, %r8d movl $6, %r9d movl $7, (%rsp) movl $8, 8(%rsp) callq _func 我们可以看到，参数传递确实是按这种调用约定来的。 这里说明一点，为什么多于6个的时候压栈，是按从右往左的顺序压栈呢？这样的设计，满足了我们对可变参数的需求。我们知道，C语言中有prinf这个函数。这个函数的参数个数就是可变的，其参数的个数是由从左往右数第一个参数格式化字符串确定的。在我们程序语言的设计中，往往可变参数的个数都是由从左往右数的某个参数确定的。那么，我们从右往左压栈，函数内部弹栈获得参数的时候就是按从左往右的顺序，因此就可以在固定的位置获得用于确定可变参数个数的参数。这就是从右往左压栈的好处。 返回值 返回值总是传递到rax上。这也就是我们最初的第一个汇编程序，返回的时候把$0赋给rax的原因。 movq $0, %rax retq 就相当于C语言中的 return 0; 保留寄存器 在我们调用函数的时候，还要遵循一个约定，那就是哪些寄存器是保留寄存器。比如说，我在函数_func里面，修改了寄存器rbx的值，那么我在主函数中，callq _func之后，并没有任何表征告诉我们rbx的值改变了，那么我们在后续的编程中就有可能使用了错误的rbx值。因此，在函数执行的时候，哪些寄存器应当保留，也属于调用约定。在这里，称调用的函数为called函数，调用called函数的函数称为calling函数。比如说： _main: callq _func retq _func: # do something 中，_main就是calling函数，_func就是called函数。 寄存器rbp, rbx, r12, r13, r14, r15是属于calling函数，其余的寄存器都属于called函数。called函数在使用上述寄存器的时候，应当对寄存器的初始值予以保留。 保留的最有效的方法就是将其push上栈，在返回之前再pop回来。这也就是我们当初在局部变量的时候，在使用rbp标记最初栈顶之前，首先要pushq %rbp, 在函数返回之前，又要popq %rbp. 同时我们也应当注意到，这也意味着我们在调用别的函数的时候，只能默认上述那几个寄存器在调用之后不会被改变，而别的寄存器是又可能被改变的。 函数调用 在讲完了调用约定之后，我们接下来再讨论一下函数调用的问题。在了解调用约定之前，我们只能放心大胆地调用自己的函数。在了解了调用约定之后，我们就可以和他人写的函数互动了。这里分多种情况讨论一下。 调用本文件中的函数 就是最基础的情况，自己调用本文件中自己写的函数，不需要任何别的东西，直接call就好了。 调用别的汇编文件中的函数 这里既有可能是自己写的多文件，也有可能是他人写的。如果要调用别的文件中的函数，那么这个函数在它被定义的那个文件中一定要是被.globl声明过的。假设有两个汇编文件my.s和other.s, 我们只需要在终端下依次键入 as my.s -o my.o as other.s -o other.o ld my.o other.o -o my -lSystem 这里要求my.s和other.s不能同时有_main. 调用C语言中的函数 假设我有一个C语言中的函数int func(int a, int b, int c). 那么我如果想在别的汇编代码中调用这个函数，只需要将这个函数的名字前加一个_. 也就是callq _func即可。参数传递和返回值都是按之前说的调用约定来做。假设C语言的代码叫做test.c, 汇编语言的代码叫做main.o, 那么我们只需要在终端下依次键入 clang test.c -c -o test.o as main.s -o main.o ld test.o main.o -o main -lSystem 调用库函数 操作系统提供了大量的库。在macOS中，大量的库函数都包含在文件/usr/lib/libSystem.dylib中。包括： libcC标准库 libinfoNetInfo库 libkvm内核虚存库 libm数学库 libpthreadPOSIX线程库 这些库的C头文件我们可以在/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk 1/usr/include/目录下找到。 我们在链接时的参数-lSystem就代表链接libSystem.dylib. 因此，我们不需要再额外做任何工作，就能按照上述的调用C语言的方式调用系统库的函数了。因此，我们心心念念的printf终于可以用了！只不过要在前面加上_. 不过，还有一点额外要注意的。在调用库函数的时候，栈需要16字节对齐。这是什么意思呢？在之前提到的调用约定中，其实还有一点，就是栈对齐。由于我们写函数的时候总是会在第一步就pushq %rbp; 同时再在这个函数中用call调用别的函数的时候，实际上又把返回地址压栈。因此，called函数的起始栈地址，比calling函数的起始栈地址高了16个字节。硬件开发者就这个特点，进行了优化。导致栈进行16字节对齐的时候，效率会特别高。因此，这也就作为了一项调用约定。 那么，栈16字节对齐究竟是什么意思呢？首先，我们的_main函数默认其进入的时候，rsp寄存器内的地址值是16字节的倍数。接下来，我们如果要call任何库函数，要保证在call之前，8(%rsp), 也就是rsp寄存器内的地址值加8，应当是16的倍数。因此，我们来算一下：在_main的最开始，rsp寄存器内的地址值是16的倍数；接下来一般人都会pushq %rbp. 这时，rsp寄存器内的地址值是16的倍数加8. 因此，我们在接下来利用栈分配局部变量的时候，一定要让增加的栈空间是16的倍数。因此，即使只有3个long型的局部变量，也要将rsp减32, 而不是减24. 我们来看如何利用printf进行输出\"helloworld, 114514\"： # helloworld.s .section __TEXT, __cstring helloworld: .asciz \"helloworld, %d\\n\" .text .globl _main _main: pushq %rbp leaq helloworld(%rip), %rdi movq $114514, %rsi movb $0, %al callq _printf popq %rbp movq $0, %rax retq 我们在__TEXT段__cstring节定义了用来输出的字符串。这个节是专门用来存储C风格字符串的。 接下来的helloworld:自然就是标签了。 .asciz定义的是C风格字符串，地位和.quad这些汇编器指令相当。它会自动在字符串结尾补上\\0. 接下来我们回忆一下printf接受的参数。第一个参数是一个字符指针，指向字符串的开头。因此，我们利用leaq helloworld(%rip), %rdi, 将字符串传入第一个参数。接下来，我们的字符串中有%d, 说明prinf还得有第二个参数。因此，我们将114514传入rsi中。这样似乎就结束了。但是，有一个需要我们注意的，就是像printf这种接受可变参数的函数，还需要将参数中VECTOR寄存器的数量放入al中。所谓VECTOR寄存器，就可以理解成存放浮点数的寄存器。我们这里没有浮点数，因此将0放入al中即可。然后callq _printf即可。 被调用 被调用的最典型的例子，就是命令行参数argc与argv了。argc是在命令行中该程序被调用时参数的个数，argv是一个char **类型，是各个参数的字符串数组。比如说， ./test helloworld 1 那么，argc就是3，argv[0]是\"./test\", argv[1]是\"helloworld\", argv[2]是\"1\". 操作系统会自动将argc和argv作为_main函数的参数传给程序。因此，我们在_main的开始，就可以用rdi获得argc, rsi获得argv. 被C语言调用 和调用C语言时在函数名前加_相反, 被C语言调用时，C代码中要把汇编语言函数前的_去掉。比如说汇编语言中有一个函数_func, 那么在C语言中调用的函数就应当是func(). 此外，需要在C语言代码的开头写上 extern void func(); 其中函数的返回值和参数都可以依据汇编语言来定，也可以写extern int func(int a);这种。 上一篇文章：macOS上的汇编入门（九）——跳转与函数 下一篇文章：macOS上的汇编入门（十一）——系统调用 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（十一）——系统调用.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（十一）——系统调用.html","title":"macOS上的汇编入门（十一）——系统调用","keywords":"","body":"在上一篇文章中，我们更深入地讨论了关于汇编语言函数方面的知识，同时也介绍了如何调用系统库libSystem.dylib的函数。在这篇文章中，我们讨论的是另一种系统提供的函数——系统调用。 什么是系统调用 所谓系统调用(System call), 就是指操作系统提供的接口。我们知道，现代的操作系统分为内核态和用户态。我们平时的汇编语言的执行过程中，都是在用户态执行的。但是，有一些核心的功能，如文件的读写、进程的创建等，都是在内核态实现的。这时候，就需要我们去调用操作系统提供给我们的接口来实现。系统调用和我们之前说的系统库有什么区别呢？其实，很多系统调用在系统库中都有封装。但是，系统调用是最底层的东西。譬如说，我们在织衣服的时候，丝线不够了。我们是不需要自己去养蚕缫丝的，只需要去丝绸店买丝线就行。丝绸店就相当于操作系统，它负责养蚕缫丝，而我们只需要去调用。同时，我们也可以不必自己去丝绸店买衣服，可以去找仆人出门。仆人有什么好处呢？这仆人十分熟悉丝绸店，知道什么丝绸店有什么丝绸店没有。我们想买紫色的丝线，仆人说“丝绸店没有紫色的丝线”，那么也就不需要去丝绸店了。仆人就相当于系统库。我们在调用系统库中涉及系统调用的函数的时候，最终都是要调用到系统调用的。 有哪些系统调用 我们前往/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk 1/usr/include/sys/这个目录，找到一个叫syscall.h的文件。这个文件的格式如下： #define SYS_syscall 0 #define SYS_exit 1 #define SYS_fork 2 #define SYS_read 3 #define SYS_write 4 #define SYS_open 5 #define SYS_close 6 #define SYS_wait4 7 第二列是系统调用的名字，第三列是系统调用号。 系统调用的名字很直白地表述了系统调用的作用，比如说SYS_exit就是退出进程，SYS_fork就是创建进程，SYS_read就是打开文件等等。 系统调用实质上是操作系统提供给我们的一个C函数接口，那么，我们去哪里找系统调用的函数原型呢？ 这个相对比较麻烦。首先，我们前往Apple官方的开源网站opensource.apple, 然后会发现每个版本的macOS都有一部分开源的文件。进入任意一个版本的开源目录下，可以找到一个以xnu开头的目录。这就是每个版本的内核代码，直接下载即可。如果不在意版本号，那么可以直接前往其在GitHub上的镜像apple/darwin-xnu下载即可。 在下载好的xnu目录下，前往子目录bsd/kern/中，找到一个文件syscalls.master. 这就是所有系统调用的函数原型。我们可以利用命令行工具cat进行查看。其文件格式如下： 0 AUE_NULL ALL { int nosys(void); } { indirect syscall } 1 AUE_EXIT ALL { void exit(int rval) NO_SYSCALL_STUB; } 2 AUE_FORK ALL { int fork(void) NO_SYSCALL_STUB; } 3 AUE_NULL ALL { user_ssize_t read(int fd, user_addr_t cbuf, user_size_t nbyte); } 4 AUE_NULL ALL { user_ssize_t write(int fd, user_addr_t cbuf, user_size_t nbyte); } 5 AUE_OPEN_RWTC ALL { int open(user_addr_t path, int flags, int mode) NO_SYSCALL_STUB; } 6 AUE_CLOSE ALL { int close(int fd); } 7 AUE_WAIT4 ALL { int wait4(int pid, user_addr_t status, int options, user_addr_t rusage) NO_SYSCALL_STUB; } 其第一列是系统调用号，第四列则是函数原型。 如何使用系统调用 使用系统调用和使用系统库函数类似，但是，系统库函数我们可以利用函数名进行调用，如_exit, _printf等。但是，我们使用系统调用，则只能利用系统调用号进行调用。这里还有一点需要注意的，就是之前在操作系统基础中提到过，macOS的内核XNU是分为BSD层和Mach层。我们常用的系统调用都属于BSD的系统调用。而BSD层在逻辑地址上是位于Mach层之上的，BSD层要从0x2000000开始。因此，我们实际使用的调用号应该是syscall.h给出的调用号加上0x2000000之后的结果，如SYS_exit的调用号就应当是0x2000001. 在汇编语言中，系统调用号应赋给rax寄存器，然后接下来系统调用的参数按照之前讲的调用约定，依次传给rdi, rsi等寄存器中。最后，使用syscall即可。 比如说，我们在程序中调用SYS_exit系统调用： movq $0x2000001, %rax movq $0, %rdi syscall 我们首先将系统调用号0x2000001赋给rax寄存器，然后根据其函数原型void exit(int rval), 其接受一个参数作为整个进程的返回值，因此，我们将0赋给rdi寄存器，然后使用syscall进行系统调用。 进程的返回 讲完了系统调用，这里顺带提一句，在许多汇编教程中，都是这么写_main函数的： .text .globl _main _main: # do something movq $0x2000001, %rax movq $0, %rdi syscall 而我在这一系列文章中都是这么写的： .text .globl _main _main: # do something retq 这有什么区别呢？ 首先，我这么写是为了和C语言对应。第一种写法对应的C程序是（exit实际上是库函数，但其底层依然是系统调用SYS_exit）： int main() { exit(0); } 而我的写法对应的C程序是： int main() { return 0; } 正常人写C程序大多会用第二种写法，因此我写汇编的时候也是对应第二种写法来写的。 其次，exit和return有什么区别呢？事实上，exit是真正的进程退出，执行完exit之后，进程就彻底没了。但是，return并不是这样。事实上，操作系统在加载一个程序进内存时，动态链接了一个目标文件crt1.o, 这个文件位于/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk 1/usr/lib/目录下。这个文件做了什么呢？它可以理解为 int rVal = main(argc, argv); exit(rVal); 这段C程序。它找到我们想要执行的文件的main函数（在汇编中是_main函数），然后将argc和argv当作main函数的参数传递给它。在main函数执行完后，会有一个返回值，这也是我们写return 0;的目的，这时rVal的值就是main函数的返回值0. 最后，调用exit进行退出。 因此，我们虽然可以在main函数中直接用exit(0);进行退出，就相当于不执行最后一行代码。但是，更优雅的方法显然是return 0;. 上一篇文章：macOS上的汇编入门（十）——再探函数 下一篇文章：macOS上的汇编入门（十二）——调试 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（十二）——调试.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（十二）——调试.html","title":"macOS上的汇编入门（十二）——调试","keywords":"","body":"随着我们编写的汇编程序越来越复杂，往往就需要调试。对于汇编语言而言，常见的调试器有LLDB和GDB. 由于我比较喜欢用LLVM系列的产品，因此，在这篇文章中我主要介绍的是LLDB来调试汇编语言的方法。关于详细的LLDB的使用方法，大家可去官网lldb.llvm.org查看。 同时，在新版本的macOS上使用GDB是一件比较麻烦的事，需要证书签名。关于使用方法请参见我之前的文章在macOS10.14上使用GDB教程。 为了演示LLDB的调试，我们首先有一个汇编程序test.s: # test.s .text .globl _main _main: movq $0x2000001, %rax movq $0, %rdi syscall 为了以源码级别调试程序，我们需要在汇编时加入调试选项-g. 也就是说，我们在终端下依次键入下面语句： as test.s -g -o test.o ld test.o -o test -lSystem 这样就可以将调试信息储存在test.o中以便我们接下来的调试。 载入程序 首先是将程序载入LLDB. 假设我们要调试的可执行程序是test. 那么，我们在终端下键入 lldb test 即可进入LLDB调试界面，同时会出现 (lldb) target create \"test\" Current executable set to 'test' (x86_64). (lldb) 的提示语句。 我们输入quit即可退出LLDB的调试界面： (lldb) quit 运行程序 接下来，我们可以输入run来执行这个程序： (lldb) run Process 1512 launched: '/Users/evian/Downloads/test' (x86_64) Process 1512 exited with status = 0 (0x00000000) 程序顺利执行，没有发生错误。 但是，如果我们在某个地方写错了，比如说写成了movq $0x2001, %rax, 那么汇编、链接时并不会发生错误，但在终端下运行时则会出现以下的错误报告： ./test [1] 1556 segmentation fault ./test 这让我们摸不着头脑，段错误是为什么会出现呢？这时，在LLDB中一个简单的run就可以让我们找到答案： (lldb) run Process 1573 launched: '/Users/evian/Downloads/test' (x86_64) Process 1573 stopped * thread #1, queue = 'com.apple.main-thread', stop reason = EXC_SYSCALL (code=8193, subcode=0x1) frame #0: 0x0000000100000fb8 test 0x100000fb8: addl %eax, (%rax) 0x100000fba: addb %al, (%rax) 0x100000fbc: sbbb $0x0, %al 0x100000fbe: addb %al, (%rax) Target 0: (test) stopped. 注意看到其中的stop reason = EXC_SYSCALL. 这就说明是我们在系统调用时出现了问题。 run除了直接运行以外，还可以传命令行参数。比如说，我们在终端下想这样运行： ./test helloworld 114514 也就是将两个命令行参数传递给test. 那么，我们在LLDB中也可以用run模拟这种传递过程： (lldb) run helloworld 114514 即可。 设置断点 LLDB的功能远不止直接执行程序这么简单。接下来的工作，都需要我们首先设置断点。比如说，我想让程序在执行完movq %0x2000001, %rax后停下来，也就是不继续执行movq %0, %rdi. 这时应当怎么办呢？ 首先，我们找到movq %0, %rdi所在的行数，是第6行。因此，我们需要在第6行设置断点。在某行设置断点的意思就是在某行之前设置断点，当程序遇到断点时就会自动停下来，不继续执行。因此，我们在LLDB中输入并得到反馈： (lldb) breakpoint set --file test.s --line 6 Breakpoint 1: where = test`main + 7, address = 0x0000000100000faf 程序就自动设置了一个断点。这句话的意思就是在名叫test.s的文件的第6行设置断点。 接下来，我们如果直接run，会出现： (lldb) run Process 1669 launched: '/Users/evian/Downloads/test' (x86_64) Process 1669 stopped * thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1 frame #0: 0x0000000100000faf test`main at test.s:6 3 .globl _main 4 _main: 5 movq $0x2000001, %rax -> 6 movq $0, %rdi 7 syscall Target 0: (test) stopped. 也就直接在第6行停了下来。我们可以用continue让其继续执行： (lldb) continue Process 1669 resuming Process 1669 exited with status = 0 (0x00000000) 或者利用nexti进行单步调试： (lldb) nexti Process 1680 stopped * thread #1, queue = 'com.apple.main-thread', stop reason = instruction step over frame #0: 0x0000000100000fb6 test`main at test.s:7 4 _main: 5 movq $0x2000001, %rax 6 movq $0, %rdi -> 7 syscall Target 0: (test) stopped. 所谓单步调试，就是指在当前指令的下一个指令处再设置一个断点，然后继续执行。实际效果也就相当于又往后执行了一个指令，然后停止。 寄存器与内存 在进程停止在某个断点处时，我们还可以读取此时寄存器和内存的值。 利用register read可以阅读大部分常用寄存器的值： (lldb) register read General Purpose Registers: rax = 0x0000000002000001 rbx = 0x0000000000000000 rcx = 0x00007ffeefbff910 rdx = 0x00007ffeefbff7e8 rdi = 0x0000000000000001 rsi = 0x00007ffeefbff7d8 rbp = 0x00007ffeefbff7c8 rsp = 0x00007ffeefbff7b8 r8 = 0x0000000000000000 r9 = 0x0000000000000000 r10 = 0x0000000000000000 r11 = 0x0000000000000000 r12 = 0x0000000000000000 r13 = 0x0000000000000000 r14 = 0x0000000000000000 r15 = 0x0000000000000000 rip = 0x0000000100000faf test`main + 7 rflags = 0x0000000000000246 cs = 0x000000000000002b fs = 0x0000000000000000 gs = 0x0000000000000000 如果输入register read —all, 则会输出所有寄存器的值。 此外，我们还可以单独查看某个寄存器，比如说 (lldb) register read rsp rsp = 0x00007ffeefbff7b8 就会返回rsp内存储的值。 同时，我们也可以查看内存中的值。我们刚刚查看到了此时栈顶指针位于0x00007ffeefbff7b8. 因此，我们利用 (lldb) memory read 0x00007ffeefbff7b8 0x7ffeefbff7b8: 35 fc 2e 6d ff 7f 00 00 35 fc 2e 6d ff 7f 00 00 5�.m�...5�.m�... 0x7ffeefbff7c8: 00 00 00 00 00 00 00 00 01 00 00 00 00 00 00 00 ................ 就获得了当前栈顶的内容。 上一篇文章：macOS上的汇编入门（十一）——系统调用 下一篇文章：macOS上的汇编入门（十三）——从编译到执行 "},"语言/Assembly-on-macOS-master/macOS上的汇编入门（十三）——从编译到执行.html":{"url":"语言/Assembly-on-macOS-master/macOS上的汇编入门（十三）——从编译到执行.html","title":"macOS上的汇编入门（十三）——从编译到执行","keywords":"","body":"作为这一系列文章中的最后一篇，这篇文章我打算讨论的是从编译到执行的全过程。因为许多地方都是要有了汇编的基础知识以后才方便讨论，所以我把它放到了最后一篇。 编译 编译并不是对汇编代码来说的，而是对更高级的语言，如C、C++来说的。如果一个语言最终的编译结果是可执行文件，那么它一定会先被编译为汇编语言，然后再被汇编、链接为可执行文件。对于C和C++来说，大部分的编译器都支持输出汇编结果。比如说对于test.c, 我们想查看其编译后的汇编代码，只需要在命令行中键入 clang test.c -S -o test.s 然后就会生成一个包含其汇编代码的test.s文件。 研究编译器生成的汇编代码很有意义。因为现代的编译器，其都针对不同的平台、架构有许多优化，这对于我们写汇编代码是很有意义的。比如说，对 return 0; 的编译结果，是 xorl %eax, %eax retq 事实上，通过异或自身来清零这一操作，在任何架构上都是最高效的。 汇编 所谓汇编，就是输入我们的汇编代码，输出目标文件。什么是目标文件呢？假设我们有一个汇编文件test.s, 然后我们利用 as test.s -o test.o 生成一个test.o文件。然后，我们在终端下利用file指令查看其文件类型： $ file test.o test.o: Mach-O 64-bit object x86_64 可以看到， 这个文件是object, 也就是目标文件。 那么，目标文件是做什么用的呢？要了解这个，首先我们需要知道「汇编」这一步骤究竟做了什么。 我们知道，汇编语言可以看作机器码的human-readable版本。因此，从最直观来看，汇编只需要把汇编代码翻译为机器码就ok了，也就是汇编代码直接变成可执行文件。这个粗略来看是对的，对于大多数代码来说，确实直接翻译为机器码就好了。但是，如果真的是这样，随着人们写的代码越来越多，汇编器的有一项工作的负担就越来越重——翻译符号。我们之前在汇编语言中大量运用了标签，一个标签就对应一个地址。此外，我们也可以引用别的文件、动态链接库的标签。因此，对于一个标签，其可能的情况有好多好多种。所以，人们就把这部分功能从汇编器中解放出来，同时，汇编器就变成了对于一个汇编文件，输出其目标文件。目标文件几乎包含的就是可执行文件中的机器码，但是标签部分却是空缺的。其会把所有遇到的符号放到一个符号表中，以便查阅。 举个例子，我们现在有两个汇编程序test.s和tmp.s, 其代码分别如下： tmp.s: # tmp.s .data .globl tmp_var tmp_var: .quad 0x114514 .text .globl _tmp_func _tmp_func: retq test.s: # test.s .data var: .asciz \"hello, world!\\n\" .text .globl _main _func: retq _main: pushq %rbp callq _func # internal call leaq var(%rip), %rdi # internal variable movb $0, %al callq _printf # dylib call movq tmp_var(%rip), %rdi # external variable callq _tmp_func # external variable popq %rbp movq $0, %rax retq 其中主函数位于test.s. 且test.s分别包含了对本文件下函数的调用、本文件下变量的访问、动态链接库中函数的调用、外部文件中函数的调用和外部文件中变量的访问。 我们在终端中依次键入 as test.s -o test.o as tmp.s -o tmp.o 得到两个目标文件。我们利用 otool -v -t test.o 可以查看test.o文件中__TEXT段__text节的代码： test.o: (__TEXT,__text) section _func: 0000000000000000 retq _main: 0000000000000001 pushq %rbp 0000000000000002 callq 0x7 0000000000000007 leaq (%rip), %rdi 000000000000000e movb $0x0, %al 0000000000000010 callq 0x15 0000000000000015 movq (%rip), %rdi 000000000000001c callq 0x21 0000000000000021 popq %rbp 0000000000000022 movq $0x0, %rax 0000000000000029 retq 同时，我们在终端中键入 nm -n -m test.o 可以查看test.o的符号表： (undefined) external _printf (undefined) external _tmp_func (undefined) external tmp_var 0000000000000000 (__TEXT,__text) non-external _func 0000000000000001 (__TEXT,__text) external _main 000000000000002a (__DATA,__data) non-external var 可以看到，对于本文件中定义的符号，符号表中已经有了位置，同时依据是否用.globl声明区分为external和non-external. 对于未在本文件中定义的符号，都是undefined. 链接 之前我们讲到的符号定位的功能，就是链接的作用。链接器接收多个目标文件，最终输出为一个可执行文件。对于刚刚我们生成的两个目标文件test.o和tmp.o, 我们在终端中键入 ld test.o tmp.o -o test -lSystem 得到可执行文件test. 我们利用otool查看其__TEXT段__text节的代码为： test: (__TEXT,__text) section _func: 0000000100000f6b retq _main: 0000000100000f6c pushq %rbp 0000000100000f6d callq 0x100000f6b 0000000100000f72 leaq 0x1097(%rip), %rdi 0000000100000f79 movb $0x0, %al 0000000100000f7b callq 0x100000f96 0000000100000f80 movq 0x1098(%rip), %rdi 0000000100000f87 callq 0x100000f95 0000000100000f8c popq %rbp 0000000100000f8d movq $0x0, %rax 0000000100000f94 retq _tmp_func: 0000000100000f95 retq 可以看到，链接器将两个目标文件的段合并了。同一个段同一个节中的代码被放在了一起。此外，之前标签处占位的地址，现在也变成了正确的地址。 接着，我们利用nm查看其符号表： (undefined) external _printf (from libSystem) (undefined) external dyld_stub_binder (from libSystem) 0000000100000000 (__TEXT,__text) [referenced dynamically] external __mh_execute_header 0000000100000f6b (__TEXT,__text) non-external _func 0000000100000f6c (__TEXT,__text) external _main 0000000100000f95 (__TEXT,__text) external _tmp_func 0000000100002008 (__DATA,__data) non-external __dyld_private 0000000100002010 (__DATA,__data) non-external var 000000010000201f (__DATA,__data) external tmp_var 其中多出来的dyld_stub_binder等只是为了动态链接，我们暂时不考虑。我们发现，之前处于undefined状态的_tmp_func和tmp_var现在已经被定义了。而且_printf这样的动态链接库中的函数，也被确定是from libSystem了。这就是链接器的主要作用。 动态链接 我刚刚上面多次提到了动态链接库，那么，动态链接究竟是什么呢？ 首先，我们考虑一个问题。我们知道，有许多库函数如_printf等都是十分常用的，所以许多文件在链接时都要链接包含这些库函数的文件。那么，如果我们的这些库函数像上面的汇编过程一样，包含在某些.o文件中，比如说lib.o. 那么，作为链接器，ld会将这些实现_printf的汇编代码合并到最终的可执行文件中。当可执行文件执行的时候，又会将这部分代码放到内存中。那么，假设我们同时运行10个链接了lib.o的可执行文件，那么，内存中同样的代码有10份。这显然是不可以接受的。 此外，还有一个问题。我们知道，系统是不断升级的。那么，系统提供的库函数也会随着时间的变化而不断升级。如果所有的库函数都像上面描述的那样，作为代码直接写死到可执行文件里面去，那么，每次升级过后，之前链接了这些库函数的可执行文件，使用的依然是老旧的库函数。如果要使用新的库函数，还得重新链接。这显然也是不可以接受的。 为了解决这两个问题，动态链接就应运而生了。与汇编、链接不同，动态链接是在执行阶段的。我们的库函数，都被放到了一个以.dylib结尾的动态链接库中。我们在使用ld链接的时候，也可以链接动态链接库，如-lSystem选项实质上就是链接了动态链接库libSystem.dylib. 链接器如果遇到动态链接库，那么只会给符号重定位，而不会将代码整合到可执行文件中。同时，可执行文件中会包含其链接的动态链接库。我们也可以利用otool查看某个可执行文件链接的动态链接库，比如说，对于上述的可执行文件test, 我们在终端下键入： otool -L test 然后就会出现其链接的动态链接库（实际上libSystem.dylib是libSystem.B.dylib的一个软链接，说不定以后库文件大规模升级以后，就会软链接到libSystem.C.dylib）： test: /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1281.0.0) 然后，到程序执行的时候，就是动态链接器dyld发挥的时候了。顺便一提，Apple的dyld是开源的，可以去opensource-apple/dyld上查看。 当程序执行的时候，首先，内核将代码装载入其逻辑地址空间，然后，又装载了动态链接器。接着，内核就把控制权转交给dyld. 动态链接器做的，是找到这个可执行文件链接的动态链接器，然后把它们装载入逻辑地址空间。用一个图表示如下： 注意到，我们提到的是将动态链接库装载入逻辑地址空间。事实上，在物理内存中，动态链接库只有一份。而内存映射单元MMU将同一个动态链接库的不同逻辑地址映射入同一个物理地址中，这样就解决了在内存中多个拷贝的问题。 同时，由于是在执行时才装载，因此，就解决了升级不便的问题。 上一篇文章：macOS上的汇编入门（十二）——调试 "},"数据库/":{"url":"数据库/","title":"数据库","keywords":"","body":"数据库 "},"数据库/Oracle/":{"url":"数据库/Oracle/","title":"Oracle","keywords":"","body":"Oracle "},"数据库/Oracle/如何读懂AWR.html":{"url":"数据库/Oracle/如何读懂AWR.html","title":"如何读懂AWR","keywords":"","body":"如何读懂AWR 什么是AWR AWR (Automatic Workload Repository) 一堆历史性能数据，放在SYSAUX表空间上， AWR和SYSAUX都是10g出现的，是Oracle调优的关键特性； 大约1999年左右开始开发，已经有15年历史 默认快照间隔1小时，10g保存7天、11g保存8天; 可以通过DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS修改 DBA_HIST_WR_CONTROL AWR程序核心是dbms_workload_repository包 @?/rdbms/admin/awrrpt 本实例 @?/rdbms/admin/awrrpti RAC中选择实例号 AWR的维护 主要是MMON(Manageability Monitor Process)和它的小工进程(m00x) MMON的功能包括: 启动slave进程m00x去做AWR快照 当某个度量阀值被超过时发出alert告警 为最近改变过的SQL对象捕获指标信息 AWR小技巧 手动执行一个快照： Exec dbms_workload_repository.create_snapshot; 创建一个AWR基线 Exec DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE(start_snap_id，end_snap_id ,baseline_name); @?/rdbms/admin/awrddrpt AWR比对报告 @?/rdbms/admin/awrgrpt RAC 全局AWR 自动生成AWR HTML报告： http://www.oracle-base.com/dba/10g/generate_multiple_awr_reports.sql 报告总结 WORKLOAD REPOSITORY report for DB Name DB Id Instance Inst Num Startup Time Release RAC ------------ ----------- ------------ -------- --------------- ----------- --- MAC 2629627371 askmaclean.com 1 22-Jan-13 16:49 11.2.0.3.0 YES Host Name Platform CPUs Cores Sockets Memory(GB) ---------------- -------------------------------- ---- ----- ------- ---------- MAC10 AIX-Based Systems (64-bit) 128 32 320.00 Snap Id Snap Time Sessions Curs/Sess --------- ------------------- -------- --------- Begin Snap: 5853 23-Jan-13 15:00:56 3,520 1.8 End Snap: 5854 23-Jan-13 15:30:41 3,765 1.9 Elapsed: 29.75 (mins) DB Time: 7,633.76 (mins) Elapsed 为该AWR性能报告的时间跨度(自然时间的跨度，例如前一个快照snapshot是4点生成的，后一个快照snapshot是6点生成的，则若使用@?/rdbms/admin/awrrpt 脚本中指定这2个快照的话，那么其elapsed = (6-4)=2 个小时)，一个AWR性能报告 至少需要2个AWR snapshot性能快照才能生成 ( 注意这2个快照时间 实例不能重启过，否则指定这2个快照生成AWR性能报告 会报错)，AWR性能报告中的 指标往往是 后一个快照和前一个快照的 指标的delta，这是因为 累计值并不能反映某段时间内的系统workload。 DB TIME= 所有前台session花费在database调用上的总和时间： 注意是前台进程foreground sessions 包括CPU时间、IO Time、和其他一系列非空闲等待时间，别忘了cpu on queue time DB TIME 不等于 响应时间，DB TIME高了未必响应慢，DB TIME低了未必响应快 DB Time描绘了数据库总体负载，但要和elapsed time逝去时间结合其他来。 Average Active Session AAS= DB time/Elapsed Time DB Time =60 min ， Elapsed Time =60 min AAS=60/60=1 负载一般 DB Time= 1min , Elapsed Time= 60 min AAS= 1/60 负载很轻 DB Time= 60000 min，Elapsed Time= 60 min AAS=1000 系统hang了吧？ DB TIME= DB CPU + Non-Idle Wait + Wait on CPU queue 如果仅有2个逻辑CPU，而2个session在60分钟都没等待事件，一直跑在CPU上，那么： DB CPU= 2 60 mins ， DB Time = 2 60 + 0 + 0 =120 AAS = 120/60=2 正好等于OS load 2。 如果有3个session都100%仅消耗CPU，那么总有一个要wait on queue DB CPU = 2* 60 mins ，wait on CPU queue= 60 mins AAS= (120+ 60)/60=3 主机load 亦为3，此时vmstat 看waiting for run time 真实世界中？ DB Cpu = xx mins ， Non-Idle Wait= enq:TX + cursor pin S on X + latch : xxx + db file sequential read + ……….. 阿猫阿狗 内存参数大小 Cache Sizes Begin End ~~~~~~~~~~~ ---------- ---------- Buffer Cache: 49,152M 49,152M Std Block Size: 8K Shared Pool Size: 13,312M 13,312M Log Buffer: 334,848K 内存管理方式：MSMM、ASMM(sga_target)、AMM(memory_target) 小内存有小内存的问题， 大内存有大内存的麻烦！ ORA-04031???!! Buffer cache和shared pool size的 begin/end值在ASMM、AMM和11gR2 MSMM下可是会动的哦！ 这里说 shared pool一直收缩，则在shrink过程中一些row cache 对象被lock住可能导致前台row cache lock等解析等待，最好别让shared pool shrink。如果这里shared pool一直在grow，那说明shared pool原有大小不足以满足需求(可能是大量硬解析)，结合下文的解析信息和SGA breakdown来一起诊断问题。 Load Profile Load Profile Per Second Per Transaction Per Exec Per Call ~~~~~~~~~~~~ --------------- --------------- ---------- ---------- DB Time(s): 256.6 0.2 0.07 0.03 DB CPU(s): 3.7 0.0 0.00 0.00 Redo size: 1,020,943.0 826.5 Logical reads: 196,888.0 159.4 Block changes: 6,339.4 5.1 Physical reads: 5,076.7 4.1 Physical writes: 379.2 0.3 User calls: 10,157.4 8.2 Parses: 204.0 0.2 Hard parses: 0.9 0.0 W/A MB processed: 5.0 0.0 Logons: 1.7 0.0 Executes: 3,936.6 3.2 Rollbacks: 1,126.3 0.9 Transactions: 1,235.3 % Blocks changed per Read: 53.49 Recursive Call %: 98.04 Rollback per transaction %: 36.57 Rows per Sort: 73.70 指标 指标含义 redo size 单位 bytes，redo size可以用来估量update/insert/delete的频率，大的redo size往往对lgwr写日志，和arch归档造成I/O压力， Per Transaction可以用来分辨是  大量小事务， 还是少量大事务。如上例每秒redo 约1MB ，每个事务800 字节，符合OLTP特征 Logical Read 单位  次数*块数， 相当于 “人*次”， 如上例  196,888 * db_block_size=1538MB/s ， 逻辑读耗CPU，主频和CPU核数都很重要，逻辑读高则DB CPU往往高，也往往可以看到latch: cache buffer chains等待。  大量OLTP系统(例如siebel)可以高达几十乃至上百Gbytes。 Block changes 单位 次数*块数 ， 描绘数据变化频率 Physical Read 单位次数*块数， 如上例 5076 * 8k = 39MB/s， 物理读消耗IO读，体现在IOPS和吞吐量等不同纬度上；但减少物理读可能意味着消耗更多CPU。好的存储 每秒物理读能力达到几GB，例如Exadata。  这个physical read包含了physical reads cache和physical reads direct Physical writes 单位  次数*块数，主要是DBWR写datafile，也有direct path write。 dbwr长期写出慢会导致定期log file switch(checkpoint no complete) 检查点无法完成的前台等待。  这个physical write 包含了physical writes direct +physical writes from cache User Calls 单位次数，用户调用数，more details from internal Parses 解析次数，包括软解析+硬解析，软解析优化得不好，则夸张地说几乎等于每秒SQL执行次数。 即执行解析比1:1，而我们希望的是 解析一次 到处运行哦！ Hard Parses 万恶之源．　Cursor pin s on X， library cache: mutex X ， latch: row cache objects /shared pool……………..。 硬解析最好少于每秒20次 W/A MB processed 单位MB  W/A workarea  workarea中处理的数据数量 结合 In-memory Sort%， sorts (disk) PGA Aggr一起看 Logons 登陆次数， logon storm 登陆风暴，结合AUDIT审计数据一起看。短连接的附带效应是游标缓存无用 Executes 执行次数，反应执行频率 Rollback 回滚次数， 反应回滚频率， 但是这个指标不太精确，参考而已，别太当真 Transactions 每秒事务数，是数据库层的TPS，可以看做压力测试或比对性能时的一个指标，孤立看无意义 % Blocks changed per Read 每次逻辑读导致数据块变化的比率；如果’redo size’, ‘block changes’ ‘pct of blocks changed per read’三个指标都很高，则说明系统正执行大量insert/update/delete; pct of blocks changed per read =  (block changes ) /( logical reads) Recursive Call % 递归调用的比率;Recursive Call % = (recursive calls)/(user calls) Rollback per transaction % 事务回滚比率。  Rollback per transaction %= (rollback)/(transactions) Rows per Sort 平均每次排序涉及到的行数 ;  Rows per Sort= ( sorts(rows) ) / ( sorts(disk) + sorts(memory)) 注意这些Load Profile 负载指标 在本环节提供了 2个维度 per second 和 per transaction。 per Second: 主要是把 快照内的delta值除以 快站时间的秒数 ， 例如 在 A快照中V$SYSSTAT视图反应 table scans (long tables) 这个指标是 100 ，在B快照中V$SYSSTAT视图反应 table scans (long tables) 这个指标是 3700, 而A快照和B快照 之间 间隔了一个小时 3600秒， 则 对于 table scans (long tables) per second 就是 ( 3700- 100) /3600=1。 pert Second是我们审视数据的主要维度 ，任何性能数据脱离了 时间模型则毫无意义。 在statspack/AWR出现之前 的调优 洪荒时代， 有很多DBA 依赖 V$SYSSTAT等视图中的累计 统计信息来调优，以当前的调优眼光来看，那无异于刀耕火种。 per transaction : 基于事务的维度， 与per second相比 是把除数从时间的秒数改为了该段时间内的事务数。 这个维度的很大用户是用来 识别应用特性的变化 ，若2个AWR性能报告中该维度指标 出现了大幅变化，例如 redo size从本来per transaction 1k变化为 10k per transaction，则说明SQL业务逻辑肯定发生了某些变化。 注意AWR中的这些指标 并不仅仅用来孤立地了解 Oracle数据库负载情况， 实施调优工作。 对于 故障诊断 例如HANG、Crash等， 完全可以通过对比问题时段的性能报告和常规时间来对比，通过各项指标的对比往往可以找出 病灶所在。 SELECT VALUE FROM DBA_HIST_SYSSTAT WHERE SNAP_ID = :B4 AND DBID = :B3 AND INSTANCE_NUMBER = :B2 AND STAT_NAME in ( \"db block changes\",\"user calls\",\"user rollbacks\",\"user commits\",redo size\",\"physical reads direct\",\"physical writes\",\"parse count (hard)\",\"parse count (total)\",\"session logical reads\",\"recursive calls\",\"redo log space requests\",\"redo entries\",\"sorts (memory)\",\"sorts (disk)\",\"sorts (rows)\",\"logons cumulative\",\"parse time cpu\",\"parse time elapsed\",\"execute count\",\"logons current\",\"opened cursors current\",\"DBWR fusion writes\",\"gcs messages sent\",\"ges messages sent\",\"global enqueue gets sync\",\"global enqueue get time\",\"gc cr blocks received\",\"gc cr block receive time\",\"gc current blocks received\",\"gc current block receive time\",\"gc cr blocks served\",\"gc cr block build time\",\"gc cr block flush time\",\"gc cr block send time\",\"gc current blocks served\",\"gc current block pin time\",\"gc current block flush time\",\"gc current block send time\",\"physical reads\",\"physical reads direct (lob)\", SELECT TOTAL_WAITS FROM DBA_HIST_SYSTEM_EVENT WHERE SNAP_ID = :B4 AND DBID = :B3 AND INSTANCE_NUMBER = :B2 AND EVENT_NAME in (\"gc buffer busy\",\"buffer busy waits\" SELECT VALUE FROM DBA_HIST_SYS_TIME_MODEL WHERE DBID = :B4 AND SNAP_ID = :B3 AND INSTANCE_NUMBER = :B2 AND STAT_NAME in (\"DB CPU\",\"sql execute elapsed time\",\"DB time\" SELECT VALUE FROM DBA_HIST_PARAMETER WHERE SNAP_ID = :B4 AND DBID = :B3 AND INSTANCE_NUMBER = :B2 AND PARAMETER_NAME in (\"__db_cache_size\",\"__shared_pool_size\",\"sga_target\",\"pga_aggregate_target\",\"undo_management\",\"db_block_size\",\"log_buffer\",\"timed_statistics\",\"statistics_level\" SELECT BYTES FROM DBA_HIST_SGASTAT WHERE SNAP_ID = :B4 AND DBID = :B3 AND INSTANCE_NUMBER = :B2 AND POOL IN ('shared pool', 'all pools') AND NAME in (\"free memory\", SELECT BYTES FROM DBA_HIST_SGASTAT WHERE SNAP_ID = :B4 AND DBID = :B3 AND INSTANCE_NUMBER = :B2 AND NAME = :B1 AND POOL IS NULL SELECT (E.BYTES_PROCESSED - B.BYTES_PROCESSED) FROM DBA_HIST_PGA_TARGET_ADVICE B, DBA_HIST_PGA_TARGET_ADVICE E WHERE B.DBID = :B4 AND B.SNAP_ID = :B3 AND B.INSTANCE_NUM BER = :B2 AND B.ADVICE_STATUS = 'ON' AND E.DBID = B.DBID AND E.SNAP_ID = :B1 AND E.INSTANCE_NUMBER = B.INSTANCE_NUMBER AND E.PGA_TARGET_FACTOR = 1 AND B.PGA_TARGET_FACT OR = 1 AND E.ADVICE_STATUS = 'ON' SELECT SUM(E.TOTAL_WAITS - NVL(B.TOTAL_WAITS, 0)) FROM DBA_HIST_SYSTEM_EVENT B, DBA_HIST_SYSTEM_EVENT E WHERE B.SNAP_ID(+) = :B4 AND E.SNAP_ID = :B3 AND B.DBID(+) = :B2 AND E.DBID = :B2 AND B.INSTANCE_NUMBER(+) = :B1 AND E.INSTANCE_NUMBER = :B1 AND B.EVENT_ID(+) = E.EVENT_ID AND (E.EVENT_NAME = 'latch free' OR E.EVENT_NAME LIKE 'latch :%') SELECT DECODE(B.TOTAL_SQL, 0, 0, 100*(1-B.SINGLE_USE_SQL/B.TOTAL_SQL)), DECODE(E.TOTAL_SQL, 0, 0, 100*(1-E.SINGLE_USE_SQL/E.TOTAL_SQL)), DECODE(B.TOTAL_SQL_MEM, 0, 0, 1 00*(1-B.SINGLE_USE_SQL_MEM/B.TOTAL_SQL_MEM)), DECODE(E.TOTAL_SQL_MEM, 0, 0, 100*(1-E.SINGLE_USE_SQL_MEM/E.TOTAL_SQL_MEM)) FROM DBA_HIST_SQL_SUMMARY B, DBA_HIST_SQL_SUMM ARY E WHERE B.SNAP_ID = :B4 AND E.SNAP_ID = :B3 AND B.INSTANCE_NUMBER = :B2 AND E.INSTANCE_NUMBER = :B2 AND B.DBID = :B1 AND E.DBID = :B1 SELECT EVENT, WAITS, TIME, DECODE(WAITS, NULL, TO_NUMBER(NULL), 0, TO_NUMBER(NULL), TIME/WAITS*1000) AVGWT, PCTWTT, WAIT_CLASS FROM (SELECT EVENT, WAITS, TIME, PCTWTT, WAIT_CLASS FROM (SELECT E.EVENT_NAME EVENT, E.TOTAL_WAITS - NVL(B.TOTAL_WAITS,0) WAITS, (E.TIME_WAITED_MICRO - NVL(B.TIME_WAITED_MICRO,0)) / 1000000 TIME, 100 * (E.TIME _WAITED_MICRO - NVL(B.TIME_WAITED_MICRO,0)) / :B1 PCTWTT, E.WAIT_CLASS WAIT_CLASS FROM DBA_HIST_SYSTEM_EVENT B, DBA_HIST_SYSTEM_EVENT E WHERE B.SNAP_ID(+) = :B5 AND E.S NAP_ID = :B4 AND B.DBID(+) = :B3 AND E.DBID = :B3 AND B.INSTANCE_NUMBER(+) = :B2 AND E.INSTANCE_NUMBER = :B2 AND B.EVENT_ID(+) = E.EVENT_ID AND E.TOTAL_WAITS > NVL(B.TO TAL_WAITS,0) AND E.WAIT_CLASS != 'Idle' UNION ALL SELECT 'CPU time' EVENT, TO_NUMBER(NULL) WAITS, :B6 /1000000 TIME, 100 * :B6 / :B1 PCTWTT, NULL WAIT_CLASS FROM DUAL W HERE :B6 > 0) ORDER BY TIME DESC, WAITS DESC) WHERE ROWNUM Instance Efficiency Percentages (Target 100%) Instance Efficiency Percentages (Target 100%) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Buffer Nowait %: 99.97 Redo NoWait %: 100.00 Buffer Hit %: 97.43 In-memory Sort %: 100.00 Library Hit %: 99.88 Soft Parse %: 99.58 Execute to Parse %: 94.82 Latch Hit %: 99.95 Parse CPU to Parse Elapsd %: 1.75 % Non-Parse CPU: 99.85 上述所有指标 的目标均为100%，即越大越好，在少数bug情况下可能超过100%或者为负值。 80%以上 %Non-Parse CPU 90%以上 Buffer Hit%, In-memory Sort%, Soft Parse% 95%以上 Library Hit%, Redo Nowait%, Buffer Nowait% 98%以上 Latch Hit% 1、 Buffer Nowait % session申请一个buffer(兼容模式)不等待的次数比例。 需要访问buffer时立即可以访问的比率， 不兼容的情况 在9i中是 buffer busy waits，从10g以后 buffer busy waits 分离为 buffer busy wait 和 read by other session2个等待事件 : 9i 中 waitstat的总次数基本等于buffer busy waits等待事件的次数 SQL> select sum(TOTAL_WAITS) from v$system_event where event='buffer busy waits'; SUM(TOTAL_WAITS) —————- 33070394 SQL> select sum(count) from v$waitstat; SUM(COUNT) ———- 33069335 10g waitstat的总次数基本等于 buffer busy waits 和 read by other session 等待的次数总和 SQL> select sum(TOTAL_WAITS) from v$system_event where event='buffer busy waits' or event='read by other session'; SUM(TOTAL_WAITS) —————- 60675815 SQL> select sum(count) from v$waitstat; SUM(COUNT) ———- 60423739 Buffer Nowait %的计算公式是 sum(v$waitstat.wait_count) / (v$sysstat statistic session logical reads)，例如在AWR中： Class Waits Total Wait Time (s) Avg Time (ms) data block 24,543 2,267 92 undo header 743 2 3 undo block 1,116 0 0 1st level bmb 35 0 0 session logical reads 40,769,800 22,544.84 204.71 Buffer Nowait %: 99.94 Buffer Nowait= ( 40,769,800 – (24543+743+1116+35))/ ( 40,769,800) = 0.99935= 99.94% SELECT SUM(WAIT_COUNT) FROM DBA_HIST_WAITSTAT WHERE SNAP_ID = :B3 AND DBID = :B2 AND INSTANCE_NUMBER = :B1 2、buffer HIT%: 经典的经典，高速缓存命中率，反应物理读和缓存命中间的纠结，但这个指标即便99% 也不能说明物理读等待少了 不合理的db_cache_size，或者是SGA自动管理ASMM /Memory 自动管理AMM下都可能因为db_cache_size过小引起大量的db file sequential /scattered read等待事件； maclean曾经遇到过因为大量硬解析导致ASMM 下shared pool共享池大幅度膨胀，而db cache相应缩小shrink的例子，最终db cache收缩到只有几百兆，本来没有的物理读等待事件都大幅涌现出来 。 此外与 buffer HIT%相关的指标值得关注的还有 table scans(long tables) 大表扫描这个统计项目、此外相关的栏目还有Buffer Pool Statistics 、Buffer Pool Advisory等（如果不知道在哪里，直接找一个AWR 去搜索这些关键词即可)。 buffer HIT%在 不同版本有多个计算公式： 在9i中 Buffer Hit Ratio = 1 – ((physical reads – physical reads direct – physical reads direct (lob)) / (db block gets + consistent gets – physical reads direct – physical reads direct (lob)) 在10g以后： Buffer Hit Ratio= 1 – ((‘physical reads cache’) / (‘consistent gets from cache’ + ‘db block gets from cache’) 注意：但是实际AWR中 似乎还是按照9i中的算法，虽然算法的区别对最后算得的比率影响不大。 对于buffer hit % 看它的命中率有多高没有意义，主要是关注 未命中的次数有多少。通过上述公式很容易反推出未命中的物理读的次数。 db block gets 、consistent gets 以及 session logical reads的关系如下： db block gets＝db block gets direct＋　db block gets from cache consistent gets　＝　consistent gets from cache＋　consistent gets direct consistent gets from cache＝　consistent gets – examination + else consistent gets – examination==>指的是不需要pin buffer直接可以执行consistent get的次数，常用于索引，只需要一次latch get session logical reads = db block gets +consistent gets 其中physical reads 、physical reads cache、physical reads direct、physical reads direct (lob)几者的关系为： physical reads = physical reads cache +　physical reads direct 这个公式其实说明了 物理读有2种 ： 物理读进入buffer cache中 ，是常见的模式 physical reads cache 物理读直接进入PGA 直接路径读， 即physical reads direct physical reads 8 Total number of data blocks read from disk. This value can be greater than the value of “physical reads direct” plus “physical reads cache” as reads into process private buffers also included in this statistic. physical reads cache 8 Total number of data blocks read from disk into the buffer cache. This is a subset of “physical reads” statistic. physical reads direct 8 Number of reads directly from disk, bypassing the buffer cache. For example, in high bandwidth, data-intensive operations such as parallel query, reads of disk blocks bypass the buffer cache to maximize transfer rates and to prevent the premature aging of shared data blocks resident in the buffer cache. physical reads direct = physical reads direct (lob) + physical reads direct temporary tablespace + physical reads direct(普通) 这个公式也说明了 直接路径读 分成三个部分： physical reads direct (lob) 直接路径读LOB对象 physical reads direct temporary tablespace 直接路径读临时表空间 physical read direct(普通) 普通的直接路径读， 一般是11g开始的自动的大表direct path read和并行引起的direct path read physical writes direct= physical writes direct (lob)+ physical writes direct temporary tablespace DBWR checkpoint buffers written = DBWR thread checkpoint buffers written+ DBWR tablespace checkpoint buffers written+ DBWR PQ tablespace checkpoint buffers written+…. 3、Redo nowait%: session在生成redo entry时不用等待的比例，redo相关的资源争用例如redo space request争用可能造成生成redo时需求等待。此项数据来源于v$sysstat中的(redo log space requests/redo entries)。 一般来说10g以后不太用关注log_buffer参数的大小，需要关注是否有十分频繁的 log switch ； 过小的redo logfile size 如果配合较大的SGA和频繁的commit提交都可能造成该问题。 考虑增到redo logfile 的尺寸 : 1~4G 每个，7~10组都是合适的。同时考虑优化redo logfile和datafile 的I/O。 4、In-memory Sort%:这个指标因为它不计算workarea中所有的操作类型，所以现在越来越鸡肋了。 纯粹在内存中完成的排序比例。数据来源于v$sysstat statistics sorts (disk) 和 sorts (memory)， In-memory Sort% = sort(memory) / ( sort(disk)+ sort(memory) ) 5、Library Hit%: library cache命中率，申请一个library cache object例如一个SQL cursor时，其已经在library cache中的比例。 数据来源 V$librarycache的pins和pinhits。 合理值：>95% ，该比例来源于1- ( Σ(pin Requests * Pct Miss) / Sum(Pin Requests) ) 维护这个指标的重点是 保持shared pool共享池有足够的Free Memory，且没有过多的内存碎片，具体可以参考这里。 显然过小的shared pool可用空间会导致library cache object被aged out换出共享池。 此外保证SQL语句绑定变量和游标可以共享也是很重要的因素。 Library Cache Activity DB/Inst: G10R25/G10R25 Snaps: 2964-2965 -> \"Pct Misses\" should be very low http://www.askmaclean.com Get Pct Pin Pct Invali- Namespace Requests Miss Requests Miss Reloads dations --------------- ------------ ------ -------------- ------ ---------- -------- BODY 5 0.0 6 16.7 1 0 CLUSTER 10 0.0 26 0.0 0 0 SQL AREA 601,357 99.8 902,828 99.7 47 2 TABLE/PROCEDURE 83 9.6 601,443 0.0 48 0 GETS NUMBER Number of times a lock was requested for objects of this namespace GETHITS NUMBER Number of times an object’s handle was found in memory GETHITRATIO NUMBER Ratio of GETHITS to GETS PINS NUMBER Number of times a PIN was requested for objects of this namespace PINHITS NUMBER Number of times all of the metadata pieces of the library object were found in memory PINHITRATIO NUMBER Ratio of PINHITS to PINS RELOADS NUMBER Any PIN of an object that is not the first PIN performed since the object handle was created, and which requires loading the object from disk INVALIDATIONS NUMBER Total number of times objects in this namespace were marked invalid because a dependent object was modified SELECT SUM(PINS), SUM(PINHITS) FROM DBA_HIST_LIBRARYCACHE WHERE SNAP_ID = :B3 AND DBID = :B2 AND INSTANCE_NUMBER = :B1 6、Soft Parse: 软解析比例，无需多说的经典指标，数据来源v$sysstat statistics的parse count(total)和parse count(hard)。 合理值>95% Soft Parse %是AWR中另一个重要的解析指标，该指标反应了快照时间内 软解析次数 和 总解析次数 (soft+hard 软解析次数+硬解析次数)的比值，若该指标很低，那么说明了可能存在剧烈的hard parse硬解析，大量的硬解析会消耗更多的CPU时间片并产生解析争用(此时可以考虑使用cursor_sharing=FORCE)； 理论上我们总是希望 Soft Parse % 接近于100%， 但并不是说100%的软解析就是最理想的解析状态，通过设置 session_cached_cursors参数和反复重用游标我们可以让解析来的更轻量级，即通俗所说的利用会话缓存游标实现的软软解析(soft soft parse)。 7、Execute to Parse% 指标反映了执行解析比 其公式为 1-(parse/execute) , 目标为100% 及接近于只 执行而不解析。 数据来源v$sysstat statistics parse count (total) 和execute count 在oracle中解析往往是执行的先提工作，但是通过游标共享 可以解析一次 执行多次， 执行解析可能分成多种场景： - hard coding => 硬编码代码 硬解析一次 ，执行一次， 则理论上其执行解析比 为 1:1 ，则理论上Execute to Parse =0 极差，且soft parse比例也为0% - 绑定变量但是仍软解析=》 软解析一次，执行一次 ， 这种情况虽然比前一种好 但是执行解析比(这里的parse，包含了软解析和硬解析)仍是1:1， 理论上Execute to Parse =0 极差， 但是soft parse比例可能很高 - 使用 静态SQL、动态绑定、session_cached_cursor、open cursors等技术实现的 解析一次，执行多次， 执行解析比为N:1， 则 Execute to Parse= 1- (1/N) 执行次数越多 Execute to Parse越接近100% ，这种是我们在OLTP环境中喜闻乐见的！ 通俗地说 soft parse% 反映了软解析率， 而软解析在oracle中仍是较昂贵的操作， 我们希望的是解析1次执行N次，如果每次执行均需要软解析，那么虽然soft parse%=100% 但是parse time仍可能是消耗DB TIME的大头。 Execute to Parse反映了 执行解析比，Execute to Parse和soft parse% 都很低 那么说明确实没有绑定变量 ， 而如果 soft parse% 接近99% 而Execute to Parse 不足90% 则说明没有执行解析比低， 需要通过 静态SQL、动态绑定、session_cached_cursor、open cursors等技术减少软解析。 8、Latch Hit%: willing-to-wait latch闩申请不要等待的比例。 数据来源V$latch gets和misses ``` Latch Name ---------------------------------------- Get Requests Misses Sleeps Spin Gets Sleep1 Sleep2 Sleep3 -------------- ----------- ----------- ---------- -------- -------- -------- shared pool 9,988,637 364 23 341 0 0 0 library cache 6,753,468 152 6 146 0 0 0 Memory Management Latch 369 1 1 0 0 0 0 qmn task queue latch 24 1 1 0 0 0 0 ``` Latch Hit%:= (1 – (Sum(misses) / Sum(gets))) 关于Latch的更多信息内容可以参考 AWR后面的专栏Latch Statistics， 注意对于一个并发设计良好的OLTP应用来说，Latch、Enqueue等并发控制不应当成为系统的主要瓶颈， 同时对于这些并发争用而言 堆积硬件CPU和内存 很难有效改善性能。 SELECT SUM(GETS), SUM(MISSES) FROM DBA_HIST_LATCH WHERE SNAP_ID = :B3 AND DBID = :B2 AND INSTANCE_NUMBER = :B1 9、Parse CPU To Parse Elapsd:该指标反映了 快照内解析CPU时间和总的解析时间的比值(Parse CPU Time/ Parse Elapsed Time)； 若该指标水平很低，那么说明在整个解析过程中 实际在CPU上运算的时间是很短的，而主要的解析时间都耗费在各种其他非空闲的等待事件上了(如latch:shared pool,row cache lock之类等) 数据来源 V$sysstat 的 parse time cpu和parse time elapsed 10、%Non-Parse CPU 非解析cpu比例，公式为 (DB CPU – Parse CPU)/DB CPU， 若大多数CPU都用在解析上了，则可能好钢没用在刃上了。 数据来源 v$sysstat 的 parse time cpu和 cpu used by this session #### Shared Pool Statistics ``` Shared Pool Statistics Begin End ------ ------ Memory Usage %: 84.64 79.67 % SQL with executions>1: 93.77 24.69 % Memory for SQL w/exec>1: 85.36 34.8 ``` 该环节提供一个大致的SQL重用及shared pool内存使用的评估。 应用是否共享SQL? 有多少内存是给只运行一次的SQL占掉的，对比共享SQL呢？ 如果该环节中% SQL with executions>1的 比例 小于%90 ， 考虑用下面链接的SQL去抓 硬编码的非绑定变量SQL语句。 利用FORCE_MATCHING_SIGNATURE捕获非绑定变量SQL Memory Usage %: (shared pool 的实时大小- shared pool free memory)/ shared pool 的实时大小， 代表shared pool的空间使用率，虽然有使用率但没有标明碎片程度 % SQL with executions>1 复用的SQL占总的SQL语句的比率,数据来源 DBA_HIST_SQL_SUMMARY 的 SINGLE_USE_SQL和TOTAL_SQL：1 – SINGLE_USE_SQL / TOTAL_SQL % Memory for SQL w/exec>1 执行2次以上的SQL所占内存占总的SQL内存的比率，数据来源DBA_HIST_SQL_SUMMARY 的SINGLE_USE_SQL_MEM和TOTAL_SQL_MEM：1 – SINGLE_USE_SQL_MEM / TOTAL_SQL_MEM ==》上面2个指标也可以用来大致了解shared pool中的内存碎片程序，因为SINGLE_USE_SQL 单次执行的SQL多的话，那么显然可能有较多的共享池内存碎片 SQL复用率低的原因一般来说就是硬绑定变量(hard Coding)未合理使用绑定变量(bind variable)，对于这种现象短期无法修改代表使用绑定变量的可以ALTER SYSTEM SET CURSOR_SHARING=FORCE; 来绕过问题，对于长期来看还是要修改代码绑定变量。 Oracle 从11g开始宣称今后将废弃CURSOR_SHARING的SIMILAR选项，同时SIMILAR选项本身也造成了很多问题，所以一律不推荐用CURSOR_SHARING=SIMILAR。 如果memory usage%比率一直很高，则可以关注下后面sga breakdown中的shared pool free memory大小，一般推荐至少让free memroy有个300~500MB 以避免隐患。 #### Top 5 Timed Events ``` Top 5 Timed Events Avg %Total ~~~~~~~~~~~~~~~~~~ wait Call Event Waits Time (s) (ms) Time Wait Class ------------------------------ ------------ ----------- ------ ------ ---------- gc buffer busy 79,083 73,024 923 65.4 Cluster enq: TX - row lock contention 35,068 17,123 488 15.3 Applicatio CPU time 12,205 10.9 gc current request 2,714 3,315 1221 3.0 Cluster gc cr multi block request 83,666 1,008 12 0.9 Cluster ``` 基于Wait Interface的调优是目前的主流！每个指标都重要！ 基于命中比例的调优，好比是统计局的报告， 张财主家财产100万，李木匠家财产1万， 平均财产50.5万。 基于等待事件的调优，好比马路上100辆汽车的行驶记录表，上车用了几分钟， 红灯等了几分钟，拥堵塞了几分钟。。。 丰富的等待事件以足够的细节来描绘系统运行的性能瓶颈，这是Mysql梦寐以求的东西…… - Waits : 该等待事件发生的次数， 对于DB CPU此项不可用 - Times : 该等待事件消耗的总计时间，单位为秒， 对于DB CPU 而言是前台进程所消耗CPU时间片的总和，但不包括Wait on CPU QUEUE - Avg Wait(ms) : 该等待事件平均等待的时间， 实际就是 Times/Waits，单位ms， 对于DB CPU此项不可用 - % Total Call Time， 该等待事件占总的call time的比率 - total call time = total CPU time + total wait time for non-idle events - % Total Call Time = time for each timed event / total call time - Wait Class: 等待类型： - Concurrency - System I/O - User I/O - Administrative - Other - Configuration - Scheduler - Cluster - Application - Idle - Network - Commit CPU 上在干什么？ 逻辑读？ 解析？Latch spin? PL/SQL、函数运算? DB CPU/CPU time是Top 1 是好事情吗？ 未必！ 注意DB CPU不包含 wait on cpu queue！ ``` SELECT e.event_name event, e.total_waits - NVL (b.total_waits, 0) waits, DECODE ( e.total_waits - NVL (b.total_waits, 0), 0, TO_NUMBER (NULL), DECODE ( e.total_timeouts - NVL (b.total_timeouts, 0), 0, TO_NUMBER (NULL), 100 * (e.total_timeouts - NVL (b.total_timeouts, 0)) / (e.total_waits - NVL (b.total_waits, 0)))) pctto, (e.time_waited_micro - NVL (b.time_waited_micro, 0)) / 1000000 time, DECODE ( (e.total_waits - NVL (b.total_waits, 0)), 0, TO_NUMBER (NULL), ( (e.time_waited_micro - NVL (b.time_waited_micro, 0)) / 1000) / (e.total_waits - NVL (b.total_waits, 0))) avgwt, DECODE (e.wait_class, 'Idle', 99, 0) idle FROM dba_hist_system_event b, dba_hist_system_event e WHERE b.snap_id(+) = &bid AND e.snap_id = &eid --AND b.dbid(+) = :dbid --AND e.dbid = :dbid AND b.instance_number(+) = 1 AND e.instance_number = 1 AND b.event_id(+) = e.event_id AND e.total_waits > NVL (b.total_waits, 0) AND e.event_name NOT IN ('smon timer', 'pmon timer', 'dispatcher timer', 'dispatcher listen timer', 'rdbms ipc message') ORDER BY idle, time DESC, waits DESC, event ``` ### 几种常见的等待事件 =========================> db file scattered read, Avg wait time应当小于20ms 如果数据库执行全表扫描或者是全索引扫描会执行 Multi block I/O ，此时等待物理I/O 结束会出现此等待事件。一般会从应用程序（SQL），I/O 方面入手调整; 注意和《Instance Activity Stats》中的index fast full scans (full) 以及 table scans (long tables)集合起来一起看。 db file sequential read ，该等待事件Avg wait time平均单次等待时间应当小于20ms \"db file sequential read\"单块读等待是一种最为常见的物理IO等待事件，这里的sequential指的是将数据块读入到相连的内存空间中(contiguous memory space)，而不是指所读取的数据块是连续的。该wait event可能在以下情景中发生: http://www.askmaclean.com/archives/db-file-sequential-read-wait-event.html latch free　　其实是未获得latch ，而进入latch sleep，见《全面解析9i以后Oracle Latch闩锁原理》 enq:XX 队列锁等待，视乎不同的队列锁有不同的情况： 你有多了解Oracle Enqueue lock队列锁机制？ - Oracle队列锁: Enqueue HW - Oracle队列锁enq:US,Undo Segment - enq: TX – row lock/index contention、allocate ITL等待事件 - enq: TT – contention等待事件 - Oracle队列锁enq:TS,Temporary Segment (also TableSpace) - enq: JI – contention等待事件 - enq: US – contention等待事件 - enq: TM – contention等待事件 - enq: RO fast object reuse等待事件 - enq: HW – contention等待事件 free buffer waits：是由于无法找到可用的buffer cache 空闲区域，需要等待DBWR 写入完成引起 一般是由于 - 低效的sql - 过小的buffer cache - DBWR 工作负荷过量 buffer busy wait/ read by other session 一般以上2个等待事件可以归为一起处理，建议客户都进行监控 。 以上等待时间可以由如下操作引起 - select/select —- read by other session: 由于需要从 数据文件中将数据块读入 buffer cache 中引起，有可能是 大量的 逻辑/物理读 ;或者过小的 buffer cache 引起 - select/update —- buffer busy waits/ read by other session 是由于更新某数据块后 需要在undo 中 重建构建 过去时间的块，有可能伴生 enq:cr-contention 是由于大量的物理读/逻辑读造成。 - update/update —- buffer busy waits 由于更新同一个数据块（非同一行，同一行是enq:TX-contention） 此类问题是热点块造成 - insert/insert —- buffer busy waits 是由于freelist 争用造成，可以将表空间更改为ASSM 管理 或者加大freelist 。 write complete waits :一般此类等待事件是由于 DBWR 将脏数据写入 数据文件，其他进程如果需要修改 buffer cache会引起此等待事件，一般是 I/O 性能问题或者是DBWR 工作负荷过量引起 Wait time 1 Seconds. control file parallel write：频繁的更新控制文件会造成大量此类等待事件，如日志频繁切换，检查点经常发生，nologging 引起频繁的数据文件更改，I/O 系统性能缓慢。 log file sync：一般此类等待时间是由于 LGWR 进程讲redo log buffer 写入redo log 中发生。如果此类事件频繁发生，可以判断为： - commit 次数是否过多 - I/O 系统问题 - 重做日志是否不必要被创建 - redo log buffer 是否过大 #### Time Model Statistics ``` Time Model Statistics DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> Total time in database user-calls (DB Time): 883542.2s -> Statistics including the word \"background\" measure background process time, and so do not contribute to the DB time statistic -> Ordered by % or DB time desc, Statistic name Statistic Name Time (s) % of DB Time ------------------------------------------ ------------------ ------------ sql execute elapsed time 805,159.7 91.1 sequence load elapsed time 41,159.2 4.7 DB CPU 20,649.1 2.3 parse time elapsed 1,112.8 .1 hard parse elapsed time 995.2 .1 hard parse (sharing criteria) elapsed time 237.3 .0 hard parse (bind mismatch) elapsed time 227.6 .0 connection management call elapsed time 29.7 .0 PL/SQL execution elapsed time 9.2 .0 PL/SQL compilation elapsed time 6.6 .0 failed parse elapsed time 2.0 .0 repeated bind elapsed time 0.4 .0 DB time 883,542.2 background elapsed time 25,439.0 background cpu time 1,980.9 ------------------------------------------------------------- ``` Time Model Statistics几个特别有用的时间指标： - parse time elapsed、hard parse elapsed time 结合起来看解析是否是主要矛盾，若是则重点是软解析还是硬解析 - sequence load elapsed time sequence序列争用是否是问题焦点 - PL/SQL compilation elapsed time PL/SQL对象编译的耗时 - 注意PL/SQL execution elapsed time 纯耗费在PL/SQL解释器上的时间。不包括花在执行和解析其包含SQL上的时间 - connection management call elapsed time 建立数据库session连接和断开的耗时 - failed parse elapsed time 解析失败，例如由于ORA-4031 - hard parse (sharing criteria) elapsed time 由于无法共享游标造成的硬解析 - hard parse (bind mismatch) elapsed time 由于bind type or bind size 不一致造成的硬解析 注意该时间模型中的指标存在包含关系所以Time Model Statistics加起来超过100%再正常不过 ``` 1) background elapsed time 2) background cpu time 3) RMAN cpu time (backup/restore) 1) DB time 2) DB CPU 2) connection management call elapsed time 2) sequence load elapsed time 2) sql execute elapsed time 2) parse time elapsed 3) hard parse elapsed time 4) hard parse (sharing criteria) elapsed time 5) hard parse (bind mismatch) elapsed time 3) failed parse elapsed time 4) failed parse (out of shared memory) elapsed time 2) PL/SQL execution elapsed time 2) inbound PL/SQL rpc elapsed time 2) PL/SQL compilation elapsed time 2) Java execution elapsed time 2) repeated bind elapsed time ``` #### Foreground Wait Class ``` Foreground Wait Class -> s - second, ms - millisecond - 1000th of a second -> ordered by wait time desc, waits desc -> %Timeouts: value of 0 indicates value was Captured Time accounts for 102.7% of Total DB time 883,542.21 (s) -> Total FG Wait Time: 886,957.73 (s) DB CPU time: 20,649.06 (s) Avg %Time Total Wait wait Wait Class Waits -outs Time (s) (ms) %DB time -------------------- ---------------- ----- ---------------- -------- --------- Cluster 9,825,884 1 525,134 53 59.4 Concurrency 688,375 0 113,782 165 12.9 User I/O 34,405,042 0 76,695 2 8.7 Commit 172,193 0 62,776 365 7.1 Application 11,422 0 57,760 5057 6.5 Configuration 19,418 1 48,889 2518 5.5 DB CPU 20,649 2.3 Other 1,757,896 94 924 1 0.1 System I/O 30,165 0 598 20 0.1 Network 171,955,673 0 400 0 0.0 Administrative 2 100 0 101 0.0 ------------------------------------------------------------- select distinct wait_class from v$event_name; WAIT_CLASS ---------------------------------------------------------------- Concurrency User I/O System I/O Administrative Other Configuration Scheduler Cluster Application Queueing Idle Network Commit ``` - Wait Class: 等待事件的类型，如上查询所示，被分作12个类型。 10.2.0.5有916个等待事件，其中Other类型占622个。 - Waits: 该类型所属等待事件在快照时间内的等待次数 - %Time Out 等待超时的比率， 未 超时次数/waits * 100 (%) - Total Wait Time: 该类型所属等待事件总的耗时，单位为秒 - Avg Wait(ms) : 该类型所属等待事件的平均单次等待时间，单位为ms ，实际这个指标对commit 和 user i/o 以及system i/o类型有点意义，其他等待类型由于等待事件差异较大所以看平均值的意义较小 - waits / txn: 该类型所属等待事件的等待次数和事务比 Other 类型，遇到该类型等待事件 的话 常见的原因是Oracle Bug或者 网络、I/O存在问题， 一般推荐联系Maclean。 Concurrency 类型 并行争用类型的等待事件， 典型的如 latch: shared pool、latch: library cache、row cache lock、library cache pin/lock Cluster 类型 为Real Application Cluster RAC环境中的等待事件， 需要注意的是 如果启用了RAC option，那么即使你的集群中只启动了一个实例，那么该实例也可能遇到 Cluster类型的等待事件, 例如gc buffer busy System I/O 主要是后台进程维护数据库所产生的I/O，例如control file parallel write 、log file parallel write、db file parallel write。 User I/O 主要是前台进程做了一些I/O操作，并不是说后台进程不会有这些等待事件。 典型的如db file sequential/scattered read、direct path read Configuration 由于配置引起的等待事件， 例如 日志切换的log file switch completion (日志文件 大小/数目 不够)，sequence的enq: SQ – contention (Sequence 使用nocache) ； Oracle认为它们是由于配置不当引起的，但实际未必真是这样的配置引起的。 Application 应用造成的等待事件， 例如enq: TM – contention和enq: TX – row lock contention； Oracle认为这是由于应用设计不当造成的等待事件， 但实际这些Application class 等待可能受到 Concurrency、Cluster、System I/O 、User I/O等多种类型等待的影响，例如本来commit只要1ms ，则某一行数据仅被锁定1ms， 但由于commit变慢 从而释放行锁变慢，引发大量的enq: TX – row lock contention等待事件。 Commit 仅log file sync ，log file sync的影响十分广泛，值得我们深入讨论。 Network : 网络类型的等待事件 例如 SQL*Net more data to client 、SQL*Net more data to dblink Idle 空闲等待事件 ，最为常见的是rdbms ipc message (等待实例内部的ipc通信才干活，即别人告知我有活干，我才干，否则我休息==》Idle)， SQL\\*Net message from client(等待SQL\\*NET传来信息，否则目前没事干) #### 前台等待事件 ``` Foreground Wait Events Snaps: 70719-70723 -> s - second, ms - millisecond - 1000th of a second -> Only events with Total Wait Time (s) >= .001 are shown -> ordered by wait time desc, waits desc (idle events last) -> %Timeouts: value of 0 indicates value was ordered by wait time desc, waits desc (idle events last) -> Only events with Total Wait Time (s) >= .001 are shown -> %Timeouts: value of 0 indicates value was ordered by statistic type (CPU Use, Virtual Memory, Hardware Config), Name Statistic Value End Value ------------------------- ---------------------- ---------------- BUSY_TIME 2,894,855 IDLE_TIME 5,568,240 IOWAIT_TIME 18,973 SYS_TIME 602,532 USER_TIME 2,090,082 LOAD 8 13 VM_IN_BYTES 0 VM_OUT_BYTES 0 PHYSICAL_MEMORY_BYTES 101,221,343,232 NUM_CPUS 24 NUM_CPU_CORES 12 NUM_CPU_SOCKETS 2 GLOBAL_RECEIVE_SIZE_MAX 4,194,304 GLOBAL_SEND_SIZE_MAX 2,097,152 TCP_RECEIVE_SIZE_DEFAULT 87,380 TCP_RECEIVE_SIZE_MAX 4,194,304 TCP_RECEIVE_SIZE_MIN 4,096 TCP_SEND_SIZE_DEFAULT 16,384 TCP_SEND_SIZE_MAX 4,194,304 TCP_SEND_SIZE_MIN 4,096 ------------------------------------------------------------- ``` Operating System Statistics 操作系统统计信息 数据来源于V$OSSTAT / DBA_HIST_OSSTAT，, TIME相关的指标单位均为百分之一秒 统计项 描述 NUM_CPU_SOCKETS 物理CPU的数目 NUM_CPU_CORES CPU的核数 NUM_CPUS 逻辑CPU的数目 SYS_TIME 在内核态被消耗掉的CPU时间片，单位为百分之一秒 USER_TIME 在用户态被消耗掉的CPU时间片，单位为百分之一秒 BUSY_TIME Busy_Time=SYS_TIME+USER_TIME 消耗的CPU时间片，单位为百分之一秒 AVG_BUSY_TIME AVG_BUSY_TIME= BUSY_TIME/NUM_CPUS IDLE_TIME 空闲的CPU时间片，单位为百分之一秒 所有CPU所能提供总的时间片 BUSY_TIME + IDLE_TIME = ELAPSED_TIME * CPU_COUNT OS_CPU_WAIT_TIME 进程等OS调度的时间，cpu queuing VM_IN_BYTES 换入页的字节数 VM_OUT_BYTES 换出页的字节数，部分版本下并不准确，例如Bug 11712010 Abstract: VIRTUAL MEMORY PAGING ON 11.2.0.2 DATABASES，仅供参考 IOWAIT_TIME 所有CPU花费在等待I/O完成上的时间  单位为百分之一秒 RSRC_MGR_CPU_WAIT_TIME 是指当resource manager控制CPU调度时，需要控制对应进程暂时不使用CPU而进程到内部运行队列中，以保证该进程对应的consumer group(消费组)没有消耗比指定resource manager指令更多的CPU。RSRC_MGR_CPU_WAIT_TIME指等在内部运行队列上的时间，在等待时不消耗CPU Service Statistcs Service Statistics Snaps: 70719-70723 -> ordered by DB Time Physical Logical Service Name DB Time (s) DB CPU (s) Reads (K) Reads (K) ---------------------------- ------------ ------------ ------------ ------------ itms-contentmasterdb-prod 897,099 20,618 35,668 1,958,580 SYS$USERS 4,312 189 5,957 13,333 itmscmp 1,941 121 14,949 18,187 itscmp 331 20 114 218 itscmp_dgmgrl 121 1 0 0 SYS$BACKGROUND 0 0 142 30,022 ITSCMP1_PR 0 0 0 0 its-reference-prod 0 0 0 0 itscmpXDB 0 0 0 0 按照Service Name来分组时间模型和 物理、逻辑读取， 部分数据来源于 WRH$_SERVICE_NAME; Service Name 对应的服务名 (v$services)， SYS$BACKGROUND代表后台进程， SYS$USERS一般是系统用户登录 DB TIME (s): 本服务名所消耗的DB TIME时间，单位为秒 DB CPU(s): 本服务名所消耗的DB CPU 时间，单位为秒 Physical Reads : 本服务名所消耗的物理读 Logical Reads : 本服务所消耗的逻辑读 Service Wait Class Stats Service Wait Class Stats Snaps: 70719-70723 -> Wait Class info for services in the Service Statistics section. -> Total Waits and Time Waited displayed for the following wait classes: User I/O, Concurrency, Administrative, Network -> Time Waited (Wt Time) in seconds Service Name ---------------------------------------------------------------- User I/O User I/O Concurcy Concurcy Admin Admin Network Network Total Wts Wt Time Total Wts Wt Time Total Wts Wt Time Total Wts Wt Time --------- --------- --------- --------- --------- --------- --------- --------- itms-contentmasterdb-prod 33321670 71443 678373 113759 0 0 1.718E+08 127 SYS$USERS 173233 3656 6738 30 2 0 72674 3 itmscmp 676773 1319 1831 0 0 0 2216 0 itscmp 219577 236 1093 0 0 0 18112 0 itscmp_dgmgrl 34 0 8 0 0 0 9 0 SYS$BACKGROUND 71940 1300 320677 56 0 0 442252 872 ------------------------------------------------------------- User I/O Total Wts : 对应该服务名下 用户I/O类等待的总的次数 User I/O Wt Time : 对应该服务名下 用户I/O累等待的总时间，单位为 1/100秒 Concurcy Total Wts: 对应该服务名下 Concurrency 类型等待的总次数 Concurcy Wt Time :对应该服务名下 Concurrency 类型等待的总时间， 单位为 1/100秒 Admin Total Wts: 对应该服务名下Admin 类等待的总次数 Admin Wt Time: 对应该服务名下Admin类等待的总时间，单位为 1/100秒 Network Total Wts : 对应服务名下Network类等待的总次数 Network Wt Time： 对应服务名下Network类等待的总事件， 单位为 1/100秒 Host CPU Host CPU (CPUs: 24 Cores: 12 Sockets: 2) ~~~~~~~~ Load Average Begin End %User %System %WIO %Idle --------- --------- --------- --------- --------- --------- 8.41 12.84 24.7 7.1 0.2 65.8 \"Load Average\" begin/end值代表每个CPU的大致运行队列大小。上例中快照开始到结束，平均 CPU负载增加了；与《2-5 Operating System Statistics》中的LOAD相呼应。 %User+%System=> 总的CPU使用率，在这里是31.8% Elapsed Time NUM_CPUS CPU utilization= 60.23 (mins) 24 31.8% = 459.67536 mins=Busy Time Instance CPU Instance CPU ~~~~~~~~~~~~ % of total CPU for Instance: 26.7 % of busy CPU for Instance: 78.2 %DB time waiting for CPU - Resource Mgr: 0.0 %Total CPU,该实例所使用的CPU占总CPU的比例 % of total CPU for Instance %Busy CPU，该实例所使用的Cpu占总的被使用CPU的比例 % of busy CPU for Instance 例如共4个逻辑CPU，其中3个被完全使用，3个中的1个完全被该实例使用，则%Total CPU= ¼ =25%，而%Busy CPU= 1/3= 33% 当CPU高时一般看%Busy CPU可以确定CPU到底是否是本实例消耗的，还是主机上其他程序 % of busy CPU for Instance= （DB CPU+ background cpu time) / (BUSY_TIME /100)= (20,649.1 + 1,980.9)/ (2,894,855 /100)= 78.17% % of Total CPU for Instance = ( DB CPU+ background cpu time)/( BUSY_TIME+IDLE_TIME/100) = (20,649.1 + 1,980.9)/ ((2,894,855+5,568,240) /100) = 26.73% %DB time waiting for CPU (Resource Manager)= (RSRC_MGR_CPU_WAIT_TIME/100)/DB TIME TOP SQL TOP SQL 的数据部分来源于 dba_hist_sqlstat SQL ordered by Elapsed Time ，按照SQL消耗的时间来排列TOP SQL SQL ordered by Elapsed Time Snaps: 70719-70723 -> Resources reported for PL/SQL code includes the resources used by all SQL statements called by the code. -> % Total DB Time is the Elapsed Time of the SQL statement divided into the Total Database Time multiplied by 100 -> %Total - Elapsed Time as a percentage of Total DB time -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Captured SQL account for 53.9% of Total DB Time (s): 883,542 -> Captured PL/SQL account for 0.5% of Total DB Time (s): 883,542 Elapsed Elapsed Time Time (s) Executions per Exec (s) %Total %CPU %IO SQL Id ---------------- -------------- ------------- ------ ------ ------ ------------- 181,411.3 38,848 4.67 20.5 .0 .1 g0yc9szpuu068 注意对于PL/SQL，SQL Statistics不仅会体现该PL/SQL的执行情况，还会包括该PL/SQL包含的SQL语句的情况。如上例一个TOP PL/SQL执行了448s，而这448s中绝大多数是这个PL/SQL下的一个SQL执行500次耗费的。 则该TOP PL/SQL和TOP SQL都上榜，一个执行一次耗时448s，一个执行500次耗时448s。 如此情况则Elapsed Time加起来可能超过100%的Elapsed Time，这是正常的。 对于鹤立鸡群的SQL很有必要一探究竟，跑个@?/rdbms/admin/awrsqrpt看看吧！ Elapsed Time (s): 该SQL累计运行所消耗的时间， Executions : 该SQL在快照时间内 总计运行的次数 ； 注意， 对于在快照时间内还没有执行完的SQL 不计为1一次，所以如果看到executions=0而 又是TOP SQL，则很有可能是因为该SQL 运行较旧还没执行完，需要特别关注一下。 Elapsed Time per Exec (s)：平均每次执行该SQL耗费的时间 ， 对于OLTP类型的SELECT/INSERT/UPDATE/DELETE而言平均单次执行时间应当非常短，如0.1秒 或者更短才能满足其业务需求，如果这类轻微的OLTP操作单次也要几秒钟的话，是无法满足对外业务的需求的； 例如你在ATM上提款，并不仅仅是对你的账务库的简单UPDATE，而需要在类似风险控制的前置系统中记录你本次的流水操作记录，实际取一次钱可能要有几十乃至上百个OLTP类型的语句被执行，但它们应当都是十分快速的操作； 如果这些操作也变得很慢，则会出现大量事务阻塞，系统负载升高，DB TIME急剧上升的现象。 对于OLTP数据库而言 如果执行计划稳定，那么这些OLTP操作的性能应当是铁板钉钉的，但是一旦某个因素 发生变化，例如存储的明显变慢、内存换页的大量出现时 则上述的这些transaction操作很可能成数倍到几十倍的变慢，这将让此事务系统短期内不可用。 对于维护操作，例如加载或清除数据，大的跑批次、报表而言 Elapsed Time per Exec (s)高一些是正常的。 %Total 该SQL所消耗的时间占总的DB Time的百分比， 即 (SQL Elapsed Time / Total DB TIME) % CPU 该SQL 所消耗的CPU 时间 占 该SQL消耗的时间里的比例， 即 (SQL CPU Time / SQL Elapsed Time) ，该指标说明了该语句是否是CPU敏感的 %IO 该SQL 所消耗的I/O 时间 占 该SQL消耗的时间里的比例， 即(SQL I/O Time/SQL Elapsed Time) ，该指标说明了该语句是否是I/O敏感的 SQL Id : 通过计算SQL 文本获得的SQL_ID ，不同的SQL文本必然有不同的SQL_ID， 对于10g~11g而言 只要SQL文本不变那么在数据库之间 该SQL 对应的SQL_ID应当不不变的， 12c中修改了SQL_ID的计算方法 Captured SQL account for 53.9% of Total DB Time (s) 对于不绑定变量的应用来说Top SQL有可能失准，所以要参考本项 SQL ordered by CPU Time SQL ordered by CPU Time Snaps: 70719-70723 -> Resources reported for PL/SQL code includes the resources used by all SQL statements called by the code. -> %Total - CPU Time as a percentage of Total DB CPU -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Captured SQL account for 34.9% of Total CPU Time (s): 20,649 -> Captured PL/SQL account for 0.5% of Total CPU Time (s): 20,649 CPU CPU per Elapsed Time (s) Executions Exec (s) %Total Time (s) %CPU %IO SQL Id ---------- ------------ ---------- ------ ---------- ------ ------ ------------- 1,545.0 1,864,424 0.00 7.5 4,687.8 33.0 65.7 8g6a701j83c8q Module: MZIndexer SELECT t0.BOOLEAN_VALUE, t0.CLASS_CODE, t0.CREATED, t0.END_DATE, t0.PRODUCT_ATTR IBUTE_ID, t0.LAST_MODIFIED, t0.OVERRIDE_FLAG, t0.PRICE, t0.PRODUCT_ATTRIBUTE_TYP E_ID, t0.PRODUCT_ID, t0.PRODUCT_PUB_RELEASE_TYPE_ID, t0.PRODUCT_VOD_TYPE_ID, t0. SAP_PRODUCT_ID, t0.START_DATE, t0.STRING_VALUE FROM mz_product_attribute t0 WHER CPU TIME : 该SQL 在快照时间内累计执行所消耗的CPU 时间片，单位为s Executions : 该SQL在快照时间内累计执行的次数 CPU per Exec (s) ：该SQL 平均单次执行所消耗的CPU时间 ， 即 ( SQL CPU TIME / SQL Executions ) %Total : 该SQL 累计消耗的CPU时间 占 该时段总的 DB CPU的比例， 即 ( SQL CPU TIME / Total DB CPU) % CPU 该SQL 所消耗的CPU 时间 占 该SQL消耗的时间里的比例， 即 (SQL CPU Time / SQL Elapsed Time) ，该指标说明了该语句是否是CPU敏感的 %IO 该SQL 所消耗的I/O 时间 占 该SQL消耗的时间里的比例， 即(SQL I/O Time/SQL Elapsed Time) ，该指标说明了该语句是否是I/O敏感的 Buffer Gets SQL ordered by Gets SQL ordered by Gets DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> Resources reported for PL/SQL code includes the resources used by all SQL statements called by the code. -> %Total - Buffer Gets as a percentage of Total Buffer Gets -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Total Buffer Gets: 2,021,476,421 -> Captured SQL account for 68.2% of Total Buffer Gets Elapsed Gets Executions per Exec %Total Time (s) %CPU %IO SQL Id ----------- ----------- ------------ ------ ---------- ------ ------ ----------- 4.61155E+08 1,864,424 247.3 22.8 4,687.8 33.0 65.7 8g6a701j83c 注意 buffer gets 逻辑读是消耗CPU TIME的重要源泉， 但并不是说消耗CPU TIME的只有buffer gets。 大多数情况下 SQL order by CPU TIME 和 SQL order by buffers gets 2个部分的TOP SQL 及其排列顺序都是一样的，此种情况说明消耗最多buffer gets的 就是消耗最多CPU 的SQL ，如果我们希望降低系统的CPU使用率，那么只需要调优SQL 降低buffer gets 即可。 但也并不是100%的情况都是如此， CPU TIME的消耗者 还包括 函数运算、PL/SQL 控制、Latch /Mutex 的Spin等等， 所以SQL order by CPU TIME 和 SQL order by buffers gets 2个部分的TOP SQL 完全不一样也是有可能的， 需要因地制宜来探究到底是什么问题导致的High CPU，进而裁度解决之道。 Buffer Gets : 该SQL在快照时间内累计运行所消耗的buffer gets，包括了consistent read 和 current read Executions : 该SQL在快照时间内累计执行的次数 Gets per Exec : 该SQL平均单次的buffer gets ， 对于事务型transaction操作而言 一般该单次buffer gets小于2000 % Total 该SQL 累计运行所消耗的buffer gets占 总的db buffer gets的比率， (SQL buffer gets / DB total buffer gets) Physical Reads SQL ordered by Reads SQL ordered by Reads DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> %Total - Physical Reads as a percentage of Total Disk Reads -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Total Disk Reads: 56,839,035 -> Captured SQL account for 34.0% of Total Physical Reads Elapsed Reads Executions per Exec %Total Time (s) %CPU %IO SQL Id ----------- ----------- ---------- ------ ---------- ------ ------ ------------- 9,006,163 1 9.0062E+06 15.8 720.9 5.9 80.9 4g36tmp70h185 Physical reads : 该SQL累计运行所消耗的物理读 Executions : 该SQL在快照时间内累计执行的次数 Reads per Exec : 该SQL 单次运行所消耗的物理读， (SQL Physical reads/Executions) ， 对于OLTP transaction 类型的操作而言单次一般不超过100 %Total : 该SQL 累计消耗的物理读 占 该时段总的 物理读的比例， 即 ( SQL physical read / Total DB physical read ) Executions SQL ordered by Executions SQL ordered by Executions Snaps: 70719-70723 -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Total Executions: 48,078,147 -> Captured SQL account for 50.4% of Total Elapsed Executions Rows Processed Rows per Exec Time (s) %CPU %IO SQL Id ------------ --------------- -------------- ---------- ------ ------ ----------- 6,327,963 11,249,645 1.8 590.5 47.8 52.7 1avv7759j8r 按照 执行次数来排序的话，也是性能报告对比时一个重要的参考因素，因为如果TOP SQL的执行次数有明显的增长，那么 性能问题的出现也是意料之中的事情了。 当然执行次数最多的，未必便是对性能影响最大的TOP SQL Executions : 该SQL在快照时间内累计执行的次数 Rows Processed： 该SQL在快照时间内累计执行所处理的总行数 Rows per Exec：　SQL平均单次执行所处理的行数， 这个指标在诊断一些 数据问题造成的SQL性能问题时很有用 Parse Calls SQL ordered by Parse Calls SQL ordered by Parse Calls Snaps: 70719-70723 -> Total Parse Calls: 2,160,124 -> Captured SQL account for 58.3% of Total % Total Parse Calls Executions Parses SQL Id ------------ ------------ --------- ------------- 496,475 577,357 22.98 d07gaa3wntdff Parse Calls : 解析调用次数， 与上文的 Load Profile中的Parse 数一样 包括 软解析soft parse和硬解析hard parse Executions : 该SQL在快照时间内累计执行的次数 %Total Parses : 本SQL 解析调用次数 占 该时段数据库总解析次数的比率， 为 (SQL Parse Calls / Total DB Parse Calls) SQL ordered by Sharable Memory SQL ordered by Sharable Memory Snaps: 70719-70723 -> Only Statements with Sharable Memory greater than 1048576 are displayed Sharable Mem (b) Executions % Total SQL Id ---------------- ------------ -------- ------------- 8,468,359 39 0.08 au89sasqfb2yn Module: MZContentBridge SELECT t0.ASPECT_RATIO, t0.CREATED, t0.FILE_EXTENSION, t0.HEIGHT, t0.VIDEO_FILE_ DIMENSIONS_ID, t0.LAST_MODIFIED, t0.NAME, t0.WIDTH FROM MZ_VIDEO_FILE_DIMENSIONS t0 WHERE (t0.HEIGHT = :1 AND t0.WIDTH = :2 ) SQL ordered by Sharable Memory , 一般该部分仅列出Sharable Mem (b)为1 MB以上的SQL 对象 (Only Statements with Sharable Memory greater than 1048576 are displayed) 数据来源是 DBA_HIST_SQLSTAT.SHARABLE_MEM Shareable Mem(b): SQL 对象所占用的共享内存使用量 Executions : 该SQL在快照时间内累计执行的次数 %Total : 该SQL 对象锁占共享内存 占总的共享内存的比率 SQL ordered by Version Count Version Count Oracle中的执行计划可以是多版本的，即对于同一个SQL语句有多个不同版本的执行计划，这些执行计划又称作子游标， 而一个SQL语句的文本可以称作一个父游标。 一个父游标对应多个子游标，产生不同子游标的原因是 SQL在被执行时无法共享之前已经生成的子游标， 原因是多种多样的，例如 在本session中做了一个优化器参数的修改 例如optimizer_index_cost_adj 从100 修改到99，则本session的优化环境optimizer env将不同于之前的子游标生成环境，这样就需要生成一个新的子游标，例如： SQL> create table emp as select * from scott.emp; Table created. SQL> select * from emp where empno=1; no rows selected SQL> select /*+ MACLEAN */ * from emp where empno=1; no rows selected SQL> select SQL_ID,version_count from V$SQLAREA WHERE SQL_TEXT like '%MACLEAN%' and SQL_TEXT not like '%like%'; SQL_ID VERSION_COUNT ------------- ------------- bxnnm7z1qmg26 1 SQL> select count(*) from v$SQL where SQL_ID='bxnnm7z1qmg26'; COUNT(*) ---------- 1 SQL> alter session set optimizer_index_cost_adj=99; Session altered. SQL> select /*+ MACLEAN */ * from emp where empno=1; no rows selected SQL> select SQL_ID,version_count from V$SQLAREA WHERE SQL_TEXT like '%MACLEAN%' and SQL_TEXT not like '%like%'; SQL_ID VERSION_COUNT ------------- ------------- bxnnm7z1qmg26 2 SQL> select count(*) from v$SQL where SQL_ID='bxnnm7z1qmg26'; COUNT(*) ---------- 2 SQL> select child_number ,OPTIMIZER_ENV_HASH_VALUE,PLAN_HASH_VALUE from v$SQL where SQL_ID='bxnnm7z1qmg26'; CHILD_NUMBER OPTIMIZER_ENV_HASH_VALUE PLAN_HASH_VALUE ------------ ------------------------ --------------- 0 3704128740 3956160932 1 3636478958 3956160932 可以看到上述 演示中修改optimizer_index_cost_adj=99 导致CBO 优化器的优化环境发生变化， 表现为不同的OPTIMIZER_ENV_HASH_VALUE，之后生成了2个子游标，但是这2个子游标的PLAN_HASH_VALUE同为3956160932，则说明了虽然是不同的子游标但实际子游标里包含了的执行计划是一样的； 所以请注意 任何一个优化环境的变化 (V$SQL_SHARED_CURSOR)以及相关衍生的BUG 都可能导致子游标无法共享，虽然子游标无法共享但这些子游标扔可能包含完全一样的执行计划，这往往是一种浪费。 注意V$SQLAREA.VERSION_COUNT 未必等于select count(*) FROM V$SQL WHERE SQL_ID=” ，即 V$SQLAREA.VERSION_COUNT 显示的子游标数目 未必等于当前实例中还存有的子游标数目， 由于shared pool aged out算法和其他一些可能导致游标失效的原因存在，所以子游标被清理掉是很常见的事情。 V$SQLAREA.VERSION_COUNT只是一个计数器，它告诉我们曾经生成了多少个child cursor，但不保证这些child 都还在shared pool里面。 此外可以通过v$SQL的child_number字段来分析该问题，如果child_number存在跳号则也说明了部分child被清理了。 子游标过多的影响， 当子游标过多(例如超过3000个时),进程需要去扫描长长的子游标列表child cursor list以找到一个合适的子游标child cursor，进而导致cursor sharing 性能问题 现大量的Cursor: Mutex S 和 library cache lock等待事件。 关于子游标的数量控制，可以参考《11gR2游标共享新特性带来的一些问题以及_cursor_features_enabled、_cursor_obsolete_threshold和106001 event》。 Executions : 该SQL在快照时间内累计执行的次数 Hash Value : 共享SQL 的哈希值 Only Statements with Version Count greater than 20 are displayed 注意该环节仅列出version count > 20的语句 Cluster Wait Time SQL ordered by Cluster Wait Time SQL ordered by Cluster Wait Time DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> %Total - Cluster Time as a percentage of Total Cluster Wait Time -> %Clu - Cluster Time as a percentage of Elapsed Time -> %CPU - CPU Time as a percentage of Elapsed Time -> %IO - User I/O Time as a percentage of Elapsed Time -> Only SQL with Cluster Wait Time > .005 seconds is reported -> Total Cluster Wait Time (s): 525,480 -> Captured SQL account for 57.2% of Total Cluster Elapsed Wait Time (s) Executions %Total Time(s) %Clu %CPU %IO SQL Id -------------- ------------ ------ ---------- ------ ------ ------ ------------- 132,639.3 38,848 25.2 181,411.3 73.1 .0 .1 g0yc9szpuu068 Only SQL with Cluster Wait Time > .005 seconds is reported 这个环节仅仅列出Cluster Wait Time > 0.005 s的SQL 该环节的数据主要来源 于 DBA_HIST_SQLSTAT.CLWAIT_DELTA Delta value of cluster wait time Cluster Wait Time : 该SQL语句累计执行过程中等待在集群等待上的时间，单位为秒， 你可以理解为 当一个SQL 执行过程中遇到了gc buffer busy、gc cr multi block request 之类的Cluster等待，则这些等待消耗的时间全部算在 Cluster Wait Time里。 Executions : 该SQL在快照时间内累计执行的次数 %Total: 该SQL所消耗的Cluster Wait time 占 总的Cluster Wait time的比率， 为(SQL cluster wait time / DB total cluster Wait Time) %Clu: 该SQL所消耗的Cluster Wait time 占该SQL 总的耗时的比率，为(SQL cluster wait time / SQL elapsed Time),该指标说明了该语句是否是集群等待敏感的 % CPU 该SQL 所消耗的CPU 时间 占 该SQL消耗的时间里的比例， 即 (SQL CPU Time / SQL Elapsed Time) ，该指标说明了该语句是否是CPU敏感的 %IO 该SQL 所消耗的I/O 时间 占 该SQL消耗的时间里的比例， 即(SQL I/O Time/SQL Elapsed Time) ，该指标说明了该语句是否是I/O敏感的 Instance Activity Stats Instance Activity Stats DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> Ordered by statistic name Statistic Total per Second per Trans -------------------------------- ------------------ -------------- ------------- Batched IO (bound) vector count 450,449 124.6 1.8 Batched IO (full) vector count 5,485 1.5 0.0 Batched IO (space) vector count 1,467 0.4 0.0 Batched IO block miss count 4,119,070 1,139.7 16.7 Batched IO buffer defrag count 39,710 11.0 0.2 Batched IO double miss count 297,357 82.3 1.2 Batched IO same unit count 1,710,492 473.3 7.0 Batched IO single block count 329,521 91.2 1.3 Batched IO slow jump count 47,104 13.0 0.2 Batched IO vector block count 2,069,852 572.7 8.4 Batched IO vector read count 262,161 72.5 1.1 Block Cleanout Optim referenced 37,574 10.4 0.2 CCursor + sql area evicted 1,457 0.4 0.0 ............... Instance Activity Stats 的数据来自于 DBA_HIST_SYSSTAT，DBA_HIST_SYSSTAT来自于V$SYSSTAT。 这里每一个指标都代表一种数据库行为的活跃度，例如redo size 是指生成redo的量，sorts (disk) 是指磁盘排序的次数，table scans (direct read) 是指直接路径扫描表的次数。 虽然这些指标均只有Total、per Second每秒、 per Trans每事务 三个维度，但对诊断问题十分有用。 我们来举几个例子： 1、 例如当 Top Event 中存在direct path read为Top 等待事件， 则需要分清楚是对普通堆表的direct read还是由于大量LOB读造成的direct path read， 这个问题可以借助 table scans (direct read)、table scans (long tables)、physical reads direct 、physical reads direct (lob) 、physical reads direct temporary几个指标来分析， 假设 physical reads direct >> 远大于 physical reads direct (lob)+physical reads direct temporary ， 且有较大的table scans (direct read)、table scans (long tables) (注意这2个指标代表的是 扫描表的次数 不同于上面的phsical reads 的单位为 块数*次数)， 则说明了是 大表扫描引起的direct path read。 2、 例如当 Top Event中存在enq Tx:index contention等待事件， 则需要分析root node splits 、branch node splits 、leaf node 90-10 splits 、leaf node splits 、failed probes on index block rec 几个指标，具体可以见文档《Oracle索引块分裂split信息汇总》 3、系统出现IO类型的等待事件为TOp Five 例如 db file sequential/scattered read ，我们需要通过AWR来获得系统IO吞吐量和IOPS: physical read bytes 主要是应用造成的物理读取(Total size in bytes of all disk reads by application activity (and not other instance activity) only.) 而physical read total bytes则包括了 rman备份恢复 和后台维护任务所涉及的物理读字节数，所以我们在研究IO负载时一般参考 physical read total bytes；以下4对指标均存在上述的关系 physical read bytes physical read total bytes 物理读的吞吐量/秒 physical read IO requests physical read total IO requests 物理读的IOPS physical write bytes physical write total bytes 物理写的吞吐量/秒 physical write IO requests physical write total IO requests 物理写的IOPS 总的物理吞吐量/秒=physical read total bytes+physical write total bytes 总的物理IOPS= physical read total IO requests+ physical write total IO requests IO的主要指标 吞吐量、IOPS和延迟 均可以从AWR中获得了， IO延迟的信息可以从 User I/O的Wait Class Avg Wait time获得，也可以参考11g出现的IOStat by Function summary Instance Activity Stats有大量的指标，但是对于这些指标的介绍 没有那一份文档有完整详尽的描述，即便在Oracle原厂内部要没有(或者是Maclean没找到)，实际是开发人员要引入某一个Activity Stats是比较容易的，并不像申请引入一个新后台进程那样麻烦，Oracle对于新版本中新后台进程的引入有严格的要求，但Activity Stats却很容易，往往一个one-off patch中就可以引入了，实际上Activity Stats在源代码层仅仅是一些计数器。’ 较为基础的statistics，大家可以参考官方文档的Statistics Descriptions描述，地址在这里。 对于深入的指标 例如 “Batched IO (space) vector count”这种由于某些新特性被引入的，一般没有很详细的材料，需要到源代码中去阅读相关模块才能总结其用途，对于这个工作一般原厂是很延迟去完成的，所以没有一个完整的列表。 如果大家有对此的疑问，请去t.askmaclean.com 发一个帖子提问。 Instance Activity Stats - Absolute Values Snaps: 7071 -> Statistics with absolute values (should not be diffed) Statistic Begin Value End Value -------------------------------- --------------- --------------- session pga memory max 1.157882826E+12 1.154290304E+12 session cursor cache count 157,042,373 157,083,136 session uga memory 5.496429019E+14 5.496775467E+14 opened cursors current 268,916 265,694 workarea memory allocated 827,704 837,487 logons current 2,609 2,613 session uga memory max 1.749481584E+13 1.749737418E+13 session pga memory 4.150306913E+11 4.150008177E+11 Instance Activity Stats – Absolute Values是显示快照 起点 和终点的一些指标的绝对值 logon current 当前时间点的登录数 opened cursors current 当前打开的游标数 session cursor cache count 当前存在的session缓存游标数 Instance Activity Stats - Thread ActivityDB/Inst: G10R25/G10R25 Snaps: 3663-3 -> Statistics identified by '(derived)' come from sources other than SYSSTAT Statistic Total per Hour -------------------------------- ------------------ --------- log switches (derived) 17 2,326.47 log switches (derived) 日志切换次数 IO 统计 Tablespace IO Stats 基于表空间分组的IO信息 Tablespace IO Stats DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> ordered by IOs (Reads + Writes) desc Tablespace ------------------------------ Av Av Av Av Buffer Av Buf Reads Reads/s Rd(ms) Blks/Rd Writes Writes/s Waits Wt(ms) -------------- ------- ------- ------- ------------ -------- ---------- ------- DATA_TS 17,349,398 4,801 2.3 1.5 141,077 39 4,083,704 5.8 INDEX_TS 9,193,122 2,544 2.0 1.0 238,563 66 3,158,187 46.1 UNDOTBS1 1,582,659 438 0.7 1.0 2 0 12,431 69.0 reads : 指 该表空间上发生的物理读的次数(单位不是块，而是次数) Av Reads/s : 指该表空间上平均每秒的物理读次数 (单位不是块，而是次数) Av Rd(ms): 指该表空间上每次读的平均读取延迟 Av Blks/Rd: 指该表空间上平均每次读取的块数目，因为一次物理读可以读多个数据块；如果Av Blks/Rd>>1 则可能系统有较多db file scattered read 可能是诊断FULL TABLE SCAN或FAST FULL INDEX SCAN，需要关注table scans (long tables) 和index fast full scans (full) 2个指标 Writes : 该表空间上发生的物理写的次数 ; 对于那些Writes总是等于0的表空间 不妨了解下是否数据为只读，如果是可以通过read only tablespace来解决 RAC中的一些性能问题。 Av Writes/s : 指该表空间上平均每秒的物理写次数 buffer Waits: 该表空间上发生buffer busy waits和read by other session的次数( 9i中buffer busy waits包含了read by other session)。 Av Buf Wt(ms): 该表空间上发生buffer Waits的平均等待时间，单位为ms File I/O File IO Stats Snaps: 70719-70723 -> ordered by Tablespace, File Tablespace Filename ------------------------ ---------------------------------------------------- Av Av Av Av Buffer Av Buf Reads Reads/s Rd(ms) Blks/Rd Writes Writes/s Waits Wt(ms) -------------- ------- ------- ------- ------------ -------- ---------- ------- AMG_ALBUM_IDX_TS +DATA/itscmp/plugged/data2/amg_album_idx_ts01.dbf 23,298 6 0.6 1.0 2 0 0 0.0 AMG_ALBUM_IDX_TS +DATA/itscmp/plugged/data3/amg_album_idx_ts02.dbf 3,003 1 0.6 1.0 2 0 0 0.0 Tablespace 表空间名 FileName 数据文件的路径 Reads: 该数据文件上累计发生过的物理读次数，不是块数 Av Reads/s: 该数据文件上平均每秒发生过的物理读次数，不是块数 Av Rd(ms): 该数据文件上平均每次物理读取的延迟，单位为ms Av Blks/Rd: 该数据文件上平均每次读取涉及到的块数，OLTP环境该值接近 1 Writes : 该数据文件上累计发生过的物理写次数，不是块数 Av Writes/s: 该数据文件上平均每秒发生过的物理写次数，不是块数 buffer Waits: 该数据文件上发生buffer busy waits和read by other session的次数( 9i中buffer busy waits包含了read by other session)。 Av Buf Wt(ms): 该数据文件上发生buffer Waits的平均等待时间，单位为ms 若某个表空间上有较高的IO负载，则有必要分析一下 是否其所属的数据文件上的IO 较为均匀 还是存在倾斜， 是否需要结合存储特征来 将数据均衡分布到不同磁盘上的数据文件上，以优化 I/O 缓冲池统计 Buffer Pool Statistics Buffer Pool Statistics Snaps: 70719-70723 -> Standard block size Pools D: default, K: keep, R: recycle -> Default Pools for other block sizes: 2k, 4k, 8k, 16k, 32k Free Writ Buffer Number of Pool Buffer Physical Physical Buff Comp Busy P Buffers Hit% Gets Reads Writes Wait Wait Waits --- ---------- ---- ------------ ------------ ----------- ------ ------ -------- 16k 15,720 N/A 0 0 0 0 0 0 D 2,259,159 98 2.005084E+09 42,753,650 560,460 0 1 8.51E+06 该环节的数据主要来源于WRH$_BUFFER_POOL_STATISTICS， 而WRH$_BUFFER_POOL_STATISTICS是定期汇总v$SYSSTAT中的数据 P pool池的名字 D: 默认的缓冲池 default buffer pool , K : Keep Pool , R: Recycle Pool ; 2k 4k 8k 16k 32k: 代表各种非标准块大小的缓冲池 Number of buffers: 实际的 缓冲块数目， 约等于 池的大小 / 池的块大小 Pool Hit % : 该缓冲池的命中率 Buffer Gets: 对该缓冲池的中块的访问次数 包括 consistent gets 和 db block gets Physical Reads: 该缓冲池Buffer Cache引起了多少物理读， 其实是physical reads cache ，单位为 块数*次数 Physical Writes ：该缓冲池中Buffer cache被写的物理写， 其实是physical writes from cache， 单位为 块数*次数 Free Buffer Waits: 等待空闲缓冲的次数， 可以看做该buffer pool 发生free buffer waits 等待的次数 Write Comp Wait: 等待DBWR写入脏buffer到磁盘的次数， 可以看做该buffer pool发生write complete waits等待的次数 Buffer Busy Waits: 该缓冲池发生buffer busy wait 等待的次数 Checkpoint Activity 检查点与 Instance Recovery Stats 实例恢复 Checkpoint Activity Snaps: 70719-70723 -> Total Physical Writes: 590,563 Other Autotune Thread MTTR Log Size Log Ckpt Settings Ckpt Ckpt Writes Writes Writes Writes Writes Writes ----------- ----------- ----------- ----------- ----------- ----------- 0 0 0 0 12,899 0 ------------------------------------------------------------- Instance Recovery Stats Snaps: 70719-70723 -> B: Begin Snapshot, E: End Snapshot Estd Targt Estd Log Ckpt Log Ckpt Opt RAC MTTR MTTR Recovery Actual Target Log Sz Timeout Interval Log Avail (s) (s) Estd IOs RedoBlks RedoBlks RedoBlks RedoBlks RedoBlks Sz(M) Time - ----- ----- -------- -------- -------- -------- -------- -------- ------ ----- B 0 6 12828 477505 1786971 5096034 1786971 N/A N/A 3 E 0 7 16990 586071 2314207 5096034 2314207 N/A N/A 3 ------------------------------------------------------------- 该环节的数据来源于WRH$_INSTANCE_RECOVERY MTTR Writes : 为了满足FAST_START_MTTR_TARGET 指定的MTTR值 而做出的物理写 WRITES_MTTR Log Size Writes ：由于最小的redo log file而做出的物理写 WRITES_LOGFILE_SIZE Log Ckpt writes: 由于 LOG_CHECKPOINT_INTERVAL 和 LOG_CHECKPOINT_TIMEOUT 驱动的增量检查点而做出的物理写 WRITES_LOG_CHECKPOINT_SETTINGS Other Settings Writes ：由于其他设置(例如FAST_START_IO_TARGET）而引起的物理写， WRITES_OTHER_SETTINGS Autotune Ckpt Writes : 由于自动调优检查点而引起的物理写， WRITES_AUTOTUNE Thread Ckpt Writes ：由于thread checkpoint而引起的物理写，WRITES_FULL_THREAD_CKPT B 代表 开始点， E 代表结尾 Targt MTTR (s) : 目标MTTR (mean time to recover)意为有效恢复时间，单位为秒。 TARGET_MTTR 的计算基于 给定的参数FAST_START_MTTR_TARGET，而TARGET_MTTR作为内部使用。 实际在使用中 Target MTTR未必能和FAST_START_MTTR_TARGET一样。 如果FAST_START_MTTR_TARGET过小，那么TARGET_MTTR 将是系统条件所允许的最小估算值； 如果FAST_START_MTTR_TARGET过大，则TARGET_MTTR以保守算法计算以获得完成恢复的最长估算时间。 estimated_mttr (s): 当前基于 脏buffer和重做日志块的数量，而评估出的有效恢复时间 。 它的估算告诉用户 以当下系统的负载若发生实例crash，则需要多久时间来做crash recovery的前滚操作，之后才能打开数据库。 Recovery Estd IOs ：实际是当前buffer cache中的脏块数量，一旦实例崩溃 这些脏块要被前滚 Actual RedoBlks ： 当前实际需要恢复的redo重做块数量 Target RedoBlks ：是 Log Sz RedoBlks 、Log Ckpt Timeout RedoBlks、 Log Ckpt Interval RedoBlks 三者的最小值 Log Sz RedoBlks : 代表 必须在log file switch日志切换之前完成的 checkpoint 中涉及到的redo block，也叫max log lag； 数据来源select LOGFILESZ from X$targetrba; select LOG_FILE_SIZE_REDO_BLKS from v$instance_recovery; Log Ckpt Timeout RedoBlks ： 为了满足LOG_CHECKPOINT_TIMEOUT 所需要处理的redo block数，lag for checkpoint timeout ； 数据来源select CT_LAG from x$targetrba; Log Ckpt Interval RedoBlks ：为了满足LOG_CHECKPOINT_INTERVAL 所需要处理的redo block数， lag for checkpoint interval； 数据来源select CI_LAG from x$targetrba; Opt Log Sz(M) : 基于FAST_START_MTTR_TARGET 而估算出来的redo logfile 的大小，单位为MB 。 Oracle官方推荐创建的重做日志大小至少大于这个估算值 Estd RAC Avail Time ：指评估的 RAC中节点失败后 集群从冻结到部分可用的时间， 这个指标仅在RAC中可用，单位为秒。 ESTD_CLUSTER_AVAILABLE_TIME Buffer Pool Advisory 缓冲池建议 Buffer Pool Advisory DB/Inst: ITSCMP/itscmp2 Snap: 70723 -> Only rows with estimated physical reads >0 are displayed -> ordered by Block Size, Buffers For Estimate Est Phys Estimated Est Size for Size Buffers Read Phys Reads Est Phys %DBtime P Est (M) Factor (thousands) Factor (thousands) Read Time for Rds --- -------- ------ ------------ ------ -------------- ------------ ------- D 1,920 .1 227 4.9 1,110,565,597 1 1.0E+09 D 3,840 .2 454 3.6 832,483,886 1 7.4E+08 D 5,760 .3 680 2.8 634,092,578 1 5.6E+08 D 7,680 .4 907 2.2 500,313,589 1 4.3E+08 D 9,600 .5 1,134 1.8 410,179,557 1 3.5E+08 D 11,520 .6 1,361 1.5 348,214,283 1 2.9E+08 D 13,440 .7 1,588 1.3 304,658,441 1 2.5E+08 D 15,360 .8 1,814 1.2 273,119,808 1 2.2E+08 D 17,280 .9 2,041 1.1 249,352,943 1 2.0E+08 D 19,200 1.0 2,268 1.0 230,687,206 1 1.8E+08 D 19,456 1.0 2,298 1.0 228,664,269 1 1.8E+08 D 21,120 1.1 2,495 0.9 215,507,858 1 1.7E+08 D 23,040 1.2 2,722 0.9 202,816,787 1 1.6E+08 D 24,960 1.3 2,948 0.8 191,974,196 1 1.5E+08 D 26,880 1.4 3,175 0.8 182,542,765 1 1.4E+08 D 28,800 1.5 3,402 0.8 174,209,199 1 1.3E+08 D 30,720 1.6 3,629 0.7 166,751,631 1 1.2E+08 D 32,640 1.7 3,856 0.7 160,002,420 1 1.2E+08 D 34,560 1.8 4,082 0.7 153,827,351 1 1.1E+08 D 36,480 1.9 4,309 0.6 148,103,338 1 1.1E+08 D 38,400 2.0 4,536 0.6 142,699,866 1 1.0E+08 缓冲池的颗粒大小 可以参考 SELECT * FROM V$SGAINFO where name like(‘Granule%’); P 指 缓冲池的名字 可能包括 有 D default buffer pool , K Keep Pool , R recycle Pool Size For Est(M): 指以该尺寸的buffer pool作为评估的对象，一般是 目前current size的 10% ~ 200%，以便了解 buffer pool 增大 ~减小 对物理读的影响 Size Factor : 尺寸因子， 只 对应buffer pool 大小 对 当前设置的比例因子， 例如current_size是 100M ， 则如果评估值是110M 那么 size Factor 就是 1.1 Buffers (thousands) ：指这个buffer pool 尺寸下的buffer 数量， 要乘以1000才是实际值 Est Phys Read Factor ：评估的物理读因子，　例如当前尺寸的buffer pool 会引起100个物理读， 则别的尺寸的buffer pool如果引起 120个物理读， 那么 对应尺寸的Est Phys Read Factor就是1.2 Estimated Phys Reads (thousands)：评估的物理读数目，　要乘以　1000才是实际值， 显然不同尺寸的buffer pool对应不同的评估的物理读数目 Est Phys Read Time ： 评估的物理读时间 Est %DBtime for Rds：评估的物理读占DB TIME的比率 我们 看buffer pool advisory 一般有2个目的： 在物理读较多的情况下，希望通过增加buffer pool 大小来缓解物理读等待，这是我们关注Size Factor > 1的buffer pool尺寸是否能共有效减少Est Phys Read Factor， 如果Est Phys Read Factor随着Size Factor 增大 而显著减少，那么说明增大buffer cache 是可以有效减少物理读的。 在内存紧张的情况下 ，希望从buffer pool中匀出部分内存来移作他用， 但是又不希望 buffer cache变小导致 物理读增多 性能下降， 则此时 观察Est Phys Read Factor 是否随着Size Factor 减小而 显著增大， 如果不是 则说明减少部分buffer cache 不会导致 物理读大幅增加，也就可以安心 减少 buffer cache 注意 Size Factor 和 Est Phys Read Factor之间不是简单的 线性关系，所以需要人为介入评估得失 PGA Aggr Summary PGA Aggr Summary Snaps: 70719-70723 -> PGA cache hit % - percentage of W/A (WorkArea) data processed only in-memory PGA Cache Hit % W/A MB Processed Extra W/A MB Read/Written --------------- ------------------ -------------------------- 99.9 412,527 375 PGA Cache Hit % : 指 W/A WorkArea工作区的数据仅在内存中处理的比率， PGA缓存命中率 workarea是PGA中负责处理 排序、哈希连接和位图合并操作的区域; workarea 也叫做 SQL 作业区域 W/A MB processes: 指 在Workarea中处理过的数据的量，单位为MB Extra W/A MB Read/Written : 指额外从磁盘上 读写的 工作区数据， 单位为 MB PGA Aggr Target Stats Warning: pga_aggregate_target was set too low for current workload, as this value was exceeded during this interval. Use the PGA Advisory view to help identify a different value for pga_aggregate_target. PGA Aggr Target Stats Snaps: 70719-70723 -> B: Begin Snap E: End Snap (rows dentified with B or E contain data which is absolute i.e. not diffed over the interval) -> Auto PGA Target - actual workarea memory target -> W/A PGA Used - amount of memory used for all Workareas (manual + auto) -> %PGA W/A Mem - percentage of PGA memory allocated to workareas -> %Auto W/A Mem - percentage of workarea memory controlled by Auto Mem Mgmt -> %Man W/A Mem - percentage of workarea memory under manual control %PGA %Auto %Man PGA Aggr Auto PGA PGA Mem W/A PGA W/A W/A W/A Global Mem Target(M) Target(M) Alloc(M) Used(M) Mem Mem Mem Bound(K) - ---------- ---------- ---------- ---------- ------ ------ ------ ---------- B 8,192 512 23,690.5 150.1 .6 100.0 .0 838,860 E 8,192 512 23,623.6 156.9 .7 100.0 .0 838,860 ------------------------------------------------------------- 此环节的数据来源主要是 WRH$_PGASTAT PGA Aggr Target(M) ：本质上就是pga_aggregate_target ， 当然在AMM(memory_target)环境下 这个值可能会自动变化 Auto PGA Target(M) : 在自动PGA 管理模式下 实际可用的工作区内存 “aggregate PGA auto target “， 因为PGA还有其他用途 ，不能全部作为workarea memory PGA Mem Alloc(M) ：目前已分配的PGA内存， 　alloc 不等于 inuse 即分配的内存不等于在使用的内存，理论上PGA会将确实不使用的内存返回给OS(PGA memory freed back to OS) ，但是存在PGA占用大量内存而不释放的场景 在上例中 pga_aggregate_target 仅为8192M ，而实际processes 在 2,615~ 8000之间，如果一个进程耗费5MB的PGA 也需要 10000M的PGA ，而实际这里 PGA Mem Alloc(M)是23,690 M ，这说明 存在PGA 的过载， 需要调整pga_aggregate_target W/A PGA Used(M) ：所有的工作区workarea(包括manual和 auto)使用的内存总和量， 单位为MB %PGA W/A Mem: 分配给workarea的内存量占总的PGA的比例， (W/A PGA Used)/PGA Mem Alloc %Auto W/A Mem : AUTO 自动工作区管理所控制的内存(workarea_size_policy=AUTO) 占总的workarea内存的比例 %Man W/A Mem : MANUAL 手动工作区管理所控制的内存(workarea_size_policy=MANUAL)占总的workarea内存的比例 Global Mem Bound(K) : 指 在自动PGA管理模式下一个工作区所能分配的最大内存(注意 一个SQL执行过程中可能有多个工作区workarea)。 Global Mem Bound(K)这个指标在实例运行过程中将被持续性的修正，以反应数据库当时工作区的负载情况。显然在有众多活跃工作区的系统负载下相应地Global Mem Bound将会下降。 但应当保持global bound值不要小于1 MB ， 否则建议 调高pga_aggregate_target PGA Aggr Target Histogram PGA Aggr Target Histogram Snaps: 70719-70723 -> Optimal Executions are purely in-memory operations Low High Optimal Optimal Total Execs Optimal Execs 1-Pass Execs M-Pass Execs ------- ------- -------------- -------------- ------------ ------------ 2K 4K 262,086 262,086 0 0 64K 128K 497 497 0 0 128K 256K 862 862 0 0 256K 512K 368 368 0 0 512K 1024K 440,585 440,585 0 0 1M 2M 68,313 68,313 0 0 2M 4M 169 161 8 0 4M 8M 50 42 8 0 8M 16M 82 82 0 0 16M 32M 1 1 0 0 32M 64M 12 12 0 0 128M 256M 2 0 2 0 ------------------------------------------------------------- 数据来源：WRH$_SQL_WORKAREA_HISTOGRAM Low Optimal： 此行所包含工作区workarea最适合内存要求的下限 High Optimal： 此行所包含工作区workarea最适合内存要求的上限 Total Execs: 在 Low Optimal~High Optimal 范围工作区内完成的总执行数 Optimal execs: optimal 执行是指完全在PGA内存中完成的执行次数 1-pass Execs : 指操作过程中仅发生1次磁盘读取的执行次数 M-pass Execs: 指操作过程中发生了1次以上的磁盘读取， 频发磁盘读取的执行次数 PGA Memory Advisory PGA Memory Advisory Snap: 70723 -> When using Auto Memory Mgmt, minimally choose a pga_aggregate_target value where Estd PGA Overalloc Count is 0 Estd Extra Estd P Estd PGA PGA Target Size W/A MB W/A MB Read/ Cache Overallo Estd Est (MB) Factr Processed Written to Disk Hit % Count Time ---------- ------- ---------------- ---------------- ------ -------- ------- 1,024 0.1 2,671,356,938.7 387,531,258.9 87.0 1.07E+07 7.9E+11 2,048 0.3 2,671,356,938.7 387,529,979.1 87.0 1.07E+07 7.9E+11 4,096 0.5 2,671,356,938.7 387,518,881.8 87.0 1.07E+07 7.9E+11 6,144 0.8 2,671,356,938.7 387,420,749.5 87.0 1.07E+07 7.9E+11 8,192 1.0 2,671,356,938.7 23,056,196.5 99.0 1.07E+07 6.9E+11 9,830 1.2 2,671,356,938.7 22,755,192.6 99.0 6.81E+06 6.9E+11 11,469 1.4 2,671,356,938.7 20,609,438.5 99.0 4.15E+06 6.9E+11 13,107 1.6 2,671,356,938.7 19,021,139.1 99.0 581,362 6.9E+11 14,746 1.8 2,671,356,938.7 18,601,191.0 99.0 543,531 6.9E+11 16,384 2.0 2,671,356,938.7 18,561,361.1 99.0 509,687 6.9E+11 24,576 3.0 2,671,356,938.7 18,527,422.3 99.0 232,817 6.9E+11 32,768 4.0 2,671,356,938.7 18,511,872.6 99.0 120,180 6.9E+11 49,152 6.0 2,671,356,938.7 18,500,815.3 99.0 8,021 6.9E+11 65,536 8.0 2,671,356,938.7 18,498,733.0 99.0 0 6.9E+11 PGA Target Est (MB) 用以评估的 PGA_AGGREGATE _TARGET值 Size Factr ， 当前用以评估的PGA_AGGREGATE _TARGET 和 当前实际设置的PGA_AGGREGATE _TARGET 之间的 比例因子 PGA Target Est / PGA_AGGREGATE_TARGE W/A MB Processed ：workarea中要处理的数据量， 单位为MB Estd Extra W/A MB Read/ Written to Disk : 以 one-pass 、M-Pass方式处理的数据量预估值， 单位为MB Estd P Cache Hit % : 预估的PGA缓存命中率 Estd PGA Overalloc Count: 预估的PGA过载量， 如上文所述PGA_AGGREGATE _TARGET仅是一个目标值，无法真正限制PGA内存的使用，当出现 PGA内存硬性需求时会产生PGA overallocate 过载(When using Auto Memory Mgmt, minimally choose a pga_aggregate_target value where Estd PGA Overalloc Count is 0) Shared Pool Advisory Shared Pool Advisory Snap: 70723 -> SP: Shared Pool Est LC: Estimated Library Cache Factr: Factor -> Note there is often a 1:Many correlation between a single logical object in the Library Cache, and the physical number of memory objects associated with it. Therefore comparing the number of Lib Cache objects (e.g. in v$librarycache), with the number of Lib Cache Memory Objects is invalid. Est LC Est LC Est LC Est LC Shared SP Est LC Time Time Load Load Est LC Pool Size Size Est LC Saved Saved Time Time Mem Obj Size(M) Factr (M) Mem Obj (s) Factr (s) Factr Hits (K) -------- ----- -------- ------------ -------- ------ ------- ------ ------------ 304 .8 56 3,987 7,728 1.0 61 1.4 332 352 .9 101 6,243 7,745 1.0 44 1.0 334 400 1.0 114 7,777 7,745 1.0 44 1.0 334 448 1.1 114 7,777 7,745 1.0 44 1.0 334 496 1.2 114 7,777 7,745 1.0 44 1.0 334 544 1.4 114 7,777 7,745 1.0 44 1.0 334 592 1.5 114 7,777 7,745 1.0 44 1.0 334 640 1.6 114 7,777 7,745 1.0 44 1.0 334 688 1.7 114 7,777 7,745 1.0 44 1.0 334 736 1.8 114 7,777 7,745 1.0 44 1.0 334 784 2.0 114 7,777 7,745 1.0 44 1.0 334 832 2.1 114 7,777 7,745 1.0 44 1.0 334 ------------------------------------------------------------- Shared Pool Size(M) : 用以评估的shared pool共享池大小，在AMM /ASMM环境下 shared_pool 大小都可能浮动 SP Size Factr ：共享池大小的比例因子，　（Shared Pool Size for Estim / SHARED_POOL_SIZE） Estd LC Size(M) : 评估的 library cache 大小 ，单位为MB ， 因为是shared pool中包含 library cache 当然还有其他例如row cache Est LC Mem Obj 指评估的指定大小的共享池内的library cache memory object的数量 ESTD_LC_MEMORY_OBJECTS Est LC Time Saved(s): 指在 指定的共享池大小情况下可找到需要的library cache memory objects，从而节约的解析时间 。 这些节约的解析时间也是 花费在共享池内重复加载需要的对象(reload)，这些对象可能因为共享池没有足够的free memory而被aged out. ESTD_LC_TIME_SAVED Est LC Time Saved Factr : Est LC Time Saved(s)的比例因子，( Est LC Time Saved(s)/ Current LC Time Saved(s) ) ESTD_LC_TIME_SAVED_FACTOR Est LC Load Time (s): 在指定的共享池大小情况下解析的耗时 Est LC Load Time Factr：Est LC Load Time (s)的比例因子， (Est LC Load Time (s)/ Current LC Load Time (s)) ESTD_LC_LOAD_TIME_FACTOR Est LC Mem Obj Hits (K) : 在指定的共享池大小情况下需要的library cache memory object正好在共享池中被找到的次数 ESTD_LC_MEMORY_OBJECT_HITS； 对于想缩小 shared_pool_size 共享池大小的需求，可以关注Est LC Mem Obj Hits (K) ，如上例中共享池为352M时Est LC Mem Obj Hits (K) 就为334且之后不动，则可以考虑缩小shared_pool_size到该值，但要注意每个版本/平台上对共享池的最低需求，包括RAC中gcs resource 、gcs shadow等资源均驻留在shared pool中，增大db_cache_size时要对应关注。 SGA Target Advisory SGA Target Advisory Snap: 70723 SGA Target SGA Size Est DB Est Physical Size (M) Factor Time (s) Reads ---------- ---------- ------------ ---------------- 3,752 0.1 1.697191E+09 1.4577142918E+12 7,504 0.3 1.222939E+09 832,293,601,354 11,256 0.4 1.000162E+09 538,390,923,784 15,008 0.5 895,087,191 399,888,743,900 18,760 0.6 840,062,594 327,287,716,803 22,512 0.8 806,389,685 282,881,041,331 26,264 0.9 782,971,706 251,988,446,808 30,016 1.0 765,293,424 228,664,652,276 33,768 1.1 751,135,535 210,005,616,650 37,520 1.3 739,350,016 194,387,820,900 41,272 1.4 733,533,785 187,299,216,679 45,024 1.5 732,921,550 187,299,216,679 48,776 1.6 732,691,962 187,299,216,679 52,528 1.8 732,538,908 187,299,216,679 56,280 1.9 732,538,917 187,299,216,679 60,032 2.0 732,462,391 187,299,458,716 ------------------------------------------------------------- 该环节数据来源于WRH$_SGA_TARGET_ADVICE SGA target Size : 用以评估的sga target大小 (sga_target) SGA Size Factor: SGA Size的比例因子， (est SGA target Size / Current SGA target Size ) Est DB Time (s): 评估对应于该指定sga target size会产生多少量的DB TIME，单位为秒 Est Physical Reads：评估对应该指定的sga target size 会产生多少的物理读 Streams Pool Advisory Streams Pool Advisory DB/Inst: ITSCMP/itscmp2 Snap: 70723 Size for Size Est Spill Est Spill Est Unspill Est Unspill Est (MB) Factor Count Time (s) Count Time (s) ---------- --------- ----------- ----------- ----------- ----------- 64 0.5 0 0 0 0 128 1.0 0 0 0 0 192 1.5 0 0 0 0 256 2.0 0 0 0 0 320 2.5 0 0 0 0 384 3.0 0 0 0 0 448 3.5 0 0 0 0 512 4.0 0 0 0 0 576 4.5 0 0 0 0 640 5.0 0 0 0 0 704 5.5 0 0 0 0 768 6.0 0 0 0 0 832 6.5 0 0 0 0 896 7.0 0 0 0 0 960 7.5 0 0 0 0 1,024 8.0 0 0 0 0 1,088 8.5 0 0 0 0 1,152 9.0 0 0 0 0 1,216 9.5 0 0 0 0 1,280 10.0 0 0 0 0 该环节只有当使用了Streams 流复制时才会有必要数据， 数据来源 WRH$_STREAMS_POOL_ADVICE Size for Est (MB) : 用以评估的 streams pool大小 Size Factor ：streams pool大小的比例因子 Est Spill Count ：评估出的 当使用该大小的流池时 message溢出到磁盘的数量 ESTD_SPILL_COUNT Est Spill Time (s)： 评估出的 当使用该大小的流池时 message溢出到磁盘的耗时，单位为秒 ESTD_SPILL_TIME Est Unspill Count：评估的　当使用该大小的流池时　message unspill 即从磁盘上读取的数量 ESTD_UNSPILL_COUNT Est Unspill Time (s) ： 评估的　当使用该大小的流池时 message unspill 即从磁盘上读取的耗时，单位为秒 ESTD_UNSPILL_TIME Java Pool Advisory java pool的相关指标与shared pool相似，不再鏖述 Wait Statistics Buffer Wait Statistics Buffer Wait Statistics Snaps: 70719-70723 -> ordered by wait time desc, waits desc Class Waits Total Wait Time (s) Avg Time (ms) ------------------ ----------- ------------------- -------------- data block 8,442,041 407,259 48 undo header 16,212 1,711 106 undo block 21,023 557 26 1st level bmb 1,038 266 256 2nd level bmb 540 185 342 bitmap block 90 25 276 segment header 197 13 66 file header block 132 6 43 bitmap index block 18 0 1 extent map 2 0 0 数据来源 ： WRH$_WAITSTAT 该环节是对 缓冲池中各类型(class) 块 等待的汇总信息， wait的原因一般是 buffer busy waits 和 read by other session class 数据块的class， 一个oracle数据块即有class 属性 还有type 属性，数据块中记录type属性(KCBH)， 而在buffer header里存有class属性(X$BH.class) Waits: 该类型数据块的等待次数 Total Wait Time (s) : 该类型数据块的合计等待时间 单位为秒 Avg Time (ms) : 该类型数据块 平均每次等待的耗时， 单位 ms 如果用户正使用 undo_management=AUTO 的SMU 则一般不会因为rollback segment过少而引起undo header block类块的等待 对于INSERT 而引起的 buffer争用等待： 对于手动segment 管理MSSM 考虑增加Freelists、Freelist Groups 使用ASSM ，当然ASSM本身没什么参数可调 对于INSERT ON INDEX 引起的争用： 使用反向索引key 使用HASH分区和本地索引 可能的情况下 减少index的densityEnqueue Activity enqueue 队列锁等待 ``` Enqueue Activity Snaps: 70719-70723 -> only enqueues with waits are shown -> Enqueue stats gathered prior to 10g should not be compared with 10g data -> ordered by Wait Time desc, Waits desc Enqueue Type (Request Reason) Requests Succ Gets Failed Gets Waits Wt Time (s) Av Wt Time(ms) TX-Transaction (index contention) 201,270 201,326 0 193,948 97,517 502.80 TM-DML 702,731 702,681 4 1,081 46,671 43,174.08 SQ-Sequence Cache 28,643 28,632 0 17,418 35,606 2,044.19 HW-Segment High Water Mark 9,210 8,845 376 1,216 12,505 10,283.85 TX-Transaction (row lock contention) 9,288 9,280 0 9,232 10,486 1,135.80 CF-Controlfile Transaction 15,851 14,094 1,756 2,798 4,565 1,631.64 TX-Transaction (allocate ITL entry) 471 369 102 360 169 469.28 Enqueue Type (Request Reason) enqueue 队列的类型，大家在研究 enqueue 问题前 至少搞清楚enqueue type 和enqueue mode ， enqueue type是队列锁所要保护的资源 如 TM 表锁 CF 控制文件锁， enqueue mode 是持有队列锁的模式 (SS、SX 、S、SSX、X) Requests : 申请对应的enqueue type资源或者队列转换(enqueue conversion 例如 S 转 SSX ) 的次数 Succ Gets ：对应的enqueue被成功 申请或转换的次数 Failed Gets ：对应的enqueue的申请　或者转换失败的次数 Waits　：由对应的enqueue的申请或者转换而造成等待的次数 Wt Time (s) ： 由对应的enqueue的申请或者转换而造成等待的等待时间 Av Wt Time(ms) ：由对应的enqueue的申请或者转换而造成等待的平均等待时间 ， Wt Time (s) / Waits ,单位为ms 主要的enqueue 等待事件： - enq: TX – row lock/index contention、allocate ITL等待事件 - enq: TM – contention等待事件 - Oracle队列锁enq:TS,Temporary Segment (also TableSpace) #### Undo Segment Summary Undo Segment Summary Snaps: 70719-70723 -> Min/Max TR (mins) - Min and Max Tuned Retention (minutes) -> STO - Snapshot Too Old count, OOS - Out of Space count -> Undo segment block stats: -> uS - unexpired Stolen, uR - unexpired Released, uU - unexpired reUsed -> eS - expired Stolen, eR - expired Released, eU - expired reUsed Undo Num Undo Number of Max Qry Max Tx Min/Max STO/ uS/uR/uU/ TS# Blocks (K) Transactions Len (s) Concurcy TR (mins) OOS eS/eR/eU 4 85.0 200,127 55,448 317 1040.2/10 0/0 0/0/0/0/0/0 Undo Segment Stats Snaps: 70719-70723 -> Most recent 35 Undostat rows, ordered by Time desc Num Undo Number of Max Qry Max Tx Tun Ret STO/ uS/uR/uU/ End Time Blocks Transactions Len (s) Concy (mins) OOS eS/eR/eU 29-Aug 05:52 11,700 35,098 55,448 234 1,070 0/0 0/0/0/0/0/0 29-Aug 05:42 12,203 24,677 54,844 284 1,065 0/0 0/0/0/0/0/0 29-Aug 05:32 14,132 37,826 54,241 237 1,060 0/0 0/0/0/0/0/0 29-Aug 05:22 14,379 32,315 53,637 317 1,050 0/0 0/0/0/0/0/0 29-Aug 05:12 15,693 34,157 53,033 299 1,045 0/0 0/0/0/0/0/0 29-Aug 05:02 16,878 36,054 52,428 250 1,040 0/0 0/0/0/0/0/0 数据来源： WRH$_UNDOSTAT ， undo相关的使用信息每10分钟刷新到v$undostat中 Undo Extent有三种状态 active 、unexpired 、expired active => extent中 包括了活动的事务 ，active的undo extent 一般不允许被其他事务重用覆盖 unexpired => extent中没有活动的事务，但相关undo 记录从inactive到目前还未经过undo retention(注意 auto undo retention的问题 因为这个特性 可能在观察dba_undo_extents时看到大部分block都是unexpired，这是正常的) 指定的时间，所以为unexpired。 对于没有guarantee retention的undo tablespace而言，unexpired extent可能被 steal 为其他事物重用 expired => extent中没有活动事务，且超过了undo retention的时间 Undo TS# 在使用的这个undo 表空间的表空间号， 一个实例 同一时间只能用1个undo tablespace ， RAC不同节点可以用不同的undo tablespace Num Undo Blocks (K) 指被消费的 undo 数据块的数量, (K)代表要乘以1000才是实际值； 可以用该指标来评估系统对undo block的消费量， 以便基于实际负载情况来评估UNDO表空间的大小 Number of Transactions 指该段时间内该undo表空间上执行过的事务transaction总量 Max Qry Len (s) 该时段内 持续最久的查询 时间， 单位为秒 Max Tx Concy 该时段内 最大的事务并发量 Min/Max TR (mins) 最小和最大的tuned undo retention ，单位为分钟； tuned undo retention 是自动undo调优特性，见undo自动调优介绍。 STO/ OOS STO 指 ORA-01555 Snapshot Too Old错误出现的次数；OOS – 指Out of Space count 错误出现的次数 uS – unexpired Stolen 尝试从未过期的undo extent中偷取undo space的次数 uR – unexpired Released 从未过期的undo extent中释放的块数目 uU – unexpired reUsed 未过期的undo extent中的block被其他事务重用的块数目 eS – expired Stolen 尝试从过期的undo extent中偷取undo space的次数 eR – expired Released 从过期的undo extent中释放的块数目 eU – expired reUsed 过期的undo extent中的block被其他事务重用的块数目 UNXPSTEALCNT NUMBER Number of attempts to obtain undo space by stealing unexpired extents from other transactions UNXPBLKRELCNT NUMBER Number of unexpired blocks removed from certain undo segments so they can be used by other transactions UNXPBLKREUCNT NUMBER Number of unexpired undo blocks reused by transactions EXPSTEALCNT NUMBER Number of attempts to steal expired undo blocks from other undo segments EXPBLKRELCNT NUMBER Number of expired undo blocks stolen from other undo segments EXPBLKREUCNT NUMBER Number of expired undo blocks reused within the same undo segments SSOLDERRCNT NUMBER Identifies the number of times the error&nbsp;ORA-01555&nbsp;occurred. You can use this statistic to decide whether or not the&nbsp;UNDO_RETENTION&nbsp;initialization parameter is set properly given the size of the undo tablespace. Increasing the value of&nbsp;UNDO_RETENTION&nbsp;can reduce the occurrence of this error. #### Latch Activity Latch Activity Snaps: 70719-70723 -> \"Get Requests\", \"Pct Get Miss\" and \"Avg Slps/Miss\" are statistics for willing-to-wait latch get requests -> \"NoWait Requests\", \"Pct NoWait Miss\" are for no-wait latch get requests -> \"Pct Misses\" for both should be very close to 0.0 Pct Avg Wait Pct Get Get Slps Time NoWait NoWait Latch Name Requests Miss /Miss (s) Requests Miss AQ deq hash table latch 4 0.0 0 0 N/A ASM Keyed state latch 9,048 0.1 0.2 0 0 N/A ASM allocation 15,017 0.2 0.8 1 0 N/A ASM db client latch 72,745 0.0 0 0 N/A ASM map headers 5,860 0.6 0.6 1 0 N/A ASM map load waiting lis 1,462 0.0 0 0 N/A ASM map operation freeli 63,539 0.1 0.4 1 0 N/A ASM map operation hash t 76,484,447 0.1 1.0 66 0 N/A latch name Latch闩的名字 Get Requests latch被以willing-to-wait模式申请并获得的次数 Pct Get Miss miss是指latch被以willing-to-wait 模式申请但是申请者必须等待的次数， Pct Get Miss = Miss/Get Requests ; miss可以从后面的Latch Sleep Breakdown 获得 Avg Slps /Miss Sleep 是指latch被以willing-to-wait模式申请最终导致session需要sleep以等待该latch的次数 ； Avg Slps /Miss = Sleeps/ Misses ; Sleeps可以从后面的Latch Sleep Breakdown 获得 Wait Time (s) 指花费在等待latch上的时间，单位为秒 NoWait Requests 指latch被以no-wait模式来申请的次数 Pct NoWait Miss 以no-wait模式来申请latch但直接失败的次数 对于高并发的latch例如cache buffers chains，其Pct Misses应当十分接近于0 一般的调优原则： - 如果latch : cache buffers chains是 Top 5 事件，则需要考虑优化SQL减少 全表扫描 并减少Top buffer gets SQL语句的逻辑读 - 如果latch : redo copy 、redo allocation 等待较多，则可以考虑增大LOG_BUFFER - 如果latch:library cache 发生较多，则考虑增大shared_pool_size #### Latch Sleep Breakdown Latch Sleep Breakdown DB/Inst: ITSCMP/itscmp2 Snaps: 70719-70723 -> ordered by misses desc Get Spin Latch Name Requests Misses Sleeps Gets cache buffers chains 3,365,097,866 12,831,875 130,058 12,683,450 row cache objects 69,050,058 349,839 1,320 348,649 session idle bit 389,437,460 268,285 2,768 265,752 enqueue hash chains 8,698,453 239,880 22,476 219,950 ges resource hash list 8,388,730 158,894 70,728 91,104 gc element 100,383,385 135,759 6,285 129,742 gcs remastering latch 12,213,169 72,373 1 72,371 enqueues 4,662,545 46,374 259 46,155 ASM map operation hash tab 76,484,447 46,231 45,210 1,952 Lsod array latch 72,598 24,224 24,577 1,519 latch name Latch闩的名字 Get Requests latch被以willing-to-wait模式申请并获得的次数 misses 是指latch被以willing-to-wait 模式申请但是申请者必须等待的次数 9i以后miss之后一般有2种情况 spin gets了 或者sleep一睡不醒直到 被post，具体见全面解析9i以后Oracle Latch闩锁原理； 8i以前的latch算法可以参考：Oracle Latch:一段描绘Latch运作的伪代码 所以一般来说9i以后的 misses= Sleeps+ Spin Gets ，虽然不是绝对如此 Sleeps 是指latch被以willing-to-wait模式申请最终导致session需要sleep以等待该latch的次数 Spin Gets 以willing-to-wait模式去申请latch，在miss之后以spin方式获得了latch的次数 #### Latch Miss Sources Latch Miss Sources Snaps: 70719-70723 -> only latches with sleeps are shown -> ordered by name, sleeps desc NoWait Waiter Latch Name Where Misses Sleeps Sleeps ASM Keyed state latch kfksolGet 0 1 1 ASM allocation kfgpnSetDisks2 0 17 0 ASM allocation kfgpnClearDisks 0 5 0 ASM allocation kfgscCreate 0 4 0 ASM allocation kfgrpGetByName 0 1 26 ASM map headers kffmUnidentify_3 0 7 8 ASM map headers kffmAllocate 0 6 0 ASM map headers kffmIdentify 0 6 11 ASM map headers kffmFree 0 1 0 ASM map operation freeli kffmTranslate2 0 15 8 ASM map operation hash t kffmUnidentify 0 44,677 36,784 ASM map operation hash t kffmTranslate 0 220 3,517 数据来源为DBA_HIST_LATCH_MISSES_SUMMARY latch name Latch闩的名字 where : 指哪些代码路径内核函数持有过这些该latch ，而不是哪些代码路径要申请这些latch； 例如kcbgtcr函数的作用是Get a block for Consistent read，其持有latch :cache buffers chain是很正常的事情 NoWait Misses: 以no-wait模式来申请latch但直接失败的次数 Sleeps: 指latch被以willing-to-wait模式申请最终导致session需要sleep以等待该latch的次数 time of sleeps resulted in making the latch request Waiter Sleeps：等待者休眠的次数 times of sleeps that waiters did for each where; Sleep 是阻塞者等待的次数 ， Waiter Sleeps是被阻塞者等待的次数 #### Mutex Sleep Summary Mutex Sleep Summary Snaps: 70719-70723 -> ordered by number of sleeps desc Wait Mutex Type Location Sleeps Time (ms) Cursor Pin kksfbc [KKSCHLFSP2] 4,364 14,520 Cursor Pin kkslce [KKSCHLPIN2] 2,396 2,498 Library Cache kglpndl1 95 903 475 Library Cache kglpin1 4 800 458 Library Cache kglpnal2 91 799 259 Library Cache kglget1 1 553 1,697 Library Cache kglpnal1 90 489 88 Library Cache kgllkdl1 85 481 1,528 Cursor Pin kksLockDelete [KKSCHLPIN6] 410 666 Cursor Stat kkocsStoreBindAwareStats [KKSSTA 346 497 Library Cache kglhdgn2 106 167 348 Library Cache kglhdgh1 64 26 84 Library Cache kgldtin1 42 19 55 Cursor Pin kksfbc [KKSCHLPIN1] 13 34 Library Cache kglhdgn1 62 11 13 Library Cache kgllkal1 80 9 12 Library Cache kgllkc1 57 6 0 Cursor Pin kksSetBindType [KKSCHLPIN3] 5 5 Library Cache kglGetHandleReference 124 4 20 Library Cache kglUpgradeLock 119 4 0 Library Cache kglget2 2 3 0 Library Cache kglati1 45 1 0 Library Cache kglini1 32 1 0 Library Cache kglobld1 75 1 0 Library Cache kglobpn1 71 1 0 Mutex是10.2.0.2以后引入的新的内存锁机制 Mutex Type Mutex的类型其实就是 mutex对应的客户的名字， 在版本10.2中基本只有KKS使用Mutex，所以仅有3种: - Cursor Stat (kgx_kks1) - Cursor Parent (kgx_kks2) - Cursor Pin (kgx_kks3) 11g中增加了Library Cache Location 发起对该Mutex申请的代码路径code location，而不是还持有该Mutex的代码路径或曰内核函数 10.2中最常见的下面的几个函数 kkspsc0 -负责解析游标 –检测我们正在解析的游标是否有对象的parent cursor heap 0存在 kksfbc –负责找到合适的子游标 或者创建一个新的子游标 kksFindCursorstat Sleeps: Mutex的Get和Sleep 当一个Mutex被申请时， 一般称为一个get request。 若初始的申请未能得到授权， 则该进程会因为此次申请而进入到255次SPIN中(_mutex_spin_count Mutex spin count)，每次SPIN循环迭代过程中该进程都会去看看Mutex被释放了吗。 若该Mutex在SPIN之后仍未被释放，则该进程针对申请的mutex进入对应的mutex wait等待事件中。 实际进程的等待事件和等待方式由mutex的类型锁决定，例如 Cursor pin、Cursor Parent。 举例来说，这种等待可能是阻塞等待，也可以是sleep。 但是请注意在V$MUTEX_SLEEP_*视图上的sleep列意味着等待的次数。相关代码函数在开始进入等待时自加这个sleep字段。 等待计时从进程进入等待前开始计算等待时间， 当一个进程结束其等待，则等待的时间加入都总和total中。 该进程再次尝试申请之前的Mutex，若该Mutex仍不可用，则它再次进入spin/wait的循环。 V$MUTEX_SLEEP_HISTORY视图的GETS列仅在成功申请到一个Mutex时才增加。 Wait Time (ms) 类似于latch，spin time 不算做mutex的消耗时间，它只包含等待消耗的时间。 ### segment statistics 段级统计 #### Segments by Logical Reads Segments by Logical Reads DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Logical Reads: 2,021,476,421 -> Captured Segments account for 83.7% of Total Tablespace Subobject Obj. Logical Owner Name Object Name Name Type Reads %Total CONTENT_OW INDEX_TS MZ_PRODUCT_ATTRIBUTE INDEX 372,849,920 18.44 CONTENT_OW INDEX_TS MZ_PRODUCT__LS_PK INDEX 329,829,632 16.32 CONTENT_OW DATA_TS MZ_PRODUCT_ATTRIBUTE TABLE 218,419,008 10.80 CONTENT_OW PLAYLIST_A MZ_PLAYLIST_ARTIST TABLE 182,426,240 9.02 CONTENT_OW DATA_TS MZ_PRODUCT TABLE 108,597,376 5.37 owner : 数据段的所有者 Tablespace Name: 数据段所在表空间名 Object Name : 对象名 Subobject Name：子对象名，例如一个分区表的某个分区 obj Type: 对象类型 一般为TABLE /INDEX 或者分区或子分区 Logical Reads ：该数据段上发生过的逻辑读 ， 单位为 块数*次数 %Total : 占总的逻辑读的百分比 ， (当前对象上发生过的逻辑读/ Total DB 逻辑读) #### Segments by Physical Reads Segments by Physical Reads DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Physical Reads: 56,839,035 -> Captured Segments account for 51.9% of Total Tablespace Subobject Obj. Physical Owner Name Object Name Name Type Reads %Total CONTENTOW SONG_TS MZ_SONG TABLE 7,311,928 12.86 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 4,896,554 8.61 CONTENT_OW DATA_TS MZ_CONTENT_PROVIDER TABLE 3,099,387 5.45 CONTENT_OW DATA_TS MZ_PRODUCT_ATTRIBUTE TABLE 1,529,971 2.69 CONTENT_OW DATA_TS MZ_PUBLICATION TABLE 1,391,735 2.45 Physical Reads: 该数据段上发生过的物理读 ， 单位为 块数*次数 %Total : 占总的物理读的百分比 ， (当前对象上发生过的逻辑读/ Total DB 逻辑读) #### Segments by Physical Read Requests Segments by Physical Read Requests DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Physical Read Requests: 33,936,360 -> Captured Segments account for 45.5% of Total Tablespace Subobject Obj. Phys Read Owner Name Object Name Name Type Requests %Total CONTENTOW DATA_TS MZ_CONTENT_PROVIDER TABLE 3,099,346 9.13 CONTENT_OW DATA_TS MZ_PRODUCT_ATTRIBUTE TABLE 1,529,950 4.51 CONTENT_OW DATA_TS MZ_PRODUCT TABLE 1,306,756 3.85 CONTENT_OW DATA_TS MZ_AUDIO_FILE TABLE 910,537 2.68 CONTENT_OW INDEX_TS MZ_PRODUCT_ATTRIBUTE INDEX 820,459 2.42 Phys Read Requests ： 物理读的申请次数 %Total ：　(该段上发生的物理读的申请次数/ physical read IO requests) #### Segments by UnOptimized Reads Segments by UnOptimized Reads DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total UnOptimized Read Requests: 811,466 -> Captured Segments account for 58.5% of Total Tablespace Subobject Obj. UnOptimized Owner Name Object Name Name Type Reads %Total CONTENTOW DATA_TS MZ_CONTENT_PROVIDER TABLE 103,580 12.76 CONTENT_OW SONG_TS MZ_SONG TABLE 56,946 7.02 CONTENT_OW DATA_TS MZ_IMAGE TABLE 47,017 5.79 CONTENT_OW DATA_TS MZ_PRODUCT_ATTRIBUTE TABLE 40,950 5.05 CONTENT_OW DATA_TS MZ_PRODUCT TABLE 30,406 3.75 UnOptimized Reads UnOptimized Read Reqs = Physical Read Reqts – Optimized Read Reqs Optimized Read Requests是指 哪些满足Exadata Smart Flash Cache ( or the Smart Flash Cache in OracleExadata V2 (Note that despite same name, concept and use of ‘Smart Flash Cache’ in Exadata V2 is different from ‘Smart Flash Cache’ in Database Smart Flash Cache))的物理读 次数 。 满足从smart flash cache走的读取申请则认为是optimized ，因为这些读取要比普通从磁盘走快得多。 此外通过smart scan 读取storage index的情况也被认为是’optimized read requests’ ，源于可以避免读取不相关的数据。 当用户不在使用Exadata时，则UnOptimized Read Reqs总是等于 Physical Read Reqts %Total : (该段上发生的物理读的UnOptimized Read Reqs / ( physical read IO requests – physical read requests optimized)) #### Segments by Optimized Reads Segments by Optimized Reads DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Optimized Read Requests: 33,124,894 -> Captured Segments account for 45.2% of Total Tablespace Subobject Obj. Optimized Owner Name Object Name Name Type Reads %Total CONTENTOW DATA_TS MZ_CONTENT_PROVIDER TABLE 2,995,766 9.04 CONTENT_OW DATA_TS MZ_PRODUCT_ATTRIBUTE TABLE 1,489,000 4.50 CONTENT_OW DATA_TS MZ_PRODUCT TABLE 1,276,350 3.85 CONTENT_OW DATA_TS MZ_AUDIO_FILE TABLE 890,775 2.69 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3 INDEX 816,067 2.46 关于optimizerd read 上面已经解释过了，这里的单位是 request 次数 %Total : (该段上发生的物理读的 Optimized Read Reqs/ physical read requests optimized ) #### Segments by Direct Physical Reads Segments by Direct Physical Reads DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Direct Physical Reads: 14,118,552 -> Captured Segments account for 94.2% of Total Tablespace Subobject Obj. Direct Owner Name Object Name Name Type Reads %Total CONTENT_OW SONG_TS MZ_SONG TABLE 7,084,416 50.18 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 4,839,984 34.28 CONTENT_OW DATA_TS MZ_PUBLICATION TABLE 1,361,133 9.64 CONTENT_OW DATA_TS SYS_LOB0000203660C00 LOB 5,904 .04 CONTENT_OW DATA_TS SYS_LOB0000203733C00 LOB 1,656 .01 Direct reads 直接路径物理读，单位为 块数*次数 %Total (该段上发生的direct path reads /Total physical reads direct ) #### Segments by Physical Writes Segments by Physical Writes DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Physical Writes: 590,563 -> Captured Segments account for 38.3% of Total Tablespace Subobject Obj. Physical Owner Name Object Name Name Type Writes %Total CONTENTOW DATA_TS MZ_CS_WORK_PENDING_R TABLE 23,595 4.00 CONTENT_OW DATA_TS MZ_PODCAST TABLE 19,834 3.36 CONTENT_OW INDEX_TS MZ_IMAGE_IX2 INDEX 16,345 2.77 SYS SYSAUX WRH$_ACTIVE_SESSION 1367_70520 TABLE 14,173 2.40 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3 INDEX 9,645 1.63 Physical Writes ，物理写 单位为 块数*次数 Total % (该段上发生的物理写 /Total physical writes ) #### Segments by Physical Write Requests Segments by Physical Write Requests DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Physical Write Requestss: 436,789 -> Captured Segments account for 43.1% of Total Tablespace Subobject Obj. Phys Write Owner Name Object Name Name Type Requests %Total CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 22,581 5.17 CONTENT_OW DATA_TS MZ_PODCAST TABLE 19,797 4.53 CONTENT_OW INDEX_TS MZ_IMAGE_IX2 INDEX 14,529 3.33 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3 INDEX 9,434 2.16 CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 8,618 1.97 Phys Write Requests 物理写的请求次数 ，单位为次数 %Total (该段上发生的物理写请求次数 /physical write IO requests ) #### Segments by Direct Physical Writes Segments by Direct Physical Writes DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Direct Physical Writes: 29,660 -> Captured Segments account for 18.3% of Total Tablespace Subobject Obj. Direct Owner Name Object Name Name Type Writes %Total SYS SYSAUX WRH$ACTIVE_SESSION 1367_70520 TABLE 4,601 15.51 CONTENT_OW DATA_TS SYS_LOB0000203733C00 LOB 620 2.09 CONTENT_OW DATA_TS SYS_LOB0000203660C00 LOB 134 .45 CONTENT_OW DATA_TS SYS_LOB0000203779C00 LOB 46 .16 CONTENT_OW DATA_TS SYS_LOB0000203796C00 LOB 41 .14 Direct Writes 直接路径写， 单位额为块数*次数 %Total 为(该段上发生的直接路径写 /physical writes direct ) #### Segments by Table Scans Segments by Table Scans DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Table Scans: 10,713 -> Captured Segments account for 1.0% of Total Tablespace Subobject Obj. Table Owner Name Object Name Name Type Scans %Total CONTENT_OW DATA_TS MZ_PUBLICATION TABLE 92 .86 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 14 .13 CONTENT_OW SONG_TS MZ_SONG TABLE 3 .03 CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 1 .01 Table Scans 来源为dba_hist_seg_stat.table_scans_delta 不过这个指标并不十分精确 #### Segments by DB Blocks Changes Segments by DB Blocks Changes DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> % of Capture shows % of DB Block Changes for each top segment compared -> with total DB Block Changes for all segments captured by the Snapshot Tablespace Subobject Obj. DB Block % of Owner Name Object Name Name Type Changes Capture CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX8 INDEX 347,856 10.21 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3A INDEX 269,504 7.91 CONTENT_OW INDEX_TS MZ_AM_REQUEST_PK INDEX 251,904 7.39 CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 201,056 5.90 CONTENT_OW INDEX_TS MZ_PRODUCT_ATTRIBUTE INDEX 199,888 5.86 DB Block Changes ，单位为块数*次数 %Total : (该段上发生block changes / db block changes ) #### Segments by Row Lock Waits Segments by Row Lock Waits DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> % of Capture shows % of row lock waits for each top segment compared -> with total row lock waits for all segments captured by the Snapshot Row Tablespace Subobject Obj. Lock % of Owner Name Object Name Name Type Waits Capture CONTENTOW LOB_8K_TS MZ_ASSET_WORK_EVENT INDEX 72,005 43.86 CONTENT_OW LOB_8K_TS MZ_CS_WORK_NOTE_RE_I _2013_1_36 INDEX 13,795 8.40 CONTENT_OW LOB_8K_TS MZ_CS_WORK_INFO_PART _2013_5_35 INDEX 12,383 7.54 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3A INDEX 8,937 5.44 CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 8,531 5.20 Row Lock Waits 是指行锁的等待次数 数据来源于 dba_hist_seg_stat.ROW_LOCK_WAITS_DELTA #### Segments by ITL WAITS Segments by ITL Waits DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> % of Capture shows % of ITL waits for each top segment compared -> with total ITL waits for all segments captured by the Snapshot Tablespace Subobject Obj. ITL % of Owner Name Object Name Name Type Waits Capture CONTENTOW LOB_8K_TS MZ_ASSET_WORK_EVENT INDEX 95 30.16 CONTENT_OW LOB_8K_TS MZ_CS_WORK_NOTE_RE_I _2013_1_36 INDEX 48 15.24 CONTENT_OW LOB_8K_TS MZ_CS_WORK_INFO_PART _2013_5_35 INDEX 21 6.67 CONTENT_OW INDEX_TS MZ_SALABLE_FIRST_AVA INDEX 21 6.67 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 20 6.35 ITL Waits 等待 ITL 的次数，数据来源为 dba_hist_seg_stat.itl_waits_delta #### Segments by Buffer Busy Waits Segments by Buffer Busy Waits DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> % of Capture shows % of Buffer Busy Waits for each top segment compared -> with total Buffer Busy Waits for all segments captured by the Snapshot Buffer Tablespace Subobject Obj. Busy % of Owner Name Object Name Name Type Waits Capture CONTENTOW LOB_8K_TS MZ_ASSET_WORK_EVENT INDEX 251,073 57.07 CONTENT_OW LOB_8K_TS MZ_CS_WORK_NOTE_RE_I _2013_1_36 INDEX 36,186 8.23 CONTENT_OW LOB_8K_TS MZ_CS_WORK_INFO_PART _2013_5_35 INDEX 31,786 7.23 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3A INDEX 15,663 3.56 CONTENT_OW INDEX_TS MZ_CS_WORK_PENDING_R INDEX 11,087 2.52 Buffer Busy Waits 该数据段上发生 buffer busy wait的次数 数据来源 dba_hist_seg_stat.buffer_busy_waits_delta #### Segments by Global Cache Buffer Segments by Global Cache Buffer BusyDB/Inst: MAC/MAC2 Snaps: 70719-7072 -> % of Capture shows % of GC Buffer Busy for each top segment compared -> with GC Buffer Busy for all segments captured by the Snapshot GC Tablespace Subobject Obj. Buffer % of Owner Name Object Name Name Type Busy Capture CONTENTOW INDEX_TS MZ_AM_REQUEST_IX3 INDEX 2,135,528 50.07 CONTENT_OW DATA_TS MZ_CONTENT_PROVIDER TABLE 652,900 15.31 CONTENTOW LOB_8K_TS MZ_ASSET_WORK_EVENT INDEX 552,161 12.95 CONTENT_OW LOB_8K_TS MZ_CS_WORK_NOTE_RE_I _2013_1_36 INDEX 113,042 2.65 CONTENT_OW LOB_8K_TS MZ_CS_WORK_INFO_PART _2013_5_35 INDEX 98,134 2.30 GC Buffer Busy 数据段上发挥僧gc buffer busy的次数， 数据源 dba_hist_seg_stat.gc_buffer_busy_delta #### Segments by CR Blocks Received Segments by CR Blocks Received DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total CR Blocks Received: 763,037 -> Captured Segments account for 40.9% of Total CR Tablespace Subobject Obj. Blocks Owner Name Object Name Name Type Received %Total CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 69,100 9.06 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 44,491 5.83 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3A INDEX 36,830 4.83 CONTENT_OW DATA_TS MZ_PODCAST TABLE 36,632 4.80 CONTENT_OW INDEX_TS MZ_AM_REQUEST_PK INDEX 19,646 2.57 CR Blocks Received ：是指RAC中本地节点接收到global cache CR blocks 的数量； 数据来源为 dba_hist_seg_stat.gc_cu_blocks_received_delta %Total : (该段上在本节点接收的Global CR blocks / gc cr blocks received ) #### Segments by Current Blocks Received Segments by Current Blocks ReceivedDB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Total Current Blocks Received: 704,731 -> Captured Segments account for 61.8% of Total Current Tablespace Subobject Obj. Blocks Owner Name Object Name Name Type Received %Total CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3 INDEX 56,287 7.99 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX3A INDEX 45,139 6.41 CONTENT_OW DATA_TS MZ_AM_REQUEST TABLE 40,350 5.73 CONTENT_OW DATA_TS MZ_CS_WORK_PENDING_R TABLE 22,808 3.24 CONTENT_OW INDEX_TS MZ_AM_REQUEST_IX8 INDEX 13,343 1.89 Current Blocks Received :是指RAC中本地节点接收到global cache Current blocks 的数量 ，数据来源DBA_HIST_SEG_STAT.gc_cu_blocks_received_delta %Total : (该段上在本节点接收的 global cache current blocks / gc current blocks received) #### Dictionary Cache Stats Dictionary Cache Stats DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> \"Pct Misses\" should be very low ( \"Final Usage\" is the number of cache entries being used Get Pct Scan Pct Mod Final Cache Requests Miss Reqs Miss Reqs Usage dc_awr_control 87 2.3 0 N/A 6 1 dc_global_oids 1,134 7.8 0 N/A 0 13 dc_histogram_data 6,119,027 0.9 0 N/A 0 11,784 dc_histogram_defs 1,898,714 2.3 0 N/A 0 5,462 dc_object_grants 175 26.9 0 N/A 0 4 dc_objects 10,254,514 0.2 0 N/A 0 3,807 dc_profiles 8,452 0.0 0 N/A 0 2 dc_rollback_segments 3,031,044 0.0 0 N/A 0 1,947 dc_segments 1,812,243 1.4 0 N/A 10 3,595 dc_sequences 15,783 69.6 0 N/A 15,782 20 dc_table_scns 70 2.9 0 N/A 0 1 dc_tablespaces 1,628,112 0.0 0 N/A 0 37 dc_users 2,037,138 0.0 0 N/A 0 52 global database name 7,698 0.0 0 N/A 0 1 outstanding_alerts 264 99.6 0 N/A 8 1 sch_lj_oids 51 7.8 0 N/A 0 1 Dictionary Cache 字典缓存也叫row cache 数据来源为dba_hist_rowcache_summary Cache 字典缓存类名kqrstcid kqrsttxt cid=3(dc_rollback_segments) Get Requests 申请获取该数据字典缓存对象的次数 gets Miss : GETMISSES 申请获取该数据字典缓存对象但 miss的次数 Pct Miss ：　GETMISSES /Gets ， Miss的比例 ，这个pct miss应当非常低 小于2%，否则有出现大量row cache lock的可能 Scan Reqs：扫描申请的次数 ，kqrssc 、kqrpScan 、kqrpsiv时发生scan 会导致扫描数增加 kqrstsrq++(scan requests) ，例如migrate tablespace 时调用 kttm2b函数 为了安全删除uet$中的记录会callback kqrpsiv (used extent cache)，实际很少见 Pct Miss：SCANMISSES/SCANS Mod Reqs: 申请修改字典缓存对象的次数，从上面的数据可以看到dc_sequences的mod reqs很高，这是因为sequence是变化较多的字典对象 Final Usage ：包含有有效数据的字典缓存记录的总数 也就是正在被使用的row cache记录 USAGE Number of cache entries that contain valid data Dictionary Cache Stats (RAC) DB/Inst: MAC/MAC2 Snaps: 70719-70723 GES GES GES Cache Requests Conflicts Releases dc_awr_control 14 2 0 dc_global_oids 88 0 102 dc_histogram_defs 43,518 0 43,521 dc_objects 21,608 17 21,176 dc_profiles 1 0 1 dc_segments 24,974 14 24,428 dc_sequences 25,178 10,644 347 dc_table_scns 2 0 2 dc_tablespaces 165 0 166 dc_users 119 0 119 outstanding_alerts 478 8 250 sch_lj_oids 4 0 4 GES Request kqrstilr total instance lock requests ，通过全局队列服务GES 来申请instance lock的次数 GES request 申请的原因可能是 dump cache object、kqrbfr LCK进程要background free some parent objects释放一些parent objects 等 GES Conflicts kqrstifr instance lock forced-releases ， LCK进程以AST方式 释放锁的次数 ，仅出现在kqrbrl中 GES Releases kqrstisr instance lock self-releases ，LCK进程要background free some parent objects释放一些parent objects 时可能自增 上述数据中可以看到仅有dc_sequences 对应的GES Conflicts较多， 对于sequence 使用ordered和non-cache选项会导致RAC中的一个边际效应，即”row cache lock”等待源于DC_SEQUENCES ROW CACHE。 DC_SEQUENCES 上的GETS request、modifications 、GES requests和GES conflict 与引发生成一个新的 sequence number的特定SQL执行频率相关。 在Oracle 10g中，ORDERED Sequence还可能在高并发下造成大量DFS lock Handle 等待，由于bug 5209859 #### Library Cache Activity Library Cache Activity DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> \"Pct Misses\" should be very low Get Pct Pin Pct Invali- Namespace Requests Miss Requests Miss Reloads dations ACCOUNT_STATUS 8,436 0.3 0 N/A 0 0 BODY 8,697 0.7 15,537 0.7 49 0 CLUSTER 317 4.7 321 4.7 0 0 DBLINK 9,212 0.1 0 N/A 0 0 EDITION 4,431 0.0 8,660 0.0 0 0 HINTSET OBJECT 1,027 9.5 1,027 14.4 0 0 INDEX 792 18.2 792 18.2 0 0 QUEUE 10 0.0 1,733 0.0 0 0 RULESET 0 N/A 8 87.5 7 0 SCHEMA 8,169 0.0 0 N/A 0 0 SQL AREA 533,409 4.8 -4,246,727,944 101.1 44,864 576 SQL AREA BUILD 71,500 65.5 0 N/A 0 0 SQL AREA STATS 41,008 90.3 41,008 90.3 1 0 TABLE/PROCEDURE 320,310 0.6 1,033,991 3.6 25,378 0 TRIGGER 847 0.0 38,442 0.3 110 0 NameSpace library cache 的命名空间 GETS Requests 该命名空间所包含对象的library cache lock被申请的次数 GETHITS 对象的 library cache handle 正好在内存中被找到的次数 Pct Misses : ( 1- ( GETHITS /GETS Requests)) *100 Pin Requests 该命名空间所包含对象上pin被申请的次数 PINHITS 要pin的对象的heap metadata正好在shared pool中的次数 Pct Miss ( 1- ( PINHITS /Pin Requests)) *100 Reloads 指从object handle 被重建开始不是第一次PIN该对象的PIN ，且该次PIN要求对象从磁盘上读取加载的次数 ;Reloads值较高的情况 建议增大shared_pool_size INVALIDATIONS 由于以来对象被修改导致该命名空间所包含对象被标记为无效的次数 Library Cache Activity (RAC) DB/Inst: MAC/MAC2 Snaps: 70719-70723 GES Lock GES Pin GES Pin GES Inval GES Invali- Namespace Requests Requests Releases Requests dations ACCOUNT_STATUS 8,436 0 0 0 0 BODY 0 15,497 15,497 0 0 CLUSTER 321 321 321 0 0 DBLINK 9,212 0 0 0 0 EDITION 4,431 4,431 4,431 0 0 HINTSET OBJECT 1,027 1,027 1,027 0 0 INDEX 792 792 792 0 0 QUEUE 8 1,733 1,733 0 0 RULESET 0 8 8 0 0 SCHEMA 4,226 0 0 0 0 TABLE/PROCEDURE 373,163 704,816 704,816 0 0 TRIGGER 0 38,430 38,430 0 0 GES Lock Request: dlm_lock_requests Lock instance-lock ReQuests 申请获得lock instance lock的次数 GES PIN request : DLM_PIN_REQUESTS Pin instance-lock ReQuests 申请获得pin instance lock的次数 GES Pin Releases DLM_PIN_RELEASES release the pin instance lock 释放pin instance lock的次数 GES Inval Requests DLM_INVALIDATION_REQUESTS get the invalidation instance lock 申请获得invalidation instance lock的次数 GES Invali- dations DLM_INVALIDATIONS 接收到其他节点的invalidation pings次数 #### Process Memory Summary Process Memory Summary DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> B: Begin Snap E: End Snap -> All rows below contain absolute values (i.e. not diffed over the interval) -> Max Alloc is Maximum PGA Allocation size at snapshot time -> Hist Max Alloc is the Historical Max Allocation for still-connected processes -> ordered by Begin/End snapshot, Alloc (MB) desc Hist Avg Std Dev Max Max Alloc Used Alloc Alloc Alloc Alloc Num Num Category (MB) (MB) (MB) (MB) (MB) (MB) Proc Alloc B Other 16,062.7 N/A 6.1 66.6 3,370 3,370 2,612 2,612 SQL 5,412.2 4,462.9 2.2 89.5 4,483 4,483 2,508 2,498 Freeable 2,116.4 .0 .9 6.3 298 N/A 2,266 2,266 PL/SQL 94.0 69.8 .0 .0 1 1 2,610 2,609 E Other 15,977.3 N/A 6.1 66.9 3,387 3,387 2,616 2,616 SQL 5,447.9 4,519.0 2.2 89.8 4,505 4,505 2,514 2,503 Freeable 2,119.9 .0 .9 6.3 297 N/A 2,273 2,273 PL/SQL 93.2 69.2 .0 .0 1 1 2,614 2,613 数据来源为dba_hist_process_mem_summary， 这里是对PGA 使用的一个小结，帮助我们了解到底谁用掉了PGA B: 开始快照 E: 结束快照 该环节列出 PGA中各分类的使用量 Category 分类名，包括”SQL”, “PL/SQL”, “OLAP” 和”JAVA”. 特殊分类是 “Freeable” 和”Other”. Free memory是指哪些 OS已经分配给进程，但没有分配给任何分类的内存。 “Other”是已经分配给分类的内存，但不是已命名的分类 Alloc (MB) allocated_total 该分类被分配的总内存 Used (MB) used_total 该分类已使用的内存 Avg Alloc (MB) allocated_avg 平均每个进程中该分类分配的内存量 Std Dev Alloc (MB) ：该分类分配的内存在每个进程之间的标准差 Max　Alloc　(MB) ALLOCATED_MAX　：在快照时间内单个进程该分类最大分配过的内存量：Max Alloc is Maximum PGA Allocation size at snapshot time Hist Max Alloc (MB) MAX_ALLOCATED_MAX: 目前仍链接着的进程该分类最大分配过的内存量：Hist Max Alloc is the Historical Max Allocation for still-connected processes Num Proc num_processes 进程数目 Num Alloc NON_ZERO_ALLOCS 分配了该类型 内存的进程数目 ### SGA信息 #### SGA Memory Summary SGA Memory Summary DB/Inst: MAC/MAC2 Snaps: 70719-70723 End Size (Bytes) SGA regions Begin Size (Bytes) (if different) Database Buffers 20,669,530,112 Fixed Size 2,241,880 Redo Buffers 125,669,376 Variable Size 10,536,094,376 sum 31,333,535,744 粗粒度的sga区域内存使用信息， End Size仅在于begin size不同时打印 #### SGA breakdown difference SGA breakdown difference DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> ordered by Pool, Name -> N/A value for Begin MB or End MB indicates the size of that Pool/Name was insignificant, or zero in that snapshot Pool Name Begin MB End MB % Diff java free memory 64.0 64.0 0.00 large PX msg pool 7.8 7.8 0.00 large free memory 247.8 247.8 0.00 shared Checkpoint queue 140.6 140.6 0.00 shared FileOpenBlock 2,459.2 2,459.2 0.00 shared KGH: NO ACCESS 1,629.6 1,629.6 0.00 shared KGLH0 997.7 990.5 -0.71 shared KKSSP 312.2 308.9 -1.06 shared SQLA 376.6 370.6 -1.61 shared db_block_hash_buckets 178.0 178.0 0.00 shared dbktb: trace buffer 156.3 156.3 0.00 shared event statistics per sess 187.1 187.1 0.00 shared free memory 1,208.9 1,220.6 0.97 shared gcs resources 435.0 435.0 0.00 shared gcs shadows 320.6 320.6 0.00 shared ges enqueues 228.9 228.9 0.00 shared ges resource 118.3 118.3 0.00 shared init_heap_kfsg 1,063.6 1,068.1 0.43 shared kglsim object batch 124.3 124.3 0.00 shared ksunfy : SSO free list 174.7 174.7 0.00 stream free memory 128.0 128.0 0.00 buffer_cache 19,712.0 19,712.0 0.00 fixed_sga 2.1 2.1 0.00 log_buffer 119.8 119.8 0.00 ------------------------------------------------------------- Pool 内存池的名字 Name 内存池中细分组件的名字 例如KGLH0 存放KEL Heap 0 、SQLA存放SQL执行计划等 Begin MB 快照开始时该组件的内存大小 End MB 快照结束时该组件的内存大小 % Diff 差异百分比 特别注意 由于AMM /ASMM引起的shared pool收缩 一般在sga breakdown中可以提现 例如SQLA 、KQR等组件大幅缩小 ，可能导致一系列的解析等待 cursor: Pin S on X 、row cache lock等 此处的free memory信息也值得我们关注， 一般推荐shared pool应当有300~400 MB 的free memory为宜 ### Streams统计 Streams CPU/IO Usage DB/Inst: ORCL/orcl1 Snaps: 556-559 -> Streams processes ordered by CPU usage -> CPU and I/O Time in micro seconds Session Type CPU Time User I/O Time Sys I/O Time QMON Coordinator 101,698 0 0 QMON Slaves 63,856 0 0 Streams Capture DB/Inst: CATGT/catgt Snaps: 911-912 -> Lag Change should be small or negative (in seconds) Captured Enqueued Pct Pct Pct Pct Per Per Lag RuleEval Enqueue RedoWait Pause Capture Name Second Second Change Time Time Time Time CAPTURE_CAT 650 391 93 0 23 0 71 Streams Apply DB/Inst: CATGT/catgt Snaps: 911-912 -> Pct DB is the percentage of all DB transactions that this apply handled -> WDEP is the wait for dependency -> WCMT is the wait for commit -> RBK is rollbacks -> MPS is messages per second -> TPM is time per message in milli-seconds -> Lag Change should be small or negative (in seconds) Applied Pct Pct Pct Pct Applied Dequeue Apply Lag Apply Name TPS DB WDEP WCMT RBK MPS TPM TPM Change APPLY_CAT 0 0 0 0 0 0 0 0 0 Capture Name : Streams捕获进程名 Captured Per Second ：每秒挖掘出来的message 条数 Enqueued Per Second: 每秒入队的message条数 lag change: 指日志生成的时间到挖掘到该日志生成 message的时间延迟 Pct Enqueue Time： 入队时间的比例 Pct redoWait Time : 等待redo的时间比例 Pct Pause Time : Pause 时间的比例 Apply Name Streams 应用Apply进程的名字 Applied TPS : 每秒应用的事务数 Pct DB: 所有的DB事务中 apply处理的比例 Pct WDEP: 由于等待依赖的数据而耗费的时间比例 Pct WCMT: 由于等待commit而耗费的时间比例 Pct RBK: 事务rollback 回滚的比例 Applied MPS: 每秒应用的message 数 Dequeue TPM: 每毫秒出队的message数 Lag Change:指最新message生成的时间到其被Apply收到的延迟 ### Resource Limit Resource Limit Stats DB/Inst: MAC/MAC2 Snap: 70723 -> only rows with Current or Maximum Utilization > 80% of Limit are shown -> ordered by resource name Current Maximum Initial Resource Name Utilization Utilization Allocation Limit ges_procs 2,612 8,007 10003 10003 processes 2,615 8,011 10000 10000 据源于dba_hist_resource_limit 注意这里仅列出当前使用或最大使用量>80% *最大限制的资源名，如果没有列在这里则说明资源使用量安全 Current Utilization 当前对该资源(包括Enqueue Resource、Lock和processes)的使用量 Maximum Utilization 从最近一次实例启动到现在该资源的最大使用量 Initial Allocation 初始分配值，一般等于参数文件中指定的值 Limit 实际上限值 ### init.ora Parameters init.ora Parameters DB/Inst: MAC/MAC2 Snaps: 70719-70723 End value Parameter Name Begin value (if different) _compression_compatibility 11.2.0 _kghdsidx_count 4 _ksmg_granule_size 67108864 _shared_pool_reserved_min_all 4100 archive_lag_target 900 audit_file_dest /u01/app/oracle/admin/MAC/adum audit_trail OS cluster_database TRUE compatible 11.2.0.2.0 control_files +DATA/MAC/control01.ctl, +RECO db_16k_cache_size 268435456 db_block_size 8192 db_cache_size 19327352832 db_create_file_dest +DATA Parameter Name 参数名 Begin value 开始快照时的参数值 End value 结束快照时的参数值 (仅在发生变化时打印) ### Global Messaging Statistics Global Messaging Statistics DB/Inst: MAC/MAC2 Snaps: 70719-70723 Statistic Total per Second per Trans acks for commit broadcast(actual) 53,705 14.9 0.2 acks for commit broadcast(logical 311,182 86.1 1.3 broadcast msgs on commit(actual) 317,082 87.7 1.3 broadcast msgs on commit(logical) 317,082 87.7 1.3 broadcast msgs on commit(wasted) 263,332 72.9 1.1 dynamically allocated gcs resourc 0 0.0 0.0 dynamically allocated gcs shadows 0 0.0 0.0 flow control messages received 267 0.1 0.0 flow control messages sent 127 0.0 0.0 gcs apply delta 0 0.0 0.0 gcs assume cvt 55,541 15.4 0.2 全局通信统计信息，数据来源WRH$_DLM_MISC; ### Global CR Served Stats Global CR Served Stats DB/Inst: MAC/MAC2 Snaps: 70719-70723 Statistic Total CR Block Requests 403,703 CURRENT Block Requests 444,896 Data Block Requests 403,705 Undo Block Requests 94,336 TX Block Requests 307,896 Current Results 652,746 Private results 21,057 Zero Results 104,720 Disk Read Results 69,418 Fail Results 508 Fairness Down Converts 102,844 Fairness Clears 15,207 Free GC Elements 0 Flushes 105,052 Flushes Queued 0 Flush Queue Full 0 Flush Max Time (us) 0 Light Works 71,793 Errors 117 LMS传输CR BLOCK的统计信息，数据来源WRH$_CR_BLOCK_SERVER ### Global CURRENT Served Stats Global CURRENT Served Stats DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Pins = CURRENT Block Pin Operations -> Flushes = Redo Flush before CURRENT Block Served Operations -> Writes = CURRENT Block Fusion Write Operations Statistic Total % Pins 73,018 12.27 75.96 8.49 2.21 1.08 Flushes 79,336 5.98 50.17 14.45 19.45 9.95 Writes 102,189 3.14 35.23 19.34 33.26 9.03 数据来源dba_hist_current_block_server Time to process current block request = (pin time + flush time + send time) Pins CURRENT Block Pin Operations ， PIN的内涵是处理一个BAST 不包含对global current block的flush和实际传输 The pin time represents how much time is required to process a BAST. It does not include the flush time and the send time. The average pin time per block served should be very low because the processing consists mainly of code path and should never be blocked. Flush 指 脏块被LMS进程传输出去之前，其相关的redo必须由LGWR已经flush 到磁盘上 Write 指fusion write number of writes which were mediated； 节点之间写脏块需求相互促成的行为 KJBL.KJBLREQWRITE gcs write request msgs 、gcs writes refused % Global Cache Transfer Stats DB/Inst: MAC/MAC2 Snaps: 70719-70723 -> Immediate (Immed) - Block Transfer NOT impacted by Remote Processing Delays -> Busy (Busy) - Block Transfer impacted by Remote Contention -> Congested (Congst) - Block Transfer impacted by Remote System Load -> ordered by CR + Current Blocks Received desc CR Current ----------------------------- ----------------------------- Inst Block Blocks % % % Blocks % % % No Class Received Immed Busy Congst Received Immed Busy Congst 1 data block 133,187 76.3 22.6 1.1 233,138 75.2 23.0 1.7 4 data block 143,165 74.1 24.9 1.0 213,204 76.6 21.8 1.6 3 data block 122,761 75.9 23.0 1.1 220,023 77.7 21.0 1.3 1 undo header 104,219 95.7 3.2 1.1 941 93.4 5.8 .7 4 undo header 95,823 95.2 3.7 1.1 809 93.4 5.3 1.2 3 undo header 95,592 95.6 3.3 1.1 912 94.6 4.5 .9 1 undo block 25,002 95.8 3.4 .9 0 N/A N/A N/A 4 undo block 23,303 96.0 3.1 .9 0 N/A N/A N/A 3 undo block 21,672 95.4 3.7 .9 0 N/A N/A N/A 1 Others 1,909 92.0 6.8 1.2 6,057 89.6 8.9 1.5 4 Others 1,736 92.4 6.1 1.5 5,841 88.8 9.9 1.3 3 Others 1,500 92.4 5.9 1.7 4,405 87.7 10.8 1.6 ``` 数据来源DBA_HIST_INST_CACHE_TRANSFER Inst No 节点号 Block Class 块的类型 CR Blocks Received 该节点上 该类型CR 块的接收数量 CR Immed %: CR块请求立即接收到的比例 CR Busy%：CR块请求由于远端争用而没有立即接收到的比例 CR Congst%: CR块请求由于远端负载高而没有立即接收到的比例 Current Blocks Received 该节点上 该类型Current 块的接收数量 Current Immed %: Current块请求立即接收到的比例 Current Busy%：Current块请求由于远端争用而没有立即接收到的比例 Current Congst%: Current块请求由于远端负载高而没有立即接收到的比例 Congst%的比例应当非常低 不高于2%， Busy%很大程度受到IO的影响，如果超过10% 一般会有严重的gc buffer busy acquire/release RAC相关指标 Global Cache Load Profile   Per Second Per Transaction Global Cache blocks received: 12.06 2.23 Global Cache blocks served: 8.18 1.51 GCS/GES messages received: 391.19 72.37 GCS/GES messages sent: 368.76 68.22 DBWR Fusion writes: 0.10 0.02 Estd Interconnect traffic (KB) 310.31   指标 指标说明 Global Cache blocks received 通过硬件连接收到远程实例的数据块的数量。发生在一个进程请求一致性读一个数据块不是在本地缓存中。Oracle发送一个请求到另外的实例。一旦缓冲区收到，这个统计值就会增加。这个统计值是另两个统计值的和：Global Cache blocks received = gc current blocks received + gc cr blocks received Global Cache blocks served 通过硬件连接发送到远程实例的数据块的数量。这个统计值是另外两个统计值的和：Global Cache blocks served = gc current blocks served + gc cr blocks served GCS/GES messages received 通过硬件连接收到远程实例的消息的数量。这个统计值通常代表RAC服务引起的开销。这个统计值是另外两个统计值的和：GCS/GES messages received = gcs msgs received + ges msgs received GCS/GES messages sent 通过硬件连接发送到远程实例的消息的数量。这个统计值通常代表RAC服务引起的开销。这个统计值是另外两个统计值的和：GCS/GES messages sent = gcs messages sent + ges messages sent DBWR Fusion writes 这个统计值显示融合写入的次数。在RAC中，单实例Oracle数据库，数据块只被写入磁盘因为数据过期，缓冲替换或者发生检查点。当一个数据块在缓存中被替换因为数据过期或发生检查点但在另外的实例没有写入磁盘，Global Cache Service会请求实例将数据块写入磁盘。因此融合写入不包括在第一个实例中的额外写入磁盘。大量的融合写入表明一个持续的问题。实例产生的融合写入请求占总的写入请求的比率用于性能分析。高比率表明DB cache大小不合适或者检查点效率低。 Estd Interconnect traffic (KB) 连接传输的KB大小。计算公式如下：Estd Interconnect traffic (KB) = ((‘gc cr blocks received’+ ‘gc current blocks received’ + ‘gc cr blocksserved’+ ‘gc current blocks served’) * Block size) + ((‘gcs messages sent’ + ‘ges messages sent’ + ‘gcs msgs received’+ ‘gcs msgs received’)*200)/1024/Elapsed Time Global Cache Efficiency Percentages (Target local+remote 100%) Buffer access – local cache %: 91.05 Buffer access – remote cache %: 0.03 Buffer access – disk %: 8.92 指标 指标说明 Buffer access – local cache % 数据块从本地缓存命中占会话总的数据库请求次数的比例。在OLTP应用中最希望的是尽可能维持这个比率较高，因为这是最低成本和最快速的获得数据库数据块的方法。计算公式：Local Cache Buffer Access Ratio = 1 – ( physical reads cache + Global Cache blocks received ) / Logical Reads Buffer access – remote cache % 数据块从远程实例缓存命中占会话总的数据块请求的比例。在OLTP应用中这个比率和Buffer access – local cache的和应该尽可能的高因为这两种方法访问数据库数据块是最快速最低成本的。这个比率的计算方法：Remote Cache Buffer Access Ratio = Global Cache blocks received / Logical Reads Buffer access – disk % 从磁盘上读数据块到缓存占会话总的数据块请求次数的比例。在OLTP应用中希望维持这个比例低因为物理读是最慢的访问数据库数据块的方式。这个比率计算方法：1 – physical reads cache / Logical Reads Global Cache and Enqueue Services – Workload Characteristics Avg global enqueue get time (ms): 0.0 Avg global cache cr block receive time (ms): 0.3 Avg global cache current block receive time (ms): 0.2 Avg global cache cr block build time (ms): 0.0 Avg global cache cr block send time (ms): 0.0 Global cache log flushes for cr blocks served %: 1.2 Avg global cache cr block flush time (ms): 1.8 Avg global cache current block pin time (ms): 1,021.7 Avg global cache current block send time (ms): 0.0 Global cache log flushes for current blocks served %: 6.9 Avg global cache current block flush time (ms): 0.9 指标 指标说明 Avg global enqueue get time (ms) 通过interconnect发送消息，为争夺资源开启一个新的全局队列或者对已经开启的队列转换访问模式所花费的时间。如果大于20ms，你的系统可能会出现超时。 Avg global cache cr block receive time (ms) 从请求实例发送消息到mastering instance（2-way get）和一些到holding instance (3-way get)花费的时间。这个时间包括在holding instance生成数据块一致性读映像的时间。CR数据块获取耗费的时间不应该大于15ms。 Avg global cache current block receive time (ms) 从请求实例发送消息到mastering instance（2-way get）和一些到holding instance (3-way get)花费的时间。这个时间包括holding instance日志刷新花费的时间。Current Block获取耗费的时间不大于30ms Avg global cache cr block build time (ms) CR数据块创建耗费的时间 Avg global cache cr block send time (ms) CR数据块发送耗费的时间 Global cache log flushes for cr blocks served % 需要日志刷新的CR数据块占总的需要服务的CR数据块的比例。 Avg global cache cr block flush time (ms) CR数据块刷新耗费的时间 Avg global cache current block pin time (ms) Current数据块pin耗费的时间 Avg global cache current block send time (ms) Current数据块发送耗费的时间 Global cache log flushes for current blocks served % 需要日志刷新的Current数据块占总的需要服务的Current数据块的比例 Avg global cache current block flush time (ms) Current数据块刷新耗费的时间 Global Cache and Enqueue Services – Messaging Statistics Avg message sent queue time (ms): 2,367.6 Avg message sent queue time on ksxp (ms): 0.1 Avg message received queue time (ms): 0.3 Avg GCS message process time (ms): 0.0 Avg GES message process time (ms): 0.0 % of direct sent messages: 54.00 % of indirect sent messages: 44.96 % of flow controlled messages: 1.03 指标 指标说明 Avg message sent queue time (ms) 一条信息进入队列到发送它的时间 Avg message sent queue time on ksxp (ms) 对端收到该信息并返回ACK的时间，这个指标很重要，直接反应了网络延迟，一般小于1ms Avg message received queue time (ms) 一条信息进入队列到收到它的时间 Avg GCS message process time (ms)   Avg GES message process time (ms)   % of direct sent messages 直接发送信息占的比率 % of indirect sent messages 间接发送信息占的比率，一般是排序或大的信息，流控制也可能引起 % of flow controlled messages 流控制信息占的比率，流控制最常见的原因是网络状况不佳， % of flowcontrolled messages应当小于1% Wait Event Histogram   % of Waits Event Total Waits >1s ADR block file read 208 38.0   3.4 44.7 13.9       ADR block file write 40 100.0               ADR file lock 48 100.0               ARCH wait for archivelog lock 3 100.0               ASM file metadata operation 12.8K 99.7 .1 .0   .0 .0 .2 .0 Backup: MML write backup piece 310.5K 7.6 .1 .1 1.3 10.4 30.2 50.2 .0 CGS wait for IPC msg 141.7K 100.0               CSS initialization 34 50.0     47.1 2.9       CSS operation: action 110 48.2 20.9 28.2 2.7         CSS operation: query 102 88.2 3.9 7.8           DFS lock handle 6607 93.9 .5 .2 .0   .0 5.3 .0 Disk file operations I/O 1474 100.0               IPC send completion sync 21.9K 99.5 .1 .1 .1 .0 .2     KJC: Wait for msg sends to complete 13 100.0               LGWR wait for redo copy 16.3K 100.0 .0             Log archive I/O 3 33.3 66.7             PX Deq: Signal ACK EXT 2256 99.8 .1 .1           PX Deq: Signal ACK RSG 2124 99.9 .1 .0           PX Deq: Slave Session Stats 7997 94.6 .9 .9 2.5 .8 .4     PX Deq: Table Q qref 2355 99.9 .1             PX Deq: reap credit 1215.7K 100.0 .0 .0           PX qref latch 1366 100.0               Parameter File I/O 194 94.8 1.0   1.0 1.0   1.5 .5 Wait Event Histogram：等待时间直方图 Event：等待事件名字 Total Waits：该等待事件在快照时间内等待的次数 %of Waits %of Waits %of Waits %of Waits %of Waits %of Waits %of Waits %of Waits > 1s ：大于1s的等待次数 Parent Latch Statistics only latches with sleeps are shown ordered by name Latch Name Get Requests Misses Sleeps Spin & Sleeps 1->3+ Real-time plan statistics latch 77,840 136 20 116/0/0/0 active checkpoint queue latch 321,023 20,528 77 20451/0/0/0 active service list 339,641 546 132 424/0/0/0 call allocation 328,283 550 148 440/0/0/0 enqueues 1,503,525 217 14 203/0/0/0 ksuosstats global area 2,605 1 1 0/0/0/0 messages 2,608,863 141,380 29 141351/0/0/0 name-service request queue 155,047 43 15 28/0/0/0 qmn task queue latch 2,368 90 78 12/0/0/0 query server process 268 30 30 0/0/0/0 redo writing 910,703 11,623 50 11573/0/0/0 resmgr:free threads list 14,454 190 4 186/0/0/0 space background task latch 11,209 15 7 8/0/0/0 Latch Name：闩名称 Get Requests：申请获得父闩的次数 Child Latch Statistics only latches with sleeps/gets > 1/100000 are shown ordered by name, gets desc Latch Name Child Num Get Requests Misses Sleeps Spin & Sleeps 1->3+ KJC message pool free list 1 96,136 82 20 62/0/0/0 Lsod array latch 10 2,222 153 118 58/0/0/0 Lsod array latch 13 2,151 43 14 29/0/0/0 Lsod array latch 4 2,066 154 124 59/0/0/0 Lsod array latch 5 1,988 105 44 63/0/0/0 Lsod array latch 9 1,734 95 32 64/0/0/0 Lsod array latch 2 1,707 88 38 55/0/0/0 Lsod array latch 11 1,695 88 32 57/0/0/0 Lsod array latch 6 1,680 158 126 64/0/0/0 Lsod array latch 12 1,657 155 111 65/0/0/0 Lsod array latch 7 1,640 90 34 59/0/0/0 Lsod array latch 1 1,627 169 153 46/0/0/0 Lsod array latch 3 1,555 87 36 54/0/0/0 Lsod array latch 8 1,487 127 88 57/0/0/0 cache buffers chains 47418 354,313 391 4 387/0/0/0 cache buffers chains 8031 337,135 250 8 242/0/0/0 cache buffers chains 78358 305,022 528 9 519/0/0/0 cache buffers chains 6927 241,808 129 4 125/0/0/0 Latch Name：闩名称 Child Num： Get Requests： Misses： Sleeps： Spin&Sleeps 1->3+： Dictionary Cache Stats (RAC) Cache GES Requests GES Conflicts GES Releases dc_awr_control 11 5 0 dc_global_oids 5 0 0 dc_histogram_defs 215 1 707 dc_objects 90 9 0 dc_segments 79 10 73 dc_sequences 35,738 37 0 dc_table_scns 6 0 0 dc_tablespace_quotas 907 77 0 dc_users 10 0 0 outstanding_alerts 576 288 0 Cache：字典缓存类名 GES Requests： GES Conflicts： GES Releases： Library Cache Activity (RAC) Namespace GES Lock Requests GES Pin Requests GES Pin Releases GES Inval Requests GES Invali- dations ACCOUNT_STATUS 242 0 0 0 0 BODY 0 1,530,013 1,530,013 0 0 CLUSTER 74 74 74 0 0 DBLINK 246 0 0 0 0 EDITION 311 311 311 0 0 HINTSET OBJECT 186 186 186 0 0 INDEX 152,360 152,360 152,360 0 0 QUEUE 223 9,717 9,717 0 0 SCHEMA 255 0 0 0 0 SUBSCRIPTION 0 26 26 0 0 TABLE/PROCEDURE 275,215 3,023,083 3,023,083 0 0 TRIGGER 0 384,493 384,493 0 0 Namespace：library cache 的命名空间 GES Lock Requests： GES Pin Requests： GES Inval Requests： GES Invali-dations： Interconnect Ping Latency Stats Ping latency of the roundtrip of a message from this instance to target instances. The target instance is identified by an instance number. Average and standard deviation of ping latency is given in miliseconds for message sizes of 500 bytes and 8K. Note that latency of a message from the instance to itself is used as control, since message latency can include wait for CPU Target Instance 500B Ping Count Avg Latency 500B msg Stddev 500B msg 8K Ping Count Avg Latency 8K msg Stddev 8K msg 1 1,138 0.20 0.03 1,138 0.20 0.03 2 1,138 0.17 0.04 1,138 0.20 0.05 3 1,138 0.19 0.22 1,138 0.23 0.22 4 1,138 0.18 0.04 1,138 0.21 0.04 Target Instance：目标实例 500B Ping Count： Avg Latency 500B msg： Stddev 500B msg： 8K Ping Count： Avg Latency 8K msg： Stddev 8K msg： Interconnect Throughput by Client Throughput of interconnect usage by major consumers All throughput numbers are megabytes per second Used By Send Mbytes/sec Receive Mbytes/sec Global Cache 0.10 0.20 Parallel Query 0.02 0.06 DB Locks 0.09 0.09 DB Streams 0.00 0.00 Other 0.02 0.01 Used By：主要消费者 Send Mbytes/sec：发送Mb/每秒 Receive Mbytes/sec：接收Mb/每秒 Interconnect Device Statistics Throughput and errors of interconnect devices (at OS level) All throughput numbers are megabytes per second Device Name IP Address Public Source Send Mbytes/sec Send Errors Send Dropped Send Buffer Overrun Send Carrier Lost Receive Mbytes/sec Receive Errors Receive Dropped Receive Buffer Overrun Receive Frame Errors bondib0 192.168.10.8 NO cluster_interconnects parameter 0.00 0 0 0 0 0.00 0 0 0   Device Name：设备名称 IP Address：IP地址 Public：是否为公用网络 Source：来源 Send Mbytes/sec：发送MB/每秒 Send Errors：发送错误 Send Dropped： Send Buffer Overrun： Send Carrier Lost： Receive Mbytes/sec： Receive Errors： Receive Dropped： Receive Buffer Overrun： Receive Frame Errors： Dynamic Remastering Stats times are in seconds Affinity objects – objects mastered due to affinity at begin/end snap Name Total per Remaster Op Begin Snap End Snap remaster ops 29 1.00     remastered objects 40 1.38     replayed locks received 1,990 68.62     replayed locks sent 877 30.24     resources cleaned 0 0.00     remaster time (s) 5.0 0.17     quiesce time (s) 1.7 0.06     freeze time (s) 0.6 0.02     cleanup time (s) 0.7 0.02     replay time (s) 0.2 0.01     fixwrite time (s) 1.3 0.04     sync time (s) 0.5 0.02     affinity objects     365 367 Name： Total： Per Remaster Op： Begin Snap： End Snap： "},"数据库/Mysql/":{"url":"数据库/Mysql/","title":"Mysql","keywords":"","body":"Mysql MySQL（官方发音为/maɪ ˌɛskjuːˈɛl/“My S-Q-L”，但也经常被错误读作/maɪ ˈsiːkwəl/“My Sequel”）原本是一个开放源码的关系数据库管理系统，原开发者为瑞典的MySQL AB公司，该公司于2008年被昇阳微系统（Sun Microsystems）收购。2009年，甲骨文公司（Oracle）收购昇阳微系统公司，MySQL成为Oracle旗下产品。 MySQL在过去由于性能高、成本低、可靠性好，已经成为最流行的开源数据库，因此被广泛地应用在Internet上的中小型网站中。随着MySQL的不断成熟，它也逐渐用于更多大规模网站和应用，比如中文维基百科、Google和Facebook等网站。非常流行的开源软件组合LAMP中的“M”指的就是MySQL。 但被甲骨文公司收购后，Oracle大幅调涨MySQL商业版的售价，且甲骨文公司不再支持另一个自由软件项目OpenSolaris的发展，因此导致自由软件社群们对于Oracle是否还会持续支持MySQL社群版（MySQL之中唯一的免费版本）有所隐忧，MySQL的创始人麦克尔·维德纽斯以MySQL为基础，成立分支计划MariaDB。而原先一些使用MySQL的开源软件逐渐转向MariaDB或其它的数据库。例如中文维基百科已于2013年正式宣布将从MySQL迁移到MariaDB数据库。 特性 使用C和C++编写，并使用了多种编译器进行测试，保证源代码的可移植性。 支持AIX、BSDi、FreeBSD、HP-UX、Linux、Mac OS、Novell NetWare、NetBSD、OpenBSD、OS/2 Wrap、Solaris、Windows等多种操作系统。 为多种编程语言提供了API。这些編程语言包括C、C++、C#、VB.NET、Delphi、Eiffel、Java、Perl、PHP、Python、Ruby和Tcl等。 支持多线程，充分利用CPU资源，支持多用户。 优化的SQL查询算法，有效地提高查询速度。 既能够作为一个单独的应用程序在客户端服务器网络环境中运行，也能够作为一个程序库而嵌入到其他的软件中。 提供多语言支持，常见的编码如中文的GB 2312、BIG5，日文的Shift JIS等都可以用作数据表名和数据列名。 提供TCP/IP、ODBC和JDBC等多种数据库连接途径。 提供用于管理、检查、優化数据库操作的管理工具。 可以处理拥有上千万条记录的大型数据库。 应用 与其他的大型数据库例如Oracle、IBM DB2、MS SQL等相比，MySQL自有它的不足之处，如规模小、功能有限等，但是这丝毫也没有减少它受欢迎的程度。对于一般的个人用户和中小型企业来说，MySQL提供的功能已经绰绰有余，而且由于MySQL是开放源码软件，因此可以大大降低总体拥有成本。 2010年以前Internet上流行的网站构架方式是LAMP（Linux Apache MySQL PHP），即是用Linux作为操作系统，Apache作为Web服务器，MySQL作为数据库，PHP（部分网站也使用Perl或Python）作为服务器端脚本解释器。由于这四个软件都是开放源码软件，因此使用这种方式可以以较低的成本创建起一个稳定、免费的网站系统。MySQL加PHP的配对在互联网上的应用相比LAMP来说更为常见，并获得了“动态配对”（Dynamic Duo）的雅号，大部分Blog网站基于的WordPress系统主要运用MySQL加PHP的配对。除了LAMP之外，用于Solaris、Windows和Mac上的网站构架也分别被称为SAMP、WAMP和MAMP。 连接方式 应用程序可透过ODBC或ADO方式，经由使用MyODBC与MySQL数据库连接。 MS .Net Framework下的程序（例如：C#、VB.NET）可透过ADO.NET的方式，经由使用MySQL.Net与MySQL数据库连接。 C/C++可使用MySQL++或是直接使用MySQL内置API与MySQL数据库连接。 PHP可透过PHP的MySQLi与MySQL数据库连接，具备比MySQL模块更好的性能。另外PHP6可使用mysqlnd与MySQL数据库连接。 JAVA程序可通过JDBC方式与MySQL进行连接，MySQL官方提供了JDBC驱动程序。 可通过MySQL客户端软件与MySQL进行连接，如mysqlfront、mysqlyog、mysqlbrowser等。 javascript可以通过使用fibjs的内置mysql模块与MySQL数据库连接 "},"数据库/Mysql/Mysql之MacOS安装mysqlclient.html":{"url":"数据库/Mysql/Mysql之MacOS安装mysqlclient.html","title":"Mysql之MacOS安装mysqlclient","keywords":"","body":"Mysql之MacOS安装mysqlclient 因为Django连接mysql 需要安装mysqlclient， 但Mac安装遇到各种问题，这里记录一下，避免以后再踩坑。 1.正常情况下，安装mysqlclient ，只要执行命令： pip install mysqlclient 即可。 但Mac如果没有安装过mysql驱动， 会提示如下报错： mysql_config: command not found !!! 2.查阅官网： https://pypi.org/project/mysqlclient/ 官网介绍到，安装mysqlclient 之前，需要先安装mysql-connector-c 执行命令安装mysql-connector-c brew install mysql-connector-c 如果安装过程中出现如下pkg-config类似错误，那么说明需要安装pkg-config error: The pkg-config script could not be found or is too old. Make sure it is in your PATH or set the PKG_CONFIG environment variable to the full path to pkg-config. 下面是到官网下载pkg-config 并安装，如果没有出现上面pkg-config的错误，可以跳过这一步，直接到第3步即可 pkg-config官网 点击version 0.29.2 进行下载，下载完成后解压，进入目录顺序执行下面3步。 ./configure make make install 如果不幸， 在执行第一步的时候就出现如下错误： configure: error: Either a previously installed pkg-config or \"glib-2.0 >= 2.16\" could not be found. Please set GLIB_CFLAGS and GLIB_LIBS to the correct values or pass --with-internal-glib to configure to use the bundled copy. 则可把第一步的命令改成: ./configure --with-internal-glib 安装成功后，建议重启电脑（我没重启电脑前，还是没法安装mysql-connector-c） 安装mysql-connector-c成功后， 根据官方说明， 这东西在MacOS中居然有bug！！ 还好， 官网说明这东西还有解决版本，就是修改mysql_cofig配置文件，如果你不知道mysql_config在哪里，可以执行下面命令查找。which mysql_config 然后修改mysql_config 里面的112行，不过which mysql_config 查找处理的文件可能只是mysql_config的一个链接（macOS 俗称替身， 无法直接修改） 所以我们要找到它的原身。例如你which mysql_config 找到的路径为： /usr/local/bin/mysql_config 那么我们cd到该路径 /usr/local/bin/ 下，然后执行 ls -l 查看文件信息。 可以看到mysql_config的真实路径是在../Cellar/mysql-connector-c/6.1.11/bin/mysql_config 这样我们就可以找到它，再进行如下修改了： Change # on macOS, on or about line 112: # Create options libs=\"-L$pkglibdir\" libs=\"$libs -l \" to # Create options libs=\"-L$pkglibdir\" libs=\"$libs -lmysqlclient -lssl -lcrypto\" 修改成功后，这时候我们就可以执行安装mysqlclient了 pip install mysqlclient "},"数据库/Mysql/Mysql删除库中所有表的数据.html":{"url":"数据库/Mysql/Mysql删除库中所有表的数据.html","title":"Mysql删除库中所有表的数据","keywords":"","body":"Mysql删除库中所有表的数据 MySQL 用 truncate 命令快速清空一个数据库中的所有表。 先执行select语句生成所有truncate语句 语句格式： select CONCAT('truncate TABLE ',table_schema,'.',TABLE_NAME, ';') from INFORMATION_SCHEMA.TABLES where table_schema in ('数据库1','数据库2'); select CONCAT('truncate TABLE ',table_schema,'.',TABLE_NAME, ';') from INFORMATION_SCHEMA.TABLES where table_schema like '%_abc'; 2.整理得到的truncate语句，然后复制truncate语句到mysql命令行执行 复制truncate语句到mysql命令行执行，可以一次复制多条执行。 mysql> truncate TABLE dbname.ZONESERVICE; Query OK, 0 rows affected "},"数据库/Mysql/数据库分库分表策略和分库分表后数据的查询.html":{"url":"数据库/Mysql/数据库分库分表策略和分库分表后数据的查询.html","title":"数据库分库分表策略和分库分表后数据的查询","keywords":"","body":"数据库分库分表策略和分库分表后数据的查询 在日常的工作中，关系型数据库本身比较容易成为系统的瓶颈点，虽然读写分离能分散数据库的读写压力，但并没有分散存储压力，当数据量达到千万甚至上亿时，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在以下几个方面： 数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，性能同样会降下。 数据库文件会得很大，数据库备份和恢复需要耗时很长。 数据库文件越大，极端情况下丢失数据的风险越高。 因此，当流量越来越大时，且单机容量达到上限时，此时需要考虑对其进行切分，切分的目的就在于减少单机数据库的负担，将由多台数据库服务器一起来分担，缩短查询时间。 切分策略 数据切分分为两种方式，纵向切分和水平切分 纵向切分 常见有纵向分库纵向分表两种。 1）. 纵向分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库，做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与“微服务治理”的做法相似，每个微服务使用单独的一个数据库。 2）. 垂直分表是基于数据库中的列进行，某个表字段较多，可以新建一张扩展表，将不经常用或者字段长度较大的字段拆出到扩展表中。在字段很多的情况下，通过大表拆小表，更便于开发与维护，也能避免跨页问题，MYSQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的开销。另外，数据库以行为单位将数据加载到内存中，这样表中字段长度越短且访问频次较高，内存能加载更多的数据，命中率更高，减少磁盘IO，从而提升数据库的性能。 垂直切分的优点： 解决业务系统层面的耦合，业务清晰 与微服务的治理类似，也能对不同业务的数据进行分级管理，维护，监控，扩展等。 高并发场景下，垂直切分一定程度的提升IO，数据库连接数，单机硬件资源的瓶颈。 垂直切分的缺点 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度。 分布式事处理复杂 依然存在单表数据量过大的问题。 水平切分 当一个应用难以再细粒度的垂直切分或切分后数据量行数依然巨大，存在单库读写，存储性能瓶颈，这时候需要进行水平切分。 水平切分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。 库内分表只解决单一表数据量过大的问题，但没有将表分布到不同机器的库上，因些对于减轻mysql的压力来说帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。 水平切分优点 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力。 应用端改造较小，不需要拆分业务模块。 水平切分缺点 跨分片的事务一致性难以保证 跨库的join关联查询性能较差 数据多次扩展维度和维护量极大。 路由规则 水平切分后同一张表会出现在多个数据库或表中，每个库和表的内容不同，对于水平分表后分库后，如何知道哪条数据在哪个库里或表里，则需要路由算法进行计算，这个算法会引入一定的复杂性。 范围路由 选取有序的数据列，如时间戳作为路由的条件，不同分段分散到不同的数据库表中，以最常见的用户ID为例，路由算法可以按照1000000的范围大小进行分段，1 ~ 9999999放到数据库1的表中，10000000~199999999放到数据库2的表中，以此累推。 范围路由设计的复杂点主要体现在分段大小的选取上，分段太小会导致切分后子表数量过多增加维护复杂度，分段太大可能会导致单表依然存在性能问题，按一般大老们的经验，分段大小100W至2000W之间，具体需要根据业务选 取合适的分段大小。 范围路由的优点 可以随着数据的增加平滑地扩充新的表或库，原有的数据不需要动。 单表大小可控 使用分片字段进行范围查找时，连续分片可快速定位查询，有效避免分片查询的问题。 热点数据成为性能瓶颈，连续分片可能存在数据热点，例如按时单字段分片，有些分片存储最近时间内的数据，可能会被频繁读写，而有些历史数据则很少被查询。 hash算法 选取某个列或几个列的值进行hash运算，然后根据hash的结果分散到不同的数据库表中，以用ID为例，假如我们一开始就规划10个数据库表，路由算法可以简单地用id % 10的值来表示数据所属的数据库编号，ID为985的用户放到编号为5的子表中。ID为10086编号放到编号为6的表中。 Hash路由设计的复杂点主要体现 在初始表数量的选取上，表数量太多维护比较麻烦，表数量太小又可能导致单表性能存在问题。而用Hash路由后，增加字表数量是非常麻烦的，所有数据都要重新分布。 Hash路由的优缺点与范围路由相反，Hash路由的优点是表分布比较均匀，缺点是扩容时很麻烦，所有数据均需要重新分布。 路由配置 配置路由就是路由表，用一张独立的表来记录路由信息。同样以用户ID为例，我们新增一张ROUTER表，这个表包含table_Id两列，根据user_id就可以查询对应的修改路由表就可以了。 配置路由设计简单，使用起来非常灵活，尤其是在扩充表的时候，只需要迁移指定的数据，然后修改路由表就可以了。 其缺点就是必须多查询一次，会影响整体性能，而且路由表本身如果太大，性能会成为瓶颈点，如果我们再将路由表分库分表，则又面临一个死循环。 分库分表带来的问题 join操作 水平分表后，虽然物理上分散在多个表中，如果需要与其它表进行join查询，需要在业务代码或者数据库中间件中进行多次join查询，然后将结果合并。 COUNT（*）操作 水平分表后，某些场景下需要将这些表当作一个表来处理，那么count(*)显得没有那么容易 了。 order by 操作 分表后，数据分散到多个表中，排序操作无法在数据库中完成，只能由业务代码或数据中间件分别查询每个子表中的数据，然后汇总进行排序。 分库分表后的查询 在分表完之后显然对于数据的查询会变的比较的复杂，特别是在表的关联方面，在有些情况下根本就不能使用JOIN。 其实个人是比较鼓励将那些大的JOIN SQL拆分成几个小的SQL来查询数据。这样虽然总体的效率可能会稍稍下降（如果使用了连接池完全可以忽略），但是查询的语句变简单了，使得后续的维护带来的方便。同时也能带来比较便利的扩展。你可以感受一下有一个100行的SQL语句给你维护，和给你10个10行并且每一块都有很好的注释的SQL去维护，去帮助调优。你愿意选哪个。不管你们信不信，反正我是选第二种，而且第二种可以很好的理解业务。 上面说到要拆分JOIN，我的意思不是将每个语句都拆分。我的准则是 O(n) 次的查询。忌讳那种查出数据后通过程序循环查出结果再去数据库中查询，也就是需要 O(n*M)这种。 瞬间感觉方法论很重要有木有 ^_^。 模拟场景 场景1：购买者下订单 1、在浏览商品的时候能获得商品的 门店ID 和 商品ID，至于导购ID这里我们能以随机的形式得到（需要根据业务来确定如何获取导购ID） 2、通过导购ID获得导购的用户信息从而得到导购的数据应该放在那张分表。 3、将下单数据存入出售者的分表，和购买者的分表。 下面展示的是伪代码 -- 获得导购分表信息，和所在门店 SELECT u.table_flag AS guide_flag, ug.store_id AS store_id FROM user AS u, user_guide AS ug WHERE u.user_id = ug.user_id AND user_guide_id = 导购ID; SET autocommit=0; START TRANSACTION; -- 创建销售订单 sell_order_2 通过程序拼凑出来的 INSERT INTO sell_order_2 VALUES(order_SnowflakeID, 导购ID, 购买者ID, 订单总额, 订单状态); -- 记录此订单有哪些商品 INSERT INTO order_goods_2 VALUES(order_goods_SnowflakeID, order_SnowflakeID, 商品ID, 商品价格, 商品个数); -- 记录购买订单表 buy_order_6 购买者所在的分表，上面的是出售者所在的分表别弄混了 -- 购买者订单ID 和 出售者订单ID是一样的 INSERT INTO buy_order_6 VALUES(order_SnowflakeID, 用户ID, 导购ID) COMMIT; SET autocommit=1; 场景2：购买者浏览订单 浏览购买者订单就是比较麻烦的，因为购买者订单信息和商品信息不是在同一分表中。 1、分页查找出购买者的订单列表。 2、将订单信息返回给浏览器后，使用ajax获取每个订单的商品。 -- 获得用户的分表信息 user_id = 66 SELECT table_flag FROM user WHERE user_id=66; +------------+ | table_flag | +------------+ | 9 | +------------+ -- 获取用户订单, 这些信息值直接先返回给浏览器的 SELECT * FROM buy_order_9 WHERE user_id=66 LIMIT 0, 1; +---------------------+---------+---------------+ | buy_order_id | user_id | user_guide_id | +---------------------+---------+---------------+ | 3792111966815784961 | 66 | 1 | +---------------------+---------+---------------+ -- 获取 user_guide_id=1 用户的分表信息 SELECT u.table_flag AS guide_flag FROM user AS u, user_guide AS ug WHERE u.user_id = ug.user_id AND user_guide_id = 1; +------------+ | guide_flag | +------------+ | 2 | +------------+ -- 浏览器通过ajax获取商品信息进行展现 SELECT * FROM order_goods_2 WHERE sell_order_id = 3792111966815784961 AND user_guide_id = 1; +---------------------+---------------------+---------------------+---------------+---------+------+ | order_goods_id | sell_order_id | goods_id | user_guide_id | price | num | +---------------------+---------------------+---------------------+---------------+---------+------+ | 3792112143781859329 | 3792111966815784961 | 3792111950445416449 | 1 | 3100.00 | 2 | | 3792112160789762049 | 3792111966815784961 | 3792111951305248769 | 1 | 5810.00 | 1 | +---------------------+---------------------+---------------------+---------------+---------+------+ 从上面的试验我们可以看到原本在 '分库分表(1)--基础表介绍' 中的关联查询就能获得出订单的数据现在需要被拆为多个部分来查询(是不可避免的, 这样做也未必不是好事)。 这里说一下我们为什么要使用ajax来获取并展现 '订单商品' 的数据： 1、我们不知道 '购买订单' 的导购的分表是哪一个，因此我们需要便利查询出的每一条 '购买订单'，如果有10个订单就需要便利10次去获取对应导购是哪个分表。 2、获得分表完之后还需要通过每个分表去关联 '订单商品' 获得商品信息。 3、获得到以上信息或需要整合成一个列表返回给浏览器。 通过上面一次性把说有数据返回给浏览器的方法，会影响到用户体验，让用户觉得很慢的感觉。并且需要写复杂的逻辑，难以维护。 我们将查询时间放大，一个查是 1s 如果有10个订单 一次性完成就可能需要 11s 以上的时间才返回给浏览器。如果先将查询的订单返回给浏览器。看上去就只需要 1s就吧数据返回给浏览器了。 场景3：导购查看订单 导购也是一个普通用户, 因此一登陆系统就知道 导购ID 和 用户ID -- 获得导购的分表信息 user_id = 6, user_guide_id = 5 SELECT table_flag FROM user WHERE user_id=6; +------------+ | table_flag | +------------+ | 6 | +------------+ -- 查询订单信息 SELECT * FROM sell_order_6 WHERE user_guide_id = 5 LIMIT 0, 3; +---------------------+---------------+---------+---------+--------+ | sell_order_id | user_guide_id | user_id | price | status | +---------------------+---------------+---------+---------+--------+ | 3792112033412943873 | 5 | 10 | 5197.00 | 1 | | 3792112033429721089 | 5 | 10 | 6826.00 | 1 | | 3792112033446498305 | 5 | 10 | 5765.00 | 1 | +---------------------+---------------+---------+---------+--------+ -- 查询订单商品信息 SELECT * FROM order_goods_6 WHERE sell_order_id IN( 3792112033412943873, 3792112033429721089, 3792112033446498305 ); +---------------------+---------------------+---------------------+---------------+---------+------+ | order_goods_id | sell_order_id | goods_id | user_guide_id | price | num | +---------------------+---------------------+---------------------+---------------+---------+------+ | 3792112273532653569 | 3792112033412943873 | 3792111951800176641 | 5 | 7826.00 | 1 | | 3792112292964864001 | 3792112033412943873 | 3792111952559345665 | 5 | 3057.00 | 2 | | 3792112273545236481 | 3792112033429721089 | 3792111952660008961 | 5 | 8540.00 | 1 | | 3792112292981641217 | 3792112033429721089 | 3792111951863091201 | 5 | 8545.00 | 1 | | 3792112273566208001 | 3792112033446498305 | 3792111952110555137 | 5 | 8383.00 | 2 | | 3792112292998418433 | 3792112033446498305 | 3792111952966193153 | 5 | 3282.00 | 2 | +---------------------+---------------------+---------------------+---------------+---------+------+ 场景4：导购修改订单 -- 修改订单价格 UPDATE sell_order_6 SET price = 1000.00 WHERE sell_order_id = 3792112033412943873; 场景5：店主为店铺添加商品 添加商品只有店铺的店主有权限。然而店主也是一个普通用户。 -- 获得店主的分表信息 user_id = 1 SELECT table_flag FROM user WHERE user_id=1; +------------+ | table_flag | +------------+ | 2 | +------------+ -- 店主添加商品 INSERT INTO goods_2 VALUES(SnowflakeID, 商品名称, 商品价格, 门店ID); "},"数据库/Mysql/MYSQL显示完整的processlist中info信息.html":{"url":"数据库/Mysql/MYSQL显示完整的processlist中info信息.html","title":"MYSQL显示完整的processlist中info信息","keywords":"","body":"MYSQL显示完整的processlist中info信息 由于数据库的使用导致cpu飙升，想要查询数据库的具体什么语句导致了cpu飙升需要查看运行中的sql语句 show processlist; 如果有SUPER权限，则可以看到全部的线程，否则，只能看到自己发起的线程（这是指，当前对应的MySQL帐户运行的线程）。 mysql> show processlist; +-------+-----------+---------------------+----------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +-------+-----------+---------------------+----------+---------+------+-------+------------------+ | 19161 | test_user | 171.8.216.253:63583 | tbkttest | Sleep | 685 | | NULL | | 19164 | test_user | 171.8.216.253:63677 | tbkttest | Sleep | 297 | | NULL | | 19165 | root | localhost | tbkttest | Query | 0 | NULL | show processlist | | 19166 | root | localhost | NULL | Sleep | 36 | | NULL | +-------+-----------+---------------------+----------+---------+------+-------+------------------+ 4 rows in set (0.00 sec) id列，一个标识，你要kill一个语句的时候很有用。 user列，显示单前用户，如果不是root，这个命令就只显示你权限范围内的sql语句。 host列，显示这个语句是从哪个ip的哪个端口上发出的。可以用来追踪出问题语句的用户。 db列，显示这个进程目前连接的是哪个数据库。 command列，显示当前连接的执行的命令，一般就是休眠（sleep），查询（query），连接（connect）。 time列，此这个状态持续的时间，单位是秒。 state列，显示使用当前连接的sql语句的状态，很重要的列，后续会有所有的状态的描述，请注意，state只是语句执行中的某一个状态，一个sql语句，已查询为例，可能需要经过copying to tmp table，Sorting result，Sending data等状态才可以完成。 info列，显示这个sql语句，因为长度有限，所以长的sql语句就显示不全，但是一个判断问题语句的重要依据。 使用show processlist;但是显示info信息是不全的，导致无法看到具体查询语句； 解决方法： 1：show full processlist; 2：select * from information_schema.processlist; "},"数据库/Mysql/MySQL高性能优化实战总结.html":{"url":"数据库/Mysql/MySQL高性能优化实战总结.html","title":"MySQL高性能优化实战总结","keywords":"","body":"MySQL高性能优化实战总结 MySQL 对于很多 Linux 从业者而言，是一个非常棘手的问题，多数情况都是因为对数据库出现问题的情况和处理思路不清晰。 在进行 MySQL 的优化之前必须要了解的就是 MySQL 的查询过程，很多的查询优化工作实际上就是遵循一些原则让 MySQL 的优化器能够按照预想的合理方式运行而已。 MySQL 查询过程 优化的哲学 注：优化有风险，修改需谨慎。 优化可能带来的问题： 优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统。 优化手段本来就有很大的风险，只不过你没能力意识到和预见到。 任何的技术可以解决一个问题，但必然存在带来一个问题的风险。 对于优化来说解决问题而带来的问题，控制在可接受的范围内才是有成果。 保持现状或出现更差的情况都是失败。 优化的需求： 稳定性和业务可持续性，通常比性能更重要。 优化不可避免涉及到变更，变更就有风险。 优化使性能变好，维持和变差是等概率事件。 切记优化，应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化。 所以优化工作，是由业务需求驱使的！ 优化由谁参与？在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。 优化思路 优化什么 在数据库优化上有两个主要方面： 安全：数据可持续性。 性能：数据的高性能访问。 优化的范围有哪些 存储、主机和操作系统方面： 主机架构稳定性 I/O 规划及配置 Swap 交换分区 OS 内核参数和网络问题 应用程序方面： 应用程序稳定性 SQL 语句性能 串行访问资源 性能欠佳会话管理 这个应用适不适合用 MySQL 数据库优化方面： 内存 数据库结构（物理&逻辑. 实例配置 说明：不管是设计系统、定位问题还是优化，都可以按照这个顺序执行。 优化维度 数据库优化维度有如下四个： 硬件 系统配置 数据库表结构 SQL 及索引 优化选择： 优化成本：硬件>系统配置>数据库表结构>SQL 及索引。 优化效果：硬件 优化工具有啥 数据库层面 检查问题常用的 12 个工具： MySQL mysqladmin：MySQL 客户端，可进行管理操作 mysqlshow：功能强大的查看 shell 命令 SHOW [SESSION | GLOBAL] variables：查看数据库参数信息 SHOW [SESSION | GLOBAL] STATUS：查看数据库的状态信息 information_schema：获取元数据的方法 SHOW ENGINE INNODB STATUS：Innodb 引擎的所有状态 SHOW PROCESSLIST：查看当前所有连接的 session 状态 explain：获取查询语句的执行计划 show index：查看表的索引信息 slow-log：记录慢查询语句 mysqldumpslow：分析 slowlog 文件的工具 不常用但好用的 7 个工具： Zabbix：监控主机、系统、数据库（部署 Zabbix 监控平台. pt-query-digest：分析慢日志 MySQL slap：分析慢日志 sysbench：压力测试工具 MySQL profiling：统计数据库整体状态工具 Performance Schema：MySQL 性能状态统计的数据 workbench：管理、备份、监控、分析、优化工具（比较费资源. 数据库层面问题解决思路 一般应急调优的思路：针对突然的业务办理卡顿，无法进行正常的业务处理，需要马上解决的场景。 1、show processlist 2、explain select id ,name from stu where name='clsn'; # ALL id name age sex select id,name from stu where id=2-1 函数 结果集>30; show index from table; 3、通过执行计划判断，索引问题（有没有、合不合理. 或者语句本身问题 4、show status like '%lock%'; # 查询锁状态 kill SESSION_ID; # 杀掉有问题的session 常规调优思路 针对业务周期性的卡顿，例如在每天 10-11 点业务特别慢，但是还能够使用，过了这段时间就好了。 查看slowlog，分析slowlog，分析出查询慢的语句； 按照一定优先级，一个一个排查所有慢语句； 分析top SQL，进行explain调试，查看语句执行时间； 调整索引或语句本身。 系统层面 CPU方面：vmstat、sar top、htop、nmon、mpstat。 内存：free、ps-aux。 IO 设备（磁盘、网络. ：iostat、ss、netstat、iptraf、iftop、lsof。 vmstat 命令说明： Procs：r 显示有多少进程正在等待 CPU 时间。b 显示处于不可中断的休眠的进程数量。在等待 I/O。 Memory：swpd 显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量。 Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1 和 s0 最好是 0。 IO：每秒从设备中读入 b1 的写入到设备 b0 的数据块的数量。反映了磁盘 I/O。 System：显示了每秒发生中断的数量（in. 和上下文交换（cs. 的数量。 CPU：显示用于运行用户代码，系统代码，空闲，等待 I/O 的 CPU 时间。 iostat 命令说明： 实例命令：iostat -dk 1 5；iostat -d -k -x 5 （查看设备使用率（%util. 和响应时间（await. . 。 TPS：该设备每秒的传输次数。“一次传输”意思是“一次 I/O 请求”。多个逻辑请求可能会被合并为“一次 I/O 请求”。 iops ：硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。 \"一次传输\"请求的大小是未知的。 KB_read/s：每秒从设备（drive expressed. 读取的数据量。 KB_wrtn/s：每秒向设备（drive expressed. 写入的数据量。 KB_read：读取的总数据量。 KB_wrtn：写入的总数量数据量；这些单位都为 Kilobytes。 系统层面问题解决办法 你认为到底负载高好，还是低好呢？在实际的生产中，一般认为 CPU 只要不超过 90% 都没什么问题。当然不排除下面这些特殊情况。 CPU 负载高，IO 负载低： 内存不够 磁盘性能差 SQL 问题：去数据库层，进一步排查 SQL 问题 IO 出问题了（磁盘到临界了、raid 设计不好、raid 降级、锁、在单位时间内 TPS 过高. TPS 过高：大量的小数据 IO、大量的全表扫描 IO 负载高，CPU 负载低： 大量小的 IO 写操作 autocommit，产生大量小 IO；IO/PS，磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。 大量大的 IO 写操作：SQL 问题的几率比较大 IO和 CPU 负载都很高： 硬件不够了或 SQL 存在问题 基础优化 优化思路 定位问题点吮吸：硬件>系统>应用>数据库>架构（高可用、读写分离、分库分表. 。 处理方向：明确优化目标、性能和安全的折中、防患未然。 硬件优化 主机方面 根据数据库类型，主机 CPU 选择、内存容量选择、磁盘选择： 平衡内存和磁盘资源 随机的 I/O 和顺序的 I/O 主机 RAID 卡的 BBU（Battery Backup Unit. 关闭 CPU 的选择 CPU 的两个关键因素：核数、主频。根据不同的业务类型进行选择： CPU 密集型：计算比较多，OLTP 主频很高的 CPU、核数还要多。 IO 密集型：查询比较，OLAP 核数要多，主频不一定高的。 内存的选择 OLAP 类型数据库，需要更多内存，和数据获取量级有关。OLTP 类型数据一般内存是 CPU 核心数量的 2 倍到 4 倍，没有最佳实践。 存储方面 根据存储数据种类的不同，选择不同的存储设备，配置合理的 RAID 级别（raid5、raid10、热备盘. 。 对于操作系统来讲，不需要太特殊的选择，最好做好冗余（raid1. （ssd、sas、sata. 。 主机 raid 卡选择： 实现操作系统磁盘的冗余（raid1. 平衡内存和磁盘资源 随机的 I/O 和顺序的 I/O 主机 raid 卡的 BBU（Battery Backup Unit. 要关闭 网络设备方面 使用流量支持更高的网络设备（交换机、路由器、网线、网卡、HBA 卡. 。注意：以上这些规划应该在初始设计系统时就应该考虑好。 服务器硬件优化 服务器硬件优化关键点： 物理状态灯 自带管理设备：远程控制卡（FENCE设备：ipmi ilo idarc. 、开关机、硬件监控。 第三方的监控软件、设备（snmp、agent. 对物理设施进行监控。 存储设备：自带的监控平台。EMC2（HP 收购了. 、 日立（HDS. 、IBM 低端 OEM HDS、高端存储是自己技术，华为存储。 系统优化 CPU：基本不需要调整，在硬件选择方面下功夫即可。 内存：基本不需要调整，在硬件选择方面下功夫即可。 SWAP：MySQL 尽量避免使用 Swap。阿里云的服务器中默认 swap 为 0。 IO ：raid、no lvm、ext4 或 xfs、ssd、IO 调度策略。 Swap 调整(不使用 swap 分区)： /proc/sys/vm/swappiness的内容改成0（临时. ，/etc/sysctl. conf上添加vm.swappiness=0（永久. 这个参数决定了 Linux 是倾向于使用 Swap，还是倾向于释放文件系统 Cache。在内存紧张的情况下，数值越低越倾向于释放文件系统 Cache。 当然，这个参数只能减少使用 Swap 的概率，并不能避免 Linux 使用 Swap。 修改 MySQL 的配置参数 innodbflush method，开启 O_DIRECT 模式。 这种情况下，InnoDB 的 buffer pool 会直接绕过文件系统 Cache 来访问磁盘，但是 redo log 依旧会使用文件系统 Cache。 值得注意的是，Redo log 是覆写模式的，即使使用了文件系统的 Cache，也不会占用太多。 IO 调度策略： #echo deadline>/sys/block/sda/queue/scheduler 临时修改为deadline 永久修改： vi /boot/grub/grub.conf 更改到如下内容: kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet 系统参数调整 Linux 系统内核参数优化： vim/etc/sysctl.conf net.ipv4.ip_local_port_range = 1024 65535：# 用户端口范围 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_fin_timeout = 30 fs.file-max=65535：# 系统最大文件句柄，控制的是能打开文件最大数量 用户限制参数（MySQL 可以不设置以下配置. ： vim/etc/security/limits.conf * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535 应用优化 业务应用和数据库应用独立。 防火墙：iptables、selinux 等其他无用服务（关闭. ： chkconfig --level 23456 acpid off chkconfig --level 23456 anacron off chkconfig --level 23456 autofs off chkconfig --level 23456 avahi-daemon off chkconfig --level 23456 bluetooth off chkconfig --level 23456 cups off chkconfig --level 23456 firstboot off chkconfig --level 23456 haldaemon off chkconfig --level 23456 hplip off chkconfig --level 23456 ip6tables off chkconfig --level 23456 iptables off chkconfig --level 23456 isdn off chkconfig --level 23456 pcscd off chkconfig --level 23456 sendmail off chkconfig --level 23456 yum-updatesd off 安装图形界面的服务器不要启动图形界面 runlevel 3。 另外，思考将来我们的业务是否真的需要 MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。 数据库优化 SQL 优化方向： 执行计划 索引 SQL 改写 架构优化方向： 高可用架构 高性能架构 分库分表 数据库参数优化 ①调整 实例整体（高级优化，扩展. ： thread_concurrency：# 并发线程数量个数 sort_buffer_size：# 排序缓存 read_buffer_size：# 顺序读取缓存 read_rnd_buffer_size：# 随机读取缓存 key_buffer_size：# 索引缓存 thread_cache_size：# (1G—>8, 2G—>16, 3G—>32, >3G—>64) ②连接层（基础优化. 设置合理的连接客户和连接方式： max_connections # 最大连接数，看交易笔数设置 max_connect_errors # 最大错误连接数，能大则大 connect_timeout # 连接超时 max_user_connections # 最大用户连接数 skip-name-resolve # 跳过域名解析 wait_timeout # 等待超时 back_log # 可以在堆栈中的连接数量 ③SQL 层（基础优化. query_cache_size： 查询缓存 >>> OLAP 类型数据库，需要重点加大此内存缓存，但是一般不会超过 GB。 对于经常被修改的数据，缓存会马上失效。我们可以使用内存数据库（redis、memecache. ，替代它的功能。 存储引擎层优化 innodb 基础优化参数： default-storage-engine innodb_buffer_pool_size # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70% innodb_file_per_table=(1,0) innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中 binlog_sync Innodb_flush_method=(O_DIRECT, fdatasync) innodb_log_buffer_size # 100M以下 innodb_log_file_size # 100M 以下 innodb_log_files_in_group # 5个成员以下,一般2-3个够用（iblogfile0-N. innodb_max_dirty_pages_pct # 达到百分之75的时候刷写 内存脏页到磁盘。 log_bin max_binlog_cache_size # 可以不设置 max_binlog_size # 可以不设置 innodb_additional_mem_pool_size #小于2G内存的机器，推荐值是20M。32G内存以上100M "},"数据库/Mysql/数据库原理.html":{"url":"数据库/Mysql/数据库原理.html","title":"数据库原理","keywords":"","body":"数据库原理 一提到关系型数据库，我禁不住想：有些东西被忽视了。关系型数据库无处不在，而且种类繁多，从小巧实用的 SQLite 到强大的 Teradata 。但很少有文章讲解数据库是如何工作的。 现在如果你查找最近时髦的技术（大数据、NoSQL或JavaScript），你能找到更多深入探讨它们如何工作的文章。 作为一个开发人员，我不喜欢用我不明白的东西。而且，数据库已经使用了40年之久，一定有理由的。多年以来，我花了成百上千个小时来真正领会这些我每天都在用的、古怪的黑盒子。关系型数据库非常有趣，因为它们是基于实用而且可复用的概念。如果你对了解一个数据库感兴趣，但是从未有时间或意愿来刻苦钻研这个内容广泛的课题，你应该喜欢这篇文章。 虽然本文标题很明确，但我的目的并不是讲如何使用数据库。因此，你应该已经掌握怎么写一个简单的 join query（联接查询）和CRUD操作（创建读取更新删除），否则你可能无法理解本文。这是唯一需要你了解的，其他的由我来讲解。 我会从一些计算机科学方面的知识谈起，比如时间复杂度。我知道有些人讨厌这个概念，但是没有它你就不能理解数据库内部的巧妙之处。由于这是个很大的话题，我将集中探讨我认为必要的内容：数据库处理SQL查询的方式。我仅仅介绍数据库背后的基本概念，以便在读完本文后你会对底层到底发生了什么有个很好的了解。 由于本文是个长篇技术文章，涉及到很多算法和数据结构知识，你尽可以慢慢读。有些概念比较难懂，你可以跳过，不影响理解整体内容。 这篇文章大约分为3个部分： 底层和上层数据库组件概况 查询优化过程概况 事务和缓冲池管理概况 回到基础 很久很久以前（在一个遥远而又遥远的星系……)，开发者必须确切地知道他们的代码需要多少次运算。他们把算法和数据结构牢记于心，因为他们的计算机运行缓慢，无法承受对CPU和内存的浪费。 在这一部分，我将提醒大家一些这类的概念，因为它们对理解数据库至关重要。我还会介绍数据库索引的概念。 O(1) vs O(n^2) 现今很多开发者不关心时间复杂度……他们是对的。 但是当你应对大量的数据（我说的可不只是成千上万哈）或者你要争取毫秒级操作，那么理解这个概念就很关键了。而且你猜怎么着，数据库要同时处理这两种情景！我不会占用你太长时间，只要你能明白这一点就够了。这个概念在下文会帮助我们理解什么是基于成本的优化。 概念 时间复杂度用来检验某个算法处理一定量的数据要花多长时间。为了描述这个复杂度，计算机科学家使用数学上的『简明解释算法中的大O符号』。这个表示法用一个函数来描述算法处理给定的数据需要多少次运算。 比如，当我说『这个算法是适用 O(某函数())』，我的意思是对于某些数据，这个算法需要 某函数(数据量) 次运算来完成。 重要的不是数据量，而是当数据量增加时运算如何增加。时间复杂度不会给出确切的运算次数，但是给出的是一种理念。 图中可以看到不同类型的复杂度的演变过程，我用了对数尺来建这个图。具体点儿说，数据量以很快的速度从1条增长到10亿条。我们可得到如下结论： 绿：O(1)或者叫常数阶复杂度，保持为常数（要不人家就不会叫常数阶复杂度了）。 红：O(log(n))对数阶复杂度，即使在十亿级数据量时也很低。 粉：最糟糕的复杂度是 O(n^2)，平方阶复杂度，运算数快速膨胀。 黑和蓝：另外两种复杂度（的运算数也是）快速增长。 例子 数据量低时，O(1) 和 O(n^2)的区别可以忽略不计。比如，你有个算法要处理2000条元素。 O(1) 算法会消耗 1 次运算 O(log(n)) 算法会消耗 7 次运算 O(n) 算法会消耗 2000 次运算 O(n*log(n)) 算法会消耗 14,000 次运算 O(n^2) 算法会消耗 4,000,000 次运算 O(1) 和 O(n^2) 的区别似乎很大（4百万）,但你最多损失 2 毫秒，只是一眨眼的功夫。确实，当今处理器每秒可处理上亿次的运算。这就是为什么性能和优化在很多IT项目中不是问题。 我说过，面临海量数据的时候，了解这个概念依然很重要。如果这一次算法需要处理 1,000,000 条元素（这对数据库来说也不算大）。 O(1) 算法会消耗 1 次运算 O(log(n)) 算法会消耗 14 次运算 O(n) 算法会消耗 1,000,000 次运算 O(n*log(n)) 算法会消耗 14,000,000 次运算 O(n^2) 算法会消耗 1,000,000,000,000 次运算 我没有具体算过，但我要说，用O(n^2) 算法的话你有时间喝杯咖啡（甚至再续一杯！）。如果在数据量后面加个0，那你就可以去睡大觉了。 继续深入 为了让你能明白 搜索一个好的哈希表会得到 O(1) 复杂度 搜索一个均衡的树会得到 O(log(n)) 复杂度 搜索一个阵列会得到 O(n) 复杂度 最好的排序算法具有 O(n*log(n)) 复杂度 糟糕的排序算法具有 O(n^2) 复杂度 注：在接下来的部分，我们将会研究这些算法和数据结构。 有多种类型的时间复杂度 一般情况场景 最佳情况场景 最差情况场景 时间复杂度经常处于最差情况场景。 这里我只探讨时间复杂度，但复杂度还包括： 算法的内存消耗 算法的磁盘 I/O 消耗 当然还有比 n^2 更糟糕的复杂度，比如： n^4：差劲！我将要提到的一些算法具备这种复杂度。 3^n：更差劲！本文中间部分研究的一些算法中有一个具备这种复杂度（而且在很多数据库中还真的使用了）。 阶乘 n：你永远得不到结果，即便在少量数据的情况下。 n^n：如果你发展到这种复杂度了，那你应该问问自己IT是不是你的菜。 注：我并没有给出『大O表示法』的真正定义，只是利用这个概念。 合并排序 当你要对一个集合排序时你怎么做？什么？调用 sort() 函数……好吧，算你对了……但是对于数据库，你需要理解这个 sort() 函数的工作原理。 优秀的排序算法有好几个，我侧重于最重要的一种：合并排序。你现在可能还不了解数据排序有什么用，但看完查询优化部分后你就会知道了。再者，合并排序有助于我们以后理解数据库常见的联接操作，即合并联接 。 合并 与很多有用的算法类似，合并排序基于这样一个技巧：将 2 个大小为 N/2 的已排序序列合并为一个 N 元素已排序序列仅需要 N 次操作。这个方法叫做合并。 我们用个简单的例子来看看这是什么意思： 通过此图你可以看到，在 2 个 4元素序列里你只需要迭代一次，就能构建最终的8元素已排序序列，因为两个4元素序列已经排好序了： 1) 在两个序列中，比较当前元素（当前=头一次出现的第一个） 2) 然后取出最小的元素放进8元素序列中 3) 找到（两个）序列的下一个元素，(比较后)取出最小的 重复1、2、3步骤，直到其中一个序列中的最后一个元素 然后取出另一个序列剩余的元素放入8元素序列中。 这个方法之所以有效，是因为两个4元素序列都已经排好序，你不需要再『回到』序列中查找比较。 既然我们明白了这个技巧，下面就是我的合并排序伪代码。 array mergeSort(array a) if(length(a)==1) return a[0]; end if //recursive calls [left_array right_array] := split_into_2_equally_sized_arrays(a); array new_left_array := mergeSort(left_array); array new_right_array := mergeSort(right_array); //merging the 2 small ordered arrays into a big one array result := merge(new_left_array,new_right_array); return result; 合并排序是把问题拆分为小问题，通过解决小问题来解决最初的问题（注：这种算法叫分治法，即『分而治之、各个击破』）。如果你不懂，不用担心，我第一次接触时也不懂。如果能帮助你理解的话，我认为这个算法是个两步算法： 拆分阶段，将序列分为更小的序列 排序阶段，把小的序列合在一起（使用合并算法）来构成更大的序列拆分阶段 在拆分阶段过程中，使用3个步骤将序列分为一元序列。步骤数量的值是 log(N) （因为 N=8, log(N)=3）。 我怎么知道这个的？ 我是天才！一句话：数学。道理是每一步都把原序列的长度除以2，步骤数就是你能把原序列长度除以2的次数。这正好是对数的定义（在底数为2时）。 排序阶段 在排序阶段，你从一元序列开始。在每一个步骤中，你应用多次合并操作，成本一共是 N=8 次运算。 第一步，4 次合并，每次成本是 2 次运算。 第二步，2 次合并，每次成本是 4 次运算。 第三步，1 次合并，成本是 8 次运算。 因为有 log(N) 个步骤，整体成本是 N*log(N) 次运算。 合并排序的强大之处 为什么这个算法如此强大？ 因为： 你可以更改算法，以便于节省内存空间，方法是不创建新的序列而是直接修改输入序列。 注：这种算法叫『原地算法』(in-place algorithm) 你可以更改算法，以便于同时使用磁盘空间和少量内存而避免巨量磁盘 I/O。方法是只向内存中加载当前处理的部分。在仅仅100MB的内存缓冲区内排序一个几个GB的表时，这是个很重要的技巧。 注：这种算法叫『外部排序』(external sorting)。 你可以更改算法，以便于在 多处理器/多线程/多服务器 上运行。 比如，分布式合并排序是Hadoop（那个著名的大数据框架）的关键组件之一。 这个算法可以点石成金（事实如此！）这个排序算法在大多数（如果不是全部的话）数据库中使用，但是它并不是唯一算法。 阵列，树和哈希表 既然我们已经了解了时间复杂度和排序背后的理念，我必须要向你介绍3种数据结构了。这个很重要，因为它们是现代数据库的支柱。我还会介绍数据库索引的概念。 阵列 二维阵列是最简单的数据结构。一个表可以看作是个阵列，比如： 这个二维阵列是带有行与列的表： 每个行代表一个主体 列用来描述主体的特征 每个列保存某一种类型对数据（整数、字符串、日期……） 虽然用这个方法保存和视觉化数据很棒，但是当你要查找特定的值它就很糟糕了。 举个例子，如果你要找到所有在 UK 工作的人，你必须查看每一行以判断该行是否属于 UK 。这会造成 N 次运算的成本（N 等于行数），还不赖嘛，但是有没有更快的方法呢？这时候树就可以登场了（或开始起作用了）。 树和数据库索引 二叉查找树是带有特殊属性的二叉树，每个节点的关键字必须： 比保存在左子树的任何键值都要大 比保存在右子树的任何键值都要小概念 这个树有 N=15 个元素。比方说我要找208： 我从键值为 136 的根开始，因为 136 398>208，所以我去找节点398的左子树 250>208，所以我去找节点250的左子树 200 现在比方说我要找40 我从键值为136的根开始，因为 136>40，所以我去找节点136的左子树。 80>40，所以我去找节点 80 的左子树 40=40，节点存在。我抽取出节点内部行的ID（图中没有画）再去表中查找对应的 ROW ID。 知道 ROW ID我就知道了数据在表中对精确位置，就可以立即获取数据。 最后，两次查询的成本就是树内部的层数。如果你仔细阅读了合并排序的部分，你就应该明白一共有 log(N)层。所以这个查询的成本是 log(N)，不错啊！ 回到我们的问题 上文说的很抽象，我们回来看看我们的问题。这次不用傻傻的数字了，想象一下前表中代表某人的国家的字符串。假设你有个树包含表中的列『country』： 如果你想知道谁在 UK 工作 你在树中查找代表 UK 的节点 在『UK 节点』你会找到 UK 员工那些行的位置 这次搜索只需 log(N) 次运算，而如果你直接使用阵列则需要 N 次运算。你刚刚想象的就是一个数据库索引。 B+树索引 查找一个特定值这个树挺好用，但是当你需要查找两个值之间的多个元素时，就会有大麻烦了。你的成本将是 O(N)，因为你必须查找树的每一个节点，以判断它是否处于那 2 个值之间（例如，对树使用中序遍历）。而且这个操作不是磁盘I/O有利的，因为你必须读取整个树。我们需要找到高效的范围查询方法。为了解决这个问题，现代数据库使用了一种修订版的树，叫做B+树。在一个B+树里： 只有最底层的节点（叶子节点）才保存信息（相关表的行位置） 其它节点只是在搜索中用来指引到正确节点的。 你可以看到，节点更多了（多了两倍）。确实，你有了额外的节点，它们就是帮助你找到正确节点的『决策节点』（正确节点保存着相关表中行的位置）。但是搜索复杂度还是在 O(log(N))（只多了一层）。一个重要的不同点是，最底层的节点是跟后续节点相连接的。 用这个 B+树，假设你要找40到100间的值： 你只需要找 40（若40不存在则找40之后最贴近的值），就像你在上一个树中所做的那样。 然后用那些连接来收集40的后续节点，直到找到100。 比方说你找到了 M 个后续节点，树总共有 N 个节点。对指定节点的搜索成本是 log(N)，跟上一个树相同。但是当你找到这个节点，你得通过后续节点的连接得到 M 个后续节点，这需要 M 次运算。那么这次搜索只消耗了 M+log(N) 次运算，区别于上一个树所用的 N 次运算。此外，你不需要读取整个树（仅需要读 M+log(N) 个节点）,这意味着更少的磁盘访问。如果 M 很小（比如 200 行）并且 N 很大（1,000,000），那结果就是天壤之别了。 然而还有新的问题（又来了！）。如果你在数据库中增加或删除一行（从而在相关的 B+树索引里）： 你必须在B+树中的节点之间保持顺序，否则节点会变得一团糟，你无法从中找到想要的节点。 你必须尽可能降低B+树的层数，否则 O(log(N)) 复杂度会变成 O(N)。 换句话说，B+树需要自我整理和自我平衡。谢天谢地，我们有智能删除和插入。但是这样也带来了成本：在B+树中，插入和删除操作是 O(log(N)) 复杂度。所以有些人听到过使用太多索引不是个好主意这类说法。没错，你减慢了快速插入/更新/删除表中的一个行的操作，因为数据库需要以代价高昂的每索引 O(log(N)) 运算来更新表的索引。再者，增加索引意味着给事务管理器带来更多的工作负荷（在本文结尾我们会探讨这个管理器）。 哈希表 我们最后一个重要的数据结构是哈希表。当你想快速查找值时，哈希表是非常有用的。而且，理解哈希表会帮助我们接下来理解一个数据库常见的联接操作，叫做『哈希联接』。这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池，我们在下文会研究这两个概念）。 哈希表这种数据结构可以用关键字来快速找到一个元素。为了构建一个哈希表，你需要定义： 元素的关键字 关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。 关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。 一个简单的例子 我们来看一个形象化的例子： 这个哈希表有10个哈希桶。因为我懒，我只给出5个桶，但是我知道你很聪明，所以我让你想象其它的5个桶。我用的哈希函数是关键字对10取模，也就是我只保留元素关键字的最后一位，用来查找它的哈希桶： 如果元素最后一位是 0，则进入哈希桶0， 如果元素最后一位是 1，则进入哈希桶1， 如果元素最后一位是 2，则进入哈希桶2， …我用的比较函数只是判断两个整数是否相等。 比方说你要找元素 78： 哈希表计算 78 的哈希码，等于 8。 查找哈希桶 8，找到的第一个元素是 78。 返回元素 78。 查询仅耗费了 2 次运算（1次计算哈希值，另一次在哈希桶中查找元素）。 现在，比方说你要找元素 59： 哈希表计算 59 的哈希码，等于9。 查找哈希桶 9，第一个找到的元素是 99。因为 99 不等于 59， 那么 99 不是正确的元素。 用同样的逻辑，查找第二个元素(9)，第三个(79)，……，最后一个(29)。 元素不存在。 搜索耗费了 7 次运算。 一个好的哈希函数 你可以看到，根据你查找的值，成本并不相同。 如果我把哈希函数改为关键字对 1,000,000 取模（就是说取后6位数字），第二次搜索只消耗一次运算，因为哈希桶 00059 里面没有元素。真正的挑战是找到好的哈希函数，让哈希桶里包含非常少的元素。 在我的例子里，找到一个好的哈希函数很容易，但这是个简单的例子。当关键字是下列形式时，好的哈希函数就更难找了： 1 个字符串（比如一个人的姓） 2 个字符串（比如一个人的姓和名） 2 个字符串和一个日期（比如一个人的姓、名和出生年月日） … 如果有了好的哈希函数，在哈希表里搜索的时间复杂度是 O(1)。 阵列 vs 哈希表 为什么不用阵列呢？ 嗯，你问得好。 一个哈希表可以只装载一半到内存，剩下的哈希桶可以留在硬盘上。 用阵列的话，你需要一个连续内存空间。如果你加载一个大表，很难分配足够的连续内存空间。 用哈希表的话，你可以选择你要的关键字（比如，一个人的国家和姓氏）。 全局概览 我们已经了解了数据库内部的基本组件，现在我们需要回来看看数据库的全貌了。 数据库是一个易于访问和修改的信息集合。不过简单的一堆文件也能达到这个效果。事实上，像SQLite这样最简单的数据库也只是一堆文件而已，但SQLite是精心设计的一堆文件，因为它允许你： 使用事务来确保数据的安全和一致性 快速处理百万条以上的数据 数据库一般可以用如下图形来理解： 撰写这部分之前，我读过很多书/论文，它们都以自己的方式描述数据库。所以，我不会特别关注如何组织数据库或者如何命名各种进程，因为我选择了自己的方式来描述这些概念以适应本文。区别就是不同的组件，总体思路为：数据库是由多种互相交互的组件构成的。 核心组件： 进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。 网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。 文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。 内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。 安全管理器（Security Manager）：用于对用户的验证和授权。 客户端管理器（Client manager）：用于管理客户端连接。 …… 工具： 备份管理器（Backup manager）：用于保存和恢复数据。 复原管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。 监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。 Administration管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。【译者注：好吧，我真的不知道Administration manager该翻译成什么，有知道的麻烦告知，不胜感激……】 …… 查询管理器： 查询解析器（Query parser）：用于检查查询是否合法 查询重写器（Query rewriter）：用于预优化查询 查询优化器（Query optimizer）：用于优化查询 查询执行器（Query executor）：用于编译和执行查询 数据管理器： 事务管理器（Transaction manager）：用于处理事务 缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存 数据访问管理器（Data access manager）：访问磁盘中的数据 在本文剩余部分，我会集中探讨数据库如何通过如下进程管理SQL查询的： 客户端管理器 查询管理器 数据管理器（含复原管理器）客户端管理器 客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。 客户端管理器也提供专有的数据库访问API。 当你连接到数据库时： 管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。这些权限由DBA分配。 然后，管理器检查是否有空闲进程（或线程）来处理你对查询。 管理器还会检查数据库是否负载很重。 管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。 然后管理器会把你的查询送给查询管理器来处理。 因为查询处理进程不是『不全则无』的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。 如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。查询管理器 这部分是数据库的威力所在，在这部分里，一个写得糟糕的查询可以转换成一个快速执行的代码，代码执行的结果被送到客户端管理器。这个多步骤操作过程如下： 查询首先被解析并判断是否合法 然后被重写，去除了无用的操作并且加入预优化部分 接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。 然后计划被编译 最后，被执行查询解析器 每一条SQL语句都要送到解析器来检查语法，如果你的查询有错，解析器将拒绝该查询。比如，如果你写成”SLECT …” 而不是 “SELECT …”，那就没有下文了。 但这还不算完，解析器还会检查关键字是否使用正确的顺序，比如 WHERE 写在 SELECT 之前会被拒绝。 然后，解析器要分析查询中的表和字段，使用数据库元数据来检查： 表是否存在 表的字段是否存在 对某类型字段的 运算 是否 可能（比如，你不能将整数和字符串进行比较，你不能对一个整数使用 substring() 函数） 接着，解析器检查在查询中你是否有权限来读取（或写入）表。再强调一次：这些权限由DBA分配。 在解析过程中，SQL 查询被转换为内部表示（通常是一个树）。 如果一切正常，内部表示被送到查询重写器。 查询重写器 在这一步，我们已经有了查询的内部表示，重写器的目标是： 预优化查询 避免不必要的运算 帮助优化器找到合理的最佳解决方案 重写器按照一系列已知的规则对查询执行检测。如果查询匹配一种模式的规则，查询就会按照这条规则来重写。下面是（可选）规则的非详尽的列表： 视图合并：如果你在查询中使用视图，视图就会转换为它的 SQL 代码。 子查询扁平化：子查询是很难优化的，因此重写器会尝试移除子查询 例如： MySQL SELECT PERSON.* FROM PERSON WHERE PERSON.person_key IN (SELECT MAILS.person_key FROM MAILS WHERE MAILS.mail LIKE 'christophe%'); 会转换为: SELECT PERSON.* FROM PERSON, MAILS WHERE PERSON.person_key = MAILS.person_key and MAILS.mail LIKE 'christophe%'; 去除不必要的运算符：比如，如果你用了 DISTINCT，而其实你有 UNIQUE 约束（这本身就防止了数据出现重复），那么 DISTINCT 关键字就被去掉了。 排除冗余的联接：如果相同的 JOIN 条件出现两次，比如隐藏在视图中的 JOIN 条件，或者由于传递性产生的无用 JOIN，都会被消除。 常数计算赋值：如果你的查询需要计算，那么在重写过程中计算会执行一次。比如 WHERE AGE > 10+2 会转换为 WHERE AGE > 12 ， TODATE(“日期字符串”) 会转换为 datetime 格式的日期值。 （高级）分区裁剪（Partition Pruning）：如果你用了分区表，重写器能够找到需要使用的分区。 （高级）物化视图重写（Materialized view rewrite）：如果你有个物化视图匹配查询谓词的一个子集，重写器将检查视图是否最新并修改查询，令查询使用物化视图而不是原始表。 （高级）自定义规则：如果你有自定义规则来修改查询（就像 Oracle policy），重写器就会执行这些规则。 （高级）OLAP转换：分析/加窗 函数，星形联接，ROLLUP 函数……都会发生转换（但我不确定这是由重写器还是优化器来完成，因为两个进程联系很紧，必须看是什么数据库）。 重写后的查询接着送到优化器，这时候好玩的就开始了。 统计 研究数据库如何优化查询之前我们需要谈谈统计，因为没有统计的数据库是愚蠢的。除非你明确指示，数据库是不会分析自己的数据的。没有分析会导致数据库做出（非常）糟糕的假设。 但是，数据库需要什么类型的信息呢？ 我必须（简要地）谈谈数据库和操作系统如何保存数据。两者使用的最小单位叫做页或块（默认 4 或 8 KB）。这就是说如果你仅需要 1KB，也会占用一个页。要是页的大小为 8KB，你就浪费了 7KB。 回来继续讲统计！ 当你要求数据库收集统计信息，数据库会计算下列值： 表中行和页的数量 表中每个列中的： 唯一值 数据长度（最小，最大，平均） 数据范围（最小，最大，平均） 表的索引信息 这些统计信息会帮助优化器估计查询所需的磁盘 I/O、CPU、和内存使用 对每个列的统计非常重要。 比如，如果一个表 PERSON 需要联接 2 个列： LAST_NAME, FIRST_NAME。 根据统计信息，数据库知道FIRST_NAME只有 1,000 个不同的值，LAST_NAME 有 1,000,000 个不同的值。 因此，数据库就会按照 LAST_NAME, FIRST_NAME 联接。 因为 LAST_NAME 不大可能重复，多数情况下比较 LAST_NAME 的头 2 、 3 个字符就够了，这将大大减少比较的次数。 不过，这些只是基本的统计。你可以让数据库做一种高级统计，叫直方图。直方图是列值分布情况的统计信息。例如： 出现最频繁的值 分位数 … 这些额外的统计会帮助数据库找到更佳的查询计划，尤其是对于等式谓词（例如： WHERE AGE = 18 ）或范围谓词（例如： WHERE AGE > 10 and AGE 统计信息保存在数据库元数据内，例如（非分区）表的统计信息位置： Oracle： USER / ALL / DBA_TABLES 和 USER / ALL / DBA_TAB_COLUMNS DB2： SYSCAT.TABLES 和 SYSCAT.COLUMNS 统计信息必须及时更新。如果一个表有 1,000,000 行而数据库认为它只有 500 行，没有比这更糟糕的了。统计唯一的不利之处是需要时间来计算，这就是为什么数据库大多默认情况下不会自动计算统计信息。数据达到百万级时统计会变得困难，这时候，你可以选择仅做基本统计或者在一个数据库样本上执行统计。 举个例子，我参与的一个项目需要处理每表上亿条数据的库，我选择只统计10%，结果造成了巨大的时间消耗。本例证明这是个糟糕的决定，因为有时候 Oracle 10G 从特定表的特定列中选出的 10% 跟全部 100% 有很大不同（对于拥有一亿行数据的表，这种情况极少发生）。这次错误的统计导致了一个本应 30 秒完成的查询最后执行了 8 个小时，查找这个现象根源的过程简直是个噩梦。这个例子显示了统计的重要性。 注：当然了，每个数据库还有其特定的更高级的统计。如果你想了解更多信息，读读数据库的文档。话虽然这么说，我已经尽力理解统计是如何使用的了，而且我找到的最好的官方文档来自PostgreSQL。 查询优化器 所有的现代数据库都在用基于成本的优化（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。 为了理解成本优化器的原理，我觉得最好用个例子来『感受』一下这个任务背后的复杂性。这里我将给出联接 2 个表的 3 个方法，我们很快就能看到即便一个简单的联接查询对于优化器来说都是个噩梦。之后，我们会了解真正的优化器是怎么做的。 对于这些联接操作，我会专注于它们的时间复杂度，但是，数据库优化器计算的是它们的 CPU 成本、磁盘 I/O 成本、和内存需求。时间复杂度和 CPU 成本的区别是，时间成本是个近似值（给我这样的懒家伙准备的）。而 CPU 成本，我这里包括了所有的运算，比如：加法、条件判断、乘法、迭代……还有呢： 每一个高级代码运算都要特定数量的低级 CPU 运算。 对于 Intel Core i7、Intel Pentium 4、AMD Opteron…等，（就 CPU 周期而言）CPU 的运算成本是不同的，也就是说它取决于 CPU 的架构。 使用时间复杂度就容易多了（至少对我来说），用它我也能了解到 CBO 的概念。由于磁盘 I/O 是个重要的概念，我偶尔也会提到它。请牢记，大多数时候瓶颈在于磁盘 I/O 而不是 CPU 使用。 索引 在研究 B+树的时候我们谈到了索引，要记住一点，索引都是已经排了序的。 仅供参考：还有其他类型的索引，比如位图索引，在 CPU、磁盘I/O、和内存方面与B+树索引的成本并不相同。 另外，很多现代数据库为了改善执行计划的成本，可以仅为当前查询动态地生成临时索引。 存取路径 在应用联接运算符（join operators）之前，你首先需要获得数据。以下就是获得数据的方法。 注：由于所有存取路径的真正问题是磁盘 I/O，我不会过多探讨时间复杂度。 全扫描 如果你读过执行计划，一定看到过『全扫描』（或只是『扫描』）一词。简单的说全扫描就是数据库完整的读一个表或索引。就磁盘 I/O 而言，很明显全表扫描的成本比索引全扫描要高昂。 范围扫描 其他类型的扫描有索引范围扫描，比如当你使用谓词 ” WHERE AGE > 20 AND AGE 20 AND AGE 唯一扫描 如果你只需要从索引中取一个值你可以用唯一扫描。 根据 ROW ID 存取 多数情况下，如果数据库使用索引，它就必须查找与索引相关的行，这样就会用到根据 ROW ID 存取的方式。 例如，假如你运行： SELECT LASTNAME, FIRSTNAME from PERSON WHERE AGE = 28 如果 person 表的 age 列有索引，优化器会使用索引找到所有年龄为 28 的人，然后它会去表中读取相关的行，这是因为索引中只有 age 的信息而你要的是姓和名。 但是，假如你换个做法： SELECT TYPE_PERSON.CATEGORY from PERSON ,TYPE_PERSON WHERE PERSON.AGE = TYPE_PERSON.AGE PERSON 表的索引会用来联接 TYPE_PERSON 表，但是 PERSON 表不会根据行ID 存取，因为你并没有要求这个表内的信息。 虽然这个方法在少量存取时表现很好，这个运算的真正问题其实是磁盘 I/O。假如需要大量的根据行ID存取，数据库也许会选择全扫描。 其它路径 我没有列举所有的存取路径，如果你感兴趣可以读一读 Oracle文档。其它数据库里也许叫法不同但背后的概念是一样的。 联接运算符 那么，我们知道如何获取数据了，那现在就把它们联接起来！ 我要展现的是3个个常用联接运算符：合并联接（Merge join），哈希联接（Hash Join）和嵌套循环联接（Nested Loop Join）。但是在此之前，我需要引入新词汇了：内关系和外关系(inner relation and outer relation) 一个关系可以是： 一个表 一个索引 上一个运算的中间结果（比如上一个联接运算的结果） 当你联接两个关系时，联接算法对两个关系的处理是不同的。在本文剩余部分，我将假定： 外关系是左侧数据集 内关系是右侧数据集 比如， A JOIN B 是 A 和 B 的联接，这里 A 是外关系，B 是内关系。 多数情况下， A JOIN B 的成本跟 B JOIN A 的成本是不同的。 在这一部分，我还将假定外关系有 N 个元素，内关系有 M 个元素。要记住，真实的优化器通过统计知道 N 和 M 的值。 注：N 和 M 是关系的基数。 嵌套循环联接 嵌套循环联接是最简单的。 道理如下： 针对外关系的每一行 查看内关系里的所有行来寻找匹配的行 下面是伪代码： nested_loop_join(array outer, array inner) for each row a in outer for each row b in inner if (match_join_condition(a,b)) write_result_in_output(a,b) end if end for end for 由于这是个双迭代，时间复杂度是 O(N*M)。 在磁盘 I/O 方面， 针对 N 行外关系的每一行，内部循环需要从内关系读取 M 行。这个算法需要从磁盘读取 N+ N*M 行。但是，如果内关系足够小，你可以把它读入内存，那么就只剩下 M + N 次读取。这样修改之后，内关系必须是最小的，因为它有更大机会装入内存。 在CPU成本方面没有什么区别，但是在磁盘 I/O 方面，最好最好的，是每个关系只读取一次。 当然，内关系可以由索引代替，对磁盘 I/O 更有利。 由于这个算法非常简单，下面这个版本在内关系太大无法装入内存时，对磁盘 I/O 更加有利。道理如下： 为了避免逐行读取两个关系， 你可以成簇读取，把（两个关系里读到的）两簇数据行保存在内存里， 比较两簇数据，保留匹配的， 然后从磁盘加载新的数据簇来继续比较 直到加载了所有数据。 可能的算法如下： // improved version to reduce the disk I/O. nested_loop_join_v2(file outer, file inner) for each bunch ba in outer // ba is now in memory for each bunch bb in inner // bb is now in memory for each row a in ba for each row b in bb if (match_join_condition(a,b)) write_result_in_output(a,b) end if end for end for end for end for 使用这个版本，时间复杂度没有变化，但是磁盘访问降低了： 用前一个版本，算法需要 N + N*M 次访问（每次访问读取一行）。 用新版本，磁盘访问变为 外关系的数据簇数量 + 外关系的数据簇数量 * 内关系的数据簇数量。 增加数据簇的尺寸，可以降低磁盘访问。哈希联接 哈希联接更复杂，不过在很多场合比嵌套循环联接成本低。 哈希联接的道理是： 1) 读取内关系的所有元素 2) 在内存里建一个哈希表 3) 逐条读取外关系的所有元素 4) （用哈希表的哈希函数）计算每个元素的哈希值，来查找内关系里相关的哈希桶内 5) 是否与外关系的元素匹配。 在时间复杂度方面我需要做些假设来简化问题： 内关系被划分成 X 个哈希桶 哈希函数几乎均匀地分布每个关系内数据的哈希值，就是说哈希桶大小一致。 外关系的元素与哈希桶内的所有元素的匹配，成本是哈希桶内元素的数量。 时间复杂度是 (M/X) (N/X) + 创建哈希表的成本(M) + 哈希函数的成本 N 。 如果哈希函数创建了足够小规模的哈希桶，那么复杂度就是 O(M+N)。 还有个哈希联接的版本，对内存有利但是对磁盘 I/O 不够有利。 这回是这样的： 1) 计算内关系和外关系双方的哈希表 2) 保存哈希表到磁盘 3) 然后逐个哈希桶比较（其中一个读入内存，另一个逐行读取）。 合并联接 合并联接是唯一产生排序的联接算法。 注：这个简化的合并联接不区分内表或外表；两个表扮演同样的角色。但是真实的实现方式是不同的，比如当处理重复值时。 1.（可选）排序联接运算：两个输入源都按照联接关键字排序。 2.合并联接运算：排序后的输入源合并到一起。 排序 我们已经谈到过合并排序，在这里合并排序是个很好的算法（但是并非最好的，如果内存足够用的话，还是哈希联接更好）。 然而有时数据集已经排序了，比如： 如果表内部就是有序的，比如联接条件里一个索引组织表 【译者注： index-organized table 】 如果关系是联接条件里的一个索引 如果联接应用在一个查询中已经排序的中间结果合并联接 这部分与我们研究过的合并排序中的合并运算非常相似。不过这一次呢，我们不是从两个关系里挑选所有元素，而是只挑选相同的元素。道理如下： 1) 在两个关系中，比较当前元素（当前=头一次出现的第一个） 2) 如果相同，就把两个元素都放入结果，再比较两个关系里的下一个元素 3) 如果不同，就去带有最小元素的关系里找下一个元素（因为下一个元素可能会匹配） 4) 重复 1、2、3步骤直到其中一个关系的最后一个元素。 因为两个关系都是已排序的，你不需要『回头去找』，所以这个方法是有效的。 该算法是个简化版，因为它没有处理两个序列中相同数据出现多次的情况（即多重匹配）。真实版本『仅仅』针对本例就更加复杂，所以我才选择简化版。 如果两个关系都已经排序，时间复杂度是 O(N+M) 如果两个关系需要排序，时间复杂度是对两个关系排序的成本：O(NLog(N) + MLog(M)) 对于计算机极客，我给出下面这个可能的算法来处理多重匹配（注：对于这个算法我不保证100%正确）： mergeJoin(relation a, relation b) relation output integer a_key:=0; integer b_key:=0; while (a[a_key]!=null and b[b_key]!=null) if (a[a_key] b[b_key]) b_key++; else //Join predicate satisfied write_result_in_output(a[a_key],b[b_key]) //We need to be careful when we increase the pointers if (a[a_key+1] != b[b_key]) b_key++; end if if (b[b_key+1] != a[a_key]) a_key++; end if if (b[b_key+1] == a[a_key] && b[b_key] == a[a_key+1]) b_key++; a_key++; end if end if end while 哪个算法最好？ 如果有最好的，就没必要弄那么多种类型了。这个问题很难，因为很多因素都要考虑，比如： 空闲内存：没有足够的内存的话就跟强大的哈希联接拜拜吧（至少是完全内存中哈希联接）。 两个数据集的大小。比如，如果一个大表联接一个很小的表，那么嵌套循环联接就比哈希联接快，因为后者有创建哈希的高昂成本；如果两个表都非常大，那么嵌套循环联接CPU成本就很高昂。 是否有索引：有两个 B+树索引的话，聪明的选择似乎是合并联接。 结果是否需要排序：即使你用到的是未排序的数据集，你也可能想用成本较高的合并联接（带排序的），因为最终得到排序的结果后，你可以把它和另一个合并联接串起来（或者也许因为查询用 ORDER BY/GROUP BY/DISTINCT 等操作符隐式或显式地要求一个排序结果）。 关系是否已经排序：这时候合并联接是最好的候选项。 联接的类型：是等值联接（比如 tableA.col1 = tableB.col2 ）？ 还是内联接？外联接？笛卡尔乘积？或者自联接？有些联接在特定环境下是无法工作的。 数据的分布：如果联接条件的数据是倾斜的（比如根据姓氏来联接人，但是很多人同姓），用哈希联接将是个灾难，原因是哈希函数将产生分布极不均匀的哈希桶。 如果你希望联接操作使用多线程或多进程。简化的例子 我们已经研究了 3 种类型的联接操作。 现在，比如说我们要联接 5 个表，来获得一个人的全部信息。一个人可以有： 多个手机号（MOBILES） 多个邮箱（MAILS） 多个地址（ADRESSES） 多个银行账号（BANK_ACCOUNTS） 换句话说，我们需要用下面的查询快速得到答案：SELECT * from PERSON, MOBILES, MAILS,ADRESSES, BANK_ACCOUNTS WHERE PERSON.PERSON_ID = MOBILES.PERSON_ID AND PERSON.PERSON_ID = MAILS.PERSON_ID AND PERSON.PERSON_ID = ADRESSES.PERSON_ID AND PERSON.PERSON_ID = BANK_ACCOUNTS.PERSON_ID 作为一个查询优化器，我必须找到处理数据最好的方法。但有 2 个问题： 每个联接使用那种类型？ 我有 3 种可选（哈希、合并、嵌套），同时可能用到 0, 1 或 2 个索引（不必说还有多种类型的索引）。 按什么顺序执行联接？ 比如，下图显示了针对 4 个表仅仅 3 次联接，可能采用的执行计划： 那么下面就是我可能采取的方法： 1) 采取粗暴的方式 用数据库统计，计算每种可能的执行计划的成本，保留最佳方案。但是，会有很多可能性。对于一个给定顺序的联接操作，每个联接有三种可能性：哈希、合并、嵌套，那么总共就有 3^4 种可能性。确定联接的顺序是个二叉树的排列问题，会有 (2*4)!/(4+1)! 种可能的顺序。对本例这个相当简化了的问题，我最后会得到 3^4*(2*4)!/(4+1)! 种可能。 抛开专业术语，那相当于 27,216 种可能性。如果给合并联接加上使用 0,1 或 2 个 B+树索引，可能性就变成了 210,000种。我是不是告诉过你这个查询其实非常简单吗？ 2) 我大叫一声辞了这份工作 很有诱惑力，但是这样一来，你不会的到查询结果，而我需要钱来付账单。 3) 我只尝试几种执行计划，挑一个成本最低的。 由于不是超人，我不能算出所有计划的成本。相反，我可以武断地从全部可能的计划中选择一个子集，计算它们的成本，把最佳的计划给你。 4) 我用聪明的规则来降低可能性的数量 有两种规则： 我可以用『逻辑』规则，它能去除无用的可能性，但是无法过滤大量的可能性。比如： 『嵌套联接的内关系必须是最小的数据集』。 我接受现实，不去找最佳方案，用更激进的规则来大大降低可能性的数量。比如：『如果一个关系很小，使用嵌套循环联接，绝不使用合并或哈希联接。』 在这个简单的例子中，我最后得到很多可能性。但现实世界的查询还会有其他关系运算符，像 OUTER JOIN, CROSS JOIN, GROUP BY, ORDER BY, PROJECTION, UNION, INTERSECT, DISTINCT … 这意味着更多的可能性。 那么，数据库是如何处理的呢？ 动态编程，贪婪算法和启发式算法 关系型数据库会尝试我刚刚提到的多种方法，优化器真正的工作是在有限时间里找到一个好的解决方案。 多数时候，优化器找到的不是最佳的方案，而是一个『不错』的 对于小规模的查询，采取粗暴的方式是有可能的。但是为了让中等规模的查询也能采取粗暴的方式，我们有办法避免不必要的计算，这就是动态编程。 动态编程 这几个字背后的理念是，很多执行计划是非常相似的。看看下图这几种计划： 它们都有相同的子树（A JOIN B），所以，不必在每个计划中计算这个子树的成本，计算一次，保存结果，当再遇到这个子树时重用。用更正规的说法，我们面对的是个重叠问题。为了避免对部分结果的重复计算，我们使用记忆法。 对于计算机极客，下面是我在先前给你的教程里找到的一个算法。我不提供解释，所以仅在你已经了解动态编程或者精通算法的情况下阅读（我提醒过你哦）： procedure findbestplan(S) if (bestplan[S].cost infinite) return bestplan[S] // else bestplan[S] has not been computed earlier, compute it now if (S contains only 1 relation) set bestplan[S].plan and bestplan[S].cost based on the best way of accessing S /* Using selections on S and indices on S */ else for each non-empty subset S1 of S such that S1 != S P1= findbestplan(S1) P2= findbestplan(S - S1) A = best algorithm for joining results of P1 and P2 cost = P1.cost + P2.cost + cost of A if cost 针对大规模查询，你也可以用动态编程方法，但是要附加额外的规则（或者称为启发式算法）来减少可能性。 如果我们仅分析一个特定类型的计划（例如左深树 left-deep tree，参考)，我们得到 n*2^n 而不是 3^n。 如果我们加上逻辑规则来避免一些模式的计划（像『如果一个表有针对指定谓词的索引，就不要对表尝试合并联接，要对索引』），就会在不给最佳方案造成过多伤害的前提下，减少可能性的数量。【译者注：原文应该是有两处笔误： as=has, to=too】 如果我们在流程里增加规则（像『联接运算先于其他所有的关系运算』），也能减少大量的可能性。 …… 贪婪算法 但是，优化器面对一个非常大的查询，或者为了尽快找到答案（然而查询速度就快不起来了），会应用另一种算法，叫贪婪算法。 原理是按照一个规则（或启发）以渐进的方式制定查询计划。在这个规则下，贪婪算法逐步寻找最佳算法，先处理一条JOIN，接着每一步按照同样规则加一条新的JOIN。 我们来看个简单的例子。比如一个针对5张表（A,B,C,D,E）4次JOIN 的查询，为了简化我们把嵌套JOIN作为可能的联接方式，按照『使用最低成本的联接』规则。 直接从 5 个表里选一个开始（比如 A） 计算每一个与 A 的联接（A 作为内关系或外关系） 发现 “A JOIN B” 成本最低 计算每一个与 “A JOIN B” 的结果联接的成本（“A JOIN B” 作为内关系或外关系） 发现 “(A JOIN B) JOIN C” 成本最低 计算每一个与 “(A JOIN B) JOIN C” 的结果联接的成本 …… 最后确定执行计划 “( ( (A JOIN B) JOIN C) JOIN D ) JOIN E )” 因为我们是武断地从表 A 开始，我们可以把同样的算法用在 B，然后 C，然后 D, 然后 E。最后保留成本最低的执行计划。 顺便说一句，这个算法有个名字，叫『最近邻居算法』。 抛开细节不谈，只需一个良好的模型和一个 Nlog(N) 复杂度的排序，问题就轻松解决了。这个算法的复杂度是 O(Nlog(N)) ，对比一下完全动态编程的 O(3^N)。如果你有个20个联接的大型查询，这意味着 26 vs 3,486,784,401 ，天壤之别！ 这个算法的问题是，我们做的假设是：找到 2 个表的最佳联接方法，保留这个联接结果，再联接下一个表，就能得到最低的成本。但是： 即使在 A, B, C 之间，A JOIN B 可得最低成本 (A JOIN C) JOIN B 也许比 (A JOIN B) JOIN C 更好。 为了改善这一状况，你可以多次使用基于不同规则的贪婪算法，并保留最佳的执行计划。 其他算法 [ 如果你已经受够了算法话题，就直接跳到下一部分。这部分对文章余下的内容不重要。] 很多计算机科学研究者热衷于寻找最佳的执行计划，他们经常为特定问题或模式探寻更好的解决方案，比如： 如果查询是星型联接（一种多联接查询），某些数据库使用一种特定的算法。 如果查询是并行的，某些数据库使用一种特定的算法。 …… 其他算法也在研究之中，就是为了替换在大型查询中的动态编程算法。贪婪算法属于一个叫做启发式算法的大家族，它根据一条规则（或启发），保存上一步找到的方法，『附加』到当前步骤来进一步搜寻解决方法。有些算法根据特定规则，一步步的应用规则但不总是保留上一步找到的最佳方法。它们统称启发式算法。 比如，基因算法就是一种： 一个方法代表一种可能的完整查询计划 每一步保留了 P 个方法（即计划），而不是一个。 0) P 个计划随机创建 1) 成本最低的计划才会保留 2) 这些最佳计划混合在一起产生 P 个新的计划 3) 一些新的计划被随机改写 4) 1，2，3步重复 T 次 5) 然后在最后一次循环，从 P 个计划里得到最佳计划。 循环次数越多，计划就越好。 这是魔术？不，这是自然法则：适者生存！ PostgreSQL 实现了基因算法，但我并没有发现它是不是默认使用这种算法的。 数据库中还使用了其它启发式算法，像『模拟退火算法（Simulated Annealing）』、『交互式改良算法（Iterative Improvement）』、『双阶段优化算法（Two-Phase Optimization）』…..不过，我不知道这些算法当前是否在企业级数据库应用了，还是仅仅用在研究型数据库。 真实的优化器 [ 这段不重要，可以跳过 ] 然而，所有上述罗里罗嗦的都非常理论化，我是个开发者而不是研究者，我喜欢具体的例子。 我们来看看 SQLite 优化器 是怎么工作的。这是个轻量化数据库，它使用一种简单优化器，基于带有附加规则的贪婪算法，来限制可能性的数量。 SQLite 在有 CROSS JOIN 操作符时从不给表重新排序 使用嵌套联接 外联接始终按顺序评估 …… 3.8.0之前的版本使用『最近邻居』贪婪算法来搜寻最佳查询计划 等等……我们见过这个算法！真是巧哈！ 从3.8.0版本（发布于2015年）开始，SQLite使用『N最近邻居』贪婪算法来搜寻最佳查询计划 我们再看看另一个优化器是怎么工作的。IBM DB2 跟所有企业级数据库都类似，我讨论它是因为在切换到大数据之前，它是我最后真正使用的数据库。 看过官方文档后，我们了解到 DB2 优化器可以让你使用 7 种级别的优化： 对联接使用贪婪算法 0 – 最小优化，使用索引扫描和嵌套循环联接，避免一些查询重写 1 – 低级优化 2 – 完全优化 对联接使用动态编程算法 3 – 中等优化和粗略的近似法 5 – 完全优化，使用带有启发式的所有技术 7 – 完全优化，类似级别5，但不用启发式 9 – 最大优化，完全不顾开销，考虑所有可能的联接顺序，包括笛卡尔乘积 可以看到 DB2 使用贪婪算法和动态编程算法。当然，他们不会把自己的启发算法分享出来的，因为查询优化器是数据库的看家本领。 DB2 的默认级别是 5，优化器使用下列特性： 使用所有可用的统计，包括线段树（frequent-value）和分位数统计（quantile statistics）。 使用所有查询重写规则（含物化查询表路由，materialized query table routing），除了在极少情况下适用的计算密集型规则。 使用动态编程模拟联接 有限使用组合内关系（composite inner relation） 对于涉及查找表的星型模式，有限使用笛卡尔乘积 考虑宽泛的访问方式，含列表预取（list prefetch，注：我们将讨论什么是列表预取），index ANDing（注：一种对索引的特殊操作），和物化查询表路由。 默认的，DB2 对联接排列使用受启发式限制的动态编程算法。 其它情况 (GROUP BY, DISTINCT…) 由简单规则处理。 查询计划缓存 由于创建查询计划是耗时的，大多数据库把计划保存在查询计划缓存，来避免重复计算。这个话题比较大，因为数据库需要知道什么时候更新过时的计划。办法是设置一个上限，如果一个表的统计变化超过了上限，关于该表的查询计划就从缓存中清除。 查询执行器 在这个阶段，我们有了一个优化的执行计划，再编译为可执行代码。然后，如果有足够资源（内存，CPU），查询执行器就会执行它。计划中的操作符 (JOIN, SORT BY …) 可以顺序或并行执行，这取决于执行器。为了获得和写入数据，查询执行器与数据管理器交互，本文下一部分来讨论数据管理器。 数据管理器 在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。但是有 2 个问题： 关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。 数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。 在这一部分，我没看看关系型数据库是如何处理这两个问题的。我不会讲数据管理器是怎么获得数据的，因为这不是最重要的（而且本文已经够长的了！）。缓存管理器 我已经说过，数据库的主要瓶颈是磁盘 I/O。为了提高性能，现代数据库使用缓存管理器。 查询执行器不会直接从文件系统拿数据，而是向缓存管理器要。缓存管理器有一个内存缓存区，叫做缓冲池，从内存读取数据显著地提升数据库性能。对此很难给出一个数量级，因为这取决于你需要的是哪种操作： 顺序访问（比如：全扫描） vs 随机访问（比如：按照row id访问） 读还是写 以及数据库使用的磁盘类型： 7.2k/10k/15k rpm的硬盘 SSD RAID 1/5/… 要我说，内存比磁盘要快100到10万倍。 然而，这导致了另一个问题（数据库总是这样…)，缓存管理器需要在查询执行器使用数据之前得到数据，否则查询管理器不得不等待数据从缓慢的磁盘中读出来。 预读 这个问题叫预读。查询执行器知道它将需要什么数据，因为它了解整个查询流，而且通过统计也了解磁盘上的数据。道理是这样的： 当查询执行器处理它的第一批数据时 会告诉缓存管理器预先装载第二批数据 当开始处理第二批数据时 告诉缓存管理器预先装载第三批数据，并且告诉缓存管理器第一批可以从缓存里清掉了。 …… 缓存管理器在缓冲池里保存所有的这些数据。为了确定一条数据是否有用，缓存管理器给缓存的数据添加了额外的信息（叫闩锁）。 有时查询执行器不知道它需要什么数据，有的数据库也不提供这个功能。相反，它们使用一种推测预读法（比如：如果查询执行器想要数据1、3、5，它不久后很可能会要 7、9、11），或者顺序预读法（这时候缓存管理器只是读取一批数据后简单地从磁盘加载下一批连续数据）。 为了监控预读的工作状况，现代数据库引入了一个度量叫缓冲/缓存命中率，用来显示请求的数据在缓存中找到而不是从磁盘读取的频率。 注：糟糕的缓存命中率不总是意味着缓存工作状态不佳。更多信息请阅读Oracle文档。 缓冲只是容量有限的内存空间，因此，为了加载新的数据，它需要移除一些数据。加载和清除缓存需要一些磁盘和网络I/O的成本。如果你有个经常执行的查询，那么每次都把查询结果加载然后清除，效率就太低了。现代数据库用缓冲区置换策略来解决这个问题。 缓冲区置换策略 多数现代数据库(至少 SQL Server, MySQL, Oracle 和 DB2)使用 LRU 算法。 LRU LRU代表最近最少使用（Least Recently Used）算法，背后的原理是：在缓存里保留的数据是最近使用的，所以更有可能再次使用。 为了更好的理解，我假设缓冲区里的数据没有被闩锁锁住（就是说是可以被移除的）。在这个简单的例子里，缓冲区可以保存 3 个元素： 1：缓存管理器（简称CM）使用数据1，把它放入空的缓冲区 2：CM使用数据4，把它放入半载的缓冲区 3：CM使用数据3，把它放入半载的缓冲区 4：CM使用数据9，缓冲区满了，所以数据1被清除，因为它是最后一个最近使用的，数据9加入到缓冲区 5：CM使用数据4，数据4已经在缓冲区了，所以它再次成为第一个最近使用的。 6：CM使用数据1，缓冲区满了，所以数据9被清除，因为它是最后一个最近使用的，数据1加入到缓冲区 …… 这个算法效果很好，但是有些限制。如果对一个大表执行全表扫描怎么办？换句话说，当表/索引的大小超出缓冲区会发生什么？使用这个算法会清除之前缓存内所有的数据，而且全扫描的数据很可能只使用一次。 改进 为了防止这个现象，有些数据库增加了特殊的规则，比如Oracle文档中的描述： 『对非常大的表来说，数据库通常使用直接路径来读取，即直接加载区块[……]，来避免填满缓冲区。对于中等大小的表，数据库可以使用直接读取或缓存读取。如果选择缓存读取，数据库把区块置于LRU的尾部，防止清空当前缓冲区。』 还有一些可能，比如使用高级版本的LRU，叫做 LRU-K。例如，SQL Server 使用 LRU-2。 这个算法的原理是把更多的历史记录考虑进来。简单LRU（也就是 LRU-1），只考虑最后一次使用的数据。LRU-K呢： 考虑数据最后第K次使用的情况 数据使用的次数加进了权重 一批新数据加载进入缓存，旧的但是经常使用的数据不会被清除（因为权重更高） 但是这个算法不会保留缓存中不再使用的数据 所以数据如果不再使用，权重值随着时间推移而降低 计算权重是需要成本的，所以SQL Server只是使用 K=2，这个值性能不错而且额外开销可以接受。 关于LRU-K更深入的知识，可以阅读早期的研究论文（1993）：数据库磁盘缓冲的LRU-K页面置换算法 其他算法 当然还有其他管理缓存的算法，比如： 2Q（类LRU-K算法） CLOCK（类LRU-K算法） MRU（最新使用的算法，用LRU同样的逻辑但不同的规则） LRFU（Least Recently and Frequently Used，最近最少使用最近最不常用） ……写缓冲区 我只探讨了读缓存 —— 在使用之前预先加载数据。用来保存数据、成批刷入磁盘，而不是逐条写入数据从而造成很多单次磁盘访问。 要记住，缓冲区保存的是页（最小的数据单位）而不是行（逻辑上/人类习惯的观察数据的方式）。缓冲池内的页如果被修改了但还没有写入磁盘，就是脏页。有很多算法来决定写入脏页的最佳时机，但这个问题与事务的概念高度关联，下面我们就谈谈事务。 事务管理器 最后但同样重要的，是事务管理器，我们将看到这个进程是如何保证每个查询在自己的事务内执行的。但开始之前，我们需要理解ACID事务的概念。 “I’m on acid” 一个ACID事务是一个工作单元，它要保证4个属性： 原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。 隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。 持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。 一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。 在同一个事务内，你可以运行多个SQL查询来读取、创建、更新和删除数据。当两个事务使用相同的数据，麻烦就来了。经典的例子是从账户A到账户B的汇款。假设有2个事务： 事务1（T1）从账户A取出100美元给账户B 事务2（T2）从账户A取出50美元给账户B 我们回来看看ACID属性： 原子性确保不管 T1 期间发生什么（服务器崩溃、网络中断…），你不能出现账户A 取走了100美元但没有给账户B 的现象（这就是数据不一致状态）。 隔离性确保如果 T1 和 T2 同时发生，最终A将减少150美元，B将得到150美元，而不是其他结果，比如因为 T2 部分抹除了 T1 的行为，A减少150美元而B只得到50美元（这也是不一致状态）。 持久性确保如果 T1 刚刚提交，数据库就发生崩溃，T1 不会消失得无影无踪。 一致性确保钱不会在系统内生成或灭失。 现代数据库不会使用纯粹的隔离作为默认模式，因为它会带来巨大的性能消耗。SQL一般定义4个隔离级别： 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』。 可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。 举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。 这叫幻读（phantom read）。 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。 这叫不可重复读（non-repeatable read）。 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。 这叫脏读（dirty read）。 多数数据库添加了自定义的隔离级别（比如 PostgreSQL、Oracle、SQL Server的快照隔离），而且并没有实现SQL规范里的所有级别（尤其是读取未提交级别）。 默认的隔离级别可以由用户/开发者在建立连接时覆盖（只需要增加很简单的一行代码）。 并发控制 确保隔离性、一致性和原子性的真正问题是对相同数据的写操作（增、更、删）： 如果所有事务只是读取数据，它们可以同时工作，不会更改另一个事务的行为。 如果（至少）有一个事务在修改其他事务读取的数据，数据库需要找个办法对其它事务隐藏这种修改。而且，它还需要确保这个修改操作不会被另一个看不到这些数据修改的事务擦除。 这个问题叫并发控制。 最简单的解决办法是依次执行每个事务（即顺序执行），但这样就完全没有伸缩性了，在一个多处理器/多核服务器上只有一个核心在工作，效率很低。 理想的办法是，每次一个事务创建或取消时： 监控所有事务的所有操作 检查是否2个（或更多）事务的部分操作因为读取/修改相同的数据而存在冲突 重新编排冲突事务中的操作来减少冲突的部分 按照一定的顺序执行冲突的部分（同时非冲突事务仍然在并发运行） 考虑事务有可能被取消 用更正规的说法，这是对冲突的调度问题。更具体点儿说，这是个非常困难而且CPU开销很大的优化问题。企业级数据库无法承担等待几个小时，来寻找每个新事务活动最好的调度，因此就使用不那么理想的方式以避免更多的时间浪费在解决冲突上。 锁管理器 为了解决这个问题，多数数据库使用锁和/或数据版本控制。这是个很大的话题，我会集中探讨锁，和一点点数据版本控制。 悲观锁 原理是： 如果一个事务需要一条数据 它就把数据锁住 如果另一个事务也需要这条数据 它就必须要等第一个事务释放这条数据 这个锁叫排他锁。 但是对一个仅仅读取数据的事务使用排他锁非常昂贵，因为这会迫使其它只需要读取相同数据的事务等待。因此就有了另一种锁，共享锁。 共享锁是这样的： 如果一个事务只需要读取数据A 它会给数据A加上『共享锁』并读取 如果第二个事务也需要仅仅读取数据A 它会给数据A加上『共享锁』并读取 如果第三个事务需要修改数据A 它会给数据A加上『排他锁』，但是必须等待另外两个事务释放它们的共享锁。 同样的，如果一块数据被加上排他锁，一个只需要读取该数据的事务必须等待排他锁释放才能给该数据加上共享锁。 锁管理器是添加和释放锁的进程，在内部用一个哈希表保存锁信息（关键字是被锁的数据），并且了解每一块数据是： 被哪个事务加的锁 哪个事务在等待数据解锁死锁 但是使用锁会导致一种情况，2个事务永远在等待一块数据： 在本图中： 事务A 给 数据1 加上排他锁并且等待获取数据2 事务B 给 数据2 加上排他锁并且等待获取数据1 这叫死锁。 在死锁发生时，锁管理器要选择取消（回滚）一个事务，以便消除死锁。这可是个艰难的决定： 杀死数据修改量最少的事务（这样能减少回滚的成本）？ 杀死持续时间最短的事务，因为其它事务的用户等的时间更长？ 杀死能用更少时间结束的事务（避免可能的资源饥荒）？ 一旦发生回滚，有多少事务会受到回滚的影响？ 在作出选择之前，锁管理器需要检查是否有死锁存在。 哈希表可以看作是个图表（见上文图），图中出现循环就说明有死锁。由于检查循环是昂贵的（所有锁组成的图表是很庞大的），经常会通过简单的途径解决：使用超时设定。如果一个锁在超时时间内没有加上，那事务就进入死锁状态。 锁管理器也可以在加锁之前检查该锁会不会变成死锁，但是想要完美的做到这一点还是很昂贵的。因此这些预检经常设置一些基本规则。 两段锁 实现纯粹的隔离最简单的方法是：事务开始时获取锁，结束时释放锁。就是说，事务开始前必须等待确保自己能加上所有的锁，当事务结束时释放自己持有的锁。这是行得通的，但是为了等待所有的锁，大量的时间被浪费了。 更快的方法是两段锁协议（Two-Phase Locking Protocol，由 DB2 和 SQL Server使用），在这里，事务分为两个阶段： 成长阶段：事务可以获得锁，但不能释放锁。 收缩阶段：事务可以释放锁（对于已经处理完而且不会再次处理的数据），但不能获得新锁。 这两条简单规则背后的原理是： 释放不再使用的锁，来降低其它事务的等待时间 防止发生这类情况：事务最初获得的数据，在事务开始后被修改，当事务重新读取该数据时发生不一致。 这个规则可以很好地工作，但有个例外：如果修改了一条数据、释放了关联的锁后，事务被取消（回滚），而另一个事务读到了修改后的值，但最后这个值却被回滚。为了避免这个问题，所有独占锁必须在事务结束时释放。 当然了，真实的数据库使用更复杂的系统，涉及到更多类型的锁（比如意向锁，intention locks）和更多的粒度（行级锁、页级锁、分区锁、表锁、表空间锁），但是道理是相同的。 我只探讨纯粹基于锁的方法，数据版本控制是解决这个问题的另一个方法。 版本控制是这样的： 每个事务可以在相同时刻修改相同的数据 每个事务有自己的数据拷贝（或者叫版本） 如果2个事务修改相同的数据，只接受一个修改，另一个将被拒绝，相关的事务回滚（或重新运行） 这将提高性能，因为： 读事务不会阻塞写事务 写事务不会阻塞读 没有『臃肿缓慢』的锁管理器带来的额外开销 除了两个事务写相同数据的时候，数据版本控制各个方面都比锁表现得更好。只不过，你很快就会发现磁盘空间消耗巨大。 数据版本控制和锁机制是两种不同的见解：乐观锁和悲观锁。两者各有利弊，完全取决于使用场景（读多还是写多）。关于数据版本控制，我推荐这篇非常优秀的文章，讲的是PostgreSQL如何实现多版本并发控制的。 一些数据库，比如DB2（直到版本 9.7）和 SQL Server（不含快照隔离）仅使用锁机制。其他的像PostgreSQL, MySQL 和 Oracle 使用锁和鼠标版本控制混合机制。我不知道是否有仅用版本控制的数据库（如果你知道请告诉我）。 Firebird 和 Interbase 用不带锁的版本控制。 版本控制对索引的影响挺有趣的：有时唯一索引会出现重复，索引的条目会多于表行数，等等。 如果你读过不同级别的隔离那部分内容，你会知道，提高隔离级别就会增加锁的数量和事务等待加锁的时间。这就是为什么多数数据库默认不会使用最高级别的隔离（即串行化）。 当然，你总是可以自己去主流数据库（像MySQL, PostgreSQL 或 Oracle）的文档里查一下。 日志管理器 我们已经知道，为了提升性能，数据库把数据保存在内存缓冲区内。但如果当事务提交时服务器崩溃，崩溃时还在内存里的数据会丢失，这破坏了事务的持久性。 你可以把所有数据都写在磁盘上，但是如果服务器崩溃，最终数据可能只有部分写入磁盘，这破坏了事务的原子性。 事务作出的任何修改必须是或者撤销，或者完成。 有 2 个办法解决这个问题： 影子副本/页（Shadow copies/pages）：每个事务创建自己的数据库副本（或部分数据库的副本），并基于这个副本来工作。一旦出错，这个副本就被移除；一旦成功，数据库立即使用文件系统的一个把戏，把副本替换到数据中，然后删掉『旧』数据。 事务日志（Transaction log）：事务日志是一个存储空间，在每次写盘之前，数据库在事务日志中写入一些信息，这样当事务崩溃或回滚，数据库知道如何移除或完成尚未完成的事务。 WAL（预写式日志） 影子副本/页在运行较多事务的大型数据库时制造了大量磁盘开销，所以现代数据库使用事务日志。事务日志必须保存在稳定的存储上，我不会深挖存储技术，但至少RAID磁盘是必须的，以防磁盘故障。 多数数据库（至少是Oracle, SQL Server, DB2, PostgreSQL, MySQL 和 SQLite) 使用预写日志协议（Write-Ahead Logging protocol ，WAL）来处理事务日志。WAL协议有 3 个规则： 1) 每个对数据库的修改都产生一条日志记录，在数据写入磁盘之前日志记录必须写入事务日志。 2) 日志记录必须按顺序写入；记录 A 发生在记录 B 之前，则 A 必须写在 B 之前。 3) 当一个事务提交时，在事务成功之前，提交顺序必须写入到事务日志。 这个工作由日志管理器完成。简单的理解就是，日志管理器处于缓存管理器（cache manager）和数据访问管理器（data access manager，负责把数据写入磁盘）之间，每个 update / delete / create / commit / rollback 操作在写入磁盘之前先写入事务日志。简单，对吧？ 回答错误！ 我们研究了这么多内容，现在你应该知道与数据库相关的每一件事都带着『数据库效应』的诅咒。好吧，我们说正经的，问题在于，如何找到写日志的同时保持良好的性能的方法。如果事务日志写得太慢，整体都会慢下来。 ARIES 1992年，IBM 研究人员『发明』了WAL的增强版，叫 ARIES。ARIES 或多或少地在现代数据库中使用，逻辑未必相同，但AIRES背后的概念无处不在。我给发明加了引号是因为，按照MIT这门课的说法，IBM 的研究人员『仅仅是写了事务恢复的最佳实践方法』。AIRES 论文发表的时候我才 5 岁，我不关心那些酸溜溜的科研人员老掉牙的闲言碎语。事实上，我提及这个典故，是在开始探讨最后一个技术点前让你轻松一下。我阅读过这篇 ARIES 论文 的大量篇幅，发现它很有趣。在这一部分我只是简要的谈一下 ARIES，不过我强烈建议，如果你想了解真正的知识，就去读那篇论文。 ARIES 代表『数据库恢复原型算法』（Algorithms for Recovery and Isolation Exploiting Semantics）。 这个技术要达到一个双重目标： 1) 写日志的同时保持良好性能 2) 快速和可靠的数据恢复 有多个原因让数据库不得不回滚事务： 因为用户取消 因为服务器或网络故障 因为事务破坏了数据库完整性（比如一个列有唯一性约束而事务添加了重复值） 因为死锁 有时候（比如网络出现故障），数据库可以恢复事务。 这怎么可能呢？为了回答这个问题，我们需要了解日志里保存的信息。 日志 事务的每一个操作（增/删/改）产生一条日志，由如下内容组成： LSN：一个唯一的日志序列号（Log Sequence Number）。LSN是按时间顺序分配的 * ，这意味着如果操作 A 先于操作 B，log A 的 LSN 要比 log B 的 LSN 小。 TransID：产生操作的事务ID。 PageID：被修改的数据在磁盘上的位置。磁盘数据的最小单位是页，所以数据的位置就是它所处页的位置。 PrevLSN：同一个事务产生的上一条日志记录的链接。 UNDO：取消本次操作的方法。 比如，如果操作是一次更新，UNDO将或者保存元素更新前的值/状态（物理UNDO），或者回到原来状态的反向操作（逻辑UNDO） **。 REDO：重复本次操作的方法。 同样的，有 2 种方法：或者保存操作后的元素值/状态，或者保存操作本身以便重复。 …：（供您参考，一个 ARIES 日志还有 2 个字段：UndoNxtLSN 和 Type）。 进一步说，磁盘上每个页（保存数据的，不是保存日志的）都记录着最后一个修改该数据操作的LSN。 *LSN的分配其实更复杂，因为它关系到日志存储的方式。但道理是相同的。 ** ARIES 只使用逻辑UNDO，因为处理物理UNDO太过混乱了。 注：据我所知，只有 PostgreSQL 没有使用UNDO，而是用一个垃圾回收服务来删除旧版本的数据。这个跟 PostgreSQL 对数据版本控制的实现有关。 为了更好的说明这一点，这有一个简单的日志记录演示图，是由查询 “UPDATE FROM PERSON SET AGE = 18;” 产生的，我们假设这个查询是事务18执行的。 每条日志都有一个唯一的LSN，链接在一起的日志属于同一个事务。日志按照时间顺序链接（链接列表的最后一条日志是最后一个操作产生的）。 日志缓冲区 为了防止写日志成为主要的瓶颈，数据库使用了日志缓冲区。 当查询执行器要求做一次修改： 1) 缓存管理器将修改存入自己的缓冲区； 2) 日志管理器将相关的日志存入自己的缓冲区； 3) 到了这一步，查询执行器认为操作完成了（因此可以请求做另一次修改）； 4) 接着（不久以后）日志管理器把日志写入事务日志，什么时候写日志由某算法来决定。 5) 接着（不久以后）缓存管理器把修改写入磁盘，什么时候写盘由某算法来决定。 当事务提交，意味着事务每一个操作的 1 2 3 4 5 步骤都完成了。写事务日志是很快的，因为它只是『在事务日志某处增加一条日志』；而数据写盘就更复杂了，因为要用『能够快速读取的方式写入数据』。 STEAL 和 FORCE 策略 出于性能方面的原因，第 5 步有可能在提交之后完成，因为一旦发生崩溃，还有可能用REDO日志恢复事务。这叫做 NO-FORCE策略。 数据库可以选择FORCE策略（比如第 5 步在提交之前必须完成）来降低恢复时的负载。 另一个问题是，要选择数据是一步步的写入（STEAL策略），还是缓冲管理器需要等待提交命令来一次性全部写入（NO-STEAL策略）。选择STEAL还是NO-STEAL取决于你想要什么：快速写入但是从 UNDO 日志恢复缓慢，还是快速恢复。 总结一下这些策略对恢复的影响： STEAL/NO-FORCE 需要 UNDO 和 REDO: 性能高，但是日志和恢复过程更复杂 (比如 ARIES)。多数数据库选择这个策略。 注：这是我从多个学术论文和教程里看到的，但并没有看到官方文档里显式说明这一点。 STEAL/ FORCE 只需要 UNDO. NO-STEAL/NO-FORCE 只需要 REDO. NO-STEAL/FORCE 什么也不需要: 性能最差，而且需要巨大的内存。 关于恢复 Ok，有了不错的日志，我们来用用它们！ 假设新来的实习生让数据库崩溃了（首要规矩：永远是实习生的错。），你重启了数据库，恢复过程开始了。 ARIES从崩溃中恢复有三个阶段： 1) 分析阶段：恢复进程读取全部事务日志，来重建崩溃过程中所发生事情的时间线，决定哪个事务要回滚（所有未提交的事务都要回滚）、崩溃时哪些数据需要写盘。 2) Redo阶段：这一关从分析中选中的一条日志记录开始，使用 REDO 来将数据库恢复到崩溃之前的状态。 在REDO阶段，REDO日志按照时间顺序处理（使用LSN）。 对每一条日志，恢复进程需要读取包含数据的磁盘页LSN。 如果LSN（磁盘页）>= LSN（日志记录），说明数据已经在崩溃前写到磁盘（但是值已经被日志之后、崩溃之前的某个操作覆盖），所以不需要做什么。 如果LSN（磁盘页） 3) Undo阶段：这一阶段回滚所有崩溃时未完成的事务。回滚从每个事务的最后一条日志开始，并且按照时间倒序处理UNDO日志（使用日志记录的PrevLSN）。 恢复过程中，事务日志必须留意恢复过程的操作，以便写入磁盘的数据与事务日志相一致。一个解决办法是移除被取消的事务产生的日志记录，但是这个太困难了。相反，ARIES在事务日志中记录补偿日志，来逻辑上删除被取消的事务的日志记录。 当事务被『手工』取消，或者被锁管理器取消（为了消除死锁），或仅仅因为网络故障而取消，那么分析阶段就不需要了。对于哪些需要 REDO 哪些需要 UNDO 的信息在 2 个内存表中： 事务表（保存当前所有事务的状态） 脏页表（保存哪些数据需要写入磁盘） 当新的事务产生时，这两个表由缓存管理器和事务管理器更新。因为是在内存中，当数据库崩溃时它们也被破坏掉了。 分析阶段的任务就是在崩溃之后，用事务日志中的信息重建上述的两个表。为了加快分析阶段，ARIES提出了一个概念：检查点（check point），就是不时地把事务表和脏页表的内容，还有此时最后一条LSN写入磁盘。那么在分析阶段当中，只需要分析这个LSN之后的日志即可。 结语 写这篇文章之前，我知道这个题目有多大，也知道写这样一篇深入的文章会相当耗时。最后证明我过于乐观了，实际上花了两倍于预期的时间，但是我学到了很多。 如果你想很好地了解数据库，我推荐这篇研究论文：《数据库系统架构》，对数据库有很好的介绍（共110页），而且非计算机专业人士也能读懂。这篇论文出色的帮助我制定了本文的写作计划，它没有像本文那样专注于数据结构和算法，更多的讲了架构方面的概念。 如果你仔细阅读了本文，你现在应该了解一个数据库是多么的强大了。鉴于文章很长，让我来提醒你我们都学到了什么： B+树索引概述 数据库的全局概述 基于成本的优化概述，特别专注了联接运算 缓冲池管理概述 事务管理概述 但是，数据库包含了更多的聪明巧技。比如，我并没有谈到下面这些棘手的问题： 如何管理数据库集群和全局事务 如何在数据库运行的时候产生快照 如何高效地存储（和压缩）数据 如何管理内存 所以，当你不得不在问题多多的 NoSQL数据库和坚如磐石的关系型数据库之间抉择的时候，要三思而行。不要误会，某些 NoSQL数据库是很棒的，但是它们毕竟还年轻，只是解决了少量应用关注的一些特定问题。 "},"数据库/Mysql/Mysql数据库死锁监控.html":{"url":"数据库/Mysql/Mysql数据库死锁监控.html","title":"Mysql数据库死锁监控","keywords":"","body":"Mysql数据库死锁监控 1）表锁定 通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析表锁定。 SHOW STATUS LIKE 'TABLE%'; 说明： Table_locks_immediate：能够立即获得表级锁的锁请求次数 Table_locks_waited：不能立即获取表级锁而需要等待的锁请求次数 分析： 如果table_locks_waited值较高，且存在性能问题，则说明存在着较严重的表级锁争用情况。这时，需要对应用做进一步的检查，来确定问题所在，应首先优化查询，然后拆分表或复制表。 2）行级锁 通过检查 Innodb_row_lock状态变量来分析行锁的争用情况。 SHOW STATUS LIKE 'INNODB_ROW_LOCK%'; 说明： Innodb_row_lock_current_waits：当前锁等待的数量 Innodb_row_lock_time：自系统启动到现在，锁定的总时间，单位：毫秒 ms。 Innodb_row_lock_time_avg：平均锁定的时间，单位：毫秒 ms。 Innodb_row_lock_time_max：最大锁定时间，单位：毫秒 ms。 Innodb_row_lock_waits：自系统启动到现在，锁等待次数，即锁定的总次数。 分析： 针对如果InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，说明可能存在锁争用的情况，针对 Innodb 类型的表，可以通过设置InnoDB Monitors来进一步观察发生锁争用的表、数据行等，并分析锁争用的原因，如下： 注：可通过语句SHOW CREATE TABLE table_name;查看表table_name使用的引擎(查询输出结果中找到ENGINE=xxxx，这里xxxx即为使用的引擎); 1、先设置InnoDB Monitor CREATE TABLE innodb_monitor(a INT) ENGINE=INNODB; 2.查看 SHOW ENGINE INNODB STATUS; 说明： 输出结果包含了详细的当前锁等待的信息，包括表名、锁类型、锁定记录的情况等等。打开监视器以后，默认情况下每 15 秒会向日志中记录监控的内容，如果长时间打开会导致.err 文件变得非常的巨大，所以我们在确认问题原因之后，要记得删除监控表(DROP TABLE innodb_monitor;)以关闭监视器。 输出结果为基于一段时间的数据采样，得出的每秒平均值，这里的时间取自系统启动到当前时间的时间间隔或者上次输出到当前时间的时间间隔 找到TRANSACTIONS部分的内容，可以查看事务死锁争用的相关情况 查看锁信息（开启InnoDB监控） 背景 在mysql处理死锁问题时，由于show engine innodb status输出来的死锁日志无任务事务上下文，并不能很好地诊断相关事务所持有的所有锁信息，包括：锁个数、锁类型等。 于是，需要能查看到更详细的事务锁占用情况。 INNODB监控机制(InnoDB Monitors) mysql提供一套INNODB监控机制，用于周期性(每15钞)输出INNODB运行相关状态(INNODB运行状态、表空间状态、表状态等)到mysqld服务标准错误输出。另外，INNODB标准监控和锁监控，也可以通过命令：show engine innodb status输出到控制台。 此部分内容一般输出到mysql error log里(查找日志位置，参见“补充知识”)。 官方说明(详见参考文档1)如下： When you enable InnoDB monitors for periodic output, InnoDB writes their output to the mysqld server standard error output (stderr). In this case, no output is sent to clients. When switched on, InnoDB monitors print data about every 15 seconds. Server output usually is directed to the error log (see Section 5.4.2, “The Error Log”). This data is useful in performance tuning. On Windows, start the server from a command prompt in a console window with the --console option if you want to direct the output to the window rather than to the error log. 该类监控机制默认是关闭状态，分析问题需要查看监控日志时再开启。 建议分析问题后，将监控关闭；否则，每15秒输出一次INNODB运行状态信息到错误日志，会使用日志变得特别大。 开启状态监控 INNODB监控机制目前主要提供如下四类监控： 标准监控(Standard InnoDB Monitor)：监视活动事务持有的表锁、行锁；事务锁等待；线程信号量等待；文件IO请求；buffer pool统计信息；InnoDB主线程purge和change buffer merge活动。 锁监控(InnoDB Lock Monitor)：提供额外的锁信息。 表空间监控(InnoDB Tablespace Monitor)：显示共享表空间中的文件段以及表空间数据结构配置验证。 表监控(InnoDB Table Monitor)：显示内部数据字典的内容。 关于四类监控开启与关闭方法，一言以蔽之，主要是通过创建系统可识读的特殊表名来完成。特别地，除表空间(InnoDB Tablespace Monitor)监控和表监控(InnoDB Table Monitor)外，其他二类监控还可能通过修改系统参数来完成。 基于系统表的方式和基于系统参数的方式，只要使用二者其中一种方式开启监控即可。 标准监控(Standard InnoDB Monitor) 基于系统表：innodb_monitor mysql会通过检查是否存在名为innodb_monitor的数据表，来判断是否开启标准监控，并打印日志。 需要开启，则创建表；需要关闭，则删除表。 CREATE TABLE innodb_monitor (a INT) ENGINE=INNODB; DROP TABLE innodb_monitor; 基于系统参数：innodb_status_output 自mysql 5.6.16版本之后，可以通过设置系统参数(innodb_status_output)的方式开启或者关闭标准监控。 set GLOBAL innodb_status_output=ON; set GLOBAL innodb_status_output=OFF; 开启锁监控(InnoDB Lock Monitor) 基于系统表：innodb_lock_monitor mysql会通过检查是否存在名为innodb_lock_monitor的数据表，来判断是否开启锁监控，并打印日志。 需要开启，则创建表；需要关闭，则删除表。 CREATE TABLE innodb_lock_monitor (a INT) ENGINE=INNODB; DROP TABLE innodb_lock_monitor; 基于系统参数：innodb_status_output_locks 自mysql 5.6.16版本之后，可以通过设置系统参数(innodb_status_output_locks)的方式开启或者关闭标准监控。 set GLOBAL innodb_status_output=ON; set GLOBAL innodb_status_output_locks=ON; set GLOBAL innodb_status_output_locks=OFF; 注：前提需要开启 innodb_status_output 开启表空间监控(InnoDB Tablespace Monitor) 基于系统表：innodb_tablespace_monitor mysql会通过检查是否存在名为innodb_tablespace_monitor的数据表，来判断是否开启表空间监控，并打印日志。 需要开启，则创建表；需要关闭，则删除表。 CREATE TABLE innodb_tablespace_monitor (a INT) ENGINE=INNODB; DROP TABLE innodb_tablespace_monitor; 注：表空间监控暂不支持通过参数方式配置，并且未来会被废弃。 开启表监控(InnoDB Table Monitor) mysql会通过检查是否存在名为innodb_table_monitor的数据表，来判断是否开启表监控，并打印日志。 需要开启，则创建表；需要关闭，则删除表。 CREATE TABLE innodb_table_monitor (a INT) ENGINE=INNODB; DROP TABLE innodb_table_monitor; 注：表监控暂不支持通过参数方式配置，并且未来会被废弃。 注意事宜 监控复位 需要特别注意的一点是：mysql服务重启后，需要重启开启相应监控，才会生效。换句话说，服务重启后，之前配置的所有监控都被复位，处于关闭状态。 基于系统表方式开启的监控，在mysql服务重启后，即使表存在，监控也不会生效。需要重启drop表，再create表，才能使监控生效。 基于系统参数方式开启的监控，在mysql服务重启后，相关系统参数值都是OFF。需要重启设置对应的参数，才能使用监控生效。 错误日志大小 不在停机或重启情况下，mysql每15秒输出一次INNODB运行状态信息到错误日志。 这会使用日志变得越来越大。建议在需要的时候开启，不需要的时候关闭掉。 基于表方式将来会被废弃 基于表方式将来会被废弃，使用基于系统参数的方式开启。 Use INFORMATION_SCHEMA or PERFORMANCE_SCHEMA tables or SET GLOBAL innodb_status_output=ON. 基于表方式无关表结构及内容 基于表方式，mysql只检验表名被创建，则开启监控。 至于，表创建到哪个数据库、表具体的数据结构、表里的内容都不关心，不会对监控开启有任何影响。 日志状态输出时间 虽说状态日志是每15秒周期性输出一次，但是由于状态收集与输出也会占用一些时间，特别是表空间日志(INNODB TABLE MONITOR OUTPUT)和表日志(INNODB TABLESPACE MONITOR OUTPUT)。因此，两次日志时间并不是规律的间隔15秒，而是自上次输出后15秒加上收集输出监控日志的时间。 补充知识 查看错误日志输出位置 mysql root@localhost:test> select @@log_error; +----------------------------------------+ | @@log_error | |----------------------------------------| | /usr/local/mysql/data/mysqld.local.err | +----------------------------------------+ 查看历史日志开启状态与输出位置 mysql root@localhost:test> show VARIABLES like 'general%'; +------------------+---------------------------------------+ | Variable_name | Value | |------------------+---------------------------------------| | general_log | ON | | general_log_file | /usr/local/mysql/data/yerba-buena.log | +------------------+---------------------------------------+ 监控日志解读 详见参考文档2及参考文档5 参考文档 Enabling InnoDB Monitors InnoDB Standard Monitor and Lock Monitor Output How to debug InnoDB lock waits How to find out who is locking a table in MySQL InnoDB Monitor INNODB监控开关 "},"数据库/Mysql/Mysql锁表问题解决.html":{"url":"数据库/Mysql/Mysql锁表问题解决.html","title":"Mysql锁表问题解决","keywords":"","body":"Mysql锁表问题解决 案例一 mysql>show processlist; 参看sql语句 一般少的话 mysql>kill thread_id; 就可以解决了 kill掉第一个锁表的进程, 依然没有改善. 既然不改善, 咱们就想办法将所有锁表的进程kill掉吧, 简单的脚本如下. #!/bin/bash mysql - u root - e \" show processlist \" | grep - i \" Locked \" >> locked_log . txt for line in ` cat locked_log.txt | awk '{print $1 }' ` do echo \" kill $line ; \" >> kill_thread_id . sql done 现在kill_thread_id.sql的内容像这个样子 kill 66402982 ; kill 66402983 ; kill 66402986 ; kill 66402991 ; ..... 好了, 我们在mysql的shell中执行, 就可以把所有锁表的进程杀死了. mysql > source kill_thread_id.sql 当然了, 也可以一行搞定 for id in `mysqladmin processlist | grep -i locked | awk '{print $1}'` do mysqladmin kill ${id} done 案例二 如果大批量的操作能够通过一系列的select语句产生，那么理论上就能对这些结果批量处理。 但是mysql并没用提供eval这样的对结果集进行分析操作的功能。所以只能现将select结果保存到临时文件中，然后再执行临时文件中的指令。 具体过程如下： mysql> SELECT concat('KILL ',id,';') FROM information_schema.processlist WHERE user='root'; +------------------------+ | concat('KILL ',id,';') +------------------------+ | KILL 3101; | KILL 2946; +------------------------+ 2 rows IN SET (0.00 sec) mysql> SELECT concat('KILL ',id,';') FROM information_schema.processlist WHERE user='root' INTO OUTFILE '/tmp/a.txt'; Query OK, 2 rows affected (0.00 sec) mysql> source /tmp/a.txt; Query OK, 0 rows affected (0.00 sec) 案例三 MySQL + PHP的模式在大并发压力下经常会导致MySQL中存在大量僵死进程，导致服务挂死。为了自动干掉这些进程，弄了个脚本，放在服务器后台通过crontab自动执行。发现这样做了以后，的确很好的缓解了这个问题。把这个脚本发出来和大家Share. 根据自己的实际需要，做了一些修改： SHELL脚本:mysqld_kill_sleep.sh #!/bin/sh mysql_pwd=\"root的密码\" mysqladmin_exec=\"/usr/local/bin/mysqladmin\" mysql_exec=\"/usr/local/bin/mysql\" mysql_timeout_dir=\"/tmp\" mysql_timeout_log=\"$mysql_timeout_dir/mysql_timeout.log\" mysql_kill_timeout_sh=\"$mysql_timeout_dir/mysql_kill_timeout.sh\" mysql_kill_timeout_log=\"$mysql_timeout_dir/mysql_kill_timeout.log\" $mysqladmin_exec -uroot -p\"$mysql_pwd\" processlist | awk '{ print $12 , $2 ,$4}' | grep -v Time | grep -v '|' | sort -rn > $mysql_timeout_log awk '{if($1>30 && $3!=\"root\") print \"'\"\"$mysql_exec\"\"' -e \" \"\\\"\" \"kill\",$2 \"\\\"\" \" -uroot \" \"-p\"\"\\\"\"\"'\"\"$mysql_pwd\"\"'\"\"\\\"\" \";\" }' $mysql_timeout_log > $mysql_kill_timeout_sh echo \"check start ....\" >> $mysql_kill_timeout_log echo `date` >> $mysql_kill_timeout_log cat $mysql_kill_timeout_sh 把这个写到mysqld_kill_sleep.sh。然后chmod 0 mysqld_kill_sleep.sh,chmod u+rx mysqld_kill_sleep.sh，然后用root账户到cron里面运行即可，时间自己调整。 执行之后显示： www# ./mysqld_kill_sleep.sh /usr/local/bin/mysql -e \"kill 27549\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27750\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27840\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27867\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27899\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27901\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27758\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27875\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27697\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27888\" -uroot -p\"mysql root的密码\"; /usr/local/bin/mysql -e \"kill 27861\" -uroot -p\"mysql root的密码\"; 如果确认没有问题了，把最后的cat修改为sh即可。 改写了下上面的脚本: #!/bin/bash mysql_pwd=\"密码\" mysql_exec=\"/usr/local/mysql/bin/mysql\" mysql_timeout_dir=\"/tmp\" mysql_kill_timeout_sh=\"$mysql_timeout_dir/mysql_kill_timeout.sh\" mysql_kill_timeout_log=\"$mysql_timeout_dir/mysql_kill_timeout.log\" $mysql_exec -uroot -p$mysql_pwd -e \"show processlist\" | grep -i \"Locked\" >> $mysql_kill_timeout_log chmod 777 $mysql_kill_timeout_log for line in `$mysql_kill_timeout_log | awk '{print $1}'` do echo \"$mysql_exec -uroot -p$mysql_pwd -e \\\"kill $line\\\"\" >> $mysql_kill_timeout_sh done chmod 777 $mysql_kill_timeout_sh cat $mysql_kill_timeout_sh "},"数据库/Mysql/MySql慢查询优化.html":{"url":"数据库/Mysql/MySql慢查询优化.html","title":"MySql慢查询优化","keywords":"","body":"MySql慢查询优化 慢查询，顾名思义，执行很慢的查询。有多慢？超过 long_query_time 参数设定的时间阈值（默认 10s），就被认为是慢的，是需要优化的。慢查询被记录在慢查询日志里。 慢查询日志默认是不开启的，如果你需要优化 SQL 语句，就可以开启这个功能，它可以让你很容易地知道哪些语句是需要优化的（想想一个 SQL 要 10s 就可怕）。好了，下面我们就一起来看看怎么处理慢查询。 慢查询配置 开启慢查询 MySQL 支持通过以下方式开启慢查询： 输入命令开启慢查询（临时），在 MySQL 服务重启后会自动关闭。 配置 my.cnf（Windows 是 my.ini）系统文件开启，修改配置文件是持久化开启慢查询的方式 方法一：通过命令开启慢查询 步骤 1：查询 slow_query_log 查看是否已开启慢查询日志： show variables like '%slow_query_log%'; mysql> show variables like '%slow_query_log%'; +---------------------+-----------------------------------+ | Variable_name | Value | +---------------------+-----------------------------------+ | slow_query_log | OFF | | slow_query_log_file | /var/lib/mysql/localhost-slow.log | +---------------------+-----------------------------------+ 2 rows in set (0.01 sec) 步骤 2：开启慢查询命令： set global slow_query_log='ON'; 步骤 3：指定记录慢查询日志 SQL 执行时间得阈值（long_query_time 单位：秒，默认 10 秒）。 如下我设置成了 1 秒，执行时间超过 1 秒的 SQL 将记录到慢查询日志中： set global long_query_time=1; 步骤 4：查询 “慢查询日志文件存放位置”。 show variables like '%slow_query_log_file%'; mysql> show variables like '%slow_query_log_file%'; +---------------------+-----------------------------------+ | Variable_name | Value | +---------------------+-----------------------------------+ | slow_query_log_file | /var/lib/mysql/localhost-slow.log | +---------------------+-----------------------------------+ 1 row in set (0.01 sec) slow_query_log_file 指定慢查询日志的存储路径及文件（默认和数据文件放一起）。 步骤 5：核对慢查询开启状态，需要退出当前 MySQL 终端，重新登录即可刷新。 配置了慢查询后，它会记录以下符合条件的 SQL： 查询语句 数据修改语句 已经回滚的 SQL 方式二：通过配置 my.cnf（Windows 是 my.ini）系统文件开启（版本：MySQL 5.5 及以上）。 在 my.cnf 文件的 [mysqld] 下增加如下配置开启慢查询，如下图： # 开启慢查询功能 slow_query_log=ON # 指定记录慢查询日志SQL执行时间得阈值 long_query_time=1 # 选填，默认数据文件路径 # slow_query_log_file=/var/lib/mysql/localhost-slow.log 重启数据库后即持久化开启慢查询，查询验证如下： mysql> show variables like '%_query_%'; +------------------------------+-----------------------------------+ | Variable_name | Value | +------------------------------+-----------------------------------+ | have_query_cache | YES | | long_query_time | 1.000000 | | slow_query_log | ON | | slow_query_log_file | /var/lib/mysql/localhost-slow.log | +------------------------------+-----------------------------------+ 6 rows in set (0.01 sec) 慢查询日志介绍 如上图，是执行时间超过 1 秒的 SQL 语句（测试）： 第一行：记录时间。 第二行：用户名 、用户的 IP 信息、线程 ID 号。 第三行：执行花费的时间【单位：秒】、执行获得锁的时间、获得的结果行数、扫描的数据行数。 第四行：这 SQL 执行的时间戳。 第五行：具体的 SQL 语句。 Explain 分析慢查询 SQL 分析 MySQL 慢查询日志，利用 Explain 关键字可以模拟优化器执行 SQL 查询语句，来分析 SQL 慢查询语句。 下面我们的测试表是一张 137w 数据的 app 信息表，我们来举例分析一下。 SQL 示例如下： -- 1.185s SELECT * from vio_basic_domain_info where app_name like '%翻译%' ; 这是一条普通的模糊查询语句，查询耗时：1.185s，查到了 148 条数据。 我们用 Explain 分析结果如下表，根据表信息可知：该 SQL 没有用到字段 app_name 上的索引，查询类型是全表扫描，扫描行数 137w。 mysql> EXPLAIN SELECT * from vio_basic_domain_info where app_name like '%翻译%' ; +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------------+ | 1 | SIMPLE | vio_basic_domain_info | NULL | ALL | NULL | NULL | NULL | NULL | 1377809 | 11.11 | Using where | +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 当这条 SQL 使用到索引时，SQL 如下：查询耗时：0.156s，查到 141 条数据： -- 0.156s SELECT * from vio_basic_domain_info where app_name like '翻译%' ; Explain 分析结果如下表；根据表信息可知：该 SQL 用到了 idx_app_name 索引，查询类型是索引范围查询，扫描行数 141 行。 由于查询的列不全在索引中（select *），因此回表了一次，取了其他列的数据。 mysql> EXPLAIN SELECT * from vio_basic_domain_info where app_name like '翻译%' ; +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | vio_basic_domain_info | NULL | range | idx_app_name | idx_app_name | 515 | NULL | 141 | 100.00 | Using index condition | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) 当这条 SQL 使用到覆盖索引时，SQL 如下：查询耗时：0.091s，查到 141 条数据。 -- 0.091s SELECT app_name from vio_basic_domain_info where app_name like '翻译%' ; Explain 分析结果如下表；根据表信息可知：和上面的 SQL 一样使用到了索引，由于查询列就包含在索引列中，又省去了 0.06s 的回表时间。 mysql> EXPLAIN SELECT app_name from vio_basic_domain_info where app_name like '翻译%' ; +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | vio_basic_domain_info | NULL | range | idx_app_name | idx_app_name | 515 | NULL | 141 | 100.00 | Using where; Using index | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) 那么是如何通过 EXPLAIN 解析结果分析 SQL 的呢？各列属性又代表着什么？一起往下看。 各列属性的简介 各列属性的简介如下： id：SELECT 的查询序列号，体现执行优先级，如果是子查询，id的序号会递增，id 值越大优先级越高，越先被执行。 select_type：表示查询的类型。 table：输出结果集的表，如设置了别名，也会显示。 partitions：匹配的分区。 type：对表的访问方式。 possible_keys：表示查询时，可能使用的索引。 key：表示实际使用的索引。 key_len：索引字段的长度。 ref：列与索引的比较。 rows：扫描出的行数（估算的行数）。 filtered：按表条件过滤的行百分比。 Extra：执行情况的描述和说明。 以上标星的几类是我们优化慢查询时常用到的。 慢查询分析常用到的属性 ①type 对表访问方式，表示 MySQL 在表中找到所需行的方式，又称“访问类型”。 存在的类型有：ALL、index、range、ref、eq_ref、const、system、NULL（从左到右，性能从低到高）。 介绍三个咱们天天见到的： ALL：（Full Table Scan）MySQL 将遍历全表以找到匹配的行，常说的全表扫描。 Index：（Full Index Scan）Index 与 ALL 区别为 Index 类型只遍历索引树。 Range：只检索给定范围的行，使用一个索引来选择行。 ②key key 列显示了 SQL 实际使用索引，通常是 possible_keys 列中的索引之一，MySQL 优化器一般会通过计算扫描行数来选择更适合的索引，如果没有选择索引，则返回 NULL。 当然，MySQL 优化器存在选择索引错误的情况，可以通过修改 SQL 强制MySQL“使用或忽视某个索引”： 强制使用一个索引：FORCE INDEX (index_name)、USE INDEX (index_name)。 强制忽略一个索引：IGNORE INDEX (index_name)。 ③rows rows 是 MySQL 估计为了找到所需的行而要读取（扫描）的行数，可能不精确。 ④Extra 这一列显示一些额外信息，很重要。 Using index：查询的列被索引覆盖，并且 where 筛选条件是索引的是前导列，Extra 中为 Using index。意味着通过索引查找就能直接找到符合条件的数据，无须回表。 注：前导列一般指联合索引中的第一列或“前几列”，以及单列索引的情况；这里为了方便理解我统称为前导列。 Using where：说明 MySQL 服务器将在存储引擎检索行后再进行过滤；即没有用到索引，回表查询。 可能的原因： 查询的列未被索引覆盖。 where 筛选条件非索引的前导列或无法正确使用到索引。 Using temporary：这意味着 MySQL 在对查询结果排序时会使用一个临时表。 Using filesort：说明 MySQL 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。 Using index condition：查询的列不全在索引中，where 条件中是一个前导列的范围。 Using where；Using index：查询的列被索引覆盖，并且 where 筛选条件是索引列之一，但不是索引的前导列或出现了其他影响直接使用索引的情况（如存在范围筛选条件等），Extra 中为 Using where；Using index，意味着无法直接通过索引查找来查询到符合条件的数据，影响并不大。 一些慢查询优化经验分享 优化 LIMIT 分页 在系统中需要分页的操作通常会使用 limit 加上偏移量的方法实现，同时加上合适的 order by 子句。 如果有对应的索引，通常效率会不错，否则 MySQL 需要做大量的文件排序操作。 一个非常令人头疼问题就是当偏移量非常大的时候，例如可能是 limit 1000000，10 这样的查询。 这是 MySQL 需要查询 1000000 条然后只返回最后 10 条，前面的 1000000 条记录都将被舍弃，这样的代价很高，会造成慢查询。 优化此类查询的一个最简单的方法是尽可能的使用索引覆盖扫描，而不是查询所有的列。 然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升。 对于下面的查询： -- 执行耗时：1.379s SELECT * from vio_basic_domain_info LIMIT 1000000,10; Explain 分析结果： mysql> EXPLAIN SELECT * from vio_basic_domain_info LIMIT 1000000,10; +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------+ | 1 | SIMPLE | vio_basic_domain_info | NULL | ALL | NULL | NULL | NULL | NULL | 1377809 | 100.00 | NULL | +----+-------------+-----------------------+------------+------+---------------+------+---------+------+---------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 该语句存在的最大问题在于 limit M，N 中偏移量 M 太大，导致每次查询都要先从整个表中找到满足条件的前 M 条记录，之后舍弃这 M 条记录并从第 M+1 条记录开始再依次找到 N 条满足条件的记录。 如果表非常大，且筛选字段没有合适的索引，且 M 特别大那么这样的代价是非常高的。 那么如果我们下一次的查询能从前一次查询结束后标记的位置开始查找，找到满足条件的 10 条记录，并记下下一次查询应该开始的位置，以便于下一次查询能直接从该位置开始。 这样就不必每次查询都先从整个表中先找到满足条件的前 M 条记录，舍弃掉，再从 M+1 开始再找到 10 条满足条件的记录了。 处理分页慢查询的方式一般有以下几种： 方法一：构造覆盖索引 通过修改 SQL，使用上覆盖索引，比如我需要只查询表中的 app_name、createTime 等少量字段，那么我秩序在 app_name、createTime 字段设置联合索引，即可实现覆盖索引，无需全表扫描。 适用于查询列较少的场景，查询列数过多的不推荐，耗时：0.390s。 mysql> EXPLAIN SELECT app_name,createTime from vio_basic_domain_info LIMIT 1000000,10; +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+---------+----------+-------------+ | 1 | SIMPLE | vio_basic_domain_info | NULL | index | NULL | idx_app_name | 515 | NULL | 1377809 | 100.00 | Using index | +----+-------------+-----------------------+------------+-------+---------------+--------------+---------+------+---------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 方法二：优化 offset 无法用上覆盖索引，那么重点是想办法快速过滤掉前 100w 条数据。我们可以利用自增主键有序的条件，先查询出第 1000001 条数据的 id 值，再往后查 10 行。 适用于主键 id 自增的场景，耗时：0.471s。 SELECT * from vio_basic_domain_info where id >=(SELECT id from vio_basic_domain_info ORDER BY id limit 1000000,1) limit 10; 原理：先基于索引查询出第 1000001 条数据对应的主键 id 的值，然后直接通过该 id 的值直接查询该 id 后面的 10 条数据。 下方 EXPLAIN 分析结果中大家可以看到这条 SQL 的两步执行流程： mysql> EXPLAIN SELECT * from vio_basic_domain_info where id >=(SELECT id from vio_basic_domain_info ORDER BY id limit 1000000,1) limit 10; +----+-------------+-----------------------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | 1 | PRIMARY | vio_basic_domain_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 10 | 100.00 | Using where | | 2 | SUBQUERY | vio_basic_domain_info | NULL | index | NULL | PRIMARY | 8 | NULL | 1000001 | 100.00 | Using index | +----+-------------+-----------------------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ 2 rows in set, 1 warning (0.40 sec) 方法三：“延迟关联” 耗时：0.439s，延迟关联适用于数量级较大的表。 SQL 如下： SELECT * from vio_basic_domain_info inner join (select id from vio_basic_domain_info order by id limit 1000000,10) as myNew using(id); 这里我们利用到了覆盖索引+延迟关联查询，相当于先只查询 id 列，利用覆盖索引快速查到该页的 10 条数据 id，然后再把返回的 10 条 id 拿到表中通过主键索引二次查询。（表数据增速快的情况对该方法影响较小） mysql> EXPLAIN SELECT * from vio_basic_domain_info inner join (select id from vio_basic_domain_info order by id limit 1000000,10) as myNew using(id); +----+-------------+-----------------------+------------+--------+---------------+---------+---------+----------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+------------+--------+---------------+---------+---------+----------+---------+----------+-------------+ | 1 | PRIMARY | | NULL | ALL | NULL | NULL | NULL | NULL | 1000010 | 100.00 | NULL | | 1 | PRIMARY | vio_basic_domain_info | NULL | eq_ref | PRIMARY | PRIMARY | 8 | myNew.id | 1 | 100.00 | NULL | | 2 | DERIVED | vio_basic_domain_info | NULL | index | NULL | PRIMARY | 8 | NULL | 1000010 | 100.00 | Using index | +----+-------------+-----------------------+------------+--------+---------------+---------+---------+----------+---------+----------+-------------+ 3 rows in set, 1 warning (0.00 sec) 排查索引没起作用的情况 ①模糊查询尽量避免用通配符'%'开头，会导致数据库引擎放弃索引进行全表扫描 如下： SELECT * FROM t WHERE username LIKE '%陈%' 优化方式：尽量在字段后面使用模糊查询。如下： SELECT * FROM t WHERE username LIKE '陈%' 如果需求是要在前面使用模糊查询： 使用 MySQL 内置函数 INSTR（str，substr）来匹配，作用类似于 Java 中的 indexOf()，查询字符串出现的角标位置。 使用 FullText 全文索引，用 match against 检索。 数据量较大的情况，建议引用 ElasticSearch、Solr，亿级数据量检索速度秒级。 当表数据量较少（几千条儿那种），别整花里胡哨的，直接用 like '%xx%'。 ②尽量避免使用 not in，会导致引擎走全表扫描。建议用 not exists 代替 如下： -- 不走索引 SELECT * FROM t WHERE name not IN ('提莫','队长'); -- 走索引 select * from t as t1 where not exists (select * from t as t2 where name IN ('提莫','队长') and t1.id = t2.id); ③尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描 如下： SELECT * FROM t WHERE id = 1 OR id = 3 优化方式：可以用 union 代替 or。如下： SELECT * FROM t WHERE id = 1 UNION SELECT * FROM t WHERE id = 3 ④尽量避免进行 null 值的判断，会导致数据库引擎放弃索引进行全表扫描 如下： SELECT * FROM t WHERE score IS NULL 优化方式：可以给字段添加默认值 0，对 0 值进行判断。如下： SELECT * FROM t WHERE score = 0 ⑤尽量避免在 where 条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描 可以将表达式、函数操作移动到等号右侧。如下： -- 全表扫描 SELECT * FROM T WHERE score/10 = 9 -- 走索引 SELECT * FROM T WHERE score = 10*9 ⑥当数据量大时，避免使用 where 1=1 的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描 如下： SELECT username, age, sex FROM T WHERE 1=1 优化方式：用代码拼装 SQL 时进行判断，没 where 条件就去掉 where，有 where 条件就加 and。 ⑦查询条件不能用 <> 或者 != 使用索引列作为条件进行查询时，需要避免使用<>或者!=等判断条件。 如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。 ⑧where 条件仅包含复合索引非前导列 如：复合（联合）索引包含 key_part1，key_part2，key_part3 三列，但 SQL 语句没有包含索引前置列\"key_part1\"，按照 MySQL 联合索引的最左匹配原则，不会走联合索引。 -- 不走索引 select col1 from table where key_part2=1 and key_part3=2 -- 走索引 select col1 from table where key_part1 =1 and key_part2=1 and key_part3=2 ⑨隐式类型转换造成不使用索引 如下 SQL 语句由于索引对列类型为 varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。 select col1 from table where col_varchar=123; "},"数据库/DB2/":{"url":"数据库/DB2/","title":"DB2","keywords":"","body":"DB2 IBM DB2企业服务器版本，是美国IBM公司发展的一套关系型数据库管理系统。它主要的运行环境为UNIX（包括IBM自家的AIX）、Linux、IBM i（旧称OS/400）、Z/OS，以及Windows服务器版本。DB2也提供性能强大的IBM InfoSphere Warehouse版本。和DB2同级的还有另外一个关系型数据库管理系统：Informix，它在2001年被IBM收购。 DB2主要应用于大型应用系统，具有较好的可伸缩性，可支持从大型机到单用户环境，应用于所有常见的服务器操作系统平台下。 DB2提供了高层次的数据利用性、完整性、安全性、可恢复性，以及小规模到大规模应用程序的执行能力，具有与平台无关的基本功能和SQL命令。DB2采用了数据分级技术，能够使大型机数据很方便地下载到LAN数据库服务器，使得客户机/服务器用户和基于LAN的应用程序可以访问大型机数据，并使数据库本地化及远程连接透明化。 DB2以拥有一个非常完备的查询优化器而著称，其外部连接改善了查询性能，并支持多任务并行查询。 DB2具有很好的网络支持能力，每个子系统可以连接十几万个分布式用户，可同时激活上千个活动线程，对大型分布式应用系统尤为适用。 DB2除了可以提供主流的OS/390和VM操作系统，以及中等规模的AS/400系统之外，IBM还提供了跨平台（包括基于UNIX的LINUX，HP-UX，SunSolaris，以及SCOUnixWare；还有用于个人电脑的OS/2操作系统，以及微软的Windows 2000和其早期的系统）的DB2产品。DB2数据库可以通过使用微软的开放数据库连接（ODBC）接口，Java数据库连接（JDBC）接口，或者CORBA接口代理被任何的应用程序访问。 从命令行方式到图形用户界面都可以使用DB2。命令行界面要求对产品知识的更多了解同样也更容易编写脚本并自动执行。图形界面是一个多平台的Java客户端，它包含了多种针对新手用户的向导服务。DB2同时支持SQL和XQuery。DB2本地执行XML数据存储，在这里XML数据以XML（不是关系型数据或者CLOB数据）格式存储以更快地通过使用XQuery进行访问。 DB2拥有基于 .NET CLI, Java, Python, Perl, PHP, Ruby, C++, C, REXX, PL/I, COBOL, RPG, FORTRAN的APIs，以及很多其它的程序语言。DB2同样支持集成于Eclipse和Visual Studio .NET集成开发环境之中。 错误处理 DB2计算机程序一个重要的特征就是错误处理。SQL communications area（SQLCA）结构曾一度被专门用于DB2程序在每个SQL语句被执行后向应用程序返回错误信息。在SQLCA block中常见错误诊断被体现在SQLCODE中。 SQL返回代码的值对应为： 0表示成功执行 正值表示成功执行但是有一个或多个警告。例如+100表示没有行被发现。 负值表示出现错误。例如－911表示锁超时（或死锁），并触发撤消程序。 DB2后来的版本增强了SQL语句执行的功能性和复杂性。多个错误或警告可以通过执行SQL语句被返回；它可以启动一个数据库触发器和其它SQL语句。替代最初的SQLCA，错误信息现在被连续不断的GET DIAGNOSTICS语句执行所检索。 察看更多的常见SQLCODEs列表SQL返回值。 "},"数据库/DB2/DB2高危操作LOAD命令风险详解.html":{"url":"数据库/DB2/DB2高危操作LOAD命令风险详解.html","title":"DB2高危操作LOAD命令风险详解","keywords":"","body":"DB2高危操作LOAD命令风险详解 LOAD是 DB2中的一个数据装载工具，它能够直接将格式化的数据写入数据库，而且只记录很少量的日志，因此比批量INSERT或者IMPORT的效率要高得多。但正是由于只写少量日志等特点，一旦LOAD失败可能会导致严重的问题，使得 LOAD命令变成了一个高风险的操作。在我行多年的数据库运维工作中，很多系统采用 LOAD提升了性能，满足了业务需求，但是也经历了很多惨痛的教训。本文重点梳理了LOAD操作常见的风险点，分析其原因，并给出相应的解决方法。 风险1：LOAD期间表不可访问 问题现象：访问正在进行LOAD操作的表时报错SQL0911N The current transaction has been rolled back because of a deadlock or timeout. Reason code \"68\". SQLSTATE=40001。 原因分析：默认的LOAD命令，比如 db2 load from a.del of del insert into a，是会锁表的，在LOAD期间会在目标表上加Z锁（超级排他锁），导致目标表不可访问。 解决方法: LOAD命令可以加上allow read access，这样在LOAD期间对表可以做查询操作。 风险2：LOAD正常完成后表状态异常 问题现象：LOAD操作正常完成，且没有任何报错，但在访问表的时候报错SQL0668N Operation not allowed for reason code \"1\" on table \"\". SQLSTATE=57016，如果使用LOAD query table命令查看表状态，发现是Set Integrity Pending。 原因分析：除了不符合表的定义的记录外，LOAD操作只检查唯一性约束，不执行引用约束检查或表约束检查。当目标表有其他约束时，LOAD完成后表就会被置于set integrity pending状态，无论是否真的有记录违反约束 。 解决方法：对异常表发出set integrity命令可以解除Set Integrity Pending状态。 风险3：LOAD失败后表状态异常 问题现象：LOAD操作失败后，访问时表报错SQL0668N Operation not allowed for reason code \"3\" on table \" \". SQLSTATE=57016。 原因分析：如果LOAD操作因为某些原因，比如中断、表空间不足等而失败，那么失败后表就处于Load Pending状态，访问的时候就会报SQL0668N, reason code 3的报错，必须再发出一次LOAD命令才能解除这种状态。 解决方法: 将原来LOAD命令中的replace/insert into改成 restart/terminate into，重新发起一次即可，restart是继续上次失败的LOAD操作，terminate则是终止 LOAD操作，直接把表置于normal状态。 风险4：LOAD导致表空间状态异常 问题现象：LOAD操作在测试环境没有问题，但在生产上执行以后，对表更新操作的时候报错SQL0290N Table space access is not allowed. SQLSTATE=55039，对同一表空间中其他表也无法更新。 原因分析：数据库日志模式有循环日志和归档日志，前者的事务日志文件会被循环使用；后者日志文件会一直保留着，以便出现问题时能通过备份+重做日志来恢复到任意时间点的数据。LOAD操作是不记日志的，所以在归档日志模式下无法通过重做日志来恢复数据，为了避免出问题时数据不可恢复，DB2会强制把表所在表空间置于backup pending状态，在backup pending状态下，表空间中所有表不允许更新操作，必须对表空间做一个备份，才能解除该状态。测试环境采用的是循环日志模式，不存在该问题，生产环境采用的归档日志，所以遇到了问题。 解决方法：在LOAD命令里加上nonrecoverable参数，可以避免表空间进入backup pending状态。nonrecoverable的意思是，允许表不可恢复。 风险5：LOAD导致表数据无法通过备份恢复 问题现象：数据库0点进行全备， 4点有LOAD操作， 在8点时数据库异常，需要通过0点的备份加上0点到8点间的日志恢复数据库到7：59分的数据。恢复完成后，访问表的时候的报错SQL1477N For table \"\" an object \"\" in tablespace \"\" cannot be accessed. SQLSTATE=55019。 原因分析：如果一张表有不记日志的操作，那么重做日志(rollforward)之后，该表就进入不可访问状态，只能删除重建。LOAD操作不记日志，所以可能在恢复数据的时候遇到上面的问题。 解决方法：将nonrecoverable 修改为copy yes，或者在LOAD完成后立刻进行数据库备份。 风险6：LOAD导致HADR切换后表不可访问 问题现象：HADR架构的数据库，在切换到备机之后，访问表时报错SQL1477N For table \"\" an object \"\" in table space \"\" cannot be accessed. SQLSTATE=55019。 原因分析：原因和风险点5中的原因类似，HADR备机会一直重做主机的日志，当主机有不记日志的操作后，备机上该表状态进入不可访问状态，切换为主后不可访问。 解决方法：主机上如果有LOAD操作，可以使用copy yes的方式，并将主备机的某个共享目录作为copy yes的目标目录。 风险7：LOAD commit时间长导致应用查询锁超时 问题现象：分区表上的LOAD操作加了allow read access，但应用查询表时仍然报锁超时的错误SQL0911N Reason code \"68\"，Locker owner为该LOAD作业，hold住锁的类型为Z锁。 原因分析：LOAD操作会有一个commit阶段，这个阶段会把缓冲池中所有与这张表相关的页清除掉。对于分区表而言，commit时间随着缓冲池大小和分区表中分区的数量的增加而增加，与LOAD的数据量无关，在LOAD commit阶段，要在表上加Z锁，可能会导致其他并发应用的锁超时问题。 解决方法：对于分区表的情况，如果只LOAD数据到一个或者几个分区上，可以先detach出来这些分区，单独LOAD，完成之后再attach进去。 风险8：LOAD terminate时间过长 问题现象：某表由于LOAD失败进入Load Pending状态，在发出load terminate命令之后，一直没有返回，且该表不可访问。 原因分析：load terminate作业的stack如下 load terminate作业的trace如下： 从stack和trace可以看出，load termiate是在清理索引，并且进行的是Direct IO。如果LOAD命令加了allow read access和indexing mode incremental(默认)参数，并且在build阶段被中断了，那么后续的load terminate操作会清理索引。索引清理的时候进行了Direct IO，导致效率低下。进行Direct IO的原因是LOAD本身的设计，如果是在线LOAD，数据会经过buffer；如果是离线的，数据不经buffer，进行Direct IO。 解决方法：如果原来的LOAD命令加了allow read access并且被中断了，那么发出load terminate的时候，也要加上allow read access。 "},"数据库/Informix/":{"url":"数据库/Informix/","title":"Informix","keywords":"","body":"Informix "},"应用/":{"url":"应用/","title":"应用","keywords":"","body":"应用 应用服务器是指通过各种协议把商业逻辑曝露给客户端的程序。它提供了访问商业逻辑的途径以供客户端应用程序使用。应用服务器使用此商业逻辑就像调用对象的一个方法一样。 随着Internet的发展壮大,“主机/终端”或“客户机/服务器”的传统的应用系统模式已经不能适应新的环境,于是就产生了新的分布式应用系统,相应地,新的开发模式也应运而生，即所谓的“浏览器/服务器”结构、“瘦客户机”模式。应用服务器便是一种实现这种模式核心技术。 Web应用程序驻留在应用服务器(Application Server)上。应用服务器为Web应用程序提供一种简单的和可管理的对系统资源的访问机制。它也提供低级的服务，如HTTP协议的实现和数据库连接管理。Servlet容器仅仅是应用服务器的一部分。除了Servlet容器外，应用服务器还可能提供其他的Java EE(Enterprise Edition)组件，如EJB容器，JNDI服务器以及JMS服务器等。 市场上可以得到多种应用服务器，其中包括Apache的Tomcat、IBM的WebSphere Application Server、Caucho Technology的Resin、Macromedia的JRun、NEC WebOTX Application Server、JBoss Application Server、Oracle(并购了BEA)的WebLogic等。其中有些如NEC WebOTX Application Server、WebLogic、WebSphere不仅仅是Servlet容器，它们也提供对EJB(Enterprise JavaBeans)、JMS(Java Message Service)以及其他Java EE技术的支持。每种类型的应用服务器都有自己的优点、局限性和适用性。 应用服务器和WEB服务器的区别 通俗的讲，Web服务器传送(serves)页面使浏览器可以浏览，然而应用程序服务器提供的是客户端应用程序可以调用(call)的方法(methods)。确切一点，你可以说：Web服务器专门处理HTTP请求(request)，但是应用程序服务器是通过很多协议来为应用程序提供(serves)商业逻辑(business logic)。 Web型 Web服务器(Web Server)可以解析(handles)HTTP协议。当Web服务器接收到一个HTTP请求(request)，会返回一个HTTP响应 (response)，例如送回一个HTML页面。为了处理一个请求(request)，Web服务器可以响应(response)一个静态页面或图片， 进行页面跳转(redirect)，或者把动态响应(dynamic response)的产生委托(delegate)给一些其它的程序例如CGI脚本，JSP(JavaServer Pages)脚本，servlets,ASP(Active Server Pages)脚本，服务器端(server-side)JavaScript,或者一些其它的服务器端(server-side)技术。无论它们(译者 注：脚本)的目的如何，这些服务器端(server-side)的程序通常产生一个HTML的响应(response)来让浏览器可以浏览。 企业WEB服务器是面向企业网络用户的信息交流平台,WEB在企业生产管理过程中的应用越来越多,是信息化应用的入口，一些应用系统都集成在WEB服务器上。要知道，Web服务器的代理模型(delegation model)非常简单。当一个请求(request)被送到Web服务器里来时，它只单纯的把请求(request)传递给可以很好的处理请求 (request)的程序(译者注：服务器端脚本)。Web服务器仅仅提供一个可以执行服务器端(server-side)程序和返回(程序所产生的)响 应(response)的环境，而不会超出职能范围。服务器端(server-side)程序通常具有事务处理(transaction processing)，数据库连接(database connectivity)和消息(messaging)等功能。 虽然Web 服务器不支持事务处理或数据库连接池，但它可以配置(employ)各种策略(strategies)来实现容错性(fault tolerance)和可扩展性(scalability)，例如负载平衡(load balancing)，缓冲(caching)。集群特征(clustering-features)经常被误认为仅仅是应用程序服务器专有的特征。 应用程序型 应用程序服务器(The Application Server) 根据定义，作为应用程序服务器，它通过各种协议，可以包括HTTP,把商业逻辑暴露给(expose)客户端应用程序。Web服务器主要是处理向 浏览器发送HTML以供浏览，而应用程序服务器提供访问商业逻辑的途径以供客户端应用程序使用。应用程序使用此商业逻辑就像你调用对象的一个方法(或过程 语言中的一个函数)一样。 应用程序服务器的客户端(包含有图形用户界面(GUI)的)可能会运行在一台PC、一个Web服务器或者甚至 是其它的应用程序服务器上。在应用程序服务器与其客户端之间来回穿梭(traveling)的信息不仅仅局限于简单的显示标记。相反，这种信息就是程序逻 辑(program logic)。 正是由于这种逻辑取得了(takes)数据和方法调用(calls)的形式而不是静态HTML,所以客户端才可以随心所欲的使用这种被暴露的商业逻辑。 在大多数情形下，应用程序服务器是通过组件(component)的应用程序接口(API)把商业逻辑暴露(expose)(给客户端应用程序)的，例 如基于J2EE(Java 2 Platform, Enterprise Edition)应用程序服务器的EJB(Enterprise JavaBean)组件模型。此外，应用程序服务器可以管理自己的资源，例如看大门的工作(gate-keeping duties)包括安全(security)，事务处理(transaction processing)，资源池(resource pooling)， 和消息(messaging)。就象Web服务器一样，应用程序服务器配置了多种可扩展(scalability)和容错(fault tolerance)技术。 "},"应用/Nginx/":{"url":"应用/Nginx/","title":"Nginx","keywords":"","body":"Nginx Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。 其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 优点 Nginx 可以在大多数 UnixLinux OS 上编译运行，并有 Windows 移植版。 Nginx 的1.4.0稳定版已经于2013年4月24日发布，一般情况下，对于新建站点，建议使用最新稳定版作为生产版本，已有站点的升级急迫性不高。 Nginx 是一个很强大的高性能Web和反向代理服务，它具有很多非常优越的特性： 在连接高并发的情况下，Nginx是Apache服务不错的替代品：Nginx在美国是做虚拟主机生意的老板们经常选择的软件平台之一。能够支持高达 50,000 个并发连接数的响应，感谢Nginx为我们选择了 epoll and kqueue作为开发模型。 服务器 Nginx作为负载均衡服务：Nginx 既可以在内部直接支持 Rails 和 PHP 程序对外进行服务，也可以支持作为 HTTP代理服务对外进行服务。Nginx采用C进行编写，不论是系统资源开销还是CPU使用效率都比 Perlbal 要好很多。 处理静态文件，索引文件以及自动索引;打开文件描述符缓冲。 无缓存的反向代理加速，简单的负载均衡和容错。 FastCGI，简单的负载均衡和容错。 模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCG或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。 支持 SSL 和 TLSSNI。 代码 Nginx代码完全用C语言从头写成，已经移植到许多体系结构和操作系统，包括：Linux、FreeBSD、Solaris、Mac OS X、AIX以及Microsoft Windows。Nginx有自己的函数库，并且除了zlib、PCRE和OpenSSL之外，标准模块只使用系统C库函数。而且，如果不需要或者考虑到潜在的授权冲突，可以不使用这些第三方库。 代理服务器 作为邮件代理服务：Nginx 同时也是一个非常优秀的邮件代理服务（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。 Nginx 是一个安装非常的简单、配置文件非常简洁（还能够支持perl语法）、Bug非常少的服务。Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够不间断服务的情况下进行软件版本的升级。 "},"应用/Nginx/Nginx配置参数中文说明.html":{"url":"应用/Nginx/Nginx配置参数中文说明.html","title":"Nginx配置参数中文说明","keywords":"","body":"Nginx配置参数中文说明 Nginx配置参数中文详细说明： #定义Nginx运行的用户和用户组 user www www; # #nginx进程数,建议设置为等于CPU总核心数. worker_processes 8; # #全局错误日志定义类型,[ debug | info | notice | warn | error | crit ] error_log /var/log/nginx/error.log info; # #进程文件 pid /var/run/nginx.pid; # #一个nginx进程打开的最多文件描述符数目,理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除,但是nginx分配请求并不均匀,所以建议与ulimit -n的值保持一致. worker_rlimit_nofile 65535; # #工作模式与连接数上限 events { #参考事件模型,use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型,如果跑在FreeBSD上面,就用kqueue模型. use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） worker_connections 65535; } # #设定http服务器 http { include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 #charset utf-8; #默认编码 server_names_hash_bucket_size 128; #服务器名字的hash表大小 client_header_buffer_size 32k; #上传文件大小限制 large_client_header_buffers 4 64k; #设定请求缓 client_max_body_size 8m; #设定请求缓 # 开启目录列表访问,合适下载服务器,默认关闭. autoindex on; # 显示目录 autoindex_exact_size on; # 显示文件大小 默认为on,显示出文件的确切大小,单位是bytes 改为off后,显示出文件的大概大小,单位是kB或者MB或者GB autoindex_localtime on; # 显示文件时间 默认为off,显示的文件时间为GMT时间 改为on后,显示的文件时间为文件的服务器时间 sendfile on; # 开启高效文件传输模式,sendfile指令指定nginx是否调用sendfile函数来输出文件,对于普通应用设为 on,如果用来进行下载等应用磁盘IO重负载应用,可设置为off,以平衡磁盘与网络I/O处理速度,降低系统的负载.注意：如果图片显示不正常把这个改成off. tcp_nopush on; # 防止网络阻塞 tcp_nodelay on; # 防止网络阻塞 keepalive_timeout 120; # (单位s)设置客户端连接保持活动的超时时间,在超过这个时间后服务器会关闭该链接 # FastCGI相关参数是为了改善网站的性能：减少资源占用,提高访问速度.下面参数看字面意思都能理解. fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; # gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #允许压缩的页面的最小字节数,页面字节数从header偷得content-length中获取.默认是0,不管页面多大都进行压缩.建议设置成大于1k的字节数,小于1k可能会越压越大 gzip_buffers 4 16k; #表示申请4个单位为16k的内存作为压缩结果流缓存,默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果 gzip_http_version 1.1; #压缩版本（默认1.1,目前大部分浏览器已经支持gzip解压.前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级.1压缩比最小,处理速度快.9压缩比最大,比较消耗cpu资源,处理速度最慢,但是因为压缩比最大,所以包最小,传输速度快 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型,默认就已经包含text/html,所以下面就不用再写了,写上去也不会有问题,但是会有一个warn. gzip_vary on;#选项可以让前端的缓存服务器缓存经过gzip压缩的页面.例如:用squid缓存经过nginx压缩的数据 #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; ##upstream的负载均衡,四种调度算法(下例主讲)## #虚拟主机的配置 server { # 监听端口 listen 80; # 域名可以有多个,用空格隔开 server_name ably.com; # HTTP 自动跳转 HTTPS rewrite ^(.*) https://$server_name$1 permanent; } server { # 监听端口 HTTPS listen 443 ssl; server_name ably.com; # 配置域名证书 ssl_certificate C:\\WebServer\\Certs\\certificate.crt; ssl_certificate_key C:\\WebServer\\Certs\\private.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; index index.html index.htm index.php; root /data/www/; location ~ .*\\.(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } # 配置地址拦截转发，解决跨域验证问题 location /oauth/{ proxy_pass https://localhost:13580/oauth/; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 图片缓存时间设置 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } # JS和CSS缓存时间设置 location ~ .*\\.(js|css)?$ { expires 1h; } # 日志格式设定 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; # 定义本虚拟主机的访问日志 access_log /var/log/nginx/access.log access; # 设定查看Nginx状态的地址.StubStatus模块能够获取Nginx自上次启动以来的工作状态，此模块非核心模块，需要在Nginx编译安装时手工指定才能使用 location /NginxStatus { stub_status on; access_log on; auth_basic \"NginxStatus\"; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生. } } } Nginx多台服务器实现负载均衡 Nginx负载均衡服务器： IP：192.168.0.4（Nginx-Server） Web服务器列表： Web1:192.168.0.5（Nginx-Node1/Nginx-Web1） Web2:192.168.0.7（Nginx-Node2/Nginx-Web2） 实现目的：用户访问Nginx-Server（“http://mongo.demo.com:8888”）时，通过Nginx负载均衡到Web1和Web2服务器 Nginx负载均衡服务器的nginx.conf配置注释如下： events { use epoll; worker_connections 65535; } http { ##upstream的负载均衡,四种调度算法## #调度算法1:轮询.每个请求按时间顺序逐一分配到不同的后端服务器,如果后端某台服务器宕机,故障系统被自动剔除,使用户访问不受影响 upstream webhost { server 192.168.0.5:6666 ; server 192.168.0.7:6666 ; } #调度算法2:weight(权重).可以根据机器配置定义权重.权重越高被分配到的几率越大 upstream webhost { server 192.168.0.5:6666 weight=2; server 192.168.0.7:6666 weight=3; } #调度算法3:ip_hash. 每个请求按访问IP的hash结果分配,这样来自同一个IP的访客固定访问一个后端服务器,有效解决了动态网页存在的session共享问题 upstream webhost { ip_hash; server 192.168.0.5:6666 ; server 192.168.0.7:6666 ; } #调度算法4:url_hash(需安装第三方插件).此方法按访问url的hash结果来分配请求,使每个url定向到同一个后端服务器,可以进一步提高后端缓存服务器的效率.Nginx本身是不支持url_hash的,如果需要使用这种调度算法,必须安装Nginx 的hash软件包 upstream webhost { server 192.168.0.5:6666 ; server 192.168.0.7:6666 ; hash $request_uri; } #调度算法5:fair(需安装第三方插件).这是比上面两个更加智能的负载均衡算法.此种算法可以依据页面大小和加载时间长短智能地进行负载均衡,也就是根据后端服务器的响应时间来分配请求,响应时间短的优先分配.Nginx本身是不支持fair的,如果需要使用这种调度算法,必须下载Nginx的upstream_fair模块 # #虚拟主机的配置(采用调度算法3:ip_hash) server { listen 80; server_name mongo.demo.com; #对 \"/\" 启用反向代理 location / { proxy_pass http://webhost; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置,可选. proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数, proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后,后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区,网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小,大于这个值,将从upstream服务器传 } } } 负载均衡操作演示如下： 操作对象：192.168.0.4（Nginx-Server） # 创建文件夹准备存放配置文件 $ mkdir -p /opt/confs $ vim /opt/confs/nginx.conf # 编辑内容如下： events { use epoll; worker_connections 65535; } http { upstream webhost { ip_hash; server 192.168.0.5:6666 ; server 192.168.0.7:6666 ; } server { listen 80; server_name mongo.demo.com; location / { proxy_pass http://webhost; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } } } # 然后保存并退出 # 启动负载均衡服务器192.168.0.4（Nginx-Server） docker run -d -p 8888:80 --name nginx-server -v /opt/confs/nginx.conf:/etc/nginx/nginx.conf --restart always nginx 操作对象：192.168.0.5（Nginx-Node1/Nginx-Web1） # 创建文件夹用于存放web页面 $ mkdir -p /opt/html $ vim /opt/html/index.html # 编辑内容如下： The host is 192.168.0.5(Docker02) - Node 1! # 然后保存并退出 # 启动192.168.0.5（Nginx-Node1/Nginx-Web1） $ docker run -d -p 6666:80 --name nginx-node1 -v /opt/html:/usr/share/nginx/html --restart always nginx 操作对象：192.168.0.7（Nginx-Node2/Nginx-Web2） # 创建文件夹用于存放web页面 $ mkdir -p /opt/html $ vim /opt/html/index.html # 编辑内容如下： The host is 192.168.0.7(Docker03) - Node 2! # 然后保存并退出 # 启动192.168.0.7（Nginx-Node2/Nginx-Web2） $ docker run -d -p 6666:80 --name nginx-node2 -v $(pwd)/html:/usr/share/nginx/html --restart always nginx 测试： 域名:mongo.demo.com，这里是用Windows系统主机访问服务器，要在当前主机的hosts中添加解析 “mongo.demo.com 192.168.0.4”，hosts文件所在的路径为 “C:\\Windows\\System32\\drivers\\etc”。 这里在Windows主机上通过浏览器访问 “http://mongo.demo.com:8888” 这个站点的时候，Nginx会根据来访的主机的ip_hash值，负载均衡到192.168.0.5（Nginx-Node1/Nginx-Web1）和192.168.0.7（Nginx-Node2/Nginx-Web2）服务器上。 如果其中一个Web服务器无效后，负载均衡服务器会自动将请求转发到正常的Web服务器。 下图是另外做的一组demo的访问效果图，而且容器的端口和IP不同（所有信息都做了相应修改）： Nginx-Server：192.168.2.129（Docker01）； Nginx-Node1：192.168.2.56（Docker02）； Nginx-Node2：192.168.2.77（Docker03）； "},"应用/分布式/":{"url":"应用/分布式/","title":"分布式","keywords":"","body":"分布式 "},"应用/分布式/分布式架构知识体系.html":{"url":"应用/分布式/分布式架构知识体系.html","title":"分布式架构知识体系","keywords":"","body":"分布式架构知识体系 随着移动互联网的发展和智能终端的普及，计算机系统早就从单机独立工作过渡到多机器协作，集群按照分布式理论构建出庞大复杂的应用服务，在分布式的基础上正进行一场云原生的技术革命，彻底打破传统的开发方式，解放了新一代的生产力。 基础理论 SOA 到 MSA 的进化 SOA 面向服务架构 由于业务发展到一定程度后，需要对服务进行解耦，进而把一个单一的大系统按逻辑拆分成不同的子系统，通过服务接口来通讯。面向服务的设计模式，最终需要总线集成服务，而且大部分时候还共享数据库，出现单点故障时会导致总线层面的故障，更进一步可能会把数据库拖垮，所以才有了更加独立的设计方案的出现。 MSA 微服务架构 微服务是真正意义上的独立服务，从服务入口到数据持久层，逻辑上都是独立隔离的，无需服务总线来接入，但同时也增加了整个分布式系统的搭建和管理难度，需要对服务进行编排和管理，所以伴随着微服务的兴起，微服务生态的整套技术栈也需要无缝接入，才能支撑起微服务的治理理念。 节点与网络 节点 传统的节点也就是一台单体的物理机，所有的服务都揉进去包括服务和数据库；随着虚拟化的发展，单台物理机往往可以分成多台虚拟机，实现资源利用的最大化，节点的概念也变成单台虚拟机上面服务；近几年容器技术逐渐成熟后，服务已经彻底容器化，也就是节点只是轻量级的容器服务。总体来说，节点就是能提供单位服务的逻辑计算资源的集合。 网络 分布式架构的根基就是网络，不管是局域网还是公网，没有网络就无法把计算机联合在一起工作，但是网络也带来了一系列的问题。网络消息的传播有先后，消息丢失和延迟是经常发生的事情，我们定义了三种网络工作模式： 同步网络 节点同步执行 消息延迟有限 高效全局锁 半同步网络 锁范围放宽 异步网络 节点独立执行 消息延迟无上限 无全局锁 部分算法不可行 常用网络传输层有两大协议的特点简介： TCP 协议 首先 tcp 协议传输可靠，尽管其他的协议可以更快传输 tcp 解决重复和乱序问题 UDP 协议 常量数据流 丢包不致命时间与顺序 时间 慢速物理时空中，时间独自在流淌着，对于串行的事务来说，很简单的就是跟着时间的脚步走就可以，先来后到的发生。而后我们发明了时钟来刻画以往发生的时间点，时钟让这个世界井然有序。但是对于分布式世界来说，跟时间打交道着实是一件痛苦的事情。 分布式世界里面，我们要协调不同节点之间的先来后到关系，不同节点本身承认的时间又各执己见，于是我们创造了网络时间协议（NTP）试图来解决不同节点之间的标准时间，但是 NTP 本身表现并不尽如人意，所以我们又构造出了逻辑时钟，最后改进为向量时钟： NTP 的一些缺点，无法完全满足分布式下并发任务的协调问题 节点间时间不同步 硬件时钟漂移 线程可能休眠 操作系统休眠 硬件休眠 逻辑时钟 定义事件先来后到 t' = max(t, t_msg + 1) 向量时钟 t_i' = max(t_i, t_msg_i) 原子钟顺序 有了衡量时间的工具，解决顺序问题自然就是水到渠成了。因为整个分布式的理论基础就是如何协商不同节点的一致性问题，而顺序则是一致性理论的基本概念，所以前文我们才需要花时间介绍衡量时间的刻度和工具。一致性理论 说到一致性理论，我们必须看一张关于一致性强弱对系统建设影响的对比图： 该图对比了不同一致性算法下的事务、性能、错误、延迟的平衡。 强一致性 ACID 单机环境下我们对传统关系型数据库有苛刻的要求，由于存在网络的延迟和消息丢失，ACID 便是保证事务的原则，这四大原则甚至我们都不需要解释出来就耳熟能详了： Atomicity：原子性，一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节； Consistency：一致性，在事务开始之前和事务结束以后，数据库的完整性没有被破坏； Isolation：隔离性，数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时，由于交叉执行而导致数据的不一致； Durabilit：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 分布式一致性 CAP 分布式环境下，我们无法保证网络的正常连接和信息的传送，于是发展出了 CAP/FLP/DLS 这三个重要的理论： AP：分布式计算系统不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition）； FLP：在异步环境中，如果节点间的网络延迟没有上限，只要有一个恶意的节点存在，就没有算法能在有限的时间内达成共识； DLS： 在一个部分同步网络的模型（也就是说：网络延时有界限但是我们并不知道在哪里）下运行的协议可以容忍 1/3 任意（换句话说，拜占庭）错误； 在一个异步模型中的确定性的协议（没有网络延时上限）不能容错（不过这个论文没有提起随机化算法可以容忍 1/3 的错误）； 同步模型中的协议（网络延时可以保证小于已知 d 时间），可以令人吃惊的达到 100% 容错，虽然对 1/2 的节点出错可以发生的情况有所限制。 弱一致性 BASE 多数情况下，其实我们也并非一定要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率，发展出来了最终一致性理论 BASE。BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）： 基本可用（Basically Available）：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用； 软状态（Soft State）：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现； 最终一致性（Eventual Consistency）：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 一致性算法 分布式架构的核心就在于一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。保证不同节点在充满不确定性网络环境下能达成相同副本的一致性是非常困难的，业界对该课题也做了大量的研究。 首先我们要了解一致性的大前提原则 (CALM)： CALM 原则的全称是 Consistency and Logical Monotonicity ，主要描述的是分布式系统中单调逻辑与一致性的关系，它的内容如下。（参考 ） 在分布式系统中，单调的逻辑都能保证 “最终一致性”，这个过程中不需要依赖中心节点的调度； 任意分布式系统，如果所有的非单调逻辑都有中心节点调度，那么这个分布式系统就可以实现最终“一致性”。 然后再关注分布式系统的数据结构 CRDT(Conflict-Free Replicated Data Types)： 我们了解到分布式一些规律原则之后，就要着手考虑如何来实现解决方案，一致性算法的前提是数据结构，或者说一切算法的根基都是数据结构，设计良好的数据结构加上精妙的算法可以高效的解决现实的问题。 经过前人不断的探索，我们得知分布式系统被广泛采用的数据结构 CRDT。（参考,） 基于状态（state-based）：即将各个节点之间的 CRDT 数据直接进行合并，所有节点都能最终合并到同一个状态，数据合并的顺序不会影响到最终的结果； 基于操作（operation-based）：将每一次对数据的操作通知给其他节点。只要节点知道了对数据的所有操作（收到操作的顺序可以是任意的），就能合并到同一个状态。 了解数据结构后，我们需要来关注一下分布式系统的一些重要的协议HATs(Highly Available Transactions)，ZAB(Zookeeper Atomic Broadcast)： 参考， 最后要学习的是业界主流的一致性算法 ： 说实话具体的算法我也还没完全搞懂，一致性算法是分布式系统最核心本质的内容，这部分的发展也会影响架构的革新，不同场景的应用也催生不同的算法。 Paxos： Raft ： Gossip： 这一节我们说完分布式系统里面核心理论基础，如何达成不同节点之间的数据一致性，下面我们将会讲到目前都有哪些主流的分布式系统。 场景分类 文件系统 单台计算机的存储始终有上限，随着网络的出现，多台计算机协作存储文件的方案也相继被提出来。最早的分布式文件系统其实也称为网络文件系统，第一个文件服务器在 1970 年代被发展出来。在 1976 年迪吉多公司设计出 File Access Listener（FAL），而现代分布式文件系统则出自赫赫有名的 Google 的论文，奠定了分布式文件系统的基础。 现代主流分布式文件系统参考,下面列举几个常用的文件系统： HDFS FastDFS Ceph mooseFS 数据库 数据库当然也属于文件系统，主数据增加了事务、检索、擦除等高级特性，所以复杂度又增加了，既要考虑数据一致性也得保证足够的性能。传统关系型数据库为了兼顾事务和性能的特性，在分布式方面的发展有限，非关系型数据库摆脱了事务的强一致性束缚，达到了最终一致性的效果，从而有了飞跃的发展，NoSql(Not Only Sql) 也产生了多个架构的数据库类型，包括 KV、列式存储、文档类型等。 列式存储：Hbase 文档存储：Elasticsearch，MongoDB KV 类型：Redis 关系型：Spanner 计算 分布式计算系统构建在分布式存储的基础上，充分发挥分布式系统的数据冗余灾备，多副本高效获取数据的特性，进而并行计算，把原本需要长时间计算的任务拆分成多个任务并行处理，从而提高了计算效率。分布式计算系统在场景上分为离线计算、实时计算和流式计算。 离线：Hadoop 实时：Spark 流式：Storm，Flink/Blink 缓存 缓存作为提升性能的利器无处不在，小到 CPU 缓存架构，大到分布式应用存储。分布式缓存系统提供了热点数据的随机访问机制，大大了提升了访问时间，但是带来的问题是如何保证数据的一致性，引入分布式锁来解决这个问题，主流的分布式存储系统基本就是 Redis 了。 持久化：Redis 非持久化：Memcache 消息 分布式消息队列系统是消除异步带来的一系列复杂步骤的一大利器，在多线程高并发场景下，我们常常需要谨慎设计业务代码，来保证多线程并发情况下不出现资源竞争导致的死锁问题。而消息队列以一种延迟消费的模式将异步任务都存到队列，然后再逐个消化。 Kafka RabbitMQ RocketMQ ActiveMQ 监控 分布式系统从单机到集群的形态发展，复杂度也大大提高，所以对整个系统的监控也是必不可少。 Zookeeper 应用 分布式系统的核心模块就是在应用如何处理业务逻辑，应用直接的调用依赖于特定的协议来通信，有基于 RPC 协议的，也有基于通用的 HTTP 协议。 HSF Dubbo 日志 错误对应分布式系统是家常便饭，而且我们设计系统的时候，本身就需要把容错作为普遍存在的现象来考虑。那么当出现故障的时候，快速恢复和排查故障就显得非常重要了。分布式日志采集存储和检索则可以给我们提供有力的工具来定位请求链路中出现问题的环节。 日志采集：flume 日志存储：ElasticSearch/Solr，SLS 日志定位：Zipkin 账本 前文我们提到所谓分布式系统，是迫于单机的性能有限，而堆硬件却又无法无休止的增加，单机堆硬件最终也会遇到性能增长曲线的瓶颈。于是我们才采用了多台计算机来干同样的活，但是这样的分布式系统始终需要中心化的节点来监控或者调度系统的资源，即使该中心节点也可能是多节点组成。 区块链则是真正的区中心化分布式系统，系统里面只有 P2P 网络协议各自通信，没有真正意义的中心节点，彼此按照区块链节点的算力、权益等机制来协调新区块的产生。 比特币 以太坊 设计模式 上节我们列举了不同场景下不同分布式系统架构扮演的角色和实现的功能，本节我们更进一步归纳分布式系统设计的时候是如何考虑架构设计的、不同设计方案直接的区别和侧重点、不同场景需要选择合作设计模式，来减少试错的成本，设计分布式系统需要考虑以下的问题。 可用性 可用性是系统运行和工作的时间比例，通常以正常运行时间的百分比来衡量。它可能受系统错误、基础架构问题、恶意攻击和系统负载的影响。分布式系统通常为用户提供服务级别协议（SLA），因此应用程序必须设计为最大化可用性。 健康检查：系统实现全链路功能检查，外部工具定期通过公开端点访问系统 负载均衡：使用队列起到削峰作用，作为请求和服务之间的缓冲区，以平滑间歇性的重负载 节流：限制应用级别、租户或整个服务所消耗资源的范围 数据管理 数据管理是分布式系统的关键要素，并影响大多数质量的属性。由于性能，可扩展性或可用性等原因，数据通常托管在不同位置和多个服务器上，这可能带来一系列挑战。例如，必须维护数据一致性，并且通常需要跨不同位置同步数据。 缓存：根据需要将数据从数据存储层加载到缓存 CQRS(Command Query Responsibility Segregation)：命令查询职责分离 事件溯源：仅使用追加方式记录域中完整的系列事件 索引表：在经常查询引用的字段上创建索引 物化视图：生成一个或多个数据预填充视图 拆分：将数据拆分为水平的分区或分片 设计与实现 良好的设计包括诸如组件设计和部署的一致性、简化管理和开发的可维护性、以及允许组件和子系统用于其他应用程序和其他方案的可重用性等因素。在设计和实施阶段做出的决策对分布式系统和服务质量和总体拥有成本产生巨大影响。 代理：反向代理 适配器：在现代应用程序和遗留系统之间实现适配器层 前后端分离：后端服务提供接口供前端应用程序调用 计算资源整合：将多个相关任务或操作合并到一个计算单元中 配置分离：将配置信息从应用程序部署包中移出到配置中心 网关聚合：使用网关将多个单独的请求聚合到一个请求中 网关卸载：将共享或专用服务功能卸载到网关代理 网关路由：使用单个端点将请求路由到多个服务 领导人选举：通过选择一个实例作为负责管理其他实例管理员，协调分布式系统的云 管道和过滤器：将复杂的任务分解为一系列可以重复使用的单独组件 边车：将应用的监控组件部署到单独的进程或容器中，以提供隔离和封装 静态内容托管：将静态内容部署到 CDN，加速访问效率 消息 分布式系统需要一个连接组件和服务的消息传递中间件，理想情况是以松散耦合的方式，以便最大限度地提高可伸缩性。异步消息传递被广泛使用，并提供许多好处，但也带来了诸如消息排序，幂等性等挑战 竞争消费者：多线程并发消费 优先级队列：消息队列分优先级，优先级高的先被消费 管理与监控 分布式系统在远程数据中心运行，无法完全控制基础结构，这使管理和监视比单机部署更困难。应用必须公开运行时信息，管理员可以使用这些信息来管理和监视系统，以及支持不断变化的业务需求和自定义，而无需停止或重新部署应用。 性能与扩展 性能表示系统在给定时间间隔内执行任何操作的响应性，而可伸缩性是系统处理负载增加而不影响性能或容易增加可用资源的能力。分布式系统通常会遇到变化的负载和活动高峰，特别是在多租户场景中，几乎是不可能预测的。相反，应用应该能够在限制范围内扩展以满足需求高峰，并在需求减少时进行扩展。可伸缩性不仅涉及计算实例，还涉及其他元素，如数据存储、消息队列等。 弹性 弹性是指系统能够优雅地处理故障并从故障中恢复。分布式系统通常是多租户，使用共享平台服务、竞争资源和带宽，通过 Internet 进行通信，以及在商用硬件上运行，意味着出现瞬态和更永久性故障的可能性增加。为了保持弹性，必须快速有效地检测故障并进行恢复。 隔离：将应用程序的元素隔离到池中，以便在其中一个失败时，其他元素将继续运行 断路器：处理连接到远程服务或资源时可能需要不同时间修复的故障 补偿交易：撤消一系列步骤执行的工作，这些步骤共同定义最终一致的操作 健康检查：系统实现全链路功能检查，外部工具定期通过公开端点访问系统 重试：通过透明地重试先前失败的操作，使应用程序在尝试连接到服务或网络资源时处理预期的临时故障 安全 安全性是系统能够防止在设计使用之外的恶意或意外行为，并防止泄露或丢失信息。分布式系统在受信任的本地边界之外的 Internet 上运行，通常向公众开放，并且可以为不受信任的用户提供服务。必须以保护应用程序免受恶意攻击，限制仅允许对已批准用户的访问，并保护敏感数据。 联合身份：将身份验证委派给外部身份提供商 看门人：通过使用专用主机实例来保护应用程序和服务，该实例充当客户端与应用程序或服务之间的代理，验证和清理请求，并在它们之间传递请求和数据 代客钥匙：使用为客户端提供对特定资源或服务的受限直接访问的令牌或密钥 工程应用 前文我们介绍了分布式系统的核心理论，面临的一些难题和解决问题的折中思路，罗列了现有主流分布式系统的分类，而且归纳了建设分布式系统的一些方法论，那么接下来我们将从工程角度来介绍真刀真枪搭建分布式系统包含的内容和步骤。 资源调度 巧妇难为无米之炊，我们一切的软件系统都是构建在硬件服务器的基础上。从最开始的物理机直接部署软件系统，到虚拟机的应用，最后到了资源上云容器化，硬件资源的使用也开始了集约化的管理。本节对比的是传统运维角色对应的职责范围，在 devops 环境下，开发运维一体化，我们要实现的也是资源的灵活高效使用。 弹性伸缩 过去软件系统随着用户量增加需要增加机器资源的话，传统的方式就是找运维申请机器，然后部署好软件服务接入集群，整个过程依赖的是运维人员的人肉经验，效率低下而且容易出错。微服务分布式则无需人肉增加物理机器，在容器化技术的支撑下，我们只需要申请云资源，然后执行容器脚本即可。 应用扩容：用户激增需要对服务进行扩展，包括自动化扩容，峰值过后的自动缩容 机器下线：对于过时应用，进行应用下线，云平台收回容器宿主资源 机器置换：对于故障机器，可供置换容器宿主资源，服务自动启动，无缝切换 网络管理 有了计算资源后，另外最重要的就是网络资源了。在现有的云化背景下，我们几乎不会直接接触到物理的带宽资源，而是直接由云平台统一管理带宽资源。我们需要的是对网络资源的最大化应用和有效的管理。 域名申请：应用申请配套域名资源的申请，多套域名映射规则的规范 域名变更：域名变更统一平台管理 负载管理：多机应用的访问策略设定 安全外联：基础访问鉴权，拦截非法请求 统一接入：提供统一接入的权限申请平台，提供统一的登录管理 故障快照 在系统故障的时候我们第一要务是系统恢复，同时保留案发现场也是非常重要的，资源调度平台则需要有统一的机制保存好故障现场。 现场保留：内存分布，线程数等资源现象的保存，如 JavaDump 钩子接入 调试接入：采用字节码技术无需入侵业务代码，可以供生产环境现场日志打点调试 流量调度 在我们建设好分布式系统后，最先受到考验的关口就是网关了，进而我们需要关注系统流量的情况，也就是如何对流量的管理，我们追求的是在系统可容纳的流量上限内，把资源留给最优质的流量使用、把非法恶意的流量挡在门外，这样节省成本的同时确保系统不会被冲击崩溃。 负载均衡 负载均衡是我们对服务如何消化流量的通用设计，通常分为物理层的底层协议分流的硬负载均衡和软件层的软负载。负载均衡解决方案已经是业界成熟的方案，我们通常会针对特定业务在不同环境进行优化，常用有如下的负载均衡解决方案 交换机 F5 LVS/ALI-LVS Nginx/Tengine VIPServer/ConfigServer 网关设计 负载均衡首当其冲的就是网关，因为中心化集群流量最先打到的地方就是网关了，如果网关扛不住压力的话，那么整个系统将不可用。 高性能：网关设计第一需要考虑的是高性能的流量转发，网关单节点通常能达到上百万的并发流量 分布式：出于流量压力分担和灾备考虑，网关设计同样需要分布式 业务筛选：网关同设计简单的规则，排除掉大部分的恶意流量 流量管理 请求校验：请求鉴权可以把多少非法请求拦截，清洗 数据缓存：多数无状态的请求存在数据热点，所以采用 CDN 可以把相当大一部分的流量消费掉 流控控制 剩下的真实流量我们采用不同的算法来分流请求。 流量分配 计数器 队列 漏斗 令牌桶 动态流控 流量限制在流量激增的时候，通常我们需要有限流措施来防止系统出现雪崩，那么就需要预估系统的流量上限，然后设定好上限数，但流量增加到一定阈值后，多出来的流量则不会进入系统，通过牺牲部分流量来保全系统的可用性。 限流策略 QPS 粒度 线程数粒度 RT 阈值 限流工具 - Sentinel 服务调度 所谓打铁还需自身硬，流量做好了调度管理后，剩下的就是服务自身的健壮性了。分布式系统服务出现故障是常有的事情，甚至我们需要把故障本身当做是分布式服务的一部分。 注册中心 我们网络管理一节中介绍了网关，网关是流量的集散地，而注册中心则是服务的根据地。 状态类型：第一好应用服务的状态，通过注册中心就可以检测服务是否可用 生命周期：应用服务不同的状态组成了应用的生命周期 版本管理 集群版本：集群不用应用有自身对应的版本号，由不同服务组成的集群也需要定义大的版本号 版本回滚：在部署异常的时候可以根据大的集群版本进行回滚管理 服务编排 服务编排的定义是：通过消息的交互序列来控制各个部分资源的交互。参与交互的资源都是对等的，没有集中的控制。微服务环境下服务众多我们需要有一个总的协调器来协议服务之间的依赖，调用关系，K8s 则是我们的不二选择。 K8s Spring Cloud HSF ZK+Dubbo 服务控制 前面我们解决了网络的健壮性和效率问题，这节介绍的是如何使我们的服务更加健壮。 发现资源管理那节我们介绍了从云平台申请了容器宿主资源后，通过自动化脚本就可以启动应用服务，启动后服务则需要发现注册中心，并且把自身的服务信息注册到服务网关，即是网关接入。注册中心则会监控服务的不同状态，做健康检查，把不可用的服务归类标记。 网关接入 健康检查 降级：当用户激增的时候，我们首先是在流量端做手脚，也就是限流。当我们发现限流后系统响应变慢了，有可能导致更多的问题时，我们也需要对服务本身做一些操作。服务降级就是把当前不是很核心的功能关闭掉，或者不是很要紧的准确性放宽范围，事后再做一些人工补救。 降低一致性约束 关闭非核心服务 简化功能 熔断：当我们都做了以上的操作后，还是觉得不放心，那么就需要再进一步操心。熔断是对过载的一种自身保护，犹如我们开关跳闸一样。比如当我们服务不断对数据库进行查询的时候，如果业务问题造成查询问题，这是数据库本身需要熔断来保证不会被应用拖垮，并且访问友好的信息，告诉服务不要再盲目调用了。 闭合状态 半开状态 断开状态 熔断工具- Hystrix 幂等：我们知道，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。那么就需要对单次操作赋予一个全局的 id 来做标识，这样多次请求后我们可以判断来源于同个客户端，避免出现脏数据。 全局一致性 ID Snowflake 数据调度 数据存储最大的挑战就是数据冗余的管理，冗余多了效率变低而且占用资源，副本少了起不到灾备的作用，我们通常的做法是把有转态的请求，通过转态分离，转化为无状态请求。 状态转移 分离状态至全局存储，请求转换为无状态流量，比如我们通常会将登陆信息缓存至全局 redis 中间件，而不需要在多个应用中去冗余用户的登陆数据。 分库分表 数据横向扩展。 分片分区 多副本冗余。 自动化运维 我们从资源申请管理的时候就介绍到 devops 的趋势，真正做到开发运维一体化则需要不同的中间件来配合完成。 配置中心 全局配置中心按环境来区分，统一管理，减少了多处配置的混乱局面。 switch diamend 部署策略 微服务分布式部署是家常便饭，如何让我们的服务更好地支撑业务发展，稳健的部署策略是我们首先需要考虑的，如下的部署策略适合不同业务和不同的阶段。 停机部署 滚动部署 蓝绿部署 灰度部署 A/B 测试 作业调度 任务调度是系统必不可少的一个环节，传统的方式是在 Linux 机器上配置 crond 定时任务或者直接在业务代码里面完成调度业务，现在则是成熟的中间件来代替。 SchedulerX Spring 定时任务 应用管理 运维工作中很大一部分时间需要对应用进行重启，上下线操作，还有日志清理。 应用重启 应用下线 日志清理 容错处理 既然我们知道分布式系统故障是家常便饭，那么应对故障的方案也是不可或缺的环节。通常我们有主动和被动的方式来处理： 主动是在错误出现的时候，我们试图再试试几次，说不定就成功了，成功的话就可以避免了该次错误 被动方式是错误的事情已经发生了，为了挽回，我们只是做时候处理，把负面影响降到最小 重试设计 重试设计的关键在于设计好重试的时间和次数，如果超过重试次数，或是一段时间，那么重试就没有意义了。开源的项目 spring-retry 可以很好地实现我们重试的计划。 事务补偿 事务补偿符合我们最终一致性的理念。补偿事务不一定会将系统中的数据返回到原始操作开始时其所处的状态。相反，它补偿操作失败前由已成功完成的步骤所执行的工作。补偿事务中步骤的顺序不一定与原始操作中步骤的顺序完全相反。例如，一个数据存储可能比另一个数据存储对不一致性更加敏感，因而补偿事务中撤销对此存储的更改的步骤应该会首先发生。对完成操作所需的每个资源采用短期的基于超时的锁并预先获取这些资源，这样有助于增加总体活动成功的可能性。仅在获取所有资源后才应执行工作。锁过期之前必须完成所有操作。 全栈监控 由于分布式系统是由众多机器共同协作的系统，而且网络也无法保证完全可用，所以我们需要建设一套对各个环节都能监控的系统，这样我们才能从底层到业务各个层面进行监控，出现意外的时候可以及时修复故障，避免更多的问题出现。 基础层 基础层面是对容器资源的监测，包含各个硬件指标的负载情况 CPU、IO、内存、线程、吞吐 中间件 分布式系统接入了大量的中间件平台，中间件本身的健康情况也需要监控。 应用层 性能监控：应用层面的需要对每个应用服务的实时指标（qps，rt），上下游依赖等进行监控 业务监控：除了应用本身的监控程度，业务监控也是保证系统正常的一个环节，通过设计合理的业务规则，对异常的情况做报警设置 监控链路 zipkin/eagleeye sls goc Alimonitor 故障恢复 当故障已经发生后，我们第一个要做的就是马上消除故障，确保系统服务正常可用，这个时候通常做回滚操作。 应用回滚 应用回滚之前需要保存好故障现场，以便排查原因。 基线回退 应用服务回滚后，代码基线也需要 revert 到前一版本。 版本回滚 整体回滚需要服务编排，通过大版本号对集群进行回滚。 性能调优 性能优化是分布式系统的大专题，涉及的面非常广，这块简直可以单独拿出来做一个系列来讲，本节就先不展开。本身我们做服务治理的过程也是在性能的优化过程。 参考 分布式锁 缓存是解决性能问题的一大利器，理想情况下，每个请求不需要额外计算就立刻能获取到结果时最快。小到 CPU 的三级缓存，大到分布式缓存，缓存无处不在，分布式缓存需要解决的就是数据的一致性，这个时候我们引入了分布式锁的概念，如何处理分布式锁的问题将决定我们获取缓存数据的效率。 高并发 多线程编程模式提升了系统的吞吐量，但也同时带来了业务的复杂度。 异步 事件驱动的异步编程是一种新的编程模式，摒弃了多线程的复杂业务处理问题，同时能够提升系统的响应效率。 总结 最后总结一下，如果有可能的话，请尝试使用单节点方式而不是分布式系统。分布式系统伴随着一些失败的操作，为了处理灾难性故障，我们使用备份；为了提高可靠性，我们引入了冗余。 分布式系统本质就是一堆机器的协同，而我们要做的就是搞出各种手段来然机器的运行达到预期。这么复杂的系统，需要了解各个环节、各个中间件的接入，是一个非常大的工程。庆幸的是，在微服务背景下，多数基础性的工作已经有人帮我们实现了。前文所描述的分布式架构，在工程实现了是需要用到分布式三件套 (Docker+K8S+Srping Cloud) 基本就可以构建出来了。 分布式架构核心技术分布图如下： 分布式技术栈使用中间件： "},"安全/":{"url":"安全/","title":"安全","keywords":"","body":"安全 "},"安全/CTF/":{"url":"安全/CTF/","title":"CTF","keywords":"","body":"CTF "},"安全/CTF/CTF之隐写术破解.html":{"url":"安全/CTF/CTF之隐写术破解.html","title":"CTF之隐写术破解","keywords":"","body":"CTF之隐写术破解 一、隐写术可以利用图片、音频、视频为载体将数据隐藏在其中，将数据隐写到图像中较为常见。 二、图像隐写术进行数据隐写分为以下几类： 在图片右击-属性-详细信息中隐藏数据信息 将数据类型进行改写（rar类型数据 将其改写成jpg格式） 根据各种类型图像的固定格式，隐藏数据 修改图像开始标志，改变其原有图像格式； 在图像结束标志后加入数据； 在图像数据中假如数据，不影响视觉效果情况下修改像素数据，加入信息。 利用隐写算法将数据隐写到图像中而不影响图像（仅限于jpg图像），隐写算法常见有F5、Guess、JSteg和JPHide等 三、破解隐写术方法及步骤： 查看图像-属性-详细信息是否包括隐藏内容 利用WinHex打开图像，搜索CTF、ctf或flag看是否在打开数据中存在相关信息 检查图像开始标志和结束标志是否正确，若不正确修改图像标志恢复图像，打开查看是否ctf或flag等信息（往往gif属于动图，需要分帧查看各帧图像组合所得数据 若不是直接的ctf或flag信息 需要考虑将其解码） jpg图像开始标志：FF D8 结束标志：FF D9 gif图像开始标志：47 49 46 38 39 61 结束标志：01 01 00 3B bmp图像开始标志：结束标志： png图像开始标志：89 50 4E 47 0D 0A 1A 0A 结束标志：00 00 00 00 49 45 4E 44 AE 42 60 82 将图像放置kali系统中，执行binwalk xxx.jpg 查看图像中是否是多个图像组合或者其中包含其他文件（若存在多幅图像组合，再执行foremost xxx.jpg会自动分离；若检测出其他文件修改其后缀即可，如.zip） 使用StegSolve对图像进行分通道扫描，查看是否为LSB隐写 在windows系统命令行下使用F5-steganography-master进行jpg图像是否为F5算法隐写 在kali系统中使用outguess-master工具（需要安装），检测是否为guess算法隐写 "},"安全/CTF/BMP图片分析.html":{"url":"安全/CTF/BMP图片分析.html","title":"BMP图片分析","keywords":"","body":"BMP图片分析 文件格式 格式组成 典型的BMP图像文件由四部分组成： 位图头文件数据结构，它包含BMP图像文件的类型、显示内容等信息； 位图信息数据结构，它包含有BMP图像的宽、高、压缩方法，以及定义颜色等信息； 调色板，这个部分是可选的，有些位图需要调色板，有些位图，比如真彩色图（24位的BMP）就不需要调色板； 位图数据，这部分的内容根据BMP位图使用的位数不同而不同，在24位图中直接使用RGB，而其他的小于24位的使用调色板中颜色索引值。 格式类型 位图一共有两种类型，即：设备相关位图（DDB）和设备无关位图（DIB）。DDB位图在早期的Windows系统（Windows 3.0以前）中是很普遍的，事实上它也是唯一的。然而，随着显示器制造技术的进步，以及显示设备的多样化，DDB位图的一些固有的问题开始浮现出来了。比如，它不能够存储（或者说获取）创建这张图片的原始设备的分辨率，这样，应用程序就不能快速的判断客户机的显示设备是否适合显示这张图片。为了解决这一难题，微软创建了DIB位图格式。 设备无关位图 (Device-Independent Bitmap) DIB位图包含下列的颜色和尺寸信息： 原始设备（即创建图片的设备）的颜色格式。 原始设备的分辨率。 原始设备的调色板 一个位数组，由红、绿、蓝（RGB）三个值代表一个像素。 一个数组压缩标志，用于表明数据的压缩方案（如果需要的话）。 以上这些信息保存在BITMAPINFO结构中，该结构由BITMAPINFOHEADER结构和两个或更多个RGBQUAD结构所组成。BITMAPINFOHEADER结构所包含的成员表明了图像的尺寸、原始设备的颜色格式、以及数据压缩方案等信息。RGBQUAD结构标识了像素所用到的颜色数据。 DIB位图也有两种形式，即：底到上型DIB(bottom-up），和顶到下型DIB(top-down）。底到上型DIB的原点（origin）在图像的左下角，而顶到下型DIB的原点在图像的左上角。如果DIB的高度值（由BITMAPINFOHEADER结构中的biHeight成员标识）是一个正值，那么就表明这个DIB是一个底到上型DIB，如果高度值是一个负值，那么它就是一个顶到下型DIB。注意：顶到下型的DIB位图是不能被压缩的。 位图的颜色格式是通过颜色面板值（planes）和颜色位值（bitcount）计算得来的，颜色面板值永远是1，而颜色位值则可以是1、4、8、16、24、32其中的一个。如果它是1，则表示位图是一张单色位图（译者注：通常是黑白位图，只有黑和白两种颜色，当然它也可以是任意两种指定的颜色），如果它是4，则表示这是一张VGA位图，如果它是8、16、24、或是32，则表示该位图是其他设备所产生的位图。如果应用程序想获取当前显示设备（或打印机）的颜色位值（或称位深度），可调用API函数GetDeviceCaps（），并将第二个参数设为BITSPIXEL即可。 显示设备的分辨率是以每米多少个像素来表明的，应用程序可以通过以下三个步骤来获取显示设备或打印机的水平分辨率： 调用GetDeviceCaps（）函数，指定第二个参数为HORZRES。 再次调用GetDeviceCaps()函数，指定第二个参数为HORZSIZE。 用第一个返回值除以第二个返回值。即：GetDeviceCaps(hDC,HORZRES)/GetDeviceCaps(hDC,HORZSIZE); 应用程序也可以使用相同的三个步骤来获取设备的垂直分辨率，不同之处只是要将HORZRES替换为VERTRES，把HORZSIZE替换为VERTSIZE，即可。 调色板是被保存在一个RGBQUAD结构的数组中，该结构指出了每一种颜色的红、绿、蓝的分量值。位数组中的每一个索引都对应于一个调色板项（即一个RGBQUAD结构），应用程序将根据这种对应关系，将像素索引值转换为像素RGB值（真实的像素颜色）。应用程序也可以通过调用GetDeviceCaps（）函数来获取当前显示设备的调色板尺寸（将该函数的第二个参数设为NUMCOLORS即可）。 Win32 API支持位数据的压缩（只对8位和4位的底到上型DIB位图）。压缩方法是采用运行长度编码方案（RLE），RLE使用两个字节来描述一个句法，第一个字节表示重复像素的个数，第二个字节表示重复像素的索引值。有关压缩位图的详细信息请参见对BITMAPINFOHEADER结构的解释。 应用程序可以从一个DDB位图创建出一个DIB位图，步骤是，先初始化一些必要的结构，然后再调用GetDIBits（）函数。不过，有些显示设备有可能不支持这个函数，你可以通过调用GetDeviceCaps（）函数来确定一下（GetDeviceCaps（）函数在调用时指定RC_DI_BITMAP作为RASTERCAPS的标志）。 应用程序可以用DIB去设置显示设备上的像素（译者注：也就是显示DIB），方法是调用SetDIBitsToDevice（）函数或调用StretchDIBits（）函数。同样，有些显示设备也有可能不支持以上这两个函数，这时你可以指定RC_DIBTODEV作为RASTERCAPS标志，然后调用GetDeviceCaps（）函数来判断该设备是否支持SetDIBitsToDevice（）函数。也可以指定RC_STRETCHDIB作为RASTERCAPS标志来调用GetDeviceCaps（）函数，来判断该设备是否支持StretchDIBits（）函数。 如果应用程序只是要简单的显示一个已经存在的DIB位图，那么它只要调用SetDIBitsToDevice（）函数就可以。比如一个电子表格软件，它可以打开一个图表文件，在窗口中简单的调用SetDIBitsToDevice（）函数，将图形显示在窗口中。但如果应用程序要重复的绘制位图的话，则应该使用BitBlt（）函数，因为BitBlt（）函数的执行速度要比SetDIBitsToDevice(）函数快很多。 设备相关位图 (Device-Dependent Bitmaps) 设备相关位图（DDB）之所以现在还被系统支持，只是为了兼容旧的Windows 3.0软件，如果程序员现在要开发一个与位图有关的程序，则应该尽量使用或生成DIB格式的位图。 DDB位图是被一个单个结构BITMAP所描述，这个结构的成员标明了该位图的宽度、高度、设备的颜色格式等信息。 DDB位图也有两种类型，即：可废弃的（discardable)DDB和不可废弃的（nondiscardable)DDB。可废弃的DDB位图就是一种当系统内存缺乏，并且该位图也没有被选入设备描述表（DC）的时候，系统就会把该DDB位图从内存中清除（即废弃）。不可废弃的DDB则是无论系统内存多少都不会被系统清除的DDB。API函数CreateDiscardableBitmap（）函数可用于创建可废弃位图。而函数CreateBitmap（）、CreateCompatibleBitmap（）、和CreateBitmapIndirect（）可用于创建不可废弃的位图。 应用程序可以通过一个DIB位图而创建一个DDB位图，只要先初始化一些必要的结构，然后再调用CreateDIBitmap（）函数就可以。如果在调用该函数时指定了CBM_INIT标志，那么这一次调用就等价于先调用CreateCompatibleBitmap（）创建当前设备格式的DDB位图，然后又调用SetDIBits（）函数转换DIB格式到DDB格式。（可能有些设备并不支持SetDIBits(）函数，你可以指定RC_DI_BITMAP作为RASTERCAPS的标志，然后调用GetDeviceCaps（）函数来判断一下）。 对应数据结构 一、BMP文件组成 BMP文件由文件头、位图信息头、颜色信息和图形数据四部分组成。 BMP文件由文件头(14个字节) 位图信息头(40个字节) 颜色信息 图形数据 1.BMP文件头（14字节） BMP文件头数据结构含有BMP文件的类型、文件大小和位图起始位置等信息。 其结构定义如下： typedef struct tagBITMAPFILEHEADER { WORD bfType; // 位图文件的类型，必须为BM(1-2字节） DWORD bfSize; // 位图文件的大小，以字节为单位（3-6字节） WORD bfReserved1; // 位图文件保留字，必须为0(7-8字节） WORD bfReserved2; // 位图文件保留字，必须为0(9-10字节） DWORD bfOffBits; // 位图数据的起始位置，以相对于位图（11-14字节） // 文件头的偏移量表示，以字节为单位 } BITMAPFILEHEADER; 文件的类型 文件的大小 文件保留字 文件保留字 文件数据的开始位置 2两个字节 4个字节 2个字节(必须设置为0) 2个字节(必须设置为0) 4个字节 bfOffBits数据是3600 0000 像素的十六进制 3600 0000 -> 0000 0036h 从文件开始到位图数据之间的偏移量(14+40+4*（2^biBitCount）)。3600 0000，为00000036h = 54，上面的文件头就是35字=54字节。 2.位图信息头（40字节） BMP位图信息头数据用于说明位图的尺寸等信息。 typedef struct tagBITMAPINFOHEADER{ DWORD biSize; // 本结构所占用字节数（15-18字节） LONG biWidth; // 位图的宽度，以像素为单位（19-22字节） LONG biHeight; // 位图的高度，以像素为单位（23-26字节） WORD biPlanes; // 目标设备的级别，必须为1(27-28字节） WORD biBitCount;// 每个像素所需的位数，必须是1（双色），（29-30字节） // 4(16色），8(256色）或24（真彩色）,32之一 DWORD biCompression; // 位图压缩类型，必须是 0（不压缩），（31-34字节） // 1(BI_RLE8压缩类型）或2(BI_RLE4压缩类型）之一 DWORD biSizeImage; // 位图的大小，以字节为单位（35-38字节） LONG biXPelsPerMeter; // 位图水平分辨率，每米像素数（39-42字节） LONG biYPelsPerMeter; // 位图垂直分辨率，每米像素数（43-46字节) DWORD biClrUsed;// 位图实际使用的颜色表中的颜色数（47-50字节） DWORD biClrImportant;// 位图显示过程中重要的颜色数（51-54字节） } BITMAPINFOHEADER; 3.颜色表 颜色表用于说明位图中的颜色，它有若干个表项，每一个表项是一个RGBQUAD类型的结构，定义一种颜色。RGBQUAD结构的定义如下： typedef struct tagRGBQUAD { BYTE rgbBlue;// 蓝色的亮度（值范围为0-255) BYTE rgbGreen; // 绿色的亮度（值范围为0-255) BYTE rgbRed; // 红色的亮度（值范围为0-255) BYTE rgbReserved;// 保留，必须为0 } RGBQUAD; 颜色表中RGBQUAD结构数据的个数有biBitCount来确定： 当biBitCount=1,4,8时，分别有2,16,256个表项； 当biBitCount=24时，没有颜色表项。 4.位图数据内容 位图数据记录了位图的每一个像素值，记录顺序是在扫描行内是从左到右,扫描行之间是从下到上。位图的一个像素值所占的字节数由biBitCount来确定: 当biBitCount=1时，8个像素占1个字节; 当biBitCount=4时，2个像素占1个字节; 当biBitCount=8时，1个像素占1个字节; 当biBitCount=24时,1个像素占3个字节; Windows规定一个扫描行所占的字节数必须是4的倍数(即以long为单位),不足的以0填充。 例如： 24Bit真彩图每一行占的实际字节数： nBytesPerLine =[(bi.biWidth*3+3)/4*4 // bi.biWidth为图像宽度 灰度图每一行占的实际字节数： nBytesPerLine = ((bi.biWidth+3)/4)*4 位图信息头和颜色表组成位图信息，BITMAPINFO结构定义如下： typedef struct tagBITMAPINFO { BITMAPINFOHEADER bmiHeader; // 位图信息头 RGBQUAD bmiColors[1]; // 颜色表 } BITMAPINFO; 5.位图数据 位图数据记录了位图的每一个像素值，记录顺序是在扫描行内是从左到右，扫描行之间是从下到上。位图的一个像素值所占的字节数： 当biBitCount=1时，8个像素占1个字节； 当biBitCount=4时，2个像素占1个字节； 当biBitCount=8时，1个像素占1个字节； 当biBitCount=24时，1个像素占3个字节； Windows规定一个扫描行所占的字节数必须是4的倍数（即以long为单位），不足的以0填充，biSizeImage = ((((bi.biWidth bi.biBitCount) + 31) & ~31) / 8) bi.biHeight; 二、文件部分 如某BMP文件开头： 424D 4690 0000 0000 0000 4600 0000 2800 0000 8000 0000 9000 0000 01001000 0300 0000 0090 0000 A00F 0000 A00F 0000 0000 0000 0000 000000F8 E007 1F00 0000*02F1 84F1 04F1 84F1 84F1 06F2 84F1 06F2 04F2 86F2 06F2 86F2 86F2 …. …. 图像文件头 1-2：(这里的数字代表的是”字”,即两个字节，下同）图像文件头。0x4d42=’BM’，表示是Windows支持的BMP格式。(注意：查ascii表B 0×42,M0x4d,bfType 为两个字节，B为low字节，M为high字节所以bfType=0x4D42，而不是0x424D，但注意) 3-6：整个文件大小。4690 0000，为00009046h=36934。 7-8：保留，必须设置为0。 9-10：保留，必须设置为0。 11-14：从文件开始到位图数据之间的偏移量(14+40+4*（2^biBitCount）)。4600 0000，为00000046h=70，上面的文件头就是35字=70字节。 位图信息头 15-18：位图图信息头长度。 19-22：位图宽度，以像素为单位。8000 0000，为00000080h=128。 23-26：位图高度，以像素为单位。9000 0000，为00000090h=144。 27-28：位图的位面数，该值总是1。0100，为0001h=1。 29-30：每个像素的位数。有1（单色），4（16色），8（256色），16（64K色，高彩色），24（16M色，真彩色），32（4096M色，增强型真彩色）。1000为0010h=16。 31-34：压缩说明：有0（不压缩），1（RLE 8，8位RLE压缩），2（RLE 4，4位RLE压缩，3（Bitfields，位域存放）。RLE简单地说是采用像素数+像素值的方式进行压缩。T408采用的是位域存放方式，用两个字节表示一个像素，位域分配为r5b6g5。图中0300 0000为00000003h=3。 35-38：用字节数表示的位图数据的大小，该数必须是4的倍数，数值上等于（≥位图宽度的最小的4的倍数）×位图高度×每个像素位数。0090 0000为00009000h=80×90×2h=36864。 39-42：用象素/米表示的水平分辨率。A00F 0000为0000 0FA0h=4000。 43-46：用象素/米表示的垂直分辨率。A00F 0000为0000 0FA0h=4000。 47-50：位图使用的颜色索引数。设为0的话，则说明使用所有调色板项。 51-54：对图象显示有重要影响的颜色索引的数目。如果是0，表示都重要。 彩色板 （55+0）到（50-1+2^biBitCount）：彩色板规范。对于调色板中的每个表项，用下述方法来描述RGB的值： 1字节用于蓝色分量 1字节用于绿色分量 1字节用于红色分量 1字节用于填充符（设置为0) 对于24-位真彩色图像就不使用彩色板，因为位图中的RGB值就代表了每个象素的颜色。 如，彩色板为00F8 0000 E007 0000 1F00 0000 0000 0000，其中： 00F8为F800h = 1111 1000 0000 0000（二进制），是蓝色分量的掩码。 E007 为 07E0h = 0000 0111 1110 0000（二进制），是绿色分量的掩码。 1F00为001Fh = 0000 0000 0001 [1]1111（二进制），是红色分量的掩码。 0000 总设置为0。 将掩码跟像素值进行“与”运算再进行移位操作就可以得到各色分量值。看看掩码，就可以明白事实上在每个像素值的两个字节16位中，按从高到低取5、6、5位分别就是r、g、b分量值。取出分量值后把r、g、b值分别乘以8、4、8就可以补齐第个分量为一个字节，再把这三个字节按rgb组合，放入存储器（同样要反序），就可以转换为24位标准BMP格式了。 图像数据阵列 55（无调色板）-bfSize：每两个字节表示一个像素。阵列中的第一个字节表示位图左下角的象素，而最后一个字节表示位图右上角的象素。 图像数据阵列 每两个字节表示一个像素。阵列中的第一个字节表示位图左下角的象素，而最后一个字节表示位图右上角的象素。 存储算法 BMP文件通常是不压缩的，所以它们通常比同一幅图像的压缩图像文件格式要大很多。例如，一个800×600的24位几乎占据1.4MB空间。因此它们通常不适合在因特网或者其它低速或者有容量限制的媒介上进行传输。根据颜色深度的不同，图像上的一个像素可以用一个或者多个字节表示，它由n/8所确定（n是位深度，1字节包含8个数据位）。图片浏览器等基于字节的ASCII值计算像素的颜色，然后从调色板中读出相应的值。更为详细的信息请参阅下面关于位图文件的部分。n位2n种颜色的位图近似字节数可以用下面的公式计算：BMP文件大小约等于 54+42的n次方+（wh*n)/8，其中高度和宽度都是像素数。需要注意的是上面公式中的54是位图文件的文件头，是彩色调色板的大小。另外需要注意的是这是一个近似值，对于n位的位图图像来说，尽管可能有最多2n中颜色，一个特定的图像可能并不会使用这些所有的颜色。由于彩色调色板仅仅定义了图像所用的颜色，所以实际的彩色调色板将小于。如果想知道这些值是如何得到的，请参考下面文件格式的部分。由于存储算法本身决定的因素，根据几个图像参数的不同计算出的大小与实际的文件大小将会有一些细小的差别。 存储序列 图象数据BGRA：默认的BMP是不支持ALPHA通道的，但对32位BMP而言，每个象素用32位(4个字节)表示，前三个字节表示RGB分量，最后一个字节可以做为ALPHA通道的值，因此32位位图可以存储带ALPHA通道的图像，在文件中，各分量的存储顺序为BGRA，BGRA，BGRA，BGRA… 另外要注意的是，BMP图像的象素存储顺序是从下到上 #define _CRT_SECURE_NO_WARNINGS #include using namespace std; #include #include #include #include #include //以下模块是完成BMP图像(彩色图像是24bit RGB各8bit)的像素获取，并存在文件名为xiang_su_zhi.txt中 unsigned char *pBmpBuf;//读入图像数据的指针 int bmpWidth;//图像的宽 int bmpHeight;//图像的高 RGBQUAD *pColorTable;//颜色表指针 int biBitCount;//图像类型，每像素位数 //读图像的位图数据、宽、高、颜色表及每像素位数等数据进内存，存放在相应的全局变量中 bool readBmp(char *bmpName) { FILE *fp = fopen(bmpName, \"rb\");//二进制读方式打开指定的图像文件 if (fp == 0) return 0; /* typedef struct tagBITMAPFILEHEADER { WORD bfType; 2 DWORD bfSize; 4 WORD bfReserved1; 2 WORD bfReserved2; 2 DWORD bfOffBits; 4 } BITMAPFILEHEADER, 14个字节 */ //跳过位图文件头结构BITMAPFILEHEADER fseek(fp, sizeof(BITMAPFILEHEADER), 0); //定义位图信息头结构变量，读取位图信息头进内存，存放在变量head中 BITMAPINFOHEADER head; /* typedef struct tagBITMAPINFOHEADER{ DWORD biSize;//typedef unsigned long DWORD;//4 LONG biWidth;//typedef long LONG; //4 LONG biHeight; WORD biPlanes;//typedef unsigned short WORD; 2 WORD biBitCount; DWORD biCompression; DWORD biSizeImage; LONG biXPelsPerMeter; LONG biYPelsPerMeter; DWORD biClrUsed; DWORD biClrImportant; } BITMAPINFOHEADER, */ /*头部信息的大小: 40个字节 */ cout hang - 8; L1--)//8*8矩阵行 { for (int L2 = lie; L2"},"安全/CTF/Radare2使用全解.html":{"url":"安全/CTF/Radare2使用全解.html","title":"Radare2使用全解","keywords":"","body":"Radare2使用全解 前言 说起逆向，你想到的可能是IDA Pro，OllyDBG。 而Radare2是一款开放源代码的逆向工程平台，它的强大超越你的想象，包括反汇编、分析数据、打补丁、比较数据、搜索、替换、虚拟化等等，同时具备超强的脚本加载能力，并且可以运行在几乎所有主流的平台（GNU/Linux, Windows, OSX...）上。可谓是一大神器。 安装 下载kali linux，自带神器 下载kali 下载安装完之后，需要进行一些配置，才能使用xshell、scrt等工具远程登陆。 具体步骤，以后会整理分享。 去官方github按找指示进行安装 https://github.com/radare/radare2 安装命令： $ sys/install.sh 使用 radare2 支持各种各样的平台，文件格式，具体可以看官网描述。它有很多各组件分别进行不同的工作。这些组件是： rax2 ---------> 用于数值转换 rasm2 -------> 反汇编和汇编 rabin2 -------> 查看文件格式 radiff2 ------> 对文件进行 diff ragg2/ragg2­cc ------> 用于更方便的生成shellcode rahash2 ------> 各种密码算法， hash算法 radare2 ------> 整合了上面的工具 rax2 数值转换，程序的 help 菜单很明确了: root@kali:~# rax2 -h Usage: rax2 [options] [expr ...] =[base] ; rax2 =10 0x46 -> output in base 10 int -> hex ; rax2 10 hex -> int ; rax2 0xa -int -> hex ; rax2 -77 -hex -> int ; rax2 0xffffffb3 int -> bin ; rax2 b30 int -> ternary ; rax2 t42 bin -> int ; rax2 1010d ternary -> int ; rax2 1010dt float -> hex ; rax2 3.33f hex -> float ; rax2 Fx40551ed8 oct -> hex ; rax2 35o hex -> oct ; rax2 Ox12 (O is a letter) bin -> hex ; rax2 1100011b hex -> bin ; rax2 Bx63 ternary -> hex ; rax2 212t hex -> ternary ; rax2 Tx23 raw -> hex ; rax2 -S raw ; rax2 -s 414141 -l ; append newline to output (for -E/-D/-r/.. -a show ascii table ; rax2 -a -b bin -> str ; rax2 -b 01000101 01110110 -B str -> bin ; rax2 -B hello -d force integer ; rax2 -d 3 -> 3 instead of 0x3 -e swap endianness ; rax2 -e 0x33 -D base64 decode ; -E base64 encode ; -f floating point ; rax2 -f 6.3+2.1 -F stdin slurp code hex ; rax2 -F 36 -K randomart ; rax2 -K 0x34 1020304050 -L bin -> hex(bignum) ; rax2 -L 111111111 # 0x1ff -n binary number ; rax2 -n 0x1234 # 34120000 -o octalstr -> raw ; rax2 -o \\162 \\62 # r2 -N binary number ; rax2 -N 0x1234 # \\x34\\x12\\x00\\x00 -r r2 style output ; rax2 -r 0x1234 -s hexstr -> raw ; rax2 -s 43 4a 50 -S raw -> hexstr ; rax2 -S ls.hex -t tstamp -> str ; rax2 -t 1234567890 -x hash string ; rax2 -x linux osx -u units ; rax2 -u 389289238 # 317.0M -w signed word ; rax2 -w 16 0xffff -v version ; rax2 -v 比如输入rax2 -s 41414141 ,会返回 AAAA rabin2 对各种文件格式进行解析。 rabin2 -I 168+r2 显示文件的信息 使用 -l 显示依赖库。 使用 -zz 显示字符串信息，可以显示 utf-8 等宽字节字符串。 可以看到显示了长度，所在位置等信息。 通过使用 -O 选项可以修改一些文件的信息。 haclh@ubuntu:~$ rabin2 -O? Operation string: Change Entrypoint: e/0x8048000 Dump Symbols: d/s/1024 Dump Section: d/S/.text Resize Section: r/.data/1024 Remove RPATH: R Add Library: a/l/libfoo.dylib Change Permissions: p/.data/rwx Show LDID entitlements: C 比如修改 section 的属性 haclh@ubuntu:~$ rabin2 -S a.out | grep text idx=14 vaddr=0x00400430 paddr=0x00000430 sz=386 vsz=386 perm=--rwx name=.text haclh@ubuntu:~$ rabin2 -O p/.text/r a.out wx 02 @ 0x1d60 haclh@ubuntu:~$ rabin2 -S a.out | grep text idx=14 vaddr=0x00400430 paddr=0x00000430 sz=386 vsz=386 perm=--r-- name=.text rasm2 这个工具用于进行各种平台的汇编和反汇编。该工具的主要选项有。 -a 设置汇编和反汇编的架构（比如x86,mips, arm...） -L 列举支持的架构。 -b 设置 位数 -d，-D 反汇编 提供的 16进制字符串。 使用示例： 首先列举支持的架构（使用 head 只列举前面几项） haclh@ubuntu:~$ rasm2 -L | head _dAe 8 16 6502 LGPL3 6502/NES/C64/Tamagotchi/T-1000 CPU _dA_ 8 8051 PD 8051 Intel CPU _dA_ 16 32 arc GPL3 Argonaut RISC Core a___ 16 32 64 arm.as LGPL3 as ARM Assembler (use ARM_AS environment) adAe 16 32 64 arm BSD Capstone ARM disassembler _dA_ 16 32 64 arm.gnu GPL3 Acorn RISC Machine CPU _d__ 16 32 arm.winedbg LGPL2 WineDBG's ARM disassembler adAe 8 16 avr GPL AVR Atmel adAe 16 32 64 bf LGPL3 Brainfuck (by pancake, nibble) v4.0.0 _dA_ 16 cr16 LGPL3 cr16 disassembly plugin 使用 arm 插件，汇编 三条 nop 指令 haclh@ubuntu:~$ rasm2 -a arm \"nop;nop;nop;\" 0000a0e10000a0e10000a0e1 然后我们使用 -d 把它反汇编出来 haclh@ubuntu:~$ rasm2 -a arm -d 0000a0e10000a0e10000a0e1 mov r0, r0 mov r0, r0 mov r0, r0 我可以在命令后面加上 -r 打印出在 radare2中实现对应的功能，需要使用的命令( wa 命令的作用是，汇编给出的指令，并把汇编得到的数据写到相应位置，默认是当前位置)。 haclh@ubuntu:~$ rasm2 -a arm -d 0000a0e10000a0e10000a0e1 -r e asm.arch=arm e asm.bits=32 \"wa mov r0, r0;mov r0, r0;mov r0, r0;\" ragg2/ragg2·cc radare2 自己实现的 c 编译器，可以方便的写shellcode . 示例一： 代码如下 int main() { write (1,\"hi\\n\", 3); exit(0); } 使用下面的命令，把它编译成x86 32位代码： ragg2-cc -a x86 -b 32 -d -o test test.c 可以生成正常的 elf 文件用于测试，可以使用 -c 只编译出 shellcode 生成的 shellcode 存在于 test.c.text 文件里面，下面是用 radare2 反汇编得到的代码，可以看到使用了 系统调用来实现代码的功能。 使用 ragg2-cc 生成的 shellcode 可以使用 ragg2中的 xor 编码器来编码字符，绕过一些字符限制，比如 \\x00。 首先生成shellcode 的16进制表示。 ragg2-cc -a x86 -b 32 -d -x test.c 然后使用 rasm2 验证下 代码和上面的是一样的。 然后使用 ragg2 使用 xor 编码器编码 shellcode 就是在 shellcode 执行前使用 xor 指令把shellcode 还原。这样就可以消除掉一些坏字符。 ragg2 也有自己 编写 shellcode 的语法。下面是一个示例，具体请看官方文档。 使用这种方式，我们就能使用最接近 汇编 的类c语言 来编写跨平台 shellcode rahash2 用于使用加密算法，hash算法等计算值 使用-L 可以列举支持的算法，比如算算 md5 haclh@ubuntu:~$ rahash2 -a md5 -s admin 0x00000000-0x00000004 md5: 21232f297a57a5a743894a0e4a801fc3 radare2 最常用的工具了。整合了上面所有的工具。直接使用 r2 target_bin 进入程序。使用-d 选项进入调试模式。 radare2 中的命令格式为 [.][times][cmd][~grep][@[@iter]addr!size][|>pipe] ; px表示打印16进制数，默认从当前位置开始。参数控制打印的字节数，下面这张图应该就可以大概解释上面的格式了。 @ addr 表示该命令从 addr 开始执行。addr 不一定是 地址也可以是 radare2 中识别的符号，比如 main 还有一个重要的东西要记得，在命令的后面加个 ? ，就可以查看帮助。直接输入? 可以查看所有的命令。 面按照我们在 ida 中使用的功能，来介绍 radare2 首先在 用 ida 分析程序时，在 ida 加载程序后默认会对程序进行分析。radare2 相应的功能是以 a 开头的。 注释很简明了。我们使用 aaa 就可以进行完整分析了。 分析前 radare2 识别不了函数，分析后就可以正常打印函数代码了（pdf 打印函数代码） 有时候我们不需要分析整个 二进制文件，或者有个函数 radare2没有识别出来我们可以 af 来分析该函数。 我们可以使用 s 跳转到想要跳转的位置。 跳转到 main 函数，并 定义该函数，然后打印函数代码 pd 类命令用于打印汇编信息。 具体看帮助。 使用 VV 进入 图形化模式（需要是函数范围内）。 在图形化模式下，输入 ? 可以查看图形化模式的帮助。 使用 hjkl 来移动图形 使用 p/P 切换图形模式 在图形模式下使用 : 可以输入radare2 命令 输入 ! ， 在调试的时候应该很有用 使用 空格 ，切换图形模式和文本模式 在文本模式模式下也可以使用 p 来切换视图。 剩下的看帮助。 下面介绍如何使用 radare2 patch程序。首先需要在打开文件时使用 r2 -w 来以可写模式打开文件，这样 pathch 才能应用到文件 ( 或者在 radare2 下使用 e io.cache=true, 来允许进行 patch, 不过这样的话文件的修改不会影响原文件 ) w 系列命令用于修改文件。 使用 wa 可以使用 汇编指令进行 patch 使用 \"wa nop;nop;nop;nop;\" 可以同时写入多条指令。 双引号不能省 或者可以使用 wx 写入 16进制数据 其他的请看 w? ，查看帮助。 还可以 可视化汇编/patch 程序 输入 Vp ，然后输入 A, 就可以了。 使用 / 系列命令可以搜索字符串， rop gadgets等 查询字符串交叉引用可以依次使用下列方法。 ax? 系列命令用于管理交叉引用。 /r 可以搜索交叉引用, aae 是使用radare2中的模拟执行功能，动态的检测交叉引用。 下面画重点 radare2中其实也是有 反编译功能, 使用 pdc 就可以查看伪代码，虽然和 ida 的还有很大的差距，但是在一些 ida 不支持 f5 的情况下这个功能还是不错的，可以用来看程序的大概逻辑。 在图形化模式下，按下 $ 看看，有惊喜。 帮我们解析汇编指令，用 c 代码的格式来显示。妈妈再也不用担心我不会汇编了。 radare2和 ida 相比还有一个最大的优势，那就是它自带模拟执行功能。它使用了一种 esil 语言，来定义程序的行为，并且可以根据这个来模拟执行程序代码。 ESIL 的具体语法可以去看官方文档。下面列举两个示例： mov ecx, ebx -> ebx,ecx,= add ebx, edi ->edi,ebx,+=,$o,of,=,$s,sf,=,$z,zf,=,$c31,cf,=,$p, 可以使用 e asm.esil = true显示 esil 代码 和 ESIL相关的命令是 ae?这一类指令。这个我也不熟悉，大概的用法是，使用 ae?这一类指令设置好 指令执行虚拟机的状态，然后设置好模拟执行的终止状态，在停止时，做一些操作，主要用于解密字符串，脱壳等等。 此外 radare2还支持各种语言对他进行调用， 以及拥有大量的插件。 总结 radare2还是很强大的，特别是全平台反编译，全平台模拟执行，各种文件的patch, 修改。感觉在 ida 没法 f5的平台上首选 radare2 常用命令 1. r2 filename 加载文件 2. aaa分析程序中所有函数，分析前 radare2 识别不了函数，分析后就可以正常打印函数代码了（pdf 打印函数代码）,aa命令只分析主函数 加个问号可以查看帮助，这里我们直接用aaa就可以分析完程序了 3. afl显示主函数，有时候我们不需要分析整个二进制文件，或者有个函数 radare2没有识别出来我们可以 af 来分析该函数。 4. s function 跳转到想跳转的位置（function） 5. VV进入图形化模式（hjkl移动图像）使用 p/P 切换图形模式，空格切换文本图形模式，文本下可以用p切换模式，小写的vv用来粗略浏览函数信息 6. pdf查看函数汇编代码 7. pd x打印汇编信息x条 8. \"wa xxx\"修改汇编指令为xxx 9. px表示打印16进制数，默认从当前位置开始，参数控制打印的字节数 10. 直接使用 r2 filename 进入程序。使用-d选项进入调试模式，输入!在调试的时候可以看到历史操作记录 11. pdc反汇编函数 12. afx查看调用函数 13. ?可以查看帮助，这个工具非常强大，需要多实践学习 "},"安全/CTF/CTF题集/":{"url":"安全/CTF/CTF题集/","title":"CTF题集","keywords":"","body":"CTF题集 目录 流量分析之文件简单提取 "},"安全/CTF/CTF题集/流量分析之文件简单提取.html":{"url":"安全/CTF/CTF题集/流量分析之文件简单提取.html","title":"流量分析之文件简单提取","keywords":"","body":"流量分析之文件简单提取 文件简单提取 简单 安全杂项 描述 来找flag吧。格式为ISG{字符串}。 附件 107+isg2014-Chopper.pcap 解题步骤： 1.先下载安装需要的工具，这里我们使用wireshark 点我下载 2. 使用wireshark打开下载到的pcap文件 经过简单分析得知有一个名叫x.tar.gz的文件，格式是一个压缩包，猜测所需的flag在该压缩包中，然后想办法获取该文件。 3. 通过pcap获取所需文件 4. 在该数据包右键，选择Follow->TCP Stream. 红框中的乱码应该为文件。 5. 过滤掉多余信息，只保留该文件的数据包。 6. 设置数据格式为raw，然后保存为文件，命名为x.tar.gz。 7. 将得到的文件使用Hex Fiend打开（MAC下使用Hex Fiend，win下使用winhex工具，下载地址请自行百度），删除掉多余信息 注：.tar.gz的文件。这种压缩格式的文件开头是1F8B，找到这个删除之前的全部内容，该文件后有boundary分隔符，将这部分删去，即掐头去尾留下来的就是真正的数据。 8. 删除掉其他多余信息后即可得到正确tar.gz文件，使用tar zxvf 命令解压后得到flag文件。 至此得到正确的flag： "},"安全/CTF/CTF题集/取证神器之使用volatility分析window内存.html":{"url":"安全/CTF/CTF题集/取证神器之使用volatility分析window内存.html","title":"取证神器之使用volatility分析window内存","keywords":"","body":"取证神器之使用volatility分析window内存 取证神器 简单 安全杂项 描述 volatility分析window内存 附件 取证2.tar.bz2 解题步骤： 1. 先解压得到的tar.bz2压缩包（使用工具解压或者命令都可以） #新建一个test目录 mkdir test #解压文件到test中，否则解压文件到当前目录 tar jxvf 取证2.tar.bz2 -C ./test 这时候我们会得到两个文件，mem.vmem suspicion。。。。 英语比较菜，先百度一下什么意思。。。 知道字面意思也不知道是什么意思。。。话不多说，先搞这个vmem文件吧 2. 使用volatility分析vmem 2.1 volatility下载与安装 介绍：volatility 是一款内存取证和分析工具，可以对 Procdump 等工具 dump 出来的内存进行分析，并提取内存中的文件。该工具支持 Windows 和 Linux，Kali 下面默认已经安装。 volatility 的许多功能由其内置的各种插件来实现，例如查看当前的网络连接，命令行中的命令，记事本中的内容等等。 方法1: 下载kali linux，系统中会自带这个工具 PS:请下载最新版本的，历史版本可能没有。。。。 方法2: Github volatility Download volatility 可能需要梯子。。。 选择自己对应的版本下载即可。 本人使用mac平台，以这个为例，附安装步骤吧，其他的自行百度。 下载volatility_2.6_mac64_standalone.zip，解压 尝试运行 为了方便后续使用，在环境变量中(~/.bash_profile)，添加 #volatility ''中替换为自己工具的绝对路径 alias volatility='/Volumes/data/macsoftware/volatility_2.6_mac64_standalone/volatility_2.6_mac64_standalone' source ~/.bash_profile 这样后续在任意目录下直接使用volatility命令就行了。 2.2 volatility的使用 基本使用： volatility -f –profile= [插件参数] 完整的使用方法，以后有时间再另行整理，先看看本次我们需要用到的一些命令（有兴趣的话，可以先-h 获取使用帮助）。 # imageinfo 获取基本信息 volatility -f mem.vmem imageinfo 这里最关键的就是获取profile的类型，因为不同的系统数据结构啥的不一样，所以得用--profile=来指定。 这里自动猜解可能的系统类型，一般情况下第一个是正确的，我们后续就用--profile=WinXPSP2x86 这个配置文件，来使用插件。 #获取进程信息 volatility -f mem.vmem --profile=WinXPSP2x86 pslist pslist、pstree、psxview可以查看隐藏进程 获取到的进程中并没有notepad之类的能够记录flag文字信息的进程，但是看到了TrueCrypt.exe 0x81f9d3e8 TrueCrypt.exe 2012 1464 2 139 0 0 2016-05-03 04:33:36 UTC+0000 TrueCrypy.exe是一款加密程序，而我们可以推出，suspicion为加密的结果。 我们需要从内存dump出key来。 (我是新手，上面这个不是我推断出的，而是百度到的……捂脸，羞羞) #获取进程中的信息 -p 进程号（使用pslist查到的）-D dump文件保存路径 volatility -f mem.vmem --profile=WinXPSP2x86 memdump -p 1464 -D ./ #这里需要注意的是，并不是获取TrueCrypt进程的信息，而是explorer.exe进程的（explorer.exe是Windows程序管理器或者文件资源管理器，它用于管理Windows图形壳，包括桌面和文件管理），估计这也是题目中是window，而不是windows的原因 - -！ 稍等片刻即可获得名叫1464.dmp的文件。 2.3 获得最终的flag 这里就又需要使用到另外一款名叫Elcomsoft Forensic Disk Decryptor（Elcomsoft硬盘取证解密器，简称为EFDD）的工具了，目的是获取加密用的key和破解加密文件。这个工具目前只找到了win版的，mac下还未找到同类工具，没办法，只能上虚拟机了。（老规矩，自行百度下载，这个软件不难找） 安装破解好之后运行。 直接下一步。 选择第三项TrueCrypt(container),下一步。 等待破解完成，得到一个key，并保存该文件。 打开F盘，获得flag "},"安全/CTF/CTF题集/图片隐写术pigs.html":{"url":"安全/CTF/CTF题集/图片隐写术pigs.html","title":"图片隐写术pigs","keywords":"","body":"图片隐写术pigs pigs 简单 安全杂项 描述 你能找到隐藏在图片中的信息吗？flag格式为flag{字符串}。 附件 194+pigs.png 解题步骤： 直接上神器Stegsolve，不要问我怎么知道的，如果非要问的话，就是百度的。 Stegsolve下载地址 下载完，配置好java的环境变量，可以直接运行。 打开后，点击左箭头，使用Gray bits查看图片，发现一个二维码，扫描后获得flag。 也可以另存为bmp图片，然后使用 python3 下的 zxing 来识别二维码。 安装依赖库：pip install qrcode pillow image zxing 识别二维码： reader = zxing.BarCodeReader() barcode = reader.decode(\"/Volumes/data/CTF/安全杂项/solved.bmp\") print(barcode.parsed) 附：使用python生成二维码 # import qrcode # 二维码内容 data = \"I Love Python\" # 生成二维码 img = qrcode.make(data=data) # 直接显示二维码 img.show() # 保存二维码为文件 # img.save(\"python.jpg\") 生成效果： 设置生成的二维码大小、颜色等参数属性： import qrcode # 实例化二维码生成类 qr = qrcode.QRCode( version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=4, ) # 设置二维码数据 data = \"I Love Python\" qr.add_data(data=data) # 启用二维码颜色设置 qr.make(fit=True) img = qr.make_image(fill_color=\"blue\", back_color=\"white\") # 显示二维码 img.show() 生成效果： "},"安全/CTF/CTF题集/webshell流量分析.html":{"url":"安全/CTF/CTF题集/webshell流量分析.html","title":"webshell流量分析","keywords":"","body":"webshell流量分析 流量分析 简单 安全杂项 描述 webshell流量分析。flag格式为hctf{字符串}。 附件 104+2045664263.rar 解题步骤： 基操走起，解压，使用wireshark打开。 将数据包按照length倒序排列，先看最大的，毕竟里面的信息最多。。。 找到了这样一段python代码 cat function.py #!/usr/bin/env python # coding:utf-8 __author__ = 'Aklis' from Crypto import Random from Crypto.Cipher import AES import sys import base64 def decrypt(encrypted, passphrase): IV = encrypted[:16] aes = AES.new(passphrase, AES.MODE_CBC, IV) return aes.decrypt(encrypted[16:]) def encrypt(message, passphrase): IV = message[:16] length = 16 count = len(message) padding = length - (count % length) message = message + '\\0' * padding aes = AES.new(passphrase, AES.MODE_CBC, IV) return aes.encrypt(message) IV = 'YUFHJKVWEASDGQDH' message = IV + 'flag is hctf{xxxxxxxxxxxxxxx}' print len(message) example = encrypt(message, 'Qq4wdrhhyEWe4qBF') print example example = decrypt(example, 'Qq4wdrhhyEWe4qBF') print example 再往下翻，又找到了一个flag cat flag mbZoEMrhAO0WWeugNjqNw3U6Tt2C+rwpgpbdWRZgfQI3MAh0sZ9qjnziUKkV90XhAOkIs/OXoYVw5uQDjVvgNA== 稍微仔细一看，下面的这段flag是base64加密后的字符串，而上面的function.py则是实现一种加解密的功能呢，根据print的格式判断，这个py运行环境应该是python2，python3的print后面需要加括号。。。。。。 先运行一下function.py，看看输出的内容吧。 虽然直接打印出来一个flag is hctf{xxxxxxxxxxxxxxx}，但是实际的flag并不是hctf{xxxxxxxxxxxxxxx}。。。所以回到刚才找到的那段flag上，先进行base64解密。 import base64 f = 'mbZoEMrhAO0WWeugNjqNw3U6Tt2C+rwpgpbdWRZgfQI3MAh0sZ9qjnziUKkV90XhAOkIs/OXoYVw5uQDjVvgNA==' example = base64.b64decode(f) print example 看看经过base64解密后的样子是不是很熟悉，跟上面function.py加密后的样子好像啊。。。。尝试再使用function.py进行解密。 最终拿到了这个flag is hctf{n0w_U_w111_n0t_f1nd_me} "},"安全/CTF/CTF题集/逆向工程之密码分析.html":{"url":"安全/CTF/CTF题集/逆向工程之密码分析.html","title":"逆向工程之密码分析","keywords":"","body":"逆向工程之密码分析 r2 简单 逆向工程 描述 请分析附件中的程序，密码即为flag。 附件 168+r2 解题步骤： 1.既然是逆向工程，所以可以使用IDA、r2之类的工具。这里我们还是按照题目中说的r2吧。 radare2安装 radare2介绍 radare2是一个开源的逆向工程和二进制分析框架，它的强大超出你的想象，包括反汇编、分析数据、打补丁、比较数据、搜索、替换、虚拟化等等，同事具备超强的脚本加载能力，它可以运行在几乎所有主流的平台（GNU/Linux, .Windows *BSD, iOS, OSX, Solaris…）并且支持很多的cpu架构以及文件格式，我认为所有它的这些特征恰好能表达出一个意思–那就是给予你的使用以极大的自由. radare2工程是由一系列的组件构成，这些组件可以在 radare2 界面或者单独被使用–比如我们将要了解的rahash2, rabin2, ragg2三个组件，所有这些组件赋予了 radare2 强大的静态或动态分析、十六进制编辑以及溢出漏洞挖掘的能力. 老规矩，还是先来安利一下kali linux，系统中会自带r2，免安装。 $ git clone https://github.com/radare/radare2.git $ cd radare2 $ ./sys/install.sh 也可以通过上述三个命令进行手动安装。安装好之后还是先用r2 -h来检查一下能否正常使用。 虽说是这个东西拿来玩的，玩也要玩的全面一点嘛，所以直接把 checksec 这些个常用工具全搞定吧。 pwntools安装 这个版本的kali中并没有checksec工具，所以手动在mac上安装吧。 mac安装pwntools #安装pwntools brew install pwntools #安装bintuils 二进制工具 brew install https://raw.githubusercontent.com/Gallopsled/pwntools-binutils/master/osx/binutils-amd64.rb 命令执行完之后,我们要导入我们pwntools的包放到环境变量。 /usr/local/Cellar/pwntools/3.12.2_1/libexec/lib/python2.7/site-packages 在系统默认安装包的site-packages写个.pth文件写入上面的地址就可以了 之后就直接可以使用命令了。 再测试一下python的pwn模块 python2 import pwn pwn.asm(\"xor eax,eax\") 出现'1\\xc0' 说明安装成功了。 kali安装pwntools git clone https://github.com/Gallopsled/pwntools cd pwntools python setup.py install 安装capstone git clone https://github.com/aquynh/capstone cd capstone make make install 装好后检验一下命令是否可用，方法同mac。 2.工具安装成功之后我们就开始吧 先来了解一下程序，直接执行。 这里我们先用checksec来检测elf运行于哪个平台，开启了什么安全措施，如果用gcc的编译后，默认会开启所有的安全措施。 【1】RELRO：RELRO会有Partial RELRO和FULL RELRO，如果开启FULL RELRO，意味着我们无法修改got表 【2】Stack：如果栈中开启Canary found，那么就不能用直接用溢出的方法覆盖栈中返回地址，而且要通过改写指针与局部变量、leak canary、overwrite canary的方法来绕过 【3】NX：NX enabled如果这个保护开启就是意味着栈中数据没有执行权限，以前的经常用的call esp或者jmp esp的方法就不能使用，但是可以利用rop这种方法绕过 【4】PIE：PIE enabled如果程序开启这个地址随机化选项就意味着程序每次运行的时候地址都会变化，而如果没有开PIE的话那么No PIE (0x400000)，括号内的数据就是程序的基地址 【5】FORTIFY：FORTIFY_SOURCE机制对格式化字符串有两个限制(1)包含%n的格式化字符串不能位于程序内存中的可写地址。(2)当使用位置参数时，必须使用范围内的所有参数。所以如果要使用%7$x，你必须同时使用1,2,3,4,5和6。 Stack: Canary found canary简介 我们知道，通常栈溢出的利用方式是通过溢出存在于栈上的局部变量，从而让多出来的数据覆盖ebp、eip等，从而达到劫持控制流的目的。然而stack canary这一技术的应用使得这种利用手段变得难以实现。canary的意思是金丝雀，来源于英国矿井工人用来探查井下气体是否有毒的金丝雀笼子。工人们每次下井都会带上一只金丝雀如果井下的气体有毒，金丝雀由于对毒性敏感就会停止鸣叫甚至死亡，从而使工人们得到预警。这个概念应用在栈保护上则是在初始化一个栈帧时在栈底设置一个随机的canary值，栈帧销毁前测试该值是否“死掉”，即是否被改变，若被改变则说明栈溢出发生，程序走另一个流程结束，以免漏洞利用成功。 可以看到Stack一行显示Canary found。此外，在函数栈帧初始化时也会在栈上放置canary值并且在退出前验证. 很显然，一旦我们触发栈溢出漏洞，除非能猜到canary值是什么，否则函数退出的时候必然会通过异或操作检测到canary被修改从而执行stack_chk_fail函数。因此，我们要么想办法获取到canary的值，要么就要防止触发stack_chk_fail，或者利用这个函数。 开启canary后就不能直接使用普通的溢出方法来覆盖栈中的函数返回地址了，要用一些巧妙的方法来绕过或者利canary本身的弱点来攻击 【1】利用canary泄露flag，这个方法很巧妙的运用了canary本身的弱点，当stack_check_fail时，会打印出正在运行中程序的名称，所以，我们只要将libc_argv[0]覆盖为flag的地址就能将flag打印出来。 【2】利用printf函数泄露一个子进程的Canary，再在另一个子进程栈中伪造Canary就可以绕过Canary的保护了。 上面信息来源于百度，反正我是看不懂。。。大概意思就是有保护措施，需要绕过canary才能进行破解。 先不管这么多，直接上r2 168+r2。 使用方法参考Radare2使用全解 pdf命令来查看汇编代码 s main(s表示seek, 跳转到main) s sym.compare_pwd 至此，我们就找到了程序的两个入口，0x004006de表示密码验证通过，0x004006f1表示密码验证失败。 这时候就该上另外一个神器了，angr。 angr github angr介绍 angr用于逆向工程中进行二进制分析的一个python框架 符号执行 （Symbolic Execution）是一种程序分析技术。其可以通过分析程序来得到让特定代码区域执行的输入。使用符号执行分析一个程序时，该程序会使用符号值作为输入，而非一般执行程序时使用的具体值。在达到目标代码时，分析器可以得到相应的路径约束，然后通过约束求解器来得到可以触发目标代码的具体值。 angr安装 pip install angr 之后就可以编写angr脚本了 代码和注释如下： #!/usr/bin/env python2 #_*_ coding:UTF-8 _*_ #导入angr包 import angr #这个模块用来来定义抽象的数据 import claripy #加载程序，建立一个angr工程 proj = angr.Project('./168+r2', auto_load_libs=False) #claripy.BVS('arg1', 50*8) 这一句即是用claripy这个模块的BVS函数来创建一个指定长度的抽象数据，BVS函数要求两个参数，第一个参数为变量名，第二个参数为变量长度。 args = [proj.filename, claripy.BVS('arg1', 50*8)] #用于指明程序在初始运行时的状态,默认就是程序的入口地址,另外有函数blank_state，可用于指定程序起始运行地址通过给定参数addr的值 state = proj.factory.entry_state(args=args) #从给定状态创建了一个模拟器，进行符号执行 simgr = proj.factory.simgr(state) #使用explore执行模拟器，find和avoid用来作为约束条件。 #find即要产生ok的状态，而避免close的状态 #avoid规避产生not ok的状态。 simgr.explore(find=0x4006DE, avoid=0x4006F1) #sm.found[0].solver 用于存储状态的解，而eval函数则输入参数的值 print simgr.found[0].solver.eval(args[1], cast_to=str) 这样就获取到了对应的password "},"安全/CTF/CTF题集/密码学之摩斯电码.html":{"url":"安全/CTF/CTF题集/密码学之摩斯电码.html","title":"密码学之摩斯电码","keywords":"","body":"密码学之摩斯电码 摩斯电码 简单 密码学 描述 你知道点点杠杠已经起源好久了吗？（flag为字符串，无前缀）..-. .-.. .- --. -- --- .-. ... . -.-. --- -.. . ... --- -. .. -.-. . 解题步骤： 这个题并不难，先来普及一下知识点。。。。 摩尔斯电码 摩尔斯电码（又译为摩斯密码，Morse code）是一种时通时断的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。 摩尔斯电码定义了包括：英文字母A-Z（无大小写区分）十进制数字0-9，以及“？”“/”“（）”“－”“．”很适合英语的通信。至今仍有很多地方在使用。在业余无线电通信中，他是全世界运用统一的电码。下面列出的是基本码表： 字母 字符电码符号字符电码符号字符电码符号字符电码符号A．━B━ ．．．C━ ．━ ．D━ ．．E．F．．━ ．G━ ━ ．H．．．．I．．J．━ ━ ━K━ ．━L．━ ．．M━ ━N━ ．O━ ━ ━P．━ ━ ．Q━ ━ ．━R．━ ．S．．．T━U．．━V．．．━W．━ ━X━ ．．━Y━ ．━ ━Z━ ━ ．．　　　　 数字 字符电码符号字符电码符号字符电码符号字符电码符号0━ ━ ━ ━ ━1．━ ━ ━ ━2．．━ ━ ━3．．．━ ━4．．．．━5．．．．．6━ ．．．．7━ ━ ．．．8━ ━ ━ ．．9━ ━ ━ ━ ．　　　　 标点符号 字符电码符号字符电码符号字符电码符号字符电码符号0━ ━ ━ ━ ━1．━ ━ ━ ━2．．━ ━ ━3．．．━ ━4．．．．━5．．．．．6━ ．．．．7━ ━ ．．．8━ ━ ━ ．．9━ ━ ━ ━ ．　　　　 非英语字符 字符电码符号字符电码符号字符电码符号字符电码符号à或å．━ ━ ．━ä或æ．━ ．━ch━ ━ ━ ━ç或ĉ━ ．━ ．．ð．．━ ━ ．é．．━ ．．è．━ ．．━ĝ━ ━ ．━ ．ĥ━ ．━ ━ ．ĵ．━ ━ ━ ．ñ━ ━ ．━ ━ö或ø━ ━ ━ ．ŝ．．．━ ．þ．━ ━ ．．ü或ŭ．．━ ━　　 特殊符号 字符电码符号字符电码符号字符电码符号字符电码符号AR．━ ．━ ．AS．━ ．．．K━ ．━ SK．．．━ ．━ BT━ ．．．━ 　　　　　　 既然咱们现在已经知道对应的字符了，按照对应的表格即可获得正确的密码，所以我们。。。。 当然不可能一个一个去对照着翻译了，直接在线解密就好了啊。。。。 在线摩斯密码加密,摩斯密码解密 是不是很简单，不过既然咱们有了码表，不妨用python写一个。 #!/usr/bin/python # -*- coding: UTF-8 -*- import sys a = \"..-. .-.. .- --. -- --- .-. ... . -.-. --- -.. . ... --- -. .. -.-. .\" s = a.split(\" \") dict = {'.-': 'A', '-...': 'B', '-.-.': 'C', '-..':'D', '.':'E', '..-.':'F', '--.': 'G', '....': 'H', '..': 'I', '.---':'J', '-.-': 'K', '.-..': 'L', '--': 'M', '-.': 'N', '---': 'O', '.--.': 'P', '--.-': 'Q', '.-.': 'R', '...': 'S', '-': 'T', '..-': 'U', '...-': 'V', '.--': 'W', '-..-': 'X', '-.--': 'Y', '--..': 'Z', '.----': '1', '..---': '2', '...--': '3', '....-': '4', '.....': '5', '-....': '6', '--...': '7', '---..': '8', '----.': '9', '-----': '0', '..--..': '?', '-..-.': '/', '-.--.-': '()', '-....-': '-', '.-.-.-': '.' }; for i in s: sys.stdout.write(dict[i]) #python3 使用 print (dict[i],end='')输出即可 "},"安全/CTF/CTF题集/逆向工程之阿拉丁神灯.html":{"url":"安全/CTF/CTF题集/逆向工程之阿拉丁神灯.html","title":"逆向工程之阿拉丁神灯","keywords":"","body":"逆向工程之阿拉丁神灯 题目链接 阿拉丁神灯 解题步骤： 1.下载文件获得一个ald.exe，先运行一下看看。 随便先输入点东西试试。。。 2.输入123，点击‘开启’出现，“通关密语错误”的提示信息。拿到这个exe，我们先来了解要破解的程序是由什么语言写的，有没有加壳（壳可以理解为对程序的加密使逆向人员难以看到源码）。 这里我们使用PEID，PEID的作用就是查看一个PE文件是用什么语言撰写的，当然了，jar和APK这种不属于PE文件（你可以理解为PE文件就是windows下的exe文件和dll文件）。以下是PEID查看文件的效果图： 可以看到ald.exe是由C#编写的，所以我们使用.net reflecter来进行反编译。 选择Search String，输入“通关密语错误”的错误提示，搜索结果双击打开。 这样就找到了应该输入的信息。 当然同样的方法，适用于使用IDA工具。。。 "},"安全/CTF/CTF题集/逆向工程easyflag.html":{"url":"安全/CTF/CTF题集/逆向工程easyflag.html","title":"逆向工程easyflag","keywords":"","body":"逆向工程easyflag asyflag 简单 逆向工程 描述 破译这个程序就能看到flag。flag格式为flag{字符串}。 附件 easyflag.zip 解题步骤： 1.下载解压附件，得到easyflag可执行文件。常规操作，随便输入一些内容，看看输出结果 2.之前用过很多次r2，这次我们换一个工具试试，用IDA打开文件。 找到刚才输出报错信息的地方，直接按下F5，查看伪代码。 通过这一串代码，我们看到程序是拿到输入的字符后，与“HELLOWORLD”每个字符ascii码+8进行比较，所以，这个就简单了，根据ascii码表一一对应找到flag即可，当然也可以自己写个脚本来进行计算。 #!/usr/bin/env python2 # _*_ coding:UTF-8 _*_ import sys s = 'HELLOWORLD' for i in s: sys.stdout.write(chr(ord(i)+8)) 执行后得到“PMTTW_WZTL”。 再次使用该字符尝试执行。 应该是OK的。 "},"安全/CTF/CTF题集/密码学之md5.html":{"url":"安全/CTF/CTF题集/密码学之md5.html","title":"密码学之md5","keywords":"","body":"密码学之md5 题目： Caesar 忘记了密码，从数据库中拿到md5——7d84fc037fa7d7bd53c88ecda36282c7，只想着明文是：flag{xxxx_hhh_passw0rd_xxxxx}这种格式，xxxx是1000-9999之内数字，xxxxx是20000-99999之间的数字 解题步骤： 还好，数字位数都不是很大，直接爆破： import hashlib import time a = str(range(1000,9999)) b = str(range(20000,99999)) s = 'flag{'+a+'_hhh_passw0rd_'+b+'}' start_time = time.time() exitflag = False for a in range(1000,9999): for b in range(20000,99999): s = 'flag{'+str(a)+'_hhh_passw0rd_'+str(b)+'}' s_md5 = hashlib.md5(s.encode()).hexdigest() print (s_md5) if(s_md5=='7d84fc037fa7d7bd53c88ecda36282c7'): end_time = time.time() print ('time:[%.3f]\\tflag:[%s]' % ((end_time-start_time),s)) exitflag = True break if exitflag: break 运行结果： time:[403.076] flag:[flag{1611_hhh_passw0rd_39802}] MD5 MD5是一个安全的散列算法，输入两个不同的明文不会得到相同的输出值，根据输出值，不能得到原始的明文，即其过程不可逆；所以要解密MD5没有现成的算法，只能用穷举法，把可能出现的明文，用MD5算法散列之后，把得到的散列值和原始的数据形成一个一对一的映射表，通过比在表中比破解密码的MD5算法散列值，通过匹配从映射表中找出破解密码所对应的原始明文。 对信息系统或者网站系统来说，MD5算法主要用在用户注册口令的加密，对于普通强度的口令加密，可以通过以下三种方式进行破解： （1）在线查询密码。一些在线的MD5值查询网站提供MD5密码值的查询，输入MD5密码值后，如果在数据库中存在，那么可以很快获取其密码值。 （2）使用MD5破解工具。网络上有许多针对MD5破解的专用软件，通过设置字典来进行破解。 （3）通过社会工程学来获取或者重新设置用户的口令。 1.下载文件时，经常看见的MD5 SHA1是干什么用的？ 在人类社会中通常使用指纹作为一个人的特征，来识别或确认一个人的身份。但在计算机中如何确认或识别一个文件呢？没错，我们使用MD5值作为文件的指纹，来验证文件。 在计算机中，每个文件说白了都是一段保存在硬盘中的数据，因为不同文件保存在硬盘上的01序列不同，所以可以通过MD5这种算法，给这段很大的文件数据，算出一个128bit的值，这个值就叫MD5值，这样就实现了我文件的识别。(不管多长的数据，得到的都是128bit的值，所以MD5叫摘要算法，这个过程是不可逆的.) 发送方要给接收方发送一个文件，但是文件中途可能被人劫持并篡改替换掉，那接收方如何确认收到的文件就是发送方的发送的原始数据呢？ 这时候发送方可以在发送文件时，跟接收方约定一个MD5，接收方接到文件后，计算文件的MD5值，如果得到的结果和发送方给的MD5值相同，就说明文件没有被替换篡改过。(类似功能的算法还有SHA系列)。 2.MD5值对应的输入值是唯一的吗？ 已知原文abcdefg，它对应的MD5值为7AC66C0F148DE9519B8BD264312C4D64， 这里输入值是abcdefg，输出值是7AC66C0F148DE9519B8BD264312C4D64， 问题是世界上只有abcdefg的输出值是7AC66C0F148DE9519B8BD264312C4D64吗？ 当然不是，理论上有无数种输入可以得到同一个MD5值，只是想在短时间内找到非常难。 3.MD5碰撞是什么意思? 两个不同输入，却得到同一个MD5，这两个输入值就算是碰撞。 4.什么是彩虹表？ 123456的MD5值为E10ADC3949BA59ABBE56E057F20F883E，我们把123456这类经常出现的值全部算出md5值然后保存为一个巨大的表。当我们想知道某个MD5值的原文内容时，就可以把这个MD5值输入到表中去反向查询原文。 如果想再深入了解一下彩虹表，可以点击这里： Ophcrack彩虹表(Rainbow Tables)原理详解 "},"安全/CTF/CTF题集/图片隐写术之教练我想打CTF.html":{"url":"安全/CTF/CTF题集/图片隐写术之教练我想打CTF.html","title":"图片隐写术之教练我想打CTF","keywords":"","body":"图片隐写术之教练我想打CTF 题目： flag格式为hctf{字符串} 附件： 145+flag.png.zip 解题步骤： 下载附件解压之后得到一张图片。 使用binwalk分析文件是否存在多重文件。 发现图片中存在zip的隐藏文件，安装zsteg，kali下的安装方法： gem install zsteg 用命令将图片中的zip压缩包提取出来并命名为2.zip zsteg -E 1b,rgb,lsb 145+flag.png > 2.zip 执行完命令之后，会在当前目录下找到一个zip文件，解压会得到一个名为1的可行文件。 chmod +x 1 ./1 得到flag。 Binwalk介绍 Binwalk是用于搜索给定二进制镜像文件以获取嵌入的文件和代码的工具。 具体来说,它被设计用于识别嵌入固件镜像内的文件和代码。 Binwalk使用libmagic库,因此它与Unix文件实用程序创建的魔数签名兼容。 Binwalk还包括一个自定义魔数签名文件,其中包含常见的诸如压缩/存档文件,固件头,Linux内核,引导加载程序,文件系统等的固件映像中常见文件的改进魔数签名。 下载与安装 $ sudo su //然后输入密码，获取root权限，避免后期执行命令时出现权限不够的情况。 $ sudo apt-get remove binwalk //卸载原有的旧版binwalk（如果有的话），采用git的方式进行安装，以便得到更好的更新。 $ sudo apt-get update //更新软件 $ sudo apt-get install build-essential autoconf git //获取开发工具git $ git clone https://github.com/devttys0/binwalk //从git上获取binwalk的源代码 $ cd binwalk //进入binwalk文件夹 $ sudo python setup.py install //导入python环境 #如果自己linux上的python是2.x版的，则紧接着还需要执行下面这步导入python-lzma模块： $ sudo apt-get install python-lzma //如果执行命令的中途出现了“无法获得锁之类的情况”，执行下面命令即可 sudo rm /var/lib/dpkg/lock 或 sudo rm /var/lib/apt/lists/lock //把lock文件删了 功能 扫描选项: -B,-- signature 扫描目标文件的常见文件签名 -R,--raw = 扫描目标文件的指定字符序列 -A,--opcodes扫描目标文件中常见可执行代码 -m,--magic = 指定要使用的自定义魔数签名文件 -b,--dumb 禁用智能签名关键字 -I,--invalid显示结果标记为无效 -x,--exclude = 排除与匹配的结果 -y,--include = 只显示匹配的结果 提取选项: -e,--extract自动提取已知的文件类型 -D,--dd = 提取签名,为文件扩展名为,然后执行 -M,--matryoshka 递归扫描提取的文件 -d,--depth = 限制matryoshka递归深度(默认值:8级深) -C,--directory = 将文件/文件夹提取到自定义目录(默认值:当前工作目录) -j,--size = 限制每个提取的文件的大小 -n,--count = 限制提取文件的数量 -r,--rm 提取后删除刻录文件 -z,--carve从文件中读取数据,但不执行提取实用程序 熵分析选项: -E,--entropy 计算文件熵 -F,--fast计算更快,但不太详细的熵分析 -J,--save将熵图保存为PNG图像 -Q,--nlegend 从熵图图中省略图例 -N,--nplot 不生成熵图 -H,--high = 设置上升沿熵触发阈值(默认值:0.95) -L,--low = 设置下降沿熵触发阈值(默认值:0.85) 原始压缩选项: -X, --deflate扫描原始deflate压缩流 -Z, --lzma 扫描原始LZMA压缩流 -P, --partial浅度扫描,速度更快 -S, --stop 找到第一个结果后停止扫描 二进制差异选项: -W,--hexdump 执行文件或文件的hexdump/diff -G,--green 只显示包含所有文件中相同字节的行 -i,--red 仅显示包含所有文件中不同字节的行 -U,--blue只显示一些文件中包含不同字节的行 -w,--terse 只显示第一个文件的十六进制转储 一般选项: -l,--length = 要扫描的字节数 -o,--offset = 以此偏移开始扫描 -O,--base = 向所有打印的偏移量添加基址 -K,--block = 设置文件块大小 -g,--swap = 扫描前每n个字节反转一次 -f,--log = 将结果记录到文件 -c,--csv 将结果记录到CSV格式的文件中 -t,--term格式化输出以适合终端窗口 -q,--quiet 禁止输出 -v,--verbose 详细输出 -h,--help显示帮助 -a,--finclude = 只扫描名称与此正则表达式匹配的文件 -p,--fexclude = 不扫描名称与此正则表达式匹配的文件 -s,--status = 启用指定端口上的状态服务器 "},"测试/":{"url":"测试/","title":"测试","keywords":"","body":"测试 "},"测试/非功能测试/":{"url":"测试/非功能测试/","title":"非功能测试","keywords":"","body":"[TOC] 非功能测试 一、性能测试 1.1客户端 1.1.1Web（前端页面性能） 工具 Google Chrome浏览器 Ctrl+Shift+I/F12开发工具 Mozilla Firefox浏览器 Shift+F5开发工具 1.1.2手机 Android Systrace systrace命令允许你收集和检查在你的设备上运行的所有系统级别进程的定时信息。它联合Android内核（比如CPU调度程序）、磁盘活动和app线程，生成一份HTML报告。 Emmagee Emmagee下载、NetEase/Emmagee · GitHub，网易开发的性能检测工具，不需要在应用中集成sdk，能够对应用的常用性能指标进行检测，并以csv的格式保存方便查看应用的各项参数。 Emmagee是一个简单易上手的Android性能监测工具，主要用于监测单个App的CPU、内存、流量、电量、电流帧数以及整体性能状态，同时支持自定义的监控频率以及性能数据的实时显示。 该工具的优势在于如同windows系统性能监视器类似，它提供的是数据采集的功能，而行为则基于用户真实的应用操作。 Android APP性能测试步骤 设计场景 ：手工或自动化工具 获取数据：可获取的数据包括：内存、CPU、电量功耗、hprof (内存泄露分析文件)、响应时间等。配合手工或自动化工具来获取数据（最好多取几次，并且每次配合不同的设备取平均值）作为最后的对比分析。 结果分析 ：拿到数据后，分析哪些模块的数据异常，再去Check code来定位问题 Android APP测试方法 压力测试 APP压力测试是在强负载（大数据量、大量并发用户等）下，模拟APP的软硬件环境的测试，查看APP在峰值使用情况下操作行为，从而有效地发现APP的功能隐患、测试系统是否具有良好的容错能力和可恢复能力。压力测试分为高负载下的长时间（如24小时以上）的稳定性压力测试和极限负载情况下导致系统崩溃的破坏性压力测试。通过压力测试，可以更快地发现内存泄漏问题，还可以更快地发现影响系统稳定性的问题。压力测试法用来测试目标系统在一定饱和状态下，例如CPU、内存等在饱和状态下、系统能够处理的session的能力，以及系统是否会出现错误。例如：测试Android APP，耗时2小时，通过Google原生测试工具monkey对APP进行模拟用户随机操作测试，根据用户选择的频率输入大量点击，滑动等操作事件及导航事件等伪随机事件，让APP在一个稳定的压力负荷下运行，同时检测应用的各项运行参数。 遍历测试 Android APP最常见的测试就是菜单遍历，就是反复遍历菜单N次，可以理解为遍历APP的每个activity。Activity是Android应用层开发的四大组件之一，主要负责和用户交互部分，有自己的生命周期，在其上可以布置按钮，文本框等各种控件，简单来说就是Android的UI部分。遍历activity就是每次获取当前activity所有的view，然后每个view都有若干操作，基于这些操作生成树状结构，进行遍历，每次执行一个操作后，update当前activity的view。例如：耗时2小时，通过脚本以用户选择的操作对APP进行循环遍历APP菜单进行测试，同时检测APP的各项运行参数。 空载测试 空载测试是指不介入负载的情况下，对APP进行测试。APP的空子测试常常是为了测试APP后台运行期间的CPU占有率，内存消耗，流量及电量消耗等。例如：耗时30分钟，启APP后按HOME键退出，让应用在后台运行，同时检测应用的各项运行参数。 指标 数据性能指标： 应用占用内存PSS(MB)：应用当前占内存的大小； 应用占用内存比(%)：应有占总内存的百分比； 机器剩余内存(MB)：机器当前剩余内存； 应用占用CPU率(%)：应用占用总CPU的百分比； CPU总使用率(%)：CPU的总使用率，包括当前应有，和系统的所有运行的应有； CPU0-CPU3是因为手机是多核的（4核显示cpu0-cpu3，10核显示到cpu0-cpu9） 流量(KB)：从检测开始共耗用的流量； 电量(%)：剩余电池的百分比，包括其他应用的，这个是有误差的，所以测试期间尽可能关闭其他软件，或者期间别操作其他的应用，避免带来误差； 电流(mA)：小于0是放电大于0是充电； 温度(C)：手机当前的温度； 电压(V)：电池工作电压； 帧率：不确定是两次取数之间的平均帧率还是取数据的瞬间帧率。 1.2服务端 1.2.1测试工具 Loadruner 性能测试是利用产品、人员和流程来降低应用程序、升级程序或补丁程序部署风险的一种手段。性能测试的主要思想是通过模拟产生真实业务的压力对被测系统进行加压，验证被测系统在不同压力情况下的表现，找出其潜在的瓶颈。 LoadRunner提供了3大主要功能模块：VirtualUser Generator（用于录制性能测试脚本），LoadRunner Controller（用于创建、运行和监控场景），LoadRunner Analysis（用于分析性能测试结果）既可以作为独立的工具完成各自的功能，又可以作为LoadRunner的一部分彼此衔接，与其他模块共同完成软件性能的整体测试。 Jmeter JMeter作为一款广为流传的开源压测产品，最初被设计用于Web应用测试，如今JMeter可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP服务器等等，还能对服务器、网络或对象模拟巨大的负载，通过不同压力类别测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能测试和回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。 JMeter的特点包括对HTTP、FTP服务器、数据库进行压力测试和性能测试；完全的可移植性；完全 Swing和轻量组件支持包；完全多线程；缓存和离线分析/回放测试结果；可链接的取样器；具有提供动态输入到测试的功能；支持脚本编程的取样器等。在设计阶段，JMeter能够充当HTTP PROXY（代理）来记录浏览器的HTTP请求，也可以记录Apache等WebServer的log文件来重现HTTP流量，并在测试运行时以此为依据设置重复次数和并发度（线程数）来进行压测。 Neoload NeoLoad是Neotys出品的一种负载和性能测试工具，可真实地模拟用户活动并监视基础架构运行状态，从而消除所有Web和移动应用程序中的瓶颈。NeoLoad通过使用无脚本GUI和一系列自动化功能，可让测试设计速度提高5-10倍，并将维护的脚本维持在原始设计时间的10％，同时帮助用户使用持续集成系统自动进行测试。 NeoLoad支持WebSocket、HTTP1/ 2、GWT、HTML5、AngularJS、Oracle Forms等技术协议，能够监控包括操作系统，应用服务器，Web服务器，数据库和网络设备在内的各种IT基础设施，同时可以通过Neotys云平台发起外部压力。 1.2.2测试场景 单交易基准场景 单交易负载场景 混合场景 稳定性场景 浪涌场景 特殊场景 1.2.3测试类型 负载测试 通过在被测系统上不断加压，直到性能指标达到极限，例如“响应时间”超过预定指标或都某种资源已经达到饱和状态。 特点： 这种性能测试方法的主要目的是找到系统处理能力的极限。 这种性能测试方法需要在给定的测试环境下进行，通常也需要考虑被测试系统的业务压力量和典型场景、使得测试结果具有业务上的意义。 这种性能测试方法一般用来了解系统的性能容量，或是配合性能调优来使用。 也就是说，这种方法是对一个系统持续不段的加压，看你在什么时候已经超出“我的要求”或系统崩溃。 压力测试 压力测试方法测试系统在一定饱和状态下，例如cpu、内存在饱和使用情况下，系统能够处理的会话能力，以及系统是否会出现错误 特点： 这种性能测试方法的主要目的是检查系统处于压力性能下时，应用的表现。 这种性能测试一般通过模拟负载等方法，使得系统的资源使用达到较高的水平。 这种性能测试方法一般用于测试系统的稳定性。 也就是说，这种测试是让系统处在很大强度的压力之下，看系统是否稳定，哪里会出问题。 配置测试 配置测试方法通过对被测系统的软\\硬件环境的调整，了解各种不同对系统的性能影响的程度，从而找到系统各项资源的最优分配原则。 特点： 这种性能测试方法的主要目的是了解各种不同因素对系统性能影响的程度，从而判断出最值得进行的调优操作。 这种性能测试方法一般在对系统性能状况有初步了解后进行。 这种性能测试方法一般用于性能调优和规划能力。 也就是说，这种测试关注点是“微调”，通过对软硬件的不段调整，找出这他们的最佳状态，使系统达到一个最强的状态。 并发测试 并发测试方法通过模拟用户并发访问，测试多用户并发访问同一个应用、同一个模块或者数据记录时是否存在死锁或其者他性能问题。 特点： 这种性能测试方法的主要目的是发现系统中可能隐藏的并发访问时的问题。 这种性能测试方法主要关注系统可能存在的并发问题，例如系统中的内存泄漏、线程锁和资源争用方面的问题。 这种性能测试方法可以在开发的各个阶段使用需要相关的测试工具的配合和支持。 也就是说，这种测试关注点是多个用户同时（并发）对一个模块或操作进行加压。 稳定性测试 在特定硬件、软件、网络环境条件下，给系统加载一定业务压力，使系统运行一段较长的时间，以此检测系统是否稳定。 特点： 这种性能测试方法的主要目的是验证是否支持长期稳定的运行。 这种性能测试方法需要在压力下持续一段时间的运行。（2~3天） 测试过程中需要关注系统的运行状况。 也就是说，这种测试的关注点是“稳定”，不需要给系统太大的压力，只要系统能够长期处于一个稳定的状态。 1.2.4测试流程 1.2.5关注内容 用户关注的是用户操作的相应时间。 其次，我们站在管理员的角度考虑需要关注的性能点。 响应时间 服务器资源使用情况是否合理 应用服务器和数据库资源使用是否合理 系统能否实现扩展 系统最多支持多少用户访问. 系统最大业务处理量是多少 系统性能可能存在的瓶颈在哪里 更换那些设备可以提高性能 系统能否支持7×24小时的业务访问 整个系统的稳定性，可恢复性 再次，站在开发（设计）人员角度去考虑。 架构设计是否合理 数据库设计是否合理 代码是否存在性能方面的问题 系统中是否有不合理的内存使用方式 系统中是否存在不合理的线程同步方式 系统中是否存在不合理的资源竞争 代码，算法，sql语句设计是否合理 等等。。。。 1.2.6性能指标 虚拟用户数 虚拟用户（Virtual User）：模拟真实业务逻辑步骤的虚拟用户，虚拟用户模拟的操作步骤都被记录在虚拟用户脚本里。Vuser脚本用于描述Vuser在场景中执行的操作。 事务 并发（Concurrency）：所有用户在同一时刻发起相同的业务请求，用于测试系统对并发操作的处理能力。 平均并发用户数的计算：C=nL / T 其中C是平均的并发用户数，n是平均每天访问用户数（login session），L是一天内用户从登录到退出的平均时间（login session的平均时间），T是考察时间长度（一天内多长时间有用户使用系统） 并发用户数峰值计算：C^约等于C + 3*根号C 其中C^是并发用户峰值，C是平均并发用户数，该公式遵循泊松分布理论。 用户并发数 用户并发数量：在同一时刻与服务器进行交互的用户数量。 请求响应时间 请求响应时间：从发出请求到得到响应这一过程的耗时。 响应时间：对请求作出响应所需要的时间 网络传输时间：N1+N2+N3+N4 应用服务器处理时间：A1+A3 数据库服务器处理时间：A2 响应时间=N1+N2+N3+N4+A1+A3+A2 事务响应时间 事务响应时间：事务可能由一系列的请求组成，事务响应时间是针对用户而言，用于说明业务响应时间。 思考时间 思考时间（Think Time）：用户操作过程中，每个请求之间的间隔时间 Think Time，从业务角度来看，这个时间指用户进行操作时每个请求之间的时间间隔，而在做新能测试时，为了模拟这样的时间间隔，引入了思考时间这个概念，来更加真实的模拟用户的操作。 在吞吐量这个公式中F=VU * R / T说明吞吐量F是VU数量、每个用户发出的请求数R和时间T的函数，而其中的R又可以用时间T和用户思考时间TS来计算：R = T / TS 下面给出一个计算思考时间的一般步骤： A、首先计算出系统的并发用户数 C=nL / T F=R×C B、统计出系统平均的吞吐量 F=VU * R / T R×C = VU * R / T C、统计出平均每个用户发出的请求数量 R=u*C*T/VU D、根据公式计算出思考时间 TS=T/R 吞吐量 吞吐量指在一次性能测试过程中，网络上传输数据流量的总和。吞吐量/传输时间=吞吐率。 指单位时间内系统处理用户的请求数 从业务角度看，吞吐量可以用：请求数/秒、页面数/秒、人数/天或处理业务数/小时等单位来衡量 从网络角度看，吞吐量可以用：字节/秒来衡量 对于交互式应用来说，吞吐量指标反映的是服务器承受的压力，他能够说明系统的负载能力 以不同方式表达的吞吐量可以说明不同层次的问题，例如，以字节数/秒方式可以表示数要受网络基础设施、服务器架构、应用服务器制约等方面的瓶颈；已请求数/秒的方式表示主要是受应用服务器和应用代码的制约体现出的瓶颈。 当没有遇到性能瓶颈的时候，吞吐量与虚拟用户数之间存在一定的联系，可以采用以下公式计算：F=VU * R /T 其中F为吞吐量，VU表示虚拟用户个数，R表示每个虚拟用户发出的请求数，T表示性能测试所用的时间 吞吐率 吞吐率（Throughput）：单位时间内网络上传输的数据流量，某些情况下也可以指单位时间内所处理的请求数（requests/second）。 点击率 点击率（Hit Per Second）：用户每秒钟向服务器提交的HTTP请求数，是WEB应用的特有指标。 资源利用率 资源利用率：指对不同系统资源的使用程度，如服务器CPU的利用率、磁盘利用率，主要针对WEB应用服务器、操作系统、数据库服务器和网络等，是分析系统性能指标并调优的重要依据。 从服务器的角度看，性能测试主要关注CPU、内存、服务器负载、网络、磁盘IO等 CPU 后台服务的所有指令和数据处理都是由CPU负责，服务对CPU的利用率对服务的性能起着决定性的作用。 Linux系统的CPU主要有如下几个维度的统计数据 us：用户态使用的cpu时间百分比 sy：系统态使用的cpu时间百分比 ni：用做nice加权的进程分配的用户态cpu时间百分比 id：空闲的cpu时间百分比 wa：cpu等待IO完成时间百分比 hi：硬中断消耗时间百分比 si：软中断消耗时间百分比 Top 命令输出详解 us & sy：大部分后台服务使用的CPU时间片中us和sy的占用比例是最高的。同时这两个指标又是互相影响的，us的比例高了，sy的比例就低，反之亦然。通常sy比例过高意味着被测服务在用户态和系统态之间切换比较频繁，此时系统整体性能会有一定下降。另外，在使用多核CPU的服务器上，CPU 0负责CPU各核间的调度，CPU 0上的使用率过高会导致其他CPU核心之间的调度效率变低。因此测试过程中CPU 0需要重点关注。 ni：每个Linux进程都有个优先级，优先级高的进程有优先执行的权利，这个叫做pri。进程除了优先级外，还有个优先级的修正值。这个修正值就叫做进程的nice值。一般来说，被测服务和服务器整体的ni值不会很高。如果测试过程中ni的值比较高，需要从服务器Linux系统配置、被测服务运行参数查找原因 id：线上服务运行过程中，需要保留一定的id冗余来应对突发的流量激增。在性能测试过程中，如果id一直很低，吞吐量上不去，需要检查被测服务线程/进程配置、服务器系统配置等。 wa：磁盘、网络等IO操作会导致CPU的wa指标提高。通常情况下，网络IO占用的wa资源不会很高，而频繁的磁盘读写会导致wa激增。如果被测服务不是IO密集型的服务，那需要检查被测服务的日志量、数据载入频率等。 hi & si：硬中断是外设对CPU的中断，即外围硬件发给CPU或者内存的异步信号就是硬中断信号；软中断由软件本身发给操作系统内核的中断信号。通常是由硬中断处理程序或进程调度程序对操作系统内核的中断，也就是我们常说的系统调用(System Call)。在性能测试过程中，hi会有一定的CPU占用率，但不会太高。对于IO密集型的服务，si的CPU占用率会高一些。 针对CPU： 针对cpu的监控，其实linux已经提供了两个比较好用的工具，一个是top，一个是vmstat。 关于这两个命令就不细说了，参考这里 top（http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/top.html） vmstat（http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/vmstat.html） 关于cpu主要关注4个值：us(user), sy(system), wa(wait), id(idle)。理论上他们加起来应该等于100%。而前三个每一个值过高都有可能表示存在某些问题。 us过高： 代码问题。比如一个耗时的循环不加sleep，或者在一些cpu密集计算（如xml解析，加解密，加解压，数据计算）时没处理好 gc频繁。一个比较容易遗漏的问题就是gc频繁时us容易过高，因为垃圾回收属于大量计算的过程。gc频繁带来的cpu过高常伴有内存的大量波动，通过内存来判断并解决该问题更好。小技巧：如何定位us过高的线程并查看它的状态。 a. top命令找到消耗us过高的进程pid b. top -Hp pid找到对应的线程tid c. printf %x tid转为16进制tid16 d. jstack pid | grep -C 20 tid16 即可查到该线程堆栈 sy过高： 上下文切换次数过多。通常是系统内线程数量较多，并且线程经常在切换，由于系统抢占相对切换时间和次数比较合理，所以sy过高通常都是主动让出cpu的情况，比如sleep或者lock wait, io wait。 wa过高： 等待io的cpu占比较多。注意与上面情况的区别，io wait引起的sy过高指的是io不停的wait然后唤醒，因为数量较大，导致上下文切换较多，强调的是动态的过程；而io wait引起的wa过高指的是io wait的线程占比较多，cpu切换到这个线程是io wait，到那个线程也是io wait，于是总cpu就是wait占比较高。 id过高： 很多人认为id高是好的，其实在性能测试中id高说明资源未完全利用，或者压测不到位，并不是好事。 内存 性能测试过程中对内存监控的主要目的是检查被测服务所占用内存的波动情况。 在Linux系统中有多个命令可以获取指定进程的内存使用情况，最常用的是top命令，其中 VIRT：进程所使用的虚拟内存的总数。它包括所有的代码，数据和共享库，加上已换出的页面，所有已申请的总内存空间 RES：进程正在使用的没有交换的物理内存（栈、堆），申请内存后该内存段已被重新赋值 SHR：进程使用共享内存的总数。该数值只是反映可能与其它进程共享的内存，不代表这段内存当前正被其他进程使用 SWAP：进程使用的虚拟内存中被换出的大小，交换的是已经申请，但没有使用的空间，包括（栈、堆、共享内存） DATA：进程除可执行代码以外的物理内存总量，即进程栈、堆申请的总空间 从上面的解释可以看出，测试过程中主要监控RES和VIRT，对于使用了共享内存的多进程架构服务，还需要监控SHR。 注： 通常我们看到Linux用top命令查看系统运行状况，普遍看到Used Memory占到了将近总内存的90%，然后很多人以为系统内存已经不足。其实，这只是Linux的为了提高文件读取的性能的内存使用机制罢了。不同于Windows，windows程序执行完后，会马上释放掉内存，把Memory降下来。而对于Linux，如果你的服务器内存还有足够多的空间的话，Linux会把程序运行的数据缓存起来，加入到Cache中，所以内存会不断增加，直到一定的限度为止.当超过这限度后，内核必须将脏页写回磁盘，以便释放内存。也就是说，当空闲内存低于一个特定的阈值时，内核的守护进程就会进行内存块回收。 用free -m 命令查看下内存的使用情况： 以上各参数的解释： total:总物理内存的大小。 used:已使用内存。 free:可用内存。 Shared:多个进程共享的内存总额。 Buffers/cached:磁盘缓存的大小。 第二行:memory使用情况。 第三行(-/+ buffers/cache)。 第四行交换分区使用情况。 区别：第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。 这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是746M,已用内存是3085M,其中包括，内核（OS）使用+Application(X, oracle,etc)使用的+buffers+cached. 第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。 所以从应用程序的角度来说，可用内存=系统free memory+buffers+cached。 我们通过free命令查看机器空闲内存时，会发现free的值很小。这主要是因为，在linux中有这么一种思想，内存不用白不用，因此它尽可能的cache和buffer一些数据，提高文件读取的性能，以方便下次使用。但实际上这些内存，如果需要的话，也是可以立刻拿来使用的。 所以计算可用内存=free+buffers+cached=total-used buffer是用于存放要输出到disk（块设备）的数据的，而cache是存放从disk上读出的数据。这二者是为了提高IO性能的，并由OS管理。 针对内存： 关于java应用的内存，通常只需要关注jvm内存，但有些特殊情况也需要关注物理内存。 关于jvm内存，常见的工具有 jstat（http://blog.csdn.net/fenglibing/article/details/6411951） jmap（http://www.cnblogs.com/ggjucheng/archive/2013/04/16/3024986.html） pidstat（https://linux.cn/article-4257-1.html） vmstat top JVM内存: 异常gc : 通常gc发生意味着总归是有一块区域空间不足而触发gc。而许多导致异常gc的情况通常是持有了不必要的引用而没有即时的释放，比如像cache这样的地方就容易处理不好导致内存泄露引发异常gc。 有可能是程序的行为是正常的，但是由于没有配置对合适的gc参数导致异常gc，这种情况通常需要调优gc参数或者堆代大小参数。 Full gc 发生的情况: 永久代满 年老代满 minor gc晋升到旧生代的平均大小大于旧生代剩余大小 CMS gc中promotion fail或concurrent mode fail OOM： OOM经常伴随着异常gc，之所以单独拿出来讲，是因为它的危害更大一些，异常gc顶多是收集速度过快或者回收不了内存，但是起码有个缓冲时间，但是出了OOM问题就大了。至于各种类型的OOM如何区分，如何发生，请参考这里（http://www.jianshu.com/p/2fdee831ed03），算是总结得比较全面的。对于常见的OOM，基本上可以一下子指出问题所在。 heap区，对象创建过多或持有太多无效引用（泄露）或者堆内存分配不足。使用jmap找到内存中对象的分布，使用ps找到相应进程及初始内存配置。 stack区, 不正确的递归调用。 perm区，初始加载包过多，分配内存不足。 堆外内存区，分配ByteBuffer未释放导致。 网络 性能测试中网络监控主要包括网络流量、网络连接状态的监控。 网络流量监控 可以使用nethogs命令。该命令与top类似，是一个实时交互的命令 在后台服务性能测试中，对于返回文本结果的服务，并不需要太多关注在流量方面。 网络连接状态监控 性能测试中对网络的监控主要是监控网络连接状态的变化和异常。对于使用TCP协议的服务，需要监控服务已建立连接的变化情况（即ESTABLISHED状态的TCP连接）。对于HTTP协议的服务，需要监控被测服务对应进程的网络缓冲区的状态、TIME_WAIT状态的连接数等。Linux自带的很多命令如netstat、ss都支持如上功能. 针对网络IO 针对网络IO比较有用的工具有 sar（https://linuxstory.org/generate-cpu-memory-io-report-sar-command/） netstat（https://linux.cn/article-2434-1.html） netstat是一个非常牛逼的命令，可以助于排查很多问题, 网络IO：网络IO的问题较为复杂，仅举几个常见的 大量TIME_WAIT。根据TCP协议，主动发起关闭连接的那一方，关闭了自己这端的连接后再收到被动发起关闭的那一方的关闭请求后，会将状态变为TIME_WAIT，并等待2MSL, 目的是等待自己的回执发送到对方。如果在服务器上发现大量TIME_WAIT，说明服务器主动断开了连接，什么情况下服务器会主动断开连接，很可能是客户端忘了断开连接，所以一个典型的案例就是jdbc连接忘记关闭，则数据库服务器可能会出现大量的TIME_WAIT状态。 大量CLOSE_WAIT。CLOSE_WAIT状态，在收到主动关闭连接的一方发出关闭连接之后，被动关闭的一方进入CLOSE_WAIT状态，如果这时候被hang住了没进行后续关闭，则会出现大量CLOSE_WAIT。啥情况会被hang住呢，举几个例子，比如刚刚的忘记关闭数据库连接，在应用服务器这端，大量的浏览器请求进来，由于没有连接池连接被hang住，这时候浏览器等待一定时间超时发送关闭连接请求，而应用服务器这边由于servlet线程被hang住了，自然没有办法走第二个关闭回去。因此在应用服务器出现大量CLOSE_WAIT。另一个例子是httpClient的坑，在调用response.getEntity(); 前都不会做inputStream.close()，如果在调用response.getEntity()前就返回了，就狗带了。（这个例子可以参考http://blog.csdn.net/shootyou/article/details/6615051） 磁盘 性能测试过程中，如果被测服务对磁盘读写过于频繁，会导致大量请求处于IO等待的状态，系统负载升高，响应时间变长，吞吐量下降。 Linux下可以用iostat命令来监控磁盘状态 tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的 kB_read/s：每秒从设备（driveexpressed）读取的数据量，单位为Kilobytes kB_wrtn/s：每秒向设备（driveexpressed）写入的数据量，单位为Kilobytes kB_read：读取的总数据量，单位为Kilobytes kB_wrtn：写入的总数量数据量，单位为Kilobytes 从iostat的输出中，能够获得系统运行最基本的统计数据。但对于性能测试来说，这些数据不能提供更多的信息。需要加上-x参数 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge） wrqm/s：每秒这个设备相关的写入请求有多少被Merge了 await：每一个IO请求的处理的平均时间（单位是毫秒） %util：在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，该参数暗示了设备的繁忙程度。 针对文件IO 针对文件io的工具有 pidstat iostat（http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html） 文件IO： 从技术上来说，对于大文件IO可以采取的措施是异步批处理，采用异步方式用于削峰并累计buffer，采用批处理能够让磁盘寻道连续从而更加快速。 1.2.7常见性能瓶颈 仅供参考 吞吐量到上限时系统负载未到阈值 一般是被测服务分配的系统资源过少导致的。测试过程中如果发现此类情况，可以从ulimit、系统开启的线程数、分配的内存等维度定位问题原因。 CPU的us和sy不高，但wa很高 如果被测服务是磁盘IO密集型型服务，wa高属于正常现象。但如果不是此类服务，最可能导致wa高的原因有两个，一是服务对磁盘读写的业务逻辑有问题，读写频率过高，写入数据量过大，如不合理的数据载入策略、log过多等，都有可能导致这种问题。二是服务器内存不足，服务在swap分区不停的换入换出。 同一请求的响应时间忽大忽小 在正常吞吐量下发生此问题，可能的原因有两方面，一是服务对资源的加锁逻辑有问题，导致处理某些请求过程中花了大量的时间等待资源解锁；二是Linux本身分配给服务的资源有限，某些请求需要等待其他请求释放资源后才能继续执行。 内存持续上涨 在吞吐量固定的前提下，如果内存持续上涨，那么很有可能是被测服务存在明显的内存泄漏，需要使用valgrind等内存检查工具进行定位。 内存泄漏检测工具valgrind神器 概述 介绍 Valgrind是一套Linux下，开放源代码（GPL V2）的仿真调试工具的集合。Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务。 工具 Valgrind一般包含下列工具： Memcheck 最常用的工具，用来检测程序中出现的内存问题，所有对内存的读写都会被检测到，一切对malloc()/free()/new/delete的调用都会被捕获。所以，它能检测以下问题： 对未初始化内存的使用； 读/写释放后的内存块； 读/写超出malloc分配的内存块； 读/写不适当的栈中内存块； 内存泄漏，指向一块内存的指针永远丢失； 不正确的malloc/free或new/delete匹配； memcpy()相关函数中的dst和src指针重叠。 Callgrind 和gprof类似的分析工具，但它对程序的运行观察更是入微，能给我们提供更多的信息。和gprof不同，它不需要在编译源代码时附加特殊选项，但加上调试选项是推荐的。Callgrind收集程序运行时的一些数据，建立函数调用关系图，还可以有选择地进行cache模拟。在运行结束时，它会把分析数据写入一个文件。callgrind_annotate可以把这个文件的内容转化成可读的形式。 Cachegrind Cache分析器，它模拟CPU中的一级缓存I1，Dl和二级缓存，能够精确地指出程序中cache的丢失和命中。如果需要，它还能够为我们提供cache丢失次数，内存引用次数，以及每行代码，每个函数，每个模块，整个程序产生的指令数。这对优化程序有很大的帮助。 Helgrind 它主要用来检查多线程程序中出现的竞争问题。Helgrind寻找内存中被多个线程访问，而又没有一贯加锁的区域，这些区域往往是线程之间失去同步的地方，而且会导致难以发掘的错误。Helgrind实现了名为“Eraser”的竞争检测算法，并做了进一步改进，减少了报告错误的次数。不过，Helgrind仍然处于实验阶段。 Massif 堆栈分析器，它能测量程序在堆栈中使用了多少内存，告诉我们堆块，堆管理块和栈的大小。Massif能帮助我们减少内存的使用，在带有虚拟内存的现代系统中，它还能够加速我们程序的运行，减少程序停留在交换区中的几率。 此外，lackey和nulgrind也会提供。Lackey是小型工具，很少用到；Nulgrind只是为开发者展示如何创建一个工具。 原理 Memcheck 能够检测出内存问题，关键在于其建立了两个全局表。Valid-Value 表 对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于CPU的每个寄存器，也有一个与之对应的bit向量。这些bits负责记录该字节或者寄存器值是否具有有效的、已初始化的值。 Valid-Address 表 对于进程整个地址空间中的每一个字节(byte)，还有与之对应的1个bit，负责记录该地址是否能够被读写。 检测原理： 当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck则报告读写错误。 内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。 安装使用 安装 从官网http://www.valgrind.org下载最新版本 #tar xvf valgrind-3.11.1.tar.bz2 #cd valgrind-3.11.1 #./configure --prefix=/usr/local/valgrind--指定安装目录 #make #make install 命令介绍 用法:valgrind[options] prog-and-args [options]: 常用选项，适用于所有Valgrind工具 -tool= 最常用的选项。运行 valgrind中名为toolname的工具。默认memcheck。 h –help 显示帮助信息。 -version 显示valgrind内核的版本，每个工具都有各自的版本。 q –quiet 安静地运行，只打印错误信息。 v –verbose 更详细的信息, 增加错误数统计。 -trace-children=no|yes 跟踪子线程? [no] -track-fds=no|yes 跟踪打开的文件描述？[no] -time-stamp=no|yes 增加时间戳到LOG信息? [no] -log-fd= 输出LOG到描述符文件 [2=stderr] -log-file= 将输出的信息写入到filename.PID的文件里，PID是运行程序的进行ID -log-file-exactly= 输出LOG信息到 file -log-file-qualifier= 取得环境变量的值来做为输出信息的文件名。 [none] -log-socket=ipaddr:port 输出LOG到socket ，ipaddr:port LOG信息输出: -xml=yes 将信息以xml格式输出，只有memcheck可用 -num-callers= show callers in stack traces [12] -error-limit=no|yes 如果太多错误，则停止显示新错误? [yes] -error-exitcode= 如果发现错误则返回错误代码 [0=disable] -db-attach=no|yes 当出现错误，valgrind会自动启动调试器gdb。[no] -db-command= 启动调试器的命令行选项[gdb -nw %f %p] 适用于Memcheck工具的相关选项： -leak-check=no|summary|full 要求对leak给出详细信息? [summary] -leak-resolution=low|med|high how much bt merging in leak check [low] -show-reachable=no|yes show reachable blocks in leak check? [no] 应用实践 下面通过介绍几个范例来说明如何使用Memcheck （其他工具暂不涉及，感兴趣可以交流），示例仅供参考，更多用途可在实际应用中不断探索。 数组越界/内存未释放 #include void k(void) { int *x = malloc(8 * sizeof(int)); x[9] = 0; //数组下标越界 } //内存未释放 int main(void) { k(); return 0; } 1）编译程序test.c gcc -Wall test.c -g -o test#Wall提示所有告警，-g gdb，-o输出 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./test --leak-check=full 所有泄露检查 3) 运行结果如下： ==2989== Memcheck, a memory error detector ==2989== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==2989== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==2989== Command: ./test ==2989== ==2989== Invalid write of size 4 ==2989== at 0x4004E2: k (test.c:5) ==2989== by 0x4004F2: main (test.c:10) ==2989== Address 0x4c27064 is 4 bytes after a block of size 32 alloc'd ==2989== at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==2989== by 0x4004D5: k (test.c:4) ==2989== by 0x4004F2: main (test.c:10) ==2989== ==2989== ==2989== HEAP SUMMARY: ==2989== in use at exit: 32 bytes in 1 blocks ==2989== total heap usage: 1 allocs, 0 frees, 32 bytes allocated ==2989== ==2989== 32 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==2989== at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==2989== by 0x4004D5: k (test.c:4) ==2989== by 0x4004F2: main (test.c:10) ==2989== ==2989== LEAK SUMMARY: ==2989== definitely lost: 32 bytes in 1 blocks ==2989== indirectly lost: 0 bytes in 0 blocks ==2989== possibly lost: 0 bytes in 0 blocks ==2989== still reachable: 0 bytes in 0 blocks ==2989==suppressed: 0 bytes in 0 blocks ==2989== ==2989== For counts of detected and suppressed errors, rerun with: -v ==2989== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 6 from 6) 内存释放后读写 #include #include int main(void) { char *p = malloc(1); //分配 *p = 'a'; char c = *p; printf(\"\\n [%c]\\n\",c); free(p); //释放 c = *p; //取值 return 0; } 1）编译程序t2.c gcc -Wall t2.c -g -o t2 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./t2 3) 运行结果如下： ==3058== Memcheck, a memory error detector ==3058== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==3058== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==3058== Command: ./t2 ==3058== [a] ==3058== Invalid read of size 1 ==3058== at 0x4005A3: main (t2.c:14) ==3058== Address 0x4c27040 is 0 bytes inside a block of size 1 free'd ==3058== at 0x4A06430: free (vg_replace_malloc.c:446) ==3058== by 0x40059E: main (t2.c:13) ==3058== ==3058== ==3058== HEAP SUMMARY: ==3058== in use at exit: 0 bytes in 0 blocks ==3058== total heap usage: 1 allocs, 1 frees, 1 bytes allocated ==3058== ==3058== All heap blocks were freed -- no leaks are possible ==3058== ==3058== For counts of detected and suppressed errors, rerun with: -v ==3058== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6) 从上输出内容可以看到，Valgrind检测到无效的读取操作然后输出“Invalid read of size 1”。 无效读写 #include #include int main(void) { char *p = malloc(1); //分配1字节 *p = 'a'; char c = *(p+1); //地址加1 printf(\"\\n [%c]\\n\",c); free(p); return 0; } 1）编译程序t3.c gcc -Wall t3.c -g -o t3 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./t3 3) 运行结果如下： ==3128== Memcheck, a memory error detector ==3128== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==3128== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==3128== Command: ./t3 ==3128== ==3128== Invalid read of size 1 #无效读取 ==3128==at 0x400579: main (t3.c:9) ==3128==Address 0x4c27041 is 0 bytes after a block of size 1 alloc'd ==3128==at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==3128==by 0x400565: main (t3.c:6) ==3128== [] ==3128== ==3128== HEAP SUMMARY: ==3128==in use at exit: 0 bytes in 0 blocks ==3128==total heap usage: 1 allocs, 1 frees, 1 bytes allocated ==3128== ==3128== All heap blocks were freed -- no leaks are possible ==3128== ==3128== For counts of detected and suppressed errors, rerun with: -v ==3128== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6) 内存泄露 #include #include int main(void) { int *p = malloc(1); *p = 'x'; char c = *p; printf(\"%c\\n\",c); //申请后未释放 return 0; } 1）编译程序t4.c gcc -Wall t4.c -g -o t4 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./t4 3) 运行结果如下： ==3221== Memcheck, a memory error detector ==3221== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==3221== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==3221== Command: ./t4 ==3221== ==3221== Invalid write of size 4 ==3221==at 0x40051E: main (t4.c:7) ==3221==Address 0x4c27040 is 0 bytes inside a block of size 1 alloc'd ==3221==at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==3221==by 0x400515: main (t4.c:6) ==3221== ==3221== Invalid read of size 4 ==3221==at 0x400528: main (t4.c:8) ==3221==Address 0x4c27040 is 0 bytes inside a block of size 1 alloc'd ==3221==at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==3221==by 0x400515: main (t4.c:6) ==3221== x ==3221== ==3221== HEAP SUMMARY: ==3221==in use at exit: 1 bytes in 1 blocks ==3221==total heap usage: 1 allocs, 0 frees, 1 bytes allocated ==3221== ==3221== 1 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==3221==at 0x4A06A2E: malloc (vg_replace_malloc.c:270) ==3221==by 0x400515: main (t4.c:6) ==3221== ==3221== LEAK SUMMARY: ==3221==definitely lost: 1 bytes in 1 blocks ==3221==indirectly lost: 0 bytes in 0 blocks ==3221== possibly lost: 0 bytes in 0 blocks ==3221==still reachable: 0 bytes in 0 blocks ==3221== suppressed: 0 bytes in 0 blocks ==3221== ==3221== For counts of detected and suppressed errors, rerun with: -v ==3221== ERROR SUMMARY: 3 errors from 3 contexts (suppressed: 6 from 6) 从检查结果看，可以发现内存泄露。 内存多次释放 #include #include int main(void) { char *p; p=(char *)malloc(100); if(p) printf(\"Memory Allocated at: %s/n\",p); else printf(\"Not Enough Memory!/n\"); free(p); //重复释放 free(p); free(p); return 0; } 1）编译程序t5.c gcc -Wall t5.c -g -o t5 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./t5 3) 运行结果如下： ==3294== Memcheck, a memory error detector ==3294== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==3294== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==3294== Command: ./t5 ==3294== ==3294== Conditional jump or move depends on uninitialised value(s) ==3294== at 0x3CD4C47E2C: vfprintf (in /lib64/libc-2.12.so) ==3294== by 0x3CD4C4F189: printf (in /lib64/libc-2.12.so) ==3294== by 0x400589: main (t5.c:9) ==3294== ==3294== Invalid free() / delete / delete[] / realloc() ==3294== at 0x4A06430: free (vg_replace_malloc.c:446) ==3294== by 0x4005B5: main (t5.c:13) ==3294== Address 0x4c27040 is 0 bytes inside a block of size 100 free'd ==3294== at 0x4A06430: free (vg_replace_malloc.c:446) ==3294== by 0x4005A9: main (t5.c:12) ==3294== ==3294== Invalid free() / delete / delete[] / realloc() ==3294== at 0x4A06430: free (vg_replace_malloc.c:446) ==3294== by 0x4005C1: main (t5.c:14) ==3294== Address 0x4c27040 is 0 bytes inside a block of size 100 free'd ==3294== at 0x4A06430: free (vg_replace_malloc.c:446) ==3294== by 0x4005A9: main (t5.c:12) ==3294== Memory Allocated at: /n==3294== ==3294== HEAP SUMMARY: ==3294== in use at exit: 0 bytes in 0 blocks ==3294== total heap usage: 1 allocs, 3 frees, 100 bytes allocated 从上面的输出可以看到(标注), 该功能检测到我们对同一个指针调用了3次释放内存操作。 内存动态管理 常见的内存分配方式分三种：静态存储，栈上分配，堆上分配。全局变量属于静态存储，它们是在编译时就被分配了存储空间，函数内的局部变量属于栈上分配，而最灵活的内存使用方式当属堆上分配，也叫做内存动态分配了。常用的内存动态分配函数包括：malloc, alloc, realloc, new等，动态释放函数包括free, delete。 一旦成功申请了动态内存，我们就需要自己对其进行内存管理，而这又是最容易犯错误的。下面的一段程序，就包括了内存动态管理中常见的错误。 #include #include int main(int argc,char *argv[]) { int i; char* p = (char*)malloc(10); char* pt=p; for(i = 0;i 1）编译程序t6.c gcc -Wall t6.c -g -o t6 2）使用Valgrind检查程序BUG valgrind --tool=memcheck --leak-check=full ./t6 3) 运行结果如下： ==3380== Memcheck, a memory error detector ==3380== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al. ==3380== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info ==3380== Command: ./t6 ==3380== ==3380== Invalid write of size 1 ==3380==at 0x40055C: main (t6.c:14) ==3380==Address 0x4c27041 is 1 bytes inside a block of size 10 free'd ==3380==at 0x4A06430: free (vg_replace_malloc.c:446) ==3380==by 0x400553: main (t6.c:13) ==3380== ==3380== Invalid free() / delete / delete[] / realloc() ==3380==at 0x4A06430: free (vg_replace_malloc.c:446) ==3380==by 0x40056A: main (t6.c:15) ==3380==Address 0x4c27040 is 0 bytes inside a block of size 10 free'd ==3380==at 0x4A06430: free (vg_replace_malloc.c:446) ==3380==by 0x400553: main (t6.c:13) ==3380== ==3380== ==3380== HEAP SUMMARY: ==3380==in use at exit: 0 bytes in 0 blocks ==3380==total heap usage: 1 allocs, 2 frees, 10 bytes allocated 申请内存在使用完成后就要释放。如果没有释放，或少释放了就是内存泄露；多释放也会产生问题。上述程序中，指针p和pt指向的是同一块内存，却被先后释放两次。系统会在堆上维护一个动态内存链表，如果被释放，就意味着该块内存可以继续被分配给其他部分，如果内存被释放后再访问，就可能覆盖其他部分的信息，这是一种严重的错误，上述程序第14行中就在释放后仍然写这块内存。 输出结果显示，第13行分配和释放函数不一致；第14行发生非法写操作，也就是往释放后的内存地址写值；第15行释放内存函数无效。 1.2.8JAVA性能调优 调优步骤：衡量系统现状、设定调优目标、寻找性能瓶颈、性能调优、衡量是否到达目标(如果未到达目标，需重新寻找性能瓶颈）、性能调优结束。 寻找性能瓶颈 性能瓶颈的表象：资源消耗过多、外部处理系统的性能不足、资源消耗不多但程序的响应速度却仍达不到要求。 资源消耗：CPU、文件IO、网络IO、内存。 外部处理系统的性能不足：所调用的其他系统提供的功能或数据库操作的响应速度不够。 资源消耗不多但程序的响应速度却仍达不到要求：程序代码运行效率不够高、未充分使用资源、程序结构不合理。 CPU消耗分析 CPU主要用于中断、内核、用户进程的任务处理，优先级为中断>内核>用户进程。 上下文切换： 每个线程分配一定的执行时间，当到达执行时间、线程中有IO阻塞或高优先级线程要执行时，将切换执行的线程。在切换时要存储目前线程的执行状态，并恢复要执行的线程的状态。 对于Java应用，典型的是在进行文件IO操作、网络IO操作、锁等待、线程Sleep时，当前线程会进入阻塞或休眠状态，从而触发上下文切换，上下文切换过多会造成内核占据较多的CPU的使用。 运行队列： 每个CPU核都维护一个可运行的线程队列。系统的load主要由CPU的运行队列来决定。 运行队列值越大，就意味着线程会要消耗越长的时间才能执行完成。 利用率： CPU在用户进程、内核、中断处理、IO等待、空闲，这五个部分使用百分比。 文件IO消耗分析 Linux在操作文件时，将数据放入文件缓存区，直到内存不够或系统要释放内存给用户进程使用。所以通常情况下只有写文件和第一次读取文件时会产生真正的文件IO。 对于Java应用，造成文件IO消耗高主要是多个线程需要进行大量内容写入（例如频繁的日志写入）的动作、磁盘设备本身的处理速度慢、文件系统慢、操作的文件本身已经很大。 网络IO消耗分析 对于分布式Java应用，网卡中断是不是均衡分配到各CPU(cat/proc/interrupts查看)。 内存消耗分析（-Xms和-Xmx设为相同的值，避免运行期JVM堆内存要不断申请内存） 对于Java应用，内存的消耗主要在Java堆内存上，只有创建线程和使用Direct ByteBuffer才会操作JVM堆外的内存。 JVM内存消耗过多会导致GC执行频繁，CPU消耗增加，应用线程的执行速度严重下降，甚至造成OutOfMemoryError，最终导致Java进程退出。 JVM堆外的内存 swap的消耗、物理内存的消耗、JVM内存的消耗。 程序执行慢原因分析 锁竞争激烈：很多线程竞争互斥资源，但资源有限， 造成其他线程都处于等待状态。 未充分使用硬件资源：线程操作被串行化。 数据量增长：单表数据量太大（如1个亿）造成数据库读写速度大幅下降（操作此表）。 调优 JVM调优 （最关键参数为：-Xms -Xmx -Xmn -XX:SurvivorRatio -XX:MaxTenuringThreshold） 代大小调优 避免新生代大小设置过小、避免新生代大小设置过大、避免Survivor设置过小或过大、合理设置新生代存活周期。 -Xmn 调整新生代大小，新生代越大通常也意味着更多对象会在minor GC阶段被回收，但可能有可能造成旧生代大小，造成频繁触发Full GC，甚至是OutOfMemoryError。 -XX:SurvivorRatio调整Eden区与Survivor区的大小，Eden 区越大通常也意味着minor GC发生频率越低，但可能有可能造成Survivor区太小，导致对象minor GC后就直接进入旧生代，从而更频繁触发Full GC。 GC策略的调优 CMS GC多数动作是和应用并发进行的，确实可以减小GC动作给应用造成的暂停时间。对于Web应用非常需要一个对应用造成暂停时间短的GC，再加上Web应用 的瓶颈都不在CPU上，在G1还不够成熟的情况下，CMS GC是不错的选择。 （如果系统不是CPU密集型，且从新生代进入旧生代的大部分对象是可以回收的，那么采用CMS GC可以更好地在旧生代满之前完成对象的回收，更大程度降低Full GC发生的可能） 在调整了内存管理方面的参数后应通过-XX:PrintGCDetails、-XX:+PrintGCTimeStamps、 -XX:+PrintGCApplicationStoppedTime以及jstat或visualvm等方式观察调整后的GC状况。 除内存管理以外的其他方面的调优参数 -XX:CompileThreshold、-XX:+UseFastAccessorMethods、 -XX:+UseBaiasedLocking。 程序调优 CPU消耗严重的解决方法 CPU us高的解决方法 CPU us 高的原因主要是执行线程不需要任何挂起动作，且一直执行，导致CPU 没有机会去调度执行其他的线程。 调优方案： 增加Thread.sleep，以释放CPU 的执行权，降低CPU 的消耗。以损失单次执行性能为代价的，但由于其降低了CPU 的消耗，对于多线程的应用而言，反而提高了总体的平均性能。 （在实际的Java应用中类似场景， 对于这种场景最佳方式是改为采用wait/notify机制） 对于其他类似循环次数过多、正则、计算等造成CPU us过高的状况， 则需要结合业务调优。 对于GC频繁，则需要通过JVM调优或程序调优，降低GC的执行次数。 CPU sy高的解决方法 CPU sy 高的原因主要是线程的运行状态要经常切换，对于这种情况，常见的一种优化方法是减少线程数。 调优方案： 将线程数降低 这种调优过后有可能会造成CPU us过高，所以合理设置线程数非常关键。 对于Java分布式应用，还有一种典型现象是应用中有较多的网络IO操作和确实需要一些锁竞争机制（如数据库连接池），但为了能够支撑搞得并发量，可采用协程（Coroutine）来支撑更高的并发量，避免并发量上涨后造成CPU sy消耗严重、系统load迅速上涨和系统性能下降。 在Java中实现协程的框架有Kilim，Kilim执行一项任务创建Task，使用Task的暂停机制，而不是Thread，Kilim承担了线程调度以及上下切换动作，Task相对于原生Thread而言就轻量级多了，且能更好利用CPU。Kilim带来的是线程使用率的提升，但同时由于要在JVM堆中保存Task上下文信息，因此在采用Kilim的情况下要消耗更多的内存。（目前JDK 7中也有一个支持协程方式的实现，另外基于JVM的Scala的Actor也可用于在Java使用协程） 文件IO消耗严重的解决方法 从程序的角度而言，造成文件IO消耗严重的原因主要是多个线程在写进行大量的数据到同一文件，导致文件很快变得很大，从而写入速度越来越慢，并造成各线程激烈争抢文件锁。 常用调优方法： 异步写文件 批量读写 限流 限制文件大小 网络IO消耗严重的解决方法 从程序的角度而言，造成网络IO消耗严重的原因主要是同时需要发送或接收的包太多。 常用调优方法： 限流，限流通常是限制发送packet的频率，从而在网络IO消耗可接受的情况下来发送packget。 内存消耗严重的解决方法 释放不必要的引用：代码持有了不需要的对象引用，造成这些对象无法被GC，从而占据了JVM堆内存。（使用ThreadLocal：注意在线程内动作执行完毕时，需执行ThreadLocal.set把对象清除，避免持有不必要的对象引用） 使用对象缓存池：创建对象要消耗一定的CPU以及内存，使用对象缓存池一定程度上可降低JVM堆内存的使用。 采用合理的缓存失效算法：如果放入太多对象在缓存池中，反而会造成内存的严重消耗， 同时由于缓存池一直对这些对象持有引用，从而造成Full GC增多，对于这种状况要合理控制缓存池的大小，避免缓存池的对象数量无限上涨。（经典的缓存失效算法来清除缓存池中的对象：FIFO、LRU、LFU等） 合理使用SoftReference和WeekReference：SoftReference的对象会在内存不够用的时候回收，WeekReference的对象会在Full GC的时候回收。 资源消耗不多但程序执行慢的情况的解决方法降低锁竞争： 线程多了，锁竞争的状况会比较明显，这时候线程很容易处于等待锁的状况，从而导致性能下降以及CPU sy上升。 使用并发包中的类：大多数采用了lock-free、nonblocking算法。 使用Treiber算法：基于CAS以及AtomicReference。 使用Michael-Scott非阻塞队列算法：基于CAS以及AtomicReference，典型ConcurrentLindkedQueue。 （基于CAS和AtomicReference来实现无阻塞是不错的选择，但值得注意的是，lock-free算法需不断的循环比较来保证资源的一致性的，对于冲突较多的应用场景而言，会带来更高的CPU消耗，因此不一定采用CAS实现无阻塞的就一定比采用lock方式的性能好。 还有一些无阻塞算法的改进：MCAS、WSTM等） 尽可能少用锁：尽可能只对需要控制的资源做加锁操作（通常没有必要对整个方法加锁，尽可能让锁最小化，只对互斥及原子操作的地方加锁，加锁时尽可能以保护资源的最小化粒度为单位--如只对需要保护的资源加锁而不是this）。 拆分锁：独占锁拆分为多把锁（读写锁拆分、类似ConcurrentHashMap中默认拆分为16把锁），很多程度上能提高读写的性能，但需要注意在采用拆分锁后，全局性质的操作会变得比较复杂（如ConcurrentHashMap中size操作）。（拆分锁太多也会造成副作用，如CPU消耗明显增加） 去除读写操作的互斥：在修改时加锁，并复制对象进行修改，修改完毕后切换对象的引用，从而读取时则不加锁。这种称为CopyOnWrite，CopyOnWriteArrayList是典型实现，好处是可以明显提升读的性能，适合读多写少的场景， 但由于写操作每次都要复制一份对象，会消耗更多的内存。 充分利用硬件资源（CPU和内存） 充分利用CPU 在能并行处理的场景中未使用足够的线程（线程增加：CPU资源消耗可接受且不会带来激烈竞争锁的场景下）， 例如单线程的计算，可以拆分为多个线程分别计算，最后将结果合并，JDK 7中的fork-join框架。 Amdahl定律公式：1/(F+(1-F)/N)。 充分利用内存 数据的缓存、耗时资源的缓存（数据库连接创建、网络连接的创建等）、页面片段的缓存。 毕竟内存的读取肯定远快于硬盘、网络的读取， 在内存消耗可接受、GC频率、以及系统结构（例如集群环境可能会带来缓存的同步）可接受情况下，应充分利用内存来缓存数据，提升系统的性能。 总结 好的调优策略是收益比（调优后提升的效果/调优改动所需付出的代价）最高的，通常来说简单的系统调优比较好做，因此尽量保持单机上应用的纯粹性， 这是大型系统的基本架构原则。 调优的三大有效原则：充分而不过分使用硬件资源、合理调整JVM、合理使用JDK包。 二、高可用 高可用性（High Availability简称HA)多被定义为IT系统的运营综合指标，其体现形式就是一个多个九的百分数，表征IT系统运营的稳定可靠程度，越靠近100%，就表明系统约稳定可靠，当然这种稳定与可靠需诸多方面的努力才能获得，例如应用程序结构设计、IT系统冗余架构、灾备机制、环境基础（水、电、空、火、间）、设备质量以及精细化运维管理，几乎缺一不可，那么HA的百分数，具体表示什么意思呢？最直接的解释就是表明1年时间内允许中断服务（运营）的时间，具体的算法如下： T=365*24*60*(1-HA) 单位：分钟 具体的参数含义请参考下表： |编号|HA（可用水平率）|T（每年可中断时间）| |:-----:|:-----:|:-----:| |1|99.9999%| 2.1容灾恢复能力的关键指标 RPO RPO:（Recovery Point Obejective，恢复点目标）是指业务系统所允许的在灾难过程中的最大数据丢失量，用来衡量容灾系统的数据冗余备份能力。 RTO RTO：（Recovery Time Objective，恢复时间目标）是指信息系统从灾难状态恢复到可运行状态所需的时间，用来衡量容灾系统的业务恢复能力。 2.2高可用级别 级别一：FT(Fault Tolerance)双机热备 通过创建与主实例保持虚拟同步的虚拟机，使应用在服务器发生故障的情况下也能够持续可用。 这种方法常通过使主虚拟机 和辅助虚拟机执行相同顺序的 x86指令来完成此过程。主虚拟机捕获所有输入和事件，并在辅助虚拟机上进行重放。 辅助虚拟机执行与主虚拟机相同的指令序列，如果运行主虚拟机的主机或运行辅助虚拟机的主机发生故障，则会发生即时且透明的故障切换。 虽然FT功能很强大，但是在虚拟化中很少用到FT功能，一是对资源浪费比较严重，二是性能下降比较快，由于是指令级别的同步，因而两台虚拟机之间的距离非常近，无法完全达到容灾的目的，三是如果主虚拟机因为执行非法指令蓝屏，则辅助虚拟机也马上就会发生，根本无法保证业务延续性。 级别二：虚拟机HA 虚拟机HA主要指在有一个共享存储池的情况下，当一台物理机挂了，这台物理机上的虚拟机可以迁移到其他物理机的机制。 因为虚拟机是有状态的，因而需要共享存储池来保证状态可以被另外一台物理机读取到。 在HA状态下，虚拟机的恢复时间一般在秒级别，也即当监控探测到物理机挂了之后，可以迅速在空闲的物理机上将虚拟机启动起来。 启动HA的物理机集群可以比较大，可以跨机架，比FT更能起到容灾的目标。 级别三：同城双活 如果一个机架，或者整个机房，甚至整个数据中心着火了，则如何保证业务的连续性呢？ 一种常用的机制是同城双活，就是在同一个城市，距离大概30km到100km的两个数据中心之间，通过高速专线互联的方式，让两个数据中心形成一个大二层网络。 同城双活最重要的是数据如何从一个数据中心同步到另一个数据中心，并且在一个数据中心故障的时候，可以实现存储设备的切换，保证状态能够快速切换到另一个数据中心。主流的存储厂商都提供在高速光纤互联情况下，在一定距离之内的两台存储设备的近实时的同步，数据双活是一切双活的基础。 基于双数据中心的数据同步，对上看起来可以形成一个统一的存储池，从而数据库层在共享存储池的情况下可以近实时的切换，例如Oracle RAC。 虚拟机在统一的存储池的情况下，也可以实现跨机房的HA，在一个机房切换到另一个机房。 SLB负载均衡实现同一机房的各个虚拟机之间的负载均衡。 GSLB可以实现跨机房的负载均衡，实现外部访问的切换。 如果在两个数据中心距离很近，并且大二层可通的情况下，也可以使用VRRP协议，通过VIP方式进行外部访问的切换。 同城双活一般宣称是实时切换，但是真正实施起来，一般在几分钟到十几分钟，对于数据量比较大的，还会几十分钟。 级别四：异地容灾 当你觉得一个地方两个数据中心还是不保险，例如海啸，地震，原子弹等，则可以在异地修建容灾数据中心。 第一大问题还是数据的问题，也即生产数据中心的数据如何备份到容灾数据中心，由于异地距离比较远，不可能像双活一样采取近同步的方式，只能通过异步的方式进行同步，也可以预见的是，容灾切换的时候，数据会丢失一部分。 由于容灾数据中心平时是不用的，不会讲所有的业务都进行容灾，否则成本太高。 对于数据的问题比较建议从业务层面进行容灾，由于数据同步会比较慢，可以根据业务需求高优先级同步重要的数据，因而容灾的层次越高越好。 例如有的用户完全不想操心，则使用存储层面的异步复制，对于存储设备来讲，是无法区分放在存储上的虚拟机哪台是重要的，哪台是不重要的，完全根据块进行复制，很可能先复制了不重要的虚拟机。 如果用户想对虚拟机做区分，则可以使用虚拟机层面的异步复制，用户知道哪些虚拟机更重要一些，哪些虚拟机不重要，则可以先同步重要的虚拟机。 如果用户可以根据业务层情况，在更细的粒度上区分哪些对业务来讲是重要的数据，例如交易数据，需要优先同步，哪些对于业务来讲是不重要的数据，例如日志数据。 在有异地容灾的情况下，可以平时进行容灾演练，看容灾数据中心是否能够真正起作用，别容灾了半天，真用上的时候掉链子。 由于是异地，容灾切换的时间一般在小时级别，几个小时不等。 级别五：异地备份 备份是比容灾更加不灵活的一种方式，和容灾的不同是，容灾需要使得虚拟机的资源时刻准备着，等需要切换的时候，马上就用，数据和虚拟机还是热数据。而备份更多的是以冷数据的方式，将虚拟机镜像，数据库镜像等变成文件存放在价格比较便宜的存储上面，成本比容灾要低得多。 存储可以是专门用于备份的存储设备，也可以使用对象存储等大容量而且成本低的存储。 备份往往区分全量备份和差量备份，一般在重要的时间点保存全量备份，然后以后的一段时间保存差量备份，然后再全量备份，再差量备份。 备份恢复的过程也是从最近的全量备份开始，逐渐补足差量备份，从而达到最接近最终状态的数据。 一旦用到备份，则说明环境已经全部不在，需要重新准备环境来运行虚拟机和存储，所以恢复的时间在天级别。 2.3容错、高可用、灾备 2.3.1容错 容错（fault tolerance）指的是， 发生故障时，系统还能继续运行。 容错的目的是，发生故障时，系统的运行水平可能有所下降，但是依然可用，不会完全失败。 2.3.2高可用 高可用（high availability）指的是， 系统能够比正常时间更久地保持一定的运行水平。 高可用不是指系统不中断（那是容错能力），而是指一旦中断能够快速恢复，即中断必须是短暂的。如果需要很长时间才能恢复可用性，就不叫高可用了 2.3.3灾备 灾备（又称灾难恢复，disaster recovery）指的是， 发生灾难时恢复业务的能力。 灾备的目的就是，保存系统的核心部分。一个好的灾备方案，就是从失败的基础设施中获取企业最宝贵的数据，然后在新的基础设施上恢复它们。注意，灾备不是为了挽救基础设置，而是为了挽救业务。 2.3.4总结 上面三个方面可以结合起来，设计一个可靠的系统。 容错：发生故障时，如何让系统继续运行。 高可用：系统中断时，如何尽快恢复。 灾备：系统毁灭时，如何抢救数据。 三、扩展性 可伸缩性/可扩展性(Scalable/scalability)：可伸缩性(可扩展性)是一种对软件系统计算处理能力的设计指标，高可伸缩性代表一种弹性，在系统扩展成长过程中，软件能够保证旺盛的生命力，通过很少的改动甚至只是硬件设备的添置，就能实现整个系统处理能力的线性增长，实现高吞吐量和低延迟高性能。 可伸缩性和纯粹性能调优有本质区别， 可伸缩性是高性能、低成本和可维护性等诸多因素的综合考量和平衡，可伸缩性讲究平滑线性的性能提升，更侧重于系统的水平伸缩，通过廉价的服务器实现分布式计算；而普通性能优化只是单台机器的性能指标优化。他们共同点都是根据应用系统特点在吞吐量和延迟之间进行一个侧重选择，当然水平伸缩分区后会带来CAP定理约束。 软件的可扩展性设计非常重要，但又比较难以掌握，业界试图通过云计算或高并发语言等方式节省开发者精力，但是，无论采取什么技术，如果应用系统内部是铁板一块，例如严重依赖数据库，系统达到一定访问规模，负载都集中到一两台数据库服务器上，这时进行分区扩展伸缩就比较困难，正如Hibernate框架创建人Gavin King所说：关系数据库是最不可扩展的。 3.1性能和扩展性 什么是性能问题？ 如果你的系统对于一个用户访问还很慢，那就是性能问题； 什么是扩展性问题？ 如果你的系统对一个用户来说是快的，但是在用户不断增长的高访问量下就慢了。 3.2延迟和吞吐量 延迟和吞吐量是衡量可扩展性的一对指标，我们希望获得低延迟和高吞吐量的系统架构。所谓低延迟，也就是用户能感受到的系统响应时间，比如一个网页在几秒内打开，越短表示延迟越低，而吞吐量表示同时有多少用户能够享受到这种低延迟，如果并发用户量很大时，用户感觉网页的打开速度很慢，这意味着系统架构的吞吐量有待提高。 扩展性的目标是用可接受的延迟获得最大的吞吐量。可靠性(可用性)目标：用可接受的延迟获得数据更新的一致性。 3.3CAP原理 3.3.1概述 CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。 CAP原则是NOSQL数据库的基石。 分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳： 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本） 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性） 分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。 一致性与可用性的决择编辑 CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。 对于web2.0网站来说，关系数据库的很多主要特性却往往无用武之地 数据库事务一致性需求 很多web实时系统并不要求严格的数据库事务，对读一致性的要求很低，有些场合对写一致性要求并不高。允许实现最终一致性。 　　 数据库的写实时性和读实时性需求 对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比方说发一条消息之 后，过几秒乃至十几秒之后，我的订阅者才看到这条动态是完全可以接受的。 　　 对复杂的SQL查询，特别是多表关联查询的需求 任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的报表查询，特别是SNS类型的网站，从需求以及产品设计角 度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能被极大的弱化了。 　　 3.3.2取舍策略 CAP三个特性只能满足其中两个，那么取舍的策略就共有三种： CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。 CP without A：如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如抢购场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。 3.4BASE理论 BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。接下来我们着重对BASE中的三要素进行详细讲解。 3.4.1基本可用 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子。 响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 3.4.2软状态 弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据听不的过程存在延时。 3.4.3最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 亚马逊首席技术官Werner Vogels在于2008年发表的一篇文章中对最终一致性进行了非常详细的介绍。他认为最终一致性时一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够胡渠道最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟，系统负载和数据复制方案设计等因素。 在实际工程实践中，最终一致性存在以下五类主要变种。 因果一致性 因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。 读己之所写 读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者而言，其读取到的数据一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。 会话一致性 会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 单调读一致性 单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。 单调写一致性 单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。 以上就是最终一致性的五类常见的变种，在时间系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性的分布式系统。事实上，可以将其中的若干个变种相互结合起来，以构建一个具有最终一致性特性的分布式系统。事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制国耻鞥通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么狠显然，从备库中读取的的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是认为数据订正，关系型数据库还是能搞保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性使相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。 3.5数据库事务的ACID 事务定义：所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 3.5.1原子性（atomicity) 一个事务要么全部提交成功，要么全部失败回滚，不能只执行其中的一部分操作，这就是事务的原子性 3.5.2一致性（consistency) 事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处于一致性状态。 如果数据库系统在运行过程中发生故障，有些事务尚未完成就被迫中断，这些未完成的事务对数据库所作的修改有一部分已写入物理数据库，这是数据库就处于一种不正确的状态，也就是不一致的状态 3.5.3隔离性（isolation） 事务的隔离性是指在并发环境中，并发的事务时相互隔离的，一个事务的执行不能不被其他事务干扰。不同的事务并发操作相同的数据时，每个事务都有各自完成的数据空间，即一个事务内部的操作及使用的数据对其他并发事务时隔离的，并发执行的各个事务之间不能相互干扰。 在标准SQL规范中，定义了4个事务隔离级别，不同的隔离级别对事务的处理不同，分别是：未授权读取，授权读取，可重复读取和串行化 未提交读（Read Uncommited），该隔离级别允许脏读取，其隔离级别最低；比如事务A和事务B同时进行，事务A在整个执行阶段，会将某数据的值从1开始一直加到10，然后进行事务提交，此时，事务B能够看到这个数据项在事务A操作过程中的所有中间值（如1变成2，2变成3等），而对这一系列的中间值的读取就是未授权读取 授权读取也称为已提交读（Read Commited），授权读取只允许获取已经提交的数据。比如事务A和事务B同时进行，事务A进行+1操作，此时，事务B无法看到这个数据项在事务A操作过程中的所有中间值，只能看到最终的10。另外，如果说有一个事务C，和事务A进行非常类似的操作，只是事务C是将数据项从10加到20，此时事务B也同样可以读取到20，即授权读取允许不可重复读取。 可重复读（Repeatable Read），就是保证在事务处理过程中，多次读取同一个数据时，其值都和事务开始时刻是一致的，因此该事务级别禁止不可重复读取和脏读取，但是有可能出现幻影数据。所谓幻影数据，就是指同样的事务操作，在前后两个时间段内执行对同一个数据项的读取，可能出现不一致的结果。在上面的例子中，可重复读取隔离级别能够保证事务B在第一次事务操作过程中，始终对数据项读取到1，但是在下一次事务操作中，即使事务B（注意，事务名字虽然相同，但是指的是另一个事务操作）采用同样的查询方式，就可能读取到10或20； 可串行读（Serializable），是最严格的事务隔离级别，它要求所有事务被串行执行，即事务只能一个接一个的进行处理，不能并发执行。 SQL Server隔离事务之间的影响是通过锁来实现的，通过阻塞来阻止上述影响。不同的隔离级别是通过加不同的锁，造成阻塞来实现的，所以会以付出性能作为代价；安全级别越高，处理效率越低；安全级别越低，效率高。 使用方法：SET TRANSACTIONISOLATION LEVEL REPEATABLE READ 未提交读： 在读数据时不会检查或使用任何锁。因此，在这种隔离级别中可能读取到没有提交的数据。 已提交读：只读取提交的数据并等待其他事务释放排他锁。读数据的共享锁在读操作完成后立即释放。已提交读是SQL Server的默认隔离级别。 可重复读： 像已提交读级别那样读数据，但会保持共享锁直到事务结束。 可串行读：工作方式类似于可重复读。但它不仅会锁定受影响的数据，还会锁定这个范围。这就阻止了新数据插入查询所涉及的范围。 3.5.4持久性（durability） 一旦事务提交，那么它对数据库中的对应数据的状态的变更就会永久保存到数据库中。--即使发生系统崩溃或机器宕机等故障，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束的状态 持久性，意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 即使出现了任何事故比如断电等，事务一旦提交，则持久化保存在数据库中。 SQL SERVER通过write-ahead transaction log来保证持久性。write-ahead transaction log的意思是，事务中对数据库的改变在写入到数据库之前，首先写入到事务日志中。而事务日志是按照顺序排号的（LSN）。当数据库崩溃或者服务器断点时，重启动SQL SERVER，SQLSERVER首先会检查日志顺序号，将本应对数据库做更改而未做的部分持久化到数据库，从而保证了持久性。 计算机系统从集中式向分布式的变革随着包括分布式网络、分布式事务和分布式数据一致性等在内的一系列问题与挑战，同时也催生了一大批诸如ACID、CAP和BASE等经典理论的快速发展。 BASE(Basically Available, Soft State, Eventual Consistency 基本可用、软状态、最终一致性) 对CAP AP理论的延伸, Redis等众多系统构建与这个理论之上 ACID是传统数据库常用的设计理念, ACID和BASE代表了两种截然相反的设计哲学，分处一致性-可用性分布图谱的两极。 在单机环境中，ACID是数据的属性；而在分布式环境中，BASE就是数据的属性。 四、安全 4.1什么是软件安全性测试 4.1.1软件安全 软件安全属于软件领域里一个重要的子领域。在以前的单机时代，安全问题主要是操作系统容易感染病毒，单机应用程序软件安全问题并不突出。但是自从互联网普及后，软件安全问题愈加显加突显，使得软件安全性测试的重要性上升到一个前所未有的高度。 软件安全一般分为两个层次，即应用程序级别的安全性和操作系统级别的安全性。应用程序级别的安全性，包括对数据或业务功能的访问，在预期的安全性情况下，操作者只能访问应用程序的特定功能、有限的数据等。操作系统级别的安全性是确保只有具备系统平台访问权限的用户才能访问，包括对系统的登录或远程访问。 本文所讲的软件安全主要是应用程序层的安全，包括两个层面：①是应用程序本身的安全性。一般来说，应用程序的安全问题主要是由软件漏洞导致的，这些漏洞可以是设计上的缺陷或是编程上的问题，甚至是开发人员预留的后门。②是应用程序的数据安全，包括数据存储安全和数据传输安全两个方面。 4.1.2软件安全性测试 一般来说，对安全性要求不高的软件，其安全性测试可以混在单元测试、集成测试、系统测试里一起做。但对安全性有较高需求的软件，则必须做专门的安全性测试，以便在破坏之前预防并识别软件的安全问题。 安全性测试(Security Testing)是指有关验证应用程序的安全等级和识别潜在安全性缺陷的过程。应用程序级安全测试的主要目的是查找软件自身程序设计中存在的安全隐患，并检查应用程序对非法侵入的防范能力, 根据安全指标不同测试策略也不同。注意：安全性测试并不最终证明应用程序是安全的，而是用于验证所设立策略的有效性，这些对策是基于威胁分析阶段所做的假设而选择的。例如，测试应用软件在防止非授权的内部或外部用户的访问或故意破坏等情况时的运作。 4.2软件安全性测试过程 (1)安全性测试方法 有许多的测试手段可以进行安全性测试，目前主要安全测试方法有： ①静态的代码安全测试：主要通过对源代码进行安全扫描，根据程序中数据流、控制流、语义等信息与其特有软件安全规则库进行匹对，从中找出代码中潜在的安全漏洞。静态的源代码安全测试是非常有用的方法，它可以在编码阶段找出所有可能存在安全风险的代码，这样开发人员可以在早期解决潜在的安全问题。而正因为如此，静态代码测试比较适用于早期的代码开发阶段，而不是测试阶段。 ②动态的渗透测试：渗透测试也是常用的安全测试方法。是使用自动化工具或者人工的方法模拟黑客的输入，对应用系统进行攻击性测试，从中找出运行时刻所存在的安全漏洞。这种测试的特点就是真实有效，一般找出来的问题都是正确的，也是较为严重的。但渗透测试一个致命的缺点是模拟的测试数据只能到达有限的测试点，覆盖率很低。 ③程序数据扫描。一个有高安全性需求的软件，在运行过程中数据是不能遭到破坏的，否则就会导致缓冲区溢出类型的攻击。数据扫描的手段通常是进行内存测试，内存测试可以发现许多诸如缓冲区溢出之类的漏洞，而这类漏洞使用除此之外的测试手段都难以发现。例如，对软件运行时的内存信息进行扫描，看是否存在一些导致隐患的信息，当然这需要专门的工具来进行验证，手工做是比较困难的。 (2)反向安全性测试过程 大部分软件的安全测试都是依据缺陷空间反向设计原则来进行的，即事先检查哪些地方可能存在安全隐患，然后针对这些可能的隐患进行测试。因此，反向测试过程是从缺陷空间出发，建立缺陷威胁模型，通过威胁模型来寻找入侵点，对入侵点进行已知漏洞的扫描测试。好处是可以对已知的缺陷进行分析，避免软件里存在已知类型的缺陷，但是对未知的攻击手段和方法通常会无能为力。 ①建立缺陷威胁模型。建立缺陷威胁模型主要是从已知的安全漏洞入手，检查软件中是否存在已知的漏洞。建立威胁模型时，需要先确定软件牵涉到哪些专业领域，再根据各个专业领域所遇到的攻击手段来进行建模。 ②寻找和扫描入侵点。检查威胁模型里的哪些缺陷可能在本软件中发生，再将可能发生的威胁纳入入侵点矩阵进行管理。如果有成熟的漏洞扫描工具，那么直接使用漏洞扫描工具进行扫描，然后将发现的可疑问题纳入入侵点矩阵进行管理。 ③入侵矩阵的验证测试。创建好入侵矩阵后，就可以针对入侵矩阵的具体条目设计对应的测试用例，然后进行测试验证。 (3)正向安全性测试过程 为了规避反向设计原则所带来的测试不完备性，需要一种正向的测试方法来对软件进行比较完备的测试，使测试过的软件能够预防未知的攻击手段和方法。 ①先标识测试空间。对测试空间的所有的可变数据进行标识，由于进行安全性测试的代价高昂，其中要重点对外部输入层进行标识。例如，需求分析、概要设计、详细设计、编码这几个阶段都要对测试空间进行标识，并建立测试空间跟踪矩阵。 ②精确定义设计空间。重点审查需求中对设计空间是否有明确定义，和需求牵涉到的数据是否都标识出了它的合法取值范围。在这个步骤中，最需要注意的是精确二字，要严格按照安全性原则来对设计空间做精确的定义。 ③标识安全隐患。根据找出的测试空间和设计空间以及它们之间的转换规则，标识出哪些测试空间和哪些转换规则可能存在安全隐患。例如,测试空间愈复杂，即测试空间划分越复杂或可变数据组合关系越多也越不安全。还有转换规则愈复杂，则出问题的可能性也愈大，这些都属于安全隐患。 ④建立和验证入侵矩阵。安全隐患标识完成后，就可以根据标识出来的安全隐患建立入侵矩阵。列出潜在安全隐患，标识出存在潜在安全隐患的可变数据，和标识出安全隐患的等级。其中对于那些安全隐患等级高的可变数据，必须进行详尽的测试用例设计。 (4)正向和反向测试的区别 正向测试过程是以测试空间为依据寻找缺陷和漏洞，反向测试过程则是以已知的缺陷空间为依据去寻找软件中是否会发生同样的缺陷和漏洞，两者各有其优缺点。反向测试过程主要的一个优点是成本较低，只要验证已知的可能发生的缺陷即可，但缺点是测试不完善，无法将测试空间覆盖完整，无法发现未知的攻击手段。正向测试过程的优点是测试比较充分，但工作量相对来说较大。因此，对安全性要求较低的软件，一般按反向测试过程来测试即可，对于安全性要求较高的软件，应以正向测试过程为主，反向测试过程为辅。 4.3常见的软件安全性缺陷和漏洞 软件的安全有很多方面的内容，主要的安全问题是由软件本身的漏洞造成的，下面介绍常见的软件安全性缺陷和漏洞。 (1)缓冲区溢出 缓冲区溢出已成为软件安全的头号公敌，许多实际中的安全问题都与它有关。造成缓冲区溢出问题通常有以下两种原因。 ①设计空间的转换规则的校验问题。即缺乏对可测数据的校验，导致非法数据没有在外部输入层被检查出来并丢弃。非法数据进入接口层和实现层后，由于它超出了接口层和实现层的对应测试空间或设计空间的范围，从而引起溢出。 ②局部测试空间和设计空间不足。当合法数据进入后，由于程序实现层内对应的测试空间或设计空间不足，导致程序处理时出现溢出。 (2)加密弱点 这几种加密弱点是不安全的： ①使用不安全的加密算法。加密算法强度不够，一些加密算法甚至可以用穷举法破解。 ②加密数据时密码是由伪随机算法产生的，而产生伪随机数的方法存在缺陷，使密码很容易被破解。 ③身份验证算法存在缺陷。 ④客户机和服务器时钟未同步，给攻击者足够的时间来破解密码或修改数据。 ⑤未对加密数据进行签名，导致攻击者可以篡改数据。所以，对于加密进行测试时，必须针对这些可能存在的加密弱点进行测试。 (3)错误处理 一般情况下，错误处理都会返回一些信息给用户，返回的出错信息可能会被恶意用户利用来进行攻击，恶意用户能够通过分析返回的错误信息知道下一步要如何做才能使攻击成功。如果错误处理时调用了一些不该有的功能，那么错误处理的过程将被利用。错误处理属于异常空间内的处理问题，异常空间内的处理要尽量简单，使用这条原则来设计可以避免这个问题。但错误处理往往牵涉到易用性方面的问题，如果错误处理的提示信息过于简单，用户可能会一头雾水，不知道下一步该怎么操作。所以,在考虑错误处理的安全性的同时，需要和易用性一起进行权衡。 (4)权限过大 如果赋予过大的权限，就可能导致只有普通用户权限的恶意用户利用过大的权限做出危害安全的操作。例如没有对能操作的内容做出限制，就可能导致用户可以访问超出规定范围的其他资源。进行安全性测试时必须测试应用程序是否使用了过大的权限，重点要分析在各种情况下应该有的权限，然后检查实际中是否超出了给定的权限。权限过大问题本质上属于设计空间过大问题，所以在设计时要控制好设计空间，避免设计空间过大造成权限过大的问题。 4.4APP安全测试 4.4.1安装包测试 关于反编译 目的是为了保护公司的知识产权和安全方面的考虑等，一些程序开发人员会在源码中硬编码一些敏感信息，如密码。而且若程序内部一些设计欠佳的逻辑，也可能隐含漏洞，一旦源码泄漏，安全隐患巨大。 为了避免这些问题，除了代码审核外，通常开发的做法是对代码进行混淆，混淆后源代码通过反软件生成的源代码是很难读懂的，测试中，我们可以直接使用反编译工具（dex2jar和jd-gui工具）查看源代码，判断是否进行了代码混淆，包括显而易见的敏感信息。 关于签名 这点IOS可以不用考虑，因为APP stroe都会校验。但Android没有此类权威检查，我们要在发布前校验一下签名使用的key是否正确，以防被恶意第三方应用覆盖安装等。可使用下列命令检查： jarsigner -verify -verbose -certs apk包路径 若结果为“jar 已验证”，说明签名校验成功。 完整性校验 为确保安装包不会在测试完成到最终交付过程中因为知足者趾问题发生文件损坏，需要对安装包进行完整性校验，通常做法是检查文件的md5值，而且一般可以通过自动化做校验。 权限设置检查 一般用户对自己的隐私问题十 分敏感，因此，我们需要对APP申请某些特定权限的必要性进行检查，如访问通讯录等。对于没有必要的权限，一般都建议开发 直接支除。 Android：直接检查manifest文件来读取应用所需要的全部权限，并结合需求进行校验此权限是否为必须的。manifest文件的修改也需要关注，在增加新权限前需要进行评估。 IOS：没有类似manifest文件来查看，IOS的用户权限只有在用户使用APP到了需要使用的权限时，系统才会弹出提示框，提示用户当前APP需要访问照片、联系人列表等组件。我们可以扫描代码来查看项目工程中有哪些权限设置。通过搜索关键类名，如通讯录一般需要访问ABAddressBookRef，照片是UIImagePickerController等。如果是纯黑盒测试，则必须覆盖到所有代码路径才能保证没有遗漏，也可使用代码覆盖率测试判断是否覆盖。 敏感信息测试 数据库是否存储敏感信息，某些应用会把cookie类数据保存在数据库中，一旦此数据被他人获取，可能造成用户账户被盗用等严重问题，测试中在跑完一个包含数据库操作的测试用例后，我们可以直接查看数据库里的数据，观察是否有敏感信息存储在内。一般来说这些敏感信息需要用户进行注销操作后删除。如果是cookie类数据，建议设置合理的过期时间。 日志是否存在敏感信息，一般开发在写程序的过程中会加入日志帮助高度，所有可能会写入一些敏感信息，通常APP的发布版不会使用日志，但也不排除特殊情况。 配置文件是否存在敏感信息，与日志类似，我们需要检查配置文件中是否包含敏感信息。 软键盘劫持 如果用户安装了第三方键盘，可能存在劫持情况，对此，我们在一些特别敏感的输入地方可以做检查，例如金融类APP登录界面的用户名密码输入框等，看是否支持第三方输入法，一般建议使用应用内的软键盘。 账户安全 密码是否明文存储在后台数据库，在评审和测试中需要关注密码的存储。 密码传输是否加密，测试中我们需要查看密码是否被 明文传输，如果是HTTP接口，我们可以使用FIddler等工具直接查看。 账户锁定策略。对于 用户输入错误密码次数过多的情况，是否会将账户临时锁定，避免被暴力破解， 同时会话情况。一些应用对同时会话会有通知功能，这样至少可以让用户知识他的账户可能已经被泄漏了。在一定程度上能免提升用户体验。 注销机制。在客户端注销后，我们需要验证任何的来自该用户的，需要身份验证的接口调用都不能成功。 数据通信安全 关键数据是否散列或加密。密码在传输中必须是加密的，其他敏感信息传输前也需要进行散列或者加加密，以免被中间节点获取并恶意利用。 关键连接是否使用安全通信，例如HTTPS。在获知接口设计后我们需要评估是否其中内容包含敏感信息，如果未使用安全通信，需要知会开发修改。 是否对数字证书合法性进行验证。即便使用了安全通信，例如HTTPS，我们也需要在客户端代码中对服务端证书进行合法性校验。测试中可以使用Fiddler工具模拟中间人攻击方法。如果客户端对于Fiddler证书没有校验而能正常调用，则存在安全隐患。 是否校验数据合法性。在一些情况下，我们需要有方法来确保服务端下发的明文数据不被篡改。通常开发侧的实现方式是对数据进行数字签名并在客户端进行校验。我们可以模拟后台返回进行相关的测试工作。此外，对于其他一些客户端未进行数据校验的接口，我们也需要有意识地思考如果不进行校验是否会产生问题，并通过模拟后台返回验证。 组件安全测试 这里主要是指Android平台各个组件是否能被 外部应用恶意调用从而带来一些安全问题。包括Activity、Service、ContentProvider、Broadcast等等。采用的测试方法是通过使用drozer工具结合查看代码的方式，具体使用方法可查看官方文档。 4.4.2服务端接口测试 主要关注服务端接口是否存在以下问题 SQL注入 XSS跨站脚本攻击 CSRF跨站请求伪造 越权访问 除了上述服务端问题外，我们还需要结合实际的需求，设计和代码，分析是否需求或设计本身就会带来安全问题。 4.4.3附录 软件权限 1）扣费风险：包括短信、拨打电话、连接网络等。 2）隐私泄露风险：包括访问手机信息、访问联系人信息等。 3）对App的输入有效性校验、认证、授权、数据加密等方面进行检测 4）限制/允许使用手机功能接入互联网 5）限制/允许使用手机发送接收信息功能 6）限制或使用本地连接 7）限制/允许使用手机拍照或录音 8）限制/允许使用手机读取用户数据 9）限制/允许使用手机写入用户数据 10）限制/允许应用程序来注册自动启动应用程序 数据安全性 1）当将密码或其它的敏感数据输入到应用程序时，其不会被存储在设备中，同时密码也不会被解码。 2）输入的密码将不以明文形式进行显示。 3）密码、信用卡明细或其他的敏感数据将不被存储在它们预输入的位置上。 4）不同的应用程序的个人身份证或密码长度必须至少在4-8个数字长度之间。 5）当应用程序处理信用卡明细或其它的敏感数据时，不以明文形式将数据写到其他单独的文件或者临时文件中。以防止应用程序异常终止而又没有删除它的临时文件，文件可能遭受入侵者的袭击，然后读取这些数据信息。 6）党建敏感数据输入到应用程序时，其不会被存储在设备中。 7）应用程序应考虑或者虚拟机器产生的用户提示信息或安全警告 8）应用程序不能忽略系统或者虚拟机器产生的用户提示信息或安全警告，更不能在安全警告显示前，利用显示误导信息欺骗用户，应用程序不应该模拟进行安全警告误导用户。 9）在数据删除之前，应用程序应当通知用户或者应用程序提供一个“取消”命令的操作。 10）应用程序应当能够处理当不允许应用软件连接到个人信息管理的情况。 11）当进行读或写用户信息操作时，应用程序将会向用户发送一个操作错误的提示信息。 12）在没有用户明确许可的前提下不损坏删除个人信息管理应用程序中的任何内容。 13）如果数据库中重要的数据正要被重写，应及时告知用户。 14）能合理的处理出现的错误。 15）意外情况下应提示用户。 通讯安全性 1）在运行软件过程中，如果有来电、SMS、蓝牙等通讯或充电时，是否能暂停程序，优先处理通信，并在处理完毕后能正常恢复软件，继续其原来的功能。 2）当创立连接时，应用程序能够处理因为网络连接中断，进而告诉用户连接中断的情况。 3）应能处理通讯延时或中断。 4）应用程序将保持工作到通讯超时，进而给用户一个错误信息指示有链接错误。 5）应能处理网络异常和及时将异常情况通报用户。 6）应用程序关闭网络连接不再使用时应及时关闭，断开。 人机接口安全测试 1）返回菜单应总保持可用。 2）命令有优先权顺序。 3）声音的设置不影响使用程序的功能。 4）应用程序必须能够处理不可预知的用户操作，例如错误的操作和同时按下多个键。 五、兼容性 5.1兼容性测试含义 兼容性测试是指要测试的软件在不同的硬件平台上、不同的应用软件之间、不同的操作系统中、不同的网络环境中是否可以正常的运行、有无异常的测试过程。即是通常说的软件的可移植性。 5.2兼容性测试分类 兼容测试主要包括： 浏览器兼容性测试：检查要测试的软件在不同浏览器上Web页面的样式和元素的展示效果以及交互是否正常；主流浏览器：windows下，IE 9以上、FireFox、Chrome。Mac下，Safari、Chrome、Firefox。 浏览器兼容性问题也可以被称为网页兼容性或网站兼容性问题，指网页在各种浏览器上的显示效果可能不一致而产生浏览器和网页间的兼容问题。 你可能遇到过功能明明是正常的，换一个浏览器就不正常的情况。这是因为不同浏览器使用内核及所支持的HTML（标准通用标记语言下的一个应用）等网页语言标准不同；以及用户客户端的环境不同（如分辨率不同）造成的显示效果不能达到理想效果，功能不正常等。 屏幕尺寸和分辨率兼容性测试：检查要测试的软件在不同分辨率下能否正常显示； 操作系统兼容性测试：检查要测试的软件在不同的操作系统下功能是否正常，显示是否正确等；主流操作系统：windows系列、Mac OS X系列、UNIX/Linux系列、Android系列、IOS系列。 不同设备型号兼容性测试：针对于APP，由于移动设备型号众多，则需要测试要测试的APP在主流设备上能否正常运行，会不会出现崩溃的现象。 5.3兼容性测试方法 兼容性测试，可以全手工测试兼容即：人工测试，主要是测试要测试的软件在主流浏览器和常用操作系统上的主流程和主界面。另外一种是借助第三方兼容性测试工具进行测试； 第三方 Web的兼容性测试工具，推荐IEtester（离线）、SuperPreview（离线）和Browsershots：browsershots.org（在线）。 IETester，是专门用于测试网页在IE浏览器各个版本中兼容性的工具，版本包含IE5.5至IE9的各个版本。 Spoon Browser Sandbox，点击你需要测试的浏览器环境，安装插件就可以进行测试了。帮助你测试网页在Safari、Chrome、Firefox和Opera浏览器中是否正常。 BrowserShots，一款免费的跨浏览器测试工具，捕捉网站在不同浏览器中的截图。最有名，最古老的浏览器兼容性测试工具。 Multiple IEs这款工具同样用于测试网页在IE浏览器各个版本的兼容性。 通常来说，人工测试工作量大，且覆盖不全；第三方测试工作虽说比较省时省力，但是在主功能和主流程测试的时候没有侧重点，不够灵活，很难发现一些隐藏的问题；所以将人工和第三方工具兼容性测试结合起来才是最好的兼容性测试方法。 5.4浏览器的兼容性测试从哪些方面入手？ 了解当前主流浏览器，挑选3-5个左右的浏览器进行兼容性测试 同浏览器的不同版本兼容性测试（一般测试最新版本） 检查界面元素的位置是否正确，与业务功能交互是否正常，排版布局是否合理美观 功能按钮（增删改查、导入导出、超链接、清空）等 各种控件的检查：日期和时间控件、搜索控件 有些特殊的图标功能比如：盘古系统上的画图功能是否正常（不覆盖区域图标、覆盖区域绘图、站点位置迁移图标、挪动地图坐标）等 5.5兼容性测试注意事项 向前兼容和向后兼容，新旧版本的软件能否正常读取、加载和交互。 异构数据库兼容， 软件要考虑其对不同数据库平台的支持能力，软件是否可直接挂接，或需提供相关的转换工具。 六、本地化 6.1概述 Localization testing（本地化测试），本地化测试的对象是软件的本地化版本。本地化测试的目的是测试特定目标区域设置的软件本地化质量。本地化测试的环境是在本地化的操作系统上安装本地化的软件。从测试方法上可以分为基本功能测试，安装/卸载测试，当地区域的软硬件兼容性测试。测试的内容主要包括软件本地化后的界面布局和软件翻译的语言质量，包含软件、文档和联机帮助等部分。 本地化就是翻译产品的 UI，有时也更改某些初始设置以使产品适合于另一个地区。本地化测试检查针对特定目标区域性或区域设置的产品本地化质量。此测试基于全球化测试的结果，后者验证对特定区域性或区域设置的功能性支持。本地化测试只能在产品的本地化版本上进行。可本地化性测试不对本地化质量进行测试。 本地化测试过程中的测试工作集中在： 受本地化影响的方面，如 UI 和内容 区域性或区域设置特定的、语言特定的和地区特定的方面 另外，本地化测试还应包括： 基本功能测试 在本地化环境中运行的安装和升级测试 根据产品的目标地区计划应用程序和硬件兼容性测试。 可以选择 Windows 2000 的任何语言版本作为测试平台。然而，必须安装目标语言支持。 用户界面和语言的本地化测试应包括的项有： 验证所有应用程序资源 验证语言的准确性和资源属性 版式错误 书面文档、联机帮助、消息、界面资源、命令键顺序等的一致性检查。 确认是否遵守系统、输入和显示环境标准 用户界面可用性 评估文化适合性 检查政治上敏感的内容 当交付本地化产品时，确保包含本地化文档（手册、联机帮助、上下文帮助等）。要检查的项包括： 翻译的质量 翻译的完整性 所有文档和应用程序 UI 中使用的术语一致 6.2软件本地化测试的内容构成 6.2.1软件本地化测试的目的 　　保证本地化的软件与源语言软件具有相同的功能和性能。 　　保证本地化的软件在语言、文化、传统观念等方面符合当地用户的习惯。 6.2.2软件本地化测试的测试策略 　　本地化软件要在各种本地化操作系统上安装并测试。 　　源语言软件安装在另一台相同源语言操作系统上，作为对比测试。 　　重点测试因本地化引起的软件功能和软件界面的错误。 　　测试本地化软件的翻译质量。 　　手工测试和自动测试相结合。 6.2.3软件本地化测试的主要内容 　　测试内容由不同的测试阶段决定，例如第一个Build，以软件界面测试为主，中间Build以功能和界面为主，最后Build终点测试安装/卸载，软件帮助和主要功能。 6.2.4安装/卸载性能测试 　　测试本地化的软件是否可以正确地安装/卸载在本地语言的操作系统上（包括是否支持本地语言的安装目录名）。安装/卸载前后安装文件、快捷方式、程序图标和注册表等的变化是否与源语言程序一致。 6.2.5软件功能测试 　　本地化软件功能是否与源语言软件功能相同。 　　是否支持当地语言的输入和输出，如对双字节支持和正确显示。 　　对当地日期，时间，货币符号等的支持性能。 　　是否支持当地语言的文件名和目录名。 6.2.6软件界面测试 　　软件安装窗口中的按钮，菜单等的布局是否合理，美观。 　　软件运行后的界面元素，包括菜单、快捷键、对话框、屏幕提示、按钮、列表框的布局和本地化字体和字号是否正确。界面文字的翻译是否与术语表一致，是否存在没有翻译的元素。 6.2.7帮助文件功能和翻译质量 　　本地化帮助文件的功能是否与源语言软件一致。 　　本地化帮助文件的布局是否合理，美观。 　　本地化帮助文件的文字翻译是否准确、专业，是否存在没有翻译的段落。 6.3软件本地化测试类型解析与测试要领 软件本地化测试是在本地化的操作系统上对本地化的软件版本进行的测试。根据软件本地化项目的规模、测试阶段以及测试方法，本地化测试分为多种类型，每种类型都对软件本地化的质量进行检测和保证。为了提高测试的质量，保证测试的效率，不同类型的本地化测试需要使用不同的方法，掌握必要的测试技巧。本文主要选取本地化测试中具有代表性的测试类型进行分析，结合软件本地化项目的测试经验对其测试要领进行剖析。 6.3.1导航测试 导航测试（Pilot Testing）是为了降低软件本地化的风险而进行的一种本地化测试。大型的全球化软件在完成国际化设计后，通常选择少量的典型语言进行软件的本地化，以此测试软件的可本地化能力，降低多种语言同时本地化的风险。 导航测试尤其是用于数十种语言本地化的新开发的软件，导航测试版本的语言主要由语言市场的重要性和规模确定，也要考虑语言编码等的代表性。例如，德语市场是欧洲的重要市场，通常作为导航测试的首要单字节字符集语言。日语是亚洲重要的市场，可以作为双字节字符集语言代表。随着中国国内软件市场规模的增加，国际软件开发商逐渐对简体中文本地化提高重视程度，简体中文有望更多成为导航测试的首选语言。 导航测试是软件本地化项目早期进行的探索性测试，需要在本地化操作系统上进行，测试的重点是软件的国际化能力和可本地化能力，包括与区域相关的特性的处理能力，也包括测试是否可以容易地进行本地化，减少硬编码等缺陷。由于导航测试在整个软件本地化过程中意义重大，而且导航测试的持续时间通常较短，另外由于是新开发的软件的本地化测试，测试人员对软件的功能和使用操作了解不多，因此，本地化公司通常需要在正是测试之前进行搜集和学习软件的相关资料，做好测试环境和人员的配备，配置具有丰富测试经验的工程师执行测试。 6.3.2可接受性测试 本地化软件的可接受性测试（Build Acceptable Testing）也称作冒烟测试（Smoke Testing），是指对编译的软件本地化版本的主要特征进行基本测试，从而确定版本是否满足详细测试的条件。理论上，每个编译的本地化新版本在进行详细测试之前，都需要进行可接受性测试，以便早期发现软件版本的可测试性，避免不必要的时间浪费。 注意，软件本地化版本的可接受性测试与软件公司为特定客户定制开发的原始语言软件在交付客户前的验收测试完全不同，验收测试主要确定软件的功能和性能是否达到了客户的需求，如果一切顺利，只进行一次验收测试就可以结束。 本地化软件在编译后，编译工程师通常需要执行版本健全性检查（Build Sanity Check），确定本地化版本的内容和主要功能可以用于测试。而编译的本地化版本是否真的满足测试条件则还要通过独立的测试人员进行可接受性测试，它要求测试人员在较短的时间内完成，确定本地化的软件版本是否满足全面测试的要求，是否正确包含了应该本地化的部分。如果版本通过了可接受性测试，则可以进入软件全面详细测试阶段，反之，则需要重新编译本地化软件版本，直到通过可接受性测试。 在进行本地化软件版本的可接受性测试时，需要配置正确的测试环境（软件和硬件），在本地化的操作系统上安装软件，确定是否可以正确安装。软件运行软件，确定软件包含了应该本地化的全部内容，并且主要功能正确。然后，卸载软件，保证软件可以彻底卸载。软件的完整性是需要注意的一个方面，通过使用文件和文件夹的比较工具软件，对比安装后的本地化软件和英文软件内容的异同，确定本地化的完整性。 6.3.3语言质量测试 语言质量测试是软件本地化测试的重要组成部分，贯穿于本地化项目的各个阶段。语言质量测试的主要内容是软件界面和联机帮助等文档的翻译质量，包括正确性、完整性、专业性和一致性。 为了保证语言测试的质量，应该安排本地化语言作为母语的软件测试工程师进行测试，同时请本地化翻译工程师提供必要的帮助。在测试之前，必须阅读和熟悉软件开发商提供的软件术语表（Glossary），了解软件翻译风格（Translation Style）的语言表达要求。 由于软件的用户界面总是首先进行本地化，因此，本地化测试的初期的软件版本的语言质量测试主要以用户界面的语言质量为主，重点测试是否存在未翻译的内容，翻译的内容是否正确，是否符合软件术语表和翻译风格要求，是否符合母语表达方式，是否符合专业和行业的习惯用法。 本地化项目后期要对联机帮助和相关文档（各种用户使用手册等）进行本地化，这个阶段的语言质量测试，除了对翻译的表达正确性和专业性进行测试之外，还有注意联机帮助文件和软件用户界面的一致性。如果对于某些软件专业术语的翻译存在疑问，需要报告一个翻译问题，请软件开发商审阅，如果确认是翻译错误，需要修改术语表和软件的翻译。 关于本地化软件的语言质量测试，一个值得注意的问题是“过翻译”，就是软件中不应该翻译的内容（例如软件的名称等）如果进行了翻译，应该报告软件“过翻译”错误。 6.3.4用户界面测试 本地化软件的用户界面测试（UI Testing），也称作外观测试（Cosmetic Testing）主要对软件的界面文字和控件布局（大小和位置）进行测试。用户界面至少包括软件的安装和卸载界面、软件的运行界面和软件的联机帮助界面。软件界面的主要组成元素包括窗口、对话框、菜单、工具栏、状态栏、屏幕提示文字等内容。 用户界面的布局测试是本地化界面测试的重要内容，由于本地化的文字通常比原始开发语言长度增长，所以一类常见的本地化错误是软件界面上的文字显示不完整，例如，按钮文字只显示一部分。另一类常见的界面错误是对话框中的控件位置排列不整齐，大小不一致。 相对于其他类型的本地化测试，用户界面测试可能是最简单的测试类型，软件测试工程师不需要过多的语言翻译知识和测试工具，但是由于软件的界面众多，而且某些对话框可能隐藏的比较深入，因此，软件测试工程师必须尽可能地熟悉被测试软件的使用方法，这样才能找出那些较为隐蔽的界面错误。另外，某个界面错误可能是一类错误，需要报告一个综合的错误，例如，软件安装界面的“上一步”或“下一步”按钮显示不完整，则可能所有安装对话框的同类按钮都存在相同的错误。 6.3.5功能测试 原始语言开发的软件的功能测试主要测试软件的各项功能是否实现以及是否正确，而本地化软件的功能测试主要测试软件经过本地化后，软件的功能是否与源软件一致，是否存在因软件本地化而产生的功能错误，例如，某些功能失效或功能错误。 本地化软件的功能测试相对于其他测试类型具有较大难度，由于大型软件的功能众多，而且有些功能不经常使用，可能需要多步组合操作才能完成，因此本地化软件的功能测试需要测试工程师熟悉软件的使用操作，对于容易产生本地化错误之处能够预测，以便减少软件测试的工作量，这就要求测试工程师具有丰富的本地化测试经验。 除了某些菜单和按钮的本地化功能失效错误外，本地化软件的功能错误还包括软件的热键和快捷键错误，例如，菜单和按钮的热键与源软件不一致或者丢失热键。另外一类是排序错误，例如，排序的结果不符合本地化语言的习惯。 发现本地化功能错误后，需要在源软件上进行相同的测试，如果源软件也存在相同的错误，则不属于本地化功能错误，而属于源软件的设计错误，需要报告源软件的功能错误。另外，如果同时进行多种本地化语言（例如，简体中文、繁体中文、日文和韩文）的测试，在一种语言上的功能错误也需要在其他语言版本上进行相同的测试，以确定该错误是单一语言特有的，还是许多本地化版本共有的错误。 软件的测试类型数量众多，可谓五花八门，而软件本地化测试又具有其自身的特点，除以上常见的本地化测试类型外，还包括联机帮助测试、本地化能力测试等测试。不论何种类型的本地化测试，其最终测试目标都是尽早找出软件本地化错误，保证本地化软件与原始开发语言软件具有相同的功能。通过正确配置本地化测试环境，合理组织本地化测试人员，采用正确的本地化流程和测试工具，完善软件缺陷的报告和跟踪处理，有助于保证软件本地化测试的有效实现。 6.3.6本地化测试软件缺陷分类详解 本地化测试发现的软件缺陷特征明显，便于分类。本文按照本地化测试软件缺陷的特征进行分类，周详地分析各种缺陷的表现特征，简要描述各类缺陷的产生原因，最后给出各类缺陷的修正方法。 6.3.6.1缺陷类型 概括地讲，软件本地化的缺陷主要分为两大类：核心缺陷和本地化缺陷。 6.3.6.2缺陷表现特征 由于本地化缺陷是本地化测试中出现的数量最多的缺陷，所以首先分析本地化缺陷的表现特征。而本地化测试中发现的核心缺陷虽然数量不多，不过他们的危害程度更大，所以需要认真对待，接下来分析他们的表现特征。 用户界面缺陷 　　控件的文字被截断(Truncation) 　　对话框中的文本框、按钮、列表框、状态栏中的本地化文字只显示一部分 　　控件或文字没有对齐(Misaligned) 　　对话框中的同类控件或本地化文字没有对齐 　　控件位置重叠(Overlapped) 　　对话框中的控件彼此重叠 　　多余的文字(Extra strings) 　　软件程式的窗口或对话框中的出现多余的文字 　　丢失的文字(Missed strings) 　　软件程式的窗口或对话框中的文字部分或全部丢失 　　不一致的控件布局(Inconsistent layout) 　　本地化软件的控件布局和源语言软件不一致 　　丢失的文字(Missed strings) 　　软件程式的窗口或对话框中的文字部分或全部丢失 　　文字的字体、字号错误(Incorrect font name and font size) 　　控件的文字显示不美观，不符合本地化语言的正确字体和字号 　　多余的空格(Extra space) 　　本地化文字字符之间存在多余的空格 　　 语言质量缺陷 　　字符没有本地化(Unlocalized strings) 　　对话框或软件程式窗口中的应该本地化的文字没有本地化 　　字符不完整地本地化(Incomplete localized strings) 　　对话框或软件程式窗口中的应该本地化的文字只有一部分本地化 　　错误的本地化字符(Error localization) 　　源语言文字被错误地本地化，或对政治敏感的文字错误地进行了本地化 　　不一致的本地化字符(Inconsistent localized string) 　　相同的文字前后翻译不一致 　　相同的文字各语言之间不一致 　　相同的文字软件用户界面和联机帮助文件不一致 　　过度本地化(Over localization) 　　不应该本地化的字符进行了本地化 　　标点符号、版权、商标符号错误(Incorrect punctuation, Copyright) 　　标点符号、版权和商标的本地化不符合本地化语言的使用习惯 　　 本地化功能缺陷 　　本地化功能缺陷是本地化软件中的某些功能不起作用，或功能错误，和源语言功能不一致。 　　功能不起作用(Not working) 　　菜单、对话框的按钮、超链接不起作用 　　功能错误(Error function) 　　菜单、对话框的按钮、超链接引起程式崩溃 　　菜单、对话框的按钮、超链接带来和源语言软件不一致的错误结果 　　超链接没有链接到本地化的网站或页面 　　软件的功能不符合本地化用户的使用需求 　　热键和快捷键错误(Error hot keys and short-cut keys) 　　菜单或对话框中存在重复的热键 　　本地化软件中缺少热键或快捷键 　　不一致的热键或快捷键 　　快捷键或快捷键无效 源语言功能缺陷 　　源语言功能缺陷是在源语言软件和全部本地化软件上都能复现的错误。 　　功能不起作用(Not working) 　　菜单不起作用 　　对话框的按钮不起作用 　　超链接不起作用 　　控件焦点跳转顺序(Tab键)不正确 　　文字内容错误(Incorrect strings) 　　软件的名称或版本编号错误 　　英文拼写错误、语法错误 　　英文用词不恰当等 源语言国际化缺陷 　　源语言国际化缺陷是在源语言软件设计过程中对软件的本地化能力的处理不足引起的，他只出目前本地化的软件中。 　　区域设置错误(Error regional setting) 　　本地化日期格式错误 　　本地化时间格式错误 　　本地化数字格式(小数点、千位分隔符)错误 　　本地化货币单位或格式错误 　　本地化度量单位错误 　　本地化纸张大小错误 　　本地化电话号码和邮政编码错误 　　双字节字符错误(Error DBCS) 　　不支持双字节字符的输入 　　双字节字符显示乱码 　　不能保存含有双字节字符内容的文件 　　不能打印双字节字符 6.3.6.3缺陷产生原因 　　核心缺陷是由于源程式软件编码错误引起的，例如研发人员对于某个功能模块的编码错误，或没有考虑软件的国际化和本地化能力，而将代码设定为某一种语言; 　　本地化缺陷是由于软件本地化过程引起的，例如语言翻译质量较差、界面控件布局不当、翻译了程式中的变量等。 6.3.6.4缺陷修正方法 　　本地化缺陷是测试中发现的数量最多的Bug，他只出目前本地化的版本上，而不出目前源语言版本上，能由本地化工程师修改本地化软件相关资源文件解决，例如修改错误的翻译文字、调整控件的大小和位置等。 　　核心缺陷中的源语言功能缺陷既出目前本地化软件，也能在源语言软件上复现，而核心缺陷中的源语言国际化缺陷，虽然只出目前本地化版本中，不过只能通过修改程式代码实现，属于源语言软件的设计错误，这类缺陷只能由软件研发人员修正。 "}}